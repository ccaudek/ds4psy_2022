<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 La regola di Bayes | Data Science per psicologi</title>
  <meta name="description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 La regola di Bayes | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  <meta name="github-repo" content="ccaudek/ds4psy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 La regola di Bayes | Data Science per psicologi" />
  
  <meta name="twitter:description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-01-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="il-teorema-della-probabilità-totale.html"/>
<link rel="next" href="considerazioni-conclusive-3.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="la-psicologia-e-la-data-science.html"><a href="la-psicologia-e-la-data-science.html"><i class="fa fa-check"></i>La psicologia e la Data science</a></li>
<li class="chapter" data-level="" data-path="come-studiare.html"><a href="come-studiare.html"><i class="fa fa-check"></i>Come studiare</a></li>
<li class="chapter" data-level="" data-path="sviluppare-un-metodo-di-studio-efficace.html"><a href="sviluppare-un-metodo-di-studio-efficace.html"><i class="fa fa-check"></i>Sviluppare un metodo di studio efficace</a></li>
</ul></li>
<li class="part"><span><b>I Nozioni preliminari</b></span></li>
<li class="chapter" data-level="1" data-path="concetti-chiave.html"><a href="concetti-chiave.html"><i class="fa fa-check"></i><b>1</b> Concetti chiave</a>
<ul>
<li class="chapter" data-level="1.1" data-path="popolazioni-e-campioni.html"><a href="popolazioni-e-campioni.html"><i class="fa fa-check"></i><b>1.1</b> Popolazioni e campioni</a></li>
<li class="chapter" data-level="1.2" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html"><i class="fa fa-check"></i><b>1.2</b> Variabili e costanti</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#variabili-casuali"><i class="fa fa-check"></i><b>1.2.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="1.2.2" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>1.2.2</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="1.2.3" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>1.2.3</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="parametri-e-modelli.html"><a href="parametri-e-modelli.html"><i class="fa fa-check"></i><b>1.3</b> Parametri e modelli</a></li>
<li class="chapter" data-level="1.4" data-path="effetto.html"><a href="effetto.html"><i class="fa fa-check"></i><b>1.4</b> Effetto</a></li>
<li class="chapter" data-level="1.5" data-path="stima-e-inferenza.html"><a href="stima-e-inferenza.html"><i class="fa fa-check"></i><b>1.5</b> Stima e inferenza</a></li>
<li class="chapter" data-level="1.6" data-path="metodi-e-procedure-della-psicologia.html"><a href="metodi-e-procedure-della-psicologia.html"><i class="fa fa-check"></i><b>1.6</b> Metodi e procedure della psicologia</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html"><i class="fa fa-check"></i><b>2</b> La misurazione in psicologia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html"><i class="fa fa-check"></i><b>2.1</b> Le scale di misura</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-nominale"><i class="fa fa-check"></i><b>2.1.1</b> Scala nominale</a></li>
<li class="chapter" data-level="2.1.2" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-ordinale"><i class="fa fa-check"></i><b>2.1.2</b> Scala ordinale</a></li>
<li class="chapter" data-level="2.1.3" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-ad-intervalli"><i class="fa fa-check"></i><b>2.1.3</b> Scala ad intervalli</a></li>
<li class="chapter" data-level="2.1.4" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-di-rapporti"><i class="fa fa-check"></i><b>2.1.4</b> Scala di rapporti</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="gerarchia-dei-livelli-di-scala-di-misura.html"><a href="gerarchia-dei-livelli-di-scala-di-misura.html"><i class="fa fa-check"></i><b>2.2</b> Gerarchia dei livelli di scala di misura</a></li>
<li class="chapter" data-level="2.3" data-path="variabili-discrete-o-continue.html"><a href="variabili-discrete-o-continue.html"><i class="fa fa-check"></i><b>2.3</b> Variabili discrete o continue</a></li>
<li class="chapter" data-level="2.4" data-path="alcune-misure-sono-migliori-di-altre.html"><a href="alcune-misure-sono-migliori-di-altre.html"><i class="fa fa-check"></i><b>2.4</b> Alcune misure sono migliori di altre</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="alcune-misure-sono-migliori-di-altre.html"><a href="alcune-misure-sono-migliori-di-altre.html#tipologie-di-errori"><i class="fa fa-check"></i><b>2.4.1</b> Tipologie di errori</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusioni.html"><a href="conclusioni.html"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="part"><span><b>Statistica descrittiva ed analisi esplorativa dei dati</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stats.html"><a href="descriptive-stats.html"><i class="fa fa-check"></i><b>3</b> Statistica descrittiva</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-descript.html"><a href="chapter-descript.html"><i class="fa fa-check"></i><b>3.1</b> Introduzione all’esplorazione dei dati</a></li>
<li class="chapter" data-level="3.2" data-path="un-excursus-storico.html"><a href="un-excursus-storico.html"><i class="fa fa-check"></i><b>3.2</b> Un excursus storico</a></li>
<li class="chapter" data-level="3.3" data-path="riassumere-i-dati.html"><a href="riassumere-i-dati.html"><i class="fa fa-check"></i><b>3.3</b> Riassumere i dati</a></li>
<li class="chapter" data-level="3.4" data-path="i-dati-grezzi.html"><a href="i-dati-grezzi.html"><i class="fa fa-check"></i><b>3.4</b> I dati grezzi</a></li>
<li class="chapter" data-level="3.5" data-path="distribuzioni-di-frequenze.html"><a href="distribuzioni-di-frequenze.html"><i class="fa fa-check"></i><b>3.5</b> Distribuzioni di frequenze</a></li>
<li class="chapter" data-level="3.6" data-path="istogramma.html"><a href="istogramma.html"><i class="fa fa-check"></i><b>3.6</b> Istogramma</a></li>
<li class="chapter" data-level="3.7" data-path="kernel-density-plot.html"><a href="kernel-density-plot.html"><i class="fa fa-check"></i><b>3.7</b> Kernel density plot</a></li>
<li class="chapter" data-level="3.8" data-path="forma-di-una-distribuzione.html"><a href="forma-di-una-distribuzione.html"><i class="fa fa-check"></i><b>3.8</b> Forma di una distribuzione</a></li>
<li class="chapter" data-level="3.9" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html"><i class="fa fa-check"></i><b>3.9</b> Indici di posizione</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#quantili"><i class="fa fa-check"></i><b>3.9.1</b> Quantili</a></li>
<li class="chapter" data-level="3.9.2" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#diagramma-a-scatola"><i class="fa fa-check"></i><b>3.9.2</b> Diagramma a scatola</a></li>
<li class="chapter" data-level="3.9.3" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#sina-plot"><i class="fa fa-check"></i><b>3.9.3</b> Sina plot</a></li>
<li class="chapter" data-level="3.9.4" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#leccellenza-grafica"><i class="fa fa-check"></i><b>3.9.4</b> L’eccellenza grafica</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html"><i class="fa fa-check"></i><b>3.10</b> Indici di tendenza centrale</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#media"><i class="fa fa-check"></i><b>3.10.1</b> Media</a></li>
<li class="chapter" data-level="3.10.2" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#media-spuntata"><i class="fa fa-check"></i><b>3.10.2</b> Media spuntata</a></li>
<li class="chapter" data-level="3.10.3" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#moda-e-mediana"><i class="fa fa-check"></i><b>3.10.3</b> Moda e mediana</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html"><i class="fa fa-check"></i><b>3.11</b> Indici di dispersione</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#indici-basati-sullordinamento-dei-dati"><i class="fa fa-check"></i><b>3.11.1</b> Indici basati sull’ordinamento dei dati</a></li>
<li class="chapter" data-level="3.11.2" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#varianza"><i class="fa fa-check"></i><b>3.11.2</b> Varianza</a></li>
<li class="chapter" data-level="3.11.3" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#precisione"><i class="fa fa-check"></i><b>3.11.3</b> Precisione</a></li>
<li class="chapter" data-level="3.11.4" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#scarto-tipo"><i class="fa fa-check"></i><b>3.11.4</b> Scarto tipo</a></li>
<li class="chapter" data-level="3.11.5" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#deviazione-mediana-assoluta"><i class="fa fa-check"></i><b>3.11.5</b> Deviazione mediana assoluta</a></li>
<li class="chapter" data-level="3.11.6" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#indici-di-variabilità-relativi"><i class="fa fa-check"></i><b>3.11.6</b> Indici di variabilità relativi</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html"><i class="fa fa-check"></i><b>3.12</b> Le relazioni tra variabili</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#diagramma-a-dispersione"><i class="fa fa-check"></i><b>3.12.1</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="3.12.2" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#covarianza"><i class="fa fa-check"></i><b>3.12.2</b> Covarianza</a></li>
<li class="chapter" data-level="3.12.3" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#correlazione"><i class="fa fa-check"></i><b>3.12.3</b> Correlazione</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html"><i class="fa fa-check"></i><b>3.13</b> Correlazione e causazione</a>
<ul>
<li class="chapter" data-level="3.13.1" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#usi-della-correlazione"><i class="fa fa-check"></i><b>3.13.1</b> Usi della correlazione</a></li>
<li class="chapter" data-level="3.13.2" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#correlazione-di-spearman"><i class="fa fa-check"></i><b>3.13.2</b> Correlazione di Spearman</a></li>
<li class="chapter" data-level="3.13.3" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#correlazione-nulla"><i class="fa fa-check"></i><b>3.13.3</b> Correlazione nulla</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive.html"><a href="considerazioni-conclusive.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="part"><span><b>Nozioni di base</b></span></li>
<li class="chapter" data-level="4" data-path="intro-prob-1.html"><a href="intro-prob-1.html"><i class="fa fa-check"></i><b>4</b> Il calcolo delle probabilità</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inf-stat-probl-inv.html"><a href="inf-stat-probl-inv.html"><i class="fa fa-check"></i><b>4.1</b> La probabilità come la logica della scienza</a></li>
<li class="chapter" data-level="4.2" data-path="che-cosè-la-probabilità.html"><a href="che-cosè-la-probabilità.html"><i class="fa fa-check"></i><b>4.2</b> Che cos’è la probabilità?</a></li>
<li class="chapter" data-level="4.3" data-path="variabili-casuali-e-probabilità-di-un-evento.html"><a href="variabili-casuali-e-probabilità-di-un-evento.html"><i class="fa fa-check"></i><b>4.3</b> Variabili casuali e probabilità di un evento</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variabili-casuali-e-probabilità-di-un-evento.html"><a href="variabili-casuali-e-probabilità-di-un-evento.html#variabili-casuali-1"><i class="fa fa-check"></i><b>4.3.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="4.3.2" data-path="variabili-casuali-e-probabilità-di-un-evento.html"><a href="variabili-casuali-e-probabilità-di-un-evento.html#eventi-e-probabilità"><i class="fa fa-check"></i><b>4.3.2</b> Eventi e probabilità</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="spazio-campionario-e-risultati-possibili.html"><a href="spazio-campionario-e-risultati-possibili.html"><i class="fa fa-check"></i><b>4.4</b> Spazio campionario e risultati possibili</a></li>
<li class="chapter" data-level="4.5" data-path="usare-la-simulazione-per-stimare-le-probabilità.html"><a href="usare-la-simulazione-per-stimare-le-probabilità.html"><i class="fa fa-check"></i><b>4.5</b> Usare la simulazione per stimare le probabilità</a></li>
<li class="chapter" data-level="4.6" data-path="la-legge-dei-grandi-numeri.html"><a href="la-legge-dei-grandi-numeri.html"><i class="fa fa-check"></i><b>4.6</b> La legge dei grandi numeri</a></li>
<li class="chapter" data-level="4.7" data-path="variabili-casuali-multiple.html"><a href="variabili-casuali-multiple.html"><i class="fa fa-check"></i><b>4.7</b> Variabili casuali multiple</a></li>
<li class="chapter" data-level="4.8" data-path="sec:fun-mass-prob.html"><a href="sec:fun-mass-prob.html"><i class="fa fa-check"></i><b>4.8</b> Funzione di massa di probabilità</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-1.html"><a href="considerazioni-conclusive-1.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-prob-cond.html"><a href="chapter-prob-cond.html"><i class="fa fa-check"></i><b>5</b> Probabilità condizionata</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilità-condizionata-su-altri-eventi.html"><a href="probabilità-condizionata-su-altri-eventi.html"><i class="fa fa-check"></i><b>5.1</b> Probabilità condizionata su altri eventi</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilità-condizionata-su-altri-eventi.html"><a href="probabilità-condizionata-su-altri-eventi.html#la-fallacia-del-condizionale-trasposto"><i class="fa fa-check"></i><b>5.1.1</b> La fallacia del condizionale trasposto</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="legge-della-probabilità-composta.html"><a href="legge-della-probabilità-composta.html"><i class="fa fa-check"></i><b>5.2</b> Legge della probabilità composta</a></li>
<li class="chapter" data-level="5.3" data-path="lindipendendenza-stocastica.html"><a href="lindipendendenza-stocastica.html"><i class="fa fa-check"></i><b>5.3</b> L’indipendendenza stocastica</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-2.html"><a href="considerazioni-conclusive-2.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter-teo-bayes.html"><a href="chapter-teo-bayes.html"><i class="fa fa-check"></i><b>6</b> Il teorema di Bayes</a>
<ul>
<li class="chapter" data-level="6.1" data-path="il-teorema-della-probabilità-totale.html"><a href="il-teorema-della-probabilità-totale.html"><i class="fa fa-check"></i><b>6.1</b> Il teorema della probabilità totale</a></li>
<li class="chapter" data-level="6.2" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html"><i class="fa fa-check"></i><b>6.2</b> La regola di Bayes</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html#le-probabilita-come-grado-di-fiducia"><i class="fa fa-check"></i><b>6.2.1</b> Le probabilità come grado di fiducia</a></li>
<li class="chapter" data-level="6.2.2" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html#aggiornamento-bayesiano"><i class="fa fa-check"></i><b>6.2.2</b> Aggiornamento bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-3.html"><a href="considerazioni-conclusive-3.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter-prob-congiunta.html"><a href="chapter-prob-congiunta.html"><i class="fa fa-check"></i><b>7</b> Probabilità congiunta</a>
<ul>
<li class="chapter" data-level="7.1" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html"><i class="fa fa-check"></i><b>7.1</b> Funzione di probabilità congiunta</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#proprietà"><i class="fa fa-check"></i><b>7.1.1</b> Proprietà</a></li>
<li class="chapter" data-level="7.1.2" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#eventi"><i class="fa fa-check"></i><b>7.1.2</b> Eventi</a></li>
<li class="chapter" data-level="7.1.3" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#regola-della-catena"><i class="fa fa-check"></i><b>7.1.3</b> Regola della catena</a></li>
<li class="chapter" data-level="7.1.4" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#funzioni-di-probabilità-marginali"><i class="fa fa-check"></i><b>7.1.4</b> Funzioni di probabilità marginali</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="indipendenza-stocastica.html"><a href="indipendenza-stocastica.html"><i class="fa fa-check"></i><b>7.2</b> Indipendenza stocastica</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-4.html"><a href="considerazioni-conclusive-4.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter-intro-density-function.html"><a href="chapter-intro-density-function.html"><i class="fa fa-check"></i><b>8</b> Funzione di densità di probabilità</a>
<ul>
<li class="chapter" data-level="8.1" data-path="spinner-e-variabili-casuali-continue-uniformi.html"><a href="spinner-e-variabili-casuali-continue-uniformi.html"><i class="fa fa-check"></i><b>8.1</b> Spinner e variabili casuali continue uniformi</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="spinner-e-variabili-casuali-continue-uniformi.html"><a href="spinner-e-variabili-casuali-continue-uniformi.html#il-paradosso-delle-variabili-casuali-continue"><i class="fa fa-check"></i><b>8.1.1</b> Il paradosso delle variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="la-funzione-di-ripartizione-per-una-variabile-casuale-continua.html"><a href="la-funzione-di-ripartizione-per-una-variabile-casuale-continua.html"><i class="fa fa-check"></i><b>8.2</b> La funzione di ripartizione per una variabile casuale continua</a></li>
<li class="chapter" data-level="8.3" data-path="la-distribuzione-uniforme.html"><a href="la-distribuzione-uniforme.html"><i class="fa fa-check"></i><b>8.3</b> La distribuzione uniforme</a></li>
<li class="chapter" data-level="8.4" data-path="la-trasformazione-logit.html"><a href="la-trasformazione-logit.html"><i class="fa fa-check"></i><b>8.4</b> La trasformazione logit</a></li>
<li class="chapter" data-level="8.5" data-path="dagli-istogrammi-alle-densità.html"><a href="dagli-istogrammi-alle-densità.html"><i class="fa fa-check"></i><b>8.5</b> Dagli istogrammi alle densità</a></li>
<li class="chapter" data-level="8.6" data-path="funzione-di-densità-di-probabilità.html"><a href="funzione-di-densità-di-probabilità.html"><i class="fa fa-check"></i><b>8.6</b> Funzione di densità di probabilità</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="exp-val-and-variance-rv.html"><a href="exp-val-and-variance-rv.html"><i class="fa fa-check"></i><b>9</b> Valore atteso e varianza</a>
<ul>
<li class="chapter" data-level="9.1" data-path="valore-atteso.html"><a href="valore-atteso.html"><i class="fa fa-check"></i><b>9.1</b> Valore atteso</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="valore-atteso.html"><a href="valore-atteso.html#interpretazione"><i class="fa fa-check"></i><b>9.1.1</b> Interpretazione</a></li>
<li class="chapter" data-level="9.1.2" data-path="valore-atteso.html"><a href="valore-atteso.html#proprietà-del-valore-atteso"><i class="fa fa-check"></i><b>9.1.2</b> Proprietà del valore atteso</a></li>
<li class="chapter" data-level="9.1.3" data-path="valore-atteso.html"><a href="valore-atteso.html#variabili-casuali-continue"><i class="fa fa-check"></i><b>9.1.3</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="varianza-1.html"><a href="varianza-1.html"><i class="fa fa-check"></i><b>9.2</b> Varianza</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="varianza-1.html"><a href="varianza-1.html#formula-alternativa-per-la-varianza"><i class="fa fa-check"></i><b>9.2.1</b> Formula alternativa per la varianza</a></li>
<li class="chapter" data-level="9.2.2" data-path="varianza-1.html"><a href="varianza-1.html#variabili-casuali-continue-1"><i class="fa fa-check"></i><b>9.2.2</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="deviazione-standard.html"><a href="deviazione-standard.html"><i class="fa fa-check"></i><b>9.3</b> Deviazione standard</a></li>
<li class="chapter" data-level="9.4" data-path="standardizzazione.html"><a href="standardizzazione.html"><i class="fa fa-check"></i><b>9.4</b> Standardizzazione</a></li>
<li class="chapter" data-level="9.5" data-path="momenti-di-variabili-casuali.html"><a href="momenti-di-variabili-casuali.html"><i class="fa fa-check"></i><b>9.5</b> Momenti di variabili casuali</a></li>
<li class="chapter" data-level="9.6" data-path="funzione-di-ripartizione.html"><a href="funzione-di-ripartizione.html"><i class="fa fa-check"></i><b>9.6</b> Funzione di ripartizione</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="distr-rv-discr.html"><a href="distr-rv-discr.html"><i class="fa fa-check"></i><b>10</b> Distribuzioni di v.c. discrete</a>
<ul>
<li class="chapter" data-level="10.1" data-path="una-prova-bernoulliana.html"><a href="una-prova-bernoulliana.html"><i class="fa fa-check"></i><b>10.1</b> Una prova Bernoulliana</a></li>
<li class="chapter" data-level="10.2" data-path="una-sequenza-di-prove-bernoulliane.html"><a href="una-sequenza-di-prove-bernoulliane.html"><i class="fa fa-check"></i><b>10.2</b> Una sequenza di prove Bernoulliane</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="una-sequenza-di-prove-bernoulliane.html"><a href="una-sequenza-di-prove-bernoulliane.html#valore-atteso-e-deviazione-standard"><i class="fa fa-check"></i><b>10.2.1</b> Valore atteso e deviazione standard</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuzione-di-poisson.html"><a href="distribuzione-di-poisson.html"><i class="fa fa-check"></i><b>10.3</b> Distribuzione di Poisson</a></li>
<li class="chapter" data-level="10.4" data-path="alcune-proprietà-della-variabile-di-poisson.html"><a href="alcune-proprietà-della-variabile-di-poisson.html"><i class="fa fa-check"></i><b>10.4</b> Alcune proprietà della variabile di Poisson</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-5.html"><a href="considerazioni-conclusive-5.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="distr-rv-cont.html"><a href="distr-rv-cont.html"><i class="fa fa-check"></i><b>11</b> Distribuzioni di v.c. continue</a>
<ul>
<li class="chapter" data-level="11.1" data-path="distribuzione-normale.html"><a href="distribuzione-normale.html"><i class="fa fa-check"></i><b>11.1</b> Distribuzione Normale</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="distribuzione-normale.html"><a href="distribuzione-normale.html#limite-delle-distribuzioni-binomiali"><i class="fa fa-check"></i><b>11.1.1</b> Limite delle distribuzioni binomiali</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="normal-random-walk.html"><a href="normal-random-walk.html"><i class="fa fa-check"></i><b>11.2</b> La Normale prodotta con una simulazione</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="normal-random-walk.html"><a href="normal-random-walk.html#concentrazione"><i class="fa fa-check"></i><b>11.2.1</b> Concentrazione</a></li>
<li class="chapter" data-level="11.2.2" data-path="normal-random-walk.html"><a href="normal-random-walk.html#funzione-di-ripartizione-1"><i class="fa fa-check"></i><b>11.2.2</b> Funzione di ripartizione</a></li>
<li class="chapter" data-level="11.2.3" data-path="normal-random-walk.html"><a href="normal-random-walk.html#distribuzione-normale-standard"><i class="fa fa-check"></i><b>11.2.3</b> Distribuzione Normale standard</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="teorema-del-limite-centrale.html"><a href="teorema-del-limite-centrale.html"><i class="fa fa-check"></i><b>11.3</b> Teorema del limite centrale</a></li>
<li class="chapter" data-level="11.4" data-path="distribuzione-chi-quadrato.html"><a href="distribuzione-chi-quadrato.html"><i class="fa fa-check"></i><b>11.4</b> Distribuzione Chi-quadrato</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="distribuzione-chi-quadrato.html"><a href="distribuzione-chi-quadrato.html#proprietà-1"><i class="fa fa-check"></i><b>11.4.1</b> Proprietà</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="distribuzione-t-di-student.html"><a href="distribuzione-t-di-student.html"><i class="fa fa-check"></i><b>11.5</b> Distribuzione <span class="math inline">\(t\)</span> di Student</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="distribuzione-t-di-student.html"><a href="distribuzione-t-di-student.html#proprietà-2"><i class="fa fa-check"></i><b>11.5.1</b> Proprietà</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="funzione-beta-di-eulero.html"><a href="funzione-beta-di-eulero.html"><i class="fa fa-check"></i><b>11.6</b> Funzione beta di Eulero</a></li>
<li class="chapter" data-level="11.7" data-path="distribuzione-beta.html"><a href="distribuzione-beta.html"><i class="fa fa-check"></i><b>11.7</b> Distribuzione Beta</a></li>
<li class="chapter" data-level="11.8" data-path="distribuzione-di-cauchy.html"><a href="distribuzione-di-cauchy.html"><i class="fa fa-check"></i><b>11.8</b> Distribuzione di Cauchy</a></li>
<li class="chapter" data-level="11.9" data-path="distribuzione-log-normale.html"><a href="distribuzione-log-normale.html"><i class="fa fa-check"></i><b>11.9</b> Distribuzione log-normale</a></li>
<li class="chapter" data-level="11.10" data-path="distribuzione-di-pareto.html"><a href="distribuzione-di-pareto.html"><i class="fa fa-check"></i><b>11.10</b> Distribuzione di Pareto</a></li>
</ul></li>
<li class="part"><span><b>Inferenza statistica bayesiana</b></span></li>
<li class="chapter" data-level="12" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html"><i class="fa fa-check"></i><b>12</b> Inferenza bayesiana</a>
<ul>
<li class="chapter" data-level="12.1" data-path="modellizzazione-bayesiana.html"><a href="modellizzazione-bayesiana.html"><i class="fa fa-check"></i><b>12.1</b> Modellizzazione bayesiana</a></li>
<li class="chapter" data-level="12.2" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html"><i class="fa fa-check"></i><b>12.2</b> Inferenza bayesiana come un problema inverso</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html#notazione"><i class="fa fa-check"></i><b>12.2.1</b> Notazione</a></li>
<li class="chapter" data-level="12.2.2" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html#funzioni-di-probabilità"><i class="fa fa-check"></i><b>12.2.2</b> Funzioni di probabilità</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="la-regola-di-bayes-1.html"><a href="la-regola-di-bayes-1.html"><i class="fa fa-check"></i><b>12.3</b> La regola di Bayes</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="la-regola-di-bayes-1.html"><a href="la-regola-di-bayes-1.html#un-esempio-di-aggiornamento-bayesiano"><i class="fa fa-check"></i><b>12.3.1</b> Un esempio di aggiornamento bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="modello-probabilistico.html"><a href="modello-probabilistico.html"><i class="fa fa-check"></i><b>12.4</b> Modello probabilistico</a></li>
<li class="chapter" data-level="12.5" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html"><i class="fa fa-check"></i><b>12.5</b> Distribuzioni a priori</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#tipologie-di-distribuzioni-a-priori"><i class="fa fa-check"></i><b>12.5.1</b> Tipologie di distribuzioni a priori</a></li>
<li class="chapter" data-level="12.5.2" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#selezione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>12.5.2</b> Selezione della distribuzione a priori</a></li>
<li class="chapter" data-level="12.5.3" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#la-distribuzione-a-priori-per-i-dati-di-zetschefuture2019"><i class="fa fa-check"></i><b>12.5.3</b> La distribuzione a priori per i dati di <span class="citation">Zetsche, Bürkner, and Renneberg (<span>2019</span>)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="verosimiglianza.html"><a href="verosimiglianza.html"><i class="fa fa-check"></i><b>12.6</b> Verosimiglianza</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="verosimiglianza.html"><a href="verosimiglianza.html#la-stima-di-massima-verosimiglianza"><i class="fa fa-check"></i><b>12.6.1</b> La stima di massima verosimiglianza</a></li>
<li class="chapter" data-level="12.6.2" data-path="verosimiglianza.html"><a href="verosimiglianza.html#la-log-verosimiglianza"><i class="fa fa-check"></i><b>12.6.2</b> La log-verosimiglianza</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="sec:const-normaliz-bino23.html"><a href="sec:const-normaliz-bino23.html"><i class="fa fa-check"></i><b>12.7</b> La verosimiglianza marginale</a></li>
<li class="chapter" data-level="12.8" data-path="distribuzione-a-posteriori.html"><a href="distribuzione-a-posteriori.html"><i class="fa fa-check"></i><b>12.8</b> Distribuzione a posteriori</a></li>
<li class="chapter" data-level="12.9" data-path="distribuzione-predittiva-a-priori.html"><a href="distribuzione-predittiva-a-priori.html"><i class="fa fa-check"></i><b>12.9</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="12.10" data-path="distribuzione-predittiva-a-posteriori.html"><a href="distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>12.10</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-6.html"><a href="considerazioni-conclusive-6.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chapter-ppc.html"><a href="chapter-ppc.html"><i class="fa fa-check"></i><b>13</b> Distribuzione predittiva a posteriori</a>
<ul>
<li class="chapter" data-level="13.1" data-path="la-distribuzione-dei-possibili-valori-futuri.html"><a href="la-distribuzione-dei-possibili-valori-futuri.html"><i class="fa fa-check"></i><b>13.1</b> La distribuzione dei possibili valori futuri</a></li>
<li class="chapter" data-level="13.2" data-path="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"><a href="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>13.2</b> Metodi MCMC per la distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="13.3" data-path="posterior-predictive-checks.html"><a href="posterior-predictive-checks.html"><i class="fa fa-check"></i><b>13.3</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-7.html"><a href="considerazioni-conclusive-7.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html"><i class="fa fa-check"></i><b>14</b> Modello Normale-Normale</a>
<ul>
<li class="chapter" data-level="14.1" data-path="distribuzione-normale-normale-con-varianza-nota.html"><a href="distribuzione-normale-normale-con-varianza-nota.html"><i class="fa fa-check"></i><b>14.1</b> Distribuzione Normale-Normale con varianza nota</a></li>
<li class="chapter" data-level="14.2" data-path="il-modello-normale-con-stan.html"><a href="il-modello-normale-con-stan.html"><i class="fa fa-check"></i><b>14.2</b> Il modello Normale con Stan</a></li>
<li class="chapter" data-level="14.3" data-path="il-modello-normale-con-quap.html"><a href="il-modello-normale-con-quap.html"><i class="fa fa-check"></i><b>14.3</b> Il modello normale con <code>quap()</code></a></li>
<li class="chapter" data-level="14.4" data-path="il-modello-normale-con-brmsbrm.html"><a href="il-modello-normale-con-brmsbrm.html"><i class="fa fa-check"></i><b>14.4</b> Il modello normale con <code>brms::brm()</code></a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-8.html"><a href="considerazioni-conclusive-8.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="regr-models-intro.html"><a href="regr-models-intro.html"><i class="fa fa-check"></i><b>15</b> Introduzione al modello lineare</a>
<ul>
<li class="chapter" data-level="15.1" data-path="la-funzione-lineare.html"><a href="la-funzione-lineare.html"><i class="fa fa-check"></i><b>15.1</b> La funzione lineare</a></li>
<li class="chapter" data-level="15.2" data-path="lerrore-di-misurazione.html"><a href="lerrore-di-misurazione.html"><i class="fa fa-check"></i><b>15.2</b> L’errore di misurazione</a></li>
<li class="chapter" data-level="15.3" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html"><i class="fa fa-check"></i><b>15.3</b> Una media per ciascuna osservazione</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore"><i class="fa fa-check"></i><b>15.3.1</b> Relazione lineare tra la media <span class="math inline">\(y \mid x\)</span> e il predittore</a></li>
<li class="chapter" data-level="15.3.2" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html#il-modello-lineare"><i class="fa fa-check"></i><b>15.3.2</b> Il modello lineare</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-9.html"><a href="considerazioni-conclusive-9.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="simbologia-di-base.html"><a href="simbologia-di-base.html"><i class="fa fa-check"></i><b>A</b> Simbologia di base</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="la-regola-di-bayes" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> La regola di Bayes</h2>
<p>Il teorema di Bayes rappresenta uno dei fondamenti della teoria della
probabilità e della statistica. Lo presentiamo qui considerando un
caso specifico per poi descriverlo nella sua forma più generale.</p>
<p>Sia <span class="math inline">\(\{F_1, F_2\}\)</span> una partizione dello spazio campionario <span class="math inline">\(\Omega\)</span>.
Consideriamo un terzo evento <span class="math inline">\(E \subset \Omega\)</span> con probabilità non
nulla di cui si conoscono le probabilità condizionate rispetto ad <span class="math inline">\(F_1\)</span>
e a <span class="math inline">\(F_2\)</span>, ovvero <span class="math inline">\(P(E \mid F_1)\)</span> e <span class="math inline">\(P(E \mid F_2)\)</span>. È chiaro per le
ipotesi fatte che se si verifica <span class="math inline">\(E\)</span> deve anche essersi verificato
almeno uno degli eventi <span class="math inline">\(F_1\)</span> e <span class="math inline">\(F_2\)</span>. Supponendo che si sia verificato
l’evento <span class="math inline">\(E\)</span>, ci chiediamo: qual è la probabilità che si sia verificato
<span class="math inline">\(F_1\)</span> piuttosto che <span class="math inline">\(F_2\)</span>?</p>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-31-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Per rispondere alla domanda precedente scriviamo:</p>
<p><span class="math display">\[
\begin{split}
P(F_1 \mid E) &amp;= \frac{P(E \cap F_1)}{P(E)}\notag\\
              &amp;= \frac{P(E \mid F_1)P(F_1)}{P(E)}.
\end{split}
\]</span></p>
<p>Sapendo che <span class="math inline">\(E = (E \cap F_1) \cup (E \cap F_2)\)</span> e che <span class="math inline">\(F_1\)</span> e <span class="math inline">\(F_2\)</span> sono eventi disgiunti, ovvero <span class="math inline">\(F_1 \cap F_2 = \emptyset\)</span>, ne segue che possiamo calcolare <span class="math inline">\(P(E)\)</span> utilizzando il teorema della probabilità totale:</p>
<p><span class="math display">\[
\begin{split}
P(E) &amp;= P(E \cap F_1) + P(E \cap F_2)\notag\\
     &amp;= P(E \mid F_1)P(F_1) + P(E \mid F_2)P(F_2).
\end{split}
\]</span></p>
<p>
Sostituendo il risultato precedente nella formula della probabilità condizionata <span class="math inline">\(P(F_1 \mid E)\)</span> otteniamo:</p>
<p><span class="math display" id="eq:bayes1">\[\begin{equation}
P(F_1 \mid E) = \frac{P(E \mid F_1)P(F_1)}{P(E \mid F_1)P(F_1) + P(E \mid F_2)P(F_2)}.
\tag{6.3}
\end{equation}\]</span></p>
<p>
La <a href="la-regola-di-bayes.html#eq:bayes1">(6.3)</a> si generalizza facilmente al caso di più di due eventi disgiunti, come indicato di seguito.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-38" class="theorem"><strong>Teorema 6.2  </strong></span>Sia <span class="math inline">\(E\)</span> un evento contenuto in <span class="math inline">\(F_1 \cup \dots \cup F_k\)</span>, dove gli eventi <span class="math inline">\(F_j, j=1, \dots, k\)</span> sono a due a due incompatibili e necessari. Allora per ognuno dei suddetti eventi <span class="math inline">\(F_j\)</span> vale la seguente formula:</p>
<p><span class="math display" id="eq:bayes2">\[\begin{equation}
P(F_j \mid E) = \frac{P(E \mid F_j)P(F_j)}{\sum_{j=1}^{k}P(F_j)P(E \mid F_j)}.
\tag{6.4}
\end{equation}\]</span></p>
</div>
<p>
La <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> prende il nome di <em>Teorema di Bayes</em> e mostra che la conoscenza del verificarsi dell’evento <span class="math inline">\(E\)</span> modifica la probabilità che abbiamo attribuito all’evento <span class="math inline">\(F_j\)</span>. Nella <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> la probabilità condizionata <span class="math inline">\(P(F_j \mid E)\)</span> prende il nome di probabilità <em>a posteriori</em> dell’evento <span class="math inline">\(F_j\)</span>: il termine “a posteriori” sta a significare “dopo che è noto che si è verificato l’evento <span class="math inline">\(E\)</span>”. Nel capitolo <a href="#chapter-intro-bayes-inference"><strong>??</strong></a> estenderemo questa discussione mostrando come la <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> possa essere formulata in un modo più generale, ovvero in modo tale che non faccia riferimento unicamente alla probabilità di eventi, ma bensì anche alle funzioni di densità di probabilità.</p>
<div class="remark">
<p><span id="unlabeled-div-39" class="remark"><em>Remark</em>. </span>Qual è la pronuncia di “Bayesian”? Per saperlo possiamo seguire <a href="https://bayes-rules.github.io/posts/fun/">questo link</a>.</p>
</div>
<div id="le-probabilita-come-grado-di-fiducia" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Le probabilità come grado di fiducia</h3>
<p>Il teorema di Bayes rende esplicito il motivo per cui la probabilità non può essere pensata come uno stato oggettivo, quanto piuttosto come un’inferenza soggettiva e condizionata. Il denominatore del membro di destra della <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: <span class="math inline">\(P(F_j\)</span>) e <span class="math inline">\(P(E \mid F_j)\)</span>. La probabilità <span class="math inline">\(P(F_j\)</span>) è la probabilità <em>probabilità a priori</em> (<em>prior</em>) dell’evento <span class="math inline">\(F_j\)</span> e rappresenta l’informazione che l’agente bayesiano possiede a proposito dell’evento <span class="math inline">\(F_j\)</span>. Diremo che <span class="math inline">\(P(F_j)\)</span> codifica il grado di fiducia che l’agente ripone in <span class="math inline">\(F_j\)</span>, sul quale non possiamo porre vincoli di alcun tipo. La probabilità condizionata <span class="math inline">\(P(E \mid F_j)\)</span> rappresenta invece la verosimiglianza di <span class="math inline">\(F_j\)</span> e ci dice quant’è plausibile che si verifichi l’evento <span class="math inline">\(E\)</span> condizionatemente al fatto che si sia verificato <span class="math inline">\(F_j\)</span>.</p>
<p>Nell’interpretazione bayesiana <span class="math inline">\(P(F_j)\)</span> rappresenta un giudizio personale dell’agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. Il teorema di Bayes descrive la regola che l’agente deve seguire per aggiornare il suo grado di fiducia in <span class="math inline">\(F_j\)</span> alla luce di un ulteriore evento <span class="math inline">\(E\)</span>. Per questo motivo abbiamo chiamato <span class="math inline">\(P(F_j \mid E)\)</span> probabilità a posteriori: essa rappresenta infatti la nuova probabilità che l’agente assegna ad <span class="math inline">\(F_j\)</span> affinché rimanga consistente con le nuove informazioni fornitegli da <span class="math inline">\(E\)</span>.</p>
<p>La probabilità a posteriori dipende sia da <span class="math inline">\(E\)</span>, sia dalla conoscenza a priori dell’agente <span class="math inline">\(P(F_j)\)</span>. In questo senso è chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità a priori, la quale a sua volta, per definizione, è un’assegnazione soggettiva. Ne segue pertanto che ogni probabilità debba essere una rappresentazione del grado di fiducia (soggettiva) dell’agente.</p>
<p>Se ogni assegnazione probabilistica rappresenta uno stato di conoscenza, è altresì vero che un particolare stato di conoscenza è arbitrario e dunque non deve esserci necessariamente accordo a priori tra diversi agenti. Tuttavia, alla luce di nuove informazioni, la teoria delle probabilità ci fornisce uno strumento che consente l’aggiornamento dello stato di conoscenza in un modo razionale.</p>
</div>
<div id="aggiornamento-bayesiano" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Aggiornamento bayesiano</h3>
<p>Il teorema di Bayes consente di modificare una credenza a priori in maniera dinamica, via via che nuove evidenze vengono raccolte, in modo tale da formulare una credenza a posteriori la quale non è mai definitiva, ma può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama <em>aggiornamento bayesiano</em>.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-40" class="exercise"><strong>Esercizio 6.3  </strong></span>Supponiamo che, per qualche strano errore di produzione, una fabbrica
produca due tipi di monete. Il primo tipo di monete ha la caratteristica
che, quando una moneta viene lanciata, la probabilità di osservare
l’esito “testa” è 0.6. Per semplicità, sia <span class="math inline">\(\theta\)</span> la probabilità di
osservare l’esito “testa”. Per una moneta del primo tipo, dunque,
<span class="math inline">\(\theta = 0.6\)</span>. Per una moneta del secondo tipo, invece, la probabilità
di produrre l’esito “testa” è 0.4. Ovvero, <span class="math inline">\(\theta = 0.4\)</span>.</p>
<p>Noi possediamo una moneta, ma non sappiamo se è del primo tipo o del secondo tipo. Sappiamo solo che il 75% delle monete sono del primo tipo e il 25% sono del secondo tipo. Sulla base di questa conoscenza <em>a priori</em> – ovvero sulla base di una conoscenza ottenuta senza avere eseguito
l’esperimento che consiste nel lanciare la moneta una serie di volte per
osservare gli esiti prodotti – possiamo dire che la probabilità di una
prima ipotesi, secondo la quale <span class="math inline">\(\theta = 0.6\)</span>, è 3 volte più grande
della probabilità di una seconda ipotesi, secondo la quale
<span class="math inline">\(\theta = 0.4\)</span>. Senza avere eseguito alcun esperimento casuale con la
moneta, questo è quello che sappiamo.</p>
<p>Ora immaginiamo di lanciare una moneta due volte e di ottenere il
risultato seguente: <span class="math inline">\(\{T, C\}\)</span>. Quello che ci chiediamo è: sulla base di
questa evidenza, come cambiano le probabilità che associamo alle due
ipotesi? In altre parole, ci chiediamo qual è la probabilità di ciascuna
ipotesi alla luce dei dati che sono stati osservati: <span class="math inline">\(P(H \mid y)\)</span>,
laddove <span class="math inline">\(y\)</span> sono i dati osservati. Tale probabilità si chiama
probabilità a posteriori. Inoltre, se confrontiamo le due ipotesi, ci
chiediamo quale valore assuma il rapporto <span class="math inline">\(\frac{P(H_1 \mid y)}{P(H_2 \mid y)}\)</span>.
Tale rapporto ci dice quanto è più probabile <span class="math inline">\(H_1\)</span> rispetto ad <span class="math inline">\(H_2\)</span>, alla luce dei dati osservati. Infine, ci chiediamo come cambia il rapporto definito sopra, quando osserviamo via via nuovi risultati prodotti dal lancio della moneta.</p>
<p>Definiamo il problema in maniera più chiara. Conosciamo le probabilità a priori, ovvero <span class="math inline">\(P(H_1) = 0.75\)</span> e <span class="math inline">\(P(H_1) = 0.25\)</span>. Quello che vogliamo conoscere sono le probabilità a posteriori <span class="math inline">\(P(H_1 \mid y)\)</span> e <span class="math inline">\(P(H_2 \mid y)\)</span>. Per trovare le probabilità a posteriori applichiamo il teorema di Bayes:</p>
<p><span class="math display">\[
\begin{split}
P(H_1 \mid y) &amp;= \frac{P(y \mid H_1) P(H_1)}{P(y)} \\
&amp;= \frac{P(y \mid H_1) P(H_1)}{P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2)},
\end{split}
\]</span></p>
<p>laddove lo sviluppo del denominatore deriva da un’applicazione del teorema della probabilità totale.
Inoltre,</p>
<p><span class="math display">\[
P(H_2 \mid y) = \frac{P(y \mid H_2) P(H_2)}{P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2)}.
\]</span></p>
<p>Se consideriamo l’ipotesi <span class="math inline">\(H_1\)</span> = “la probabilità di testa è 0.6”, allora
la verosimiglianza dei dati <span class="math inline">\(\{T, C\}\)</span>, ovvero la probabilità di osservare questa specifica sequenza di T e C, è uguale a <span class="math inline">\(0.6 \times 0.4 = 0.24.\)</span>
Dunque, <span class="math inline">\(P(y \mid H_1) = 0.24\)</span>.</p>
<p>Se invece consideriamo l’ipotesi <span class="math inline">\(H_2\)</span> = “la probabilità di testa è 0.4”, allora la verosimiglianza dei dati <span class="math inline">\(\{T, C\}\)</span> è <span class="math inline">\(0.4 \times 0.6 = 0.24\)</span>, ovvero, <span class="math inline">\(P(y \mid H_2) = 0.24\)</span>. In base alle due ipotesi <span class="math inline">\(H_1\)</span> e <span class="math inline">\(H_2\)</span>, dunque, i dati osservati hanno la
medesima plausibilità di essere osservati.
Per semplicità, calcoliamo anche</p>
<p><span class="math display">\[
\begin{split}
P(y) &amp;= P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2) \\
&amp;= 0.24 \cdot 0.75 + 0.24 \cdot 0.25 \\
&amp;= 0.24.
\end{split}
\]</span></p>
<p>Le probabilità a posteriori diventano:</p>
<p><span class="math display">\[
\begin{split}
P(H_1 \mid y) &amp;= \frac{P(y \mid H_1) P(H_1)}{P(y)}\\
&amp;= \frac{0.24 \cdot 0.75}{0.24} \\
&amp;= 0.75,
\end{split}
\]</span></p>
<p><span class="math display">\[
\begin{split}
P(H_2 \mid y) &amp;= \frac{P(y \mid H_2) P(H_2)}{P(y)} \\
&amp;= \frac{0.24 \cdot 0.25}{0.24} \\
&amp;= 0.25.
\end{split}
\]</span></p>
<p>Possiamo dunque concludere dicendo che, sulla base dei dati osservati, l’ipotesi <span class="math inline">\(H_1\)</span> ha una probabilità 3 volte maggiore di essere vera dell’ipotesi <span class="math inline">\(H_2\)</span>.</p>
<p>È tuttavia possibile raccogliere più evidenze e, sulla base di esse, le probabilità a posteriori cambieranno. Supponiamo di lanciare la moneta una terza volta e di osservare croce. I nostri dati dunque sono <span class="math inline">\(\{T, C, C\}\)</span>.</p>
<p>Di conseguenza, <span class="math inline">\(P(y \mid H_1) = 0.6 \cdot 0.4 \cdot 0.4 = 0.096\)</span> e <span class="math inline">\(P(y \mid H_2) = 0.4 \cdot 0.6 \cdot 0.6 = 0.144\)</span>.
Ne segue che le probabilità a posteriori diventano:</p>
<p><span class="math display">\[
\begin{split}
P(H_1 \mid y) &amp;= \frac{P(y \mid H_1) P(H_1)}{P(y)} \\
&amp;= \frac{0.096 \cdot 0.75}{0.096 \cdot 0.75 + 0.144 \cdot 0.25} \\
&amp;= 0.667,
\end{split}
\]</span></p>
<p><span class="math display">\[
\begin{split}
P(H_2 \mid y) &amp;= \frac{P(y \mid H_2) P(H_2)}{P(y)} \\
&amp;= \frac{0.144 \cdot 0.25}{0.096 \cdot 0.75 + 0.144 \cdot 0.25} \\
&amp;= 0.333.
\end{split}
\]</span></p>
<p>In queste circostanze, le evidenze che favoriscono <span class="math inline">\(H_1\)</span> nei confronti
di <span class="math inline">\(H_2\)</span> sono solo pari ad un fattore di 2.</p>
<p>Se otteniamo ancora croce in un quarto lancio della moneta, i nostri
dati diventano: <span class="math inline">\(\{T, C, C, C\}\)</span>.
Ripetendo il ragionamento fatto sopra,
<span class="math inline">\(P(y \mid H_1) = 0.6 \cdot 0.4 \cdot 0.4 \cdot 0.4 = 0.0384\)</span> e
<span class="math inline">\(P(y \mid H_2) = 0.4 \cdot 0.6 \cdot 0.6 \cdot 0.6 = 0.0864\)</span>.
Dunque</p>
<p><span class="math display">\[\begin{equation}
P(H_1 \mid y) = \frac{0.0384 \cdot 0.75}{0.0384 \cdot 0.75 + 0.0864 \cdot 0.25} = 0.571,\notag
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
P(H_2 \mid y) = \frac{0.0864 \cdot 0.25}{0.0384 \cdot 0.75 + 0.0864 \cdot 0.25} = 0.429.\notag
\end{equation}\]</span></p>
<p>e le evidenze a favore di <span class="math inline">\(H_1\)</span> si riducono a 1.33. Se si ottenesse un
altro esito croce in un sesto lancio della moneta, l’ipotesi <span class="math inline">\(H2\)</span>
diventerebbe più probabile dell’ipotesi <span class="math inline">\(H_1\)</span>.</p>
<p>In conclusione, questo esercizio ci fa capire come sia possibile aggiornare le nostre credenze sulla base delle evidenze disponibili, ovvero come sia possibile passare da un grado di conoscenza del mondo a priori a una conoscenza a posteriori.
Se prima di lanciare la moneta ritenevamo che l’ipotesi <span class="math inline">\(H_1\)</span> fosse tre volte più plausibile dell’ipotesi <span class="math inline">\(H_2\)</span>, dopo avere osservato uno specifico campione di dati siamo giunti alla conclusione opposta.
Il processo di aggiornamento bayesiano, dunque, ci fornisce un metodo per modificare il livello di fiducia in una data ipotesi, alla luce di nuove informazioni.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="il-teorema-della-probabilità-totale.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="considerazioni-conclusive-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/ds4psy/edit/master/017_bayes_theorem.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ds4psy.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
