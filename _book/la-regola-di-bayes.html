<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 La regola di Bayes | Data Science per psicologi</title>
  <meta name="description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 La regola di Bayes | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  <meta name="github-repo" content="ccaudek/ds4psy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 La regola di Bayes | Data Science per psicologi" />
  
  <meta name="twitter:description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-01-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="il-teorema-della-probabilitÃ -totale.html"/>
<link rel="next" href="considerazioni-conclusive-3.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="la-psicologia-e-la-data-science.html"><a href="la-psicologia-e-la-data-science.html"><i class="fa fa-check"></i>La psicologia e la Data science</a></li>
<li class="chapter" data-level="" data-path="come-studiare.html"><a href="come-studiare.html"><i class="fa fa-check"></i>Come studiare</a></li>
<li class="chapter" data-level="" data-path="sviluppare-un-metodo-di-studio-efficace.html"><a href="sviluppare-un-metodo-di-studio-efficace.html"><i class="fa fa-check"></i>Sviluppare un metodo di studio efficace</a></li>
</ul></li>
<li class="part"><span><b>I Nozioni preliminari</b></span></li>
<li class="chapter" data-level="1" data-path="concetti-chiave.html"><a href="concetti-chiave.html"><i class="fa fa-check"></i><b>1</b> Concetti chiave</a>
<ul>
<li class="chapter" data-level="1.1" data-path="popolazioni-e-campioni.html"><a href="popolazioni-e-campioni.html"><i class="fa fa-check"></i><b>1.1</b> Popolazioni e campioni</a></li>
<li class="chapter" data-level="1.2" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html"><i class="fa fa-check"></i><b>1.2</b> Variabili e costanti</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#variabili-casuali"><i class="fa fa-check"></i><b>1.2.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="1.2.2" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>1.2.2</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="1.2.3" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>1.2.3</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="parametri-e-modelli.html"><a href="parametri-e-modelli.html"><i class="fa fa-check"></i><b>1.3</b> Parametri e modelli</a></li>
<li class="chapter" data-level="1.4" data-path="effetto.html"><a href="effetto.html"><i class="fa fa-check"></i><b>1.4</b> Effetto</a></li>
<li class="chapter" data-level="1.5" data-path="stima-e-inferenza.html"><a href="stima-e-inferenza.html"><i class="fa fa-check"></i><b>1.5</b> Stima e inferenza</a></li>
<li class="chapter" data-level="1.6" data-path="metodi-e-procedure-della-psicologia.html"><a href="metodi-e-procedure-della-psicologia.html"><i class="fa fa-check"></i><b>1.6</b> Metodi e procedure della psicologia</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html"><i class="fa fa-check"></i><b>2</b> La misurazione in psicologia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html"><i class="fa fa-check"></i><b>2.1</b> Le scale di misura</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-nominale"><i class="fa fa-check"></i><b>2.1.1</b> Scala nominale</a></li>
<li class="chapter" data-level="2.1.2" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-ordinale"><i class="fa fa-check"></i><b>2.1.2</b> Scala ordinale</a></li>
<li class="chapter" data-level="2.1.3" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-ad-intervalli"><i class="fa fa-check"></i><b>2.1.3</b> Scala ad intervalli</a></li>
<li class="chapter" data-level="2.1.4" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-di-rapporti"><i class="fa fa-check"></i><b>2.1.4</b> Scala di rapporti</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="gerarchia-dei-livelli-di-scala-di-misura.html"><a href="gerarchia-dei-livelli-di-scala-di-misura.html"><i class="fa fa-check"></i><b>2.2</b> Gerarchia dei livelli di scala di misura</a></li>
<li class="chapter" data-level="2.3" data-path="variabili-discrete-o-continue.html"><a href="variabili-discrete-o-continue.html"><i class="fa fa-check"></i><b>2.3</b> Variabili discrete o continue</a></li>
<li class="chapter" data-level="2.4" data-path="alcune-misure-sono-migliori-di-altre.html"><a href="alcune-misure-sono-migliori-di-altre.html"><i class="fa fa-check"></i><b>2.4</b> Alcune misure sono migliori di altre</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="alcune-misure-sono-migliori-di-altre.html"><a href="alcune-misure-sono-migliori-di-altre.html#tipologie-di-errori"><i class="fa fa-check"></i><b>2.4.1</b> Tipologie di errori</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusioni.html"><a href="conclusioni.html"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="part"><span><b>Statistica descrittiva ed analisi esplorativa dei dati</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stats.html"><a href="descriptive-stats.html"><i class="fa fa-check"></i><b>3</b> Statistica descrittiva</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-descript.html"><a href="chapter-descript.html"><i class="fa fa-check"></i><b>3.1</b> Introduzione allâesplorazione dei dati</a></li>
<li class="chapter" data-level="3.2" data-path="un-excursus-storico.html"><a href="un-excursus-storico.html"><i class="fa fa-check"></i><b>3.2</b> Un excursus storico</a></li>
<li class="chapter" data-level="3.3" data-path="riassumere-i-dati.html"><a href="riassumere-i-dati.html"><i class="fa fa-check"></i><b>3.3</b> Riassumere i dati</a></li>
<li class="chapter" data-level="3.4" data-path="i-dati-grezzi.html"><a href="i-dati-grezzi.html"><i class="fa fa-check"></i><b>3.4</b> I dati grezzi</a></li>
<li class="chapter" data-level="3.5" data-path="distribuzioni-di-frequenze.html"><a href="distribuzioni-di-frequenze.html"><i class="fa fa-check"></i><b>3.5</b> Distribuzioni di frequenze</a></li>
<li class="chapter" data-level="3.6" data-path="istogramma.html"><a href="istogramma.html"><i class="fa fa-check"></i><b>3.6</b> Istogramma</a></li>
<li class="chapter" data-level="3.7" data-path="kernel-density-plot.html"><a href="kernel-density-plot.html"><i class="fa fa-check"></i><b>3.7</b> Kernel density plot</a></li>
<li class="chapter" data-level="3.8" data-path="forma-di-una-distribuzione.html"><a href="forma-di-una-distribuzione.html"><i class="fa fa-check"></i><b>3.8</b> Forma di una distribuzione</a></li>
<li class="chapter" data-level="3.9" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html"><i class="fa fa-check"></i><b>3.9</b> Indici di posizione</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#quantili"><i class="fa fa-check"></i><b>3.9.1</b> Quantili</a></li>
<li class="chapter" data-level="3.9.2" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#diagramma-a-scatola"><i class="fa fa-check"></i><b>3.9.2</b> Diagramma a scatola</a></li>
<li class="chapter" data-level="3.9.3" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#sina-plot"><i class="fa fa-check"></i><b>3.9.3</b> Sina plot</a></li>
<li class="chapter" data-level="3.9.4" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#leccellenza-grafica"><i class="fa fa-check"></i><b>3.9.4</b> Lâeccellenza grafica</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html"><i class="fa fa-check"></i><b>3.10</b> Indici di tendenza centrale</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#media"><i class="fa fa-check"></i><b>3.10.1</b> Media</a></li>
<li class="chapter" data-level="3.10.2" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#media-spuntata"><i class="fa fa-check"></i><b>3.10.2</b> Media spuntata</a></li>
<li class="chapter" data-level="3.10.3" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#moda-e-mediana"><i class="fa fa-check"></i><b>3.10.3</b> Moda e mediana</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html"><i class="fa fa-check"></i><b>3.11</b> Indici di dispersione</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#indici-basati-sullordinamento-dei-dati"><i class="fa fa-check"></i><b>3.11.1</b> Indici basati sullâordinamento dei dati</a></li>
<li class="chapter" data-level="3.11.2" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#varianza"><i class="fa fa-check"></i><b>3.11.2</b> Varianza</a></li>
<li class="chapter" data-level="3.11.3" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#precisione"><i class="fa fa-check"></i><b>3.11.3</b> Precisione</a></li>
<li class="chapter" data-level="3.11.4" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#scarto-tipo"><i class="fa fa-check"></i><b>3.11.4</b> Scarto tipo</a></li>
<li class="chapter" data-level="3.11.5" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#deviazione-mediana-assoluta"><i class="fa fa-check"></i><b>3.11.5</b> Deviazione mediana assoluta</a></li>
<li class="chapter" data-level="3.11.6" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#indici-di-variabilitÃ -relativi"><i class="fa fa-check"></i><b>3.11.6</b> Indici di variabilitÃ  relativi</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html"><i class="fa fa-check"></i><b>3.12</b> Le relazioni tra variabili</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#diagramma-a-dispersione"><i class="fa fa-check"></i><b>3.12.1</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="3.12.2" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#covarianza"><i class="fa fa-check"></i><b>3.12.2</b> Covarianza</a></li>
<li class="chapter" data-level="3.12.3" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#correlazione"><i class="fa fa-check"></i><b>3.12.3</b> Correlazione</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html"><i class="fa fa-check"></i><b>3.13</b> Correlazione e causazione</a>
<ul>
<li class="chapter" data-level="3.13.1" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#usi-della-correlazione"><i class="fa fa-check"></i><b>3.13.1</b> Usi della correlazione</a></li>
<li class="chapter" data-level="3.13.2" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#correlazione-di-spearman"><i class="fa fa-check"></i><b>3.13.2</b> Correlazione di Spearman</a></li>
<li class="chapter" data-level="3.13.3" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#correlazione-nulla"><i class="fa fa-check"></i><b>3.13.3</b> Correlazione nulla</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive.html"><a href="considerazioni-conclusive.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="part"><span><b>Nozioni di base</b></span></li>
<li class="chapter" data-level="4" data-path="intro-prob-1.html"><a href="intro-prob-1.html"><i class="fa fa-check"></i><b>4</b> Il calcolo delle probabilitÃ </a>
<ul>
<li class="chapter" data-level="4.1" data-path="inf-stat-probl-inv.html"><a href="inf-stat-probl-inv.html"><i class="fa fa-check"></i><b>4.1</b> La probabilitÃ  come la logica della scienza</a></li>
<li class="chapter" data-level="4.2" data-path="che-cosÃ¨-la-probabilitÃ .html"><a href="che-cosÃ¨-la-probabilitÃ .html"><i class="fa fa-check"></i><b>4.2</b> Che cosâÃ¨ la probabilitÃ ?</a></li>
<li class="chapter" data-level="4.3" data-path="variabili-casuali-e-probabilitÃ -di-un-evento.html"><a href="variabili-casuali-e-probabilitÃ -di-un-evento.html"><i class="fa fa-check"></i><b>4.3</b> Variabili casuali e probabilitÃ  di un evento</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variabili-casuali-e-probabilitÃ -di-un-evento.html"><a href="variabili-casuali-e-probabilitÃ -di-un-evento.html#variabili-casuali-1"><i class="fa fa-check"></i><b>4.3.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="4.3.2" data-path="variabili-casuali-e-probabilitÃ -di-un-evento.html"><a href="variabili-casuali-e-probabilitÃ -di-un-evento.html#eventi-e-probabilitÃ "><i class="fa fa-check"></i><b>4.3.2</b> Eventi e probabilitÃ </a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="spazio-campionario-e-risultati-possibili.html"><a href="spazio-campionario-e-risultati-possibili.html"><i class="fa fa-check"></i><b>4.4</b> Spazio campionario e risultati possibili</a></li>
<li class="chapter" data-level="4.5" data-path="usare-la-simulazione-per-stimare-le-probabilitÃ .html"><a href="usare-la-simulazione-per-stimare-le-probabilitÃ .html"><i class="fa fa-check"></i><b>4.5</b> Usare la simulazione per stimare le probabilitÃ </a></li>
<li class="chapter" data-level="4.6" data-path="la-legge-dei-grandi-numeri.html"><a href="la-legge-dei-grandi-numeri.html"><i class="fa fa-check"></i><b>4.6</b> La legge dei grandi numeri</a></li>
<li class="chapter" data-level="4.7" data-path="variabili-casuali-multiple.html"><a href="variabili-casuali-multiple.html"><i class="fa fa-check"></i><b>4.7</b> Variabili casuali multiple</a></li>
<li class="chapter" data-level="4.8" data-path="sec:fun-mass-prob.html"><a href="sec:fun-mass-prob.html"><i class="fa fa-check"></i><b>4.8</b> Funzione di massa di probabilitÃ </a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-1.html"><a href="considerazioni-conclusive-1.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-prob-cond.html"><a href="chapter-prob-cond.html"><i class="fa fa-check"></i><b>5</b> ProbabilitÃ  condizionata</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilitÃ -condizionata-su-altri-eventi.html"><a href="probabilitÃ -condizionata-su-altri-eventi.html"><i class="fa fa-check"></i><b>5.1</b> ProbabilitÃ  condizionata su altri eventi</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilitÃ -condizionata-su-altri-eventi.html"><a href="probabilitÃ -condizionata-su-altri-eventi.html#la-fallacia-del-condizionale-trasposto"><i class="fa fa-check"></i><b>5.1.1</b> La fallacia del condizionale trasposto</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="legge-della-probabilitÃ -composta.html"><a href="legge-della-probabilitÃ -composta.html"><i class="fa fa-check"></i><b>5.2</b> Legge della probabilitÃ  composta</a></li>
<li class="chapter" data-level="5.3" data-path="lindipendendenza-stocastica.html"><a href="lindipendendenza-stocastica.html"><i class="fa fa-check"></i><b>5.3</b> Lâindipendendenza stocastica</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-2.html"><a href="considerazioni-conclusive-2.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter-teo-bayes.html"><a href="chapter-teo-bayes.html"><i class="fa fa-check"></i><b>6</b> Il teorema di Bayes</a>
<ul>
<li class="chapter" data-level="6.1" data-path="il-teorema-della-probabilitÃ -totale.html"><a href="il-teorema-della-probabilitÃ -totale.html"><i class="fa fa-check"></i><b>6.1</b> Il teorema della probabilitÃ  totale</a></li>
<li class="chapter" data-level="6.2" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html"><i class="fa fa-check"></i><b>6.2</b> La regola di Bayes</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html#le-probabilita-come-grado-di-fiducia"><i class="fa fa-check"></i><b>6.2.1</b> Le probabilitaÌ come grado di fiducia</a></li>
<li class="chapter" data-level="6.2.2" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html#aggiornamento-bayesiano"><i class="fa fa-check"></i><b>6.2.2</b> Aggiornamento bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-3.html"><a href="considerazioni-conclusive-3.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter-prob-congiunta.html"><a href="chapter-prob-congiunta.html"><i class="fa fa-check"></i><b>7</b> ProbabilitÃ  congiunta</a>
<ul>
<li class="chapter" data-level="7.1" data-path="funzione-di-probabilitÃ -congiunta.html"><a href="funzione-di-probabilitÃ -congiunta.html"><i class="fa fa-check"></i><b>7.1</b> Funzione di probabilitÃ  congiunta</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="funzione-di-probabilitÃ -congiunta.html"><a href="funzione-di-probabilitÃ -congiunta.html#proprietÃ "><i class="fa fa-check"></i><b>7.1.1</b> ProprietÃ </a></li>
<li class="chapter" data-level="7.1.2" data-path="funzione-di-probabilitÃ -congiunta.html"><a href="funzione-di-probabilitÃ -congiunta.html#eventi"><i class="fa fa-check"></i><b>7.1.2</b> Eventi</a></li>
<li class="chapter" data-level="7.1.3" data-path="funzione-di-probabilitÃ -congiunta.html"><a href="funzione-di-probabilitÃ -congiunta.html#regola-della-catena"><i class="fa fa-check"></i><b>7.1.3</b> Regola della catena</a></li>
<li class="chapter" data-level="7.1.4" data-path="funzione-di-probabilitÃ -congiunta.html"><a href="funzione-di-probabilitÃ -congiunta.html#funzioni-di-probabilitÃ -marginali"><i class="fa fa-check"></i><b>7.1.4</b> Funzioni di probabilitÃ  marginali</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="indipendenza-stocastica.html"><a href="indipendenza-stocastica.html"><i class="fa fa-check"></i><b>7.2</b> Indipendenza stocastica</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-4.html"><a href="considerazioni-conclusive-4.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter-intro-density-function.html"><a href="chapter-intro-density-function.html"><i class="fa fa-check"></i><b>8</b> Funzione di densitÃ  di probabilitÃ </a>
<ul>
<li class="chapter" data-level="8.1" data-path="spinner-e-variabili-casuali-continue-uniformi.html"><a href="spinner-e-variabili-casuali-continue-uniformi.html"><i class="fa fa-check"></i><b>8.1</b> Spinner e variabili casuali continue uniformi</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="spinner-e-variabili-casuali-continue-uniformi.html"><a href="spinner-e-variabili-casuali-continue-uniformi.html#il-paradosso-delle-variabili-casuali-continue"><i class="fa fa-check"></i><b>8.1.1</b> Il paradosso delle variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="la-funzione-di-ripartizione-per-una-variabile-casuale-continua.html"><a href="la-funzione-di-ripartizione-per-una-variabile-casuale-continua.html"><i class="fa fa-check"></i><b>8.2</b> La funzione di ripartizione per una variabile casuale continua</a></li>
<li class="chapter" data-level="8.3" data-path="la-distribuzione-uniforme.html"><a href="la-distribuzione-uniforme.html"><i class="fa fa-check"></i><b>8.3</b> La distribuzione uniforme</a></li>
<li class="chapter" data-level="8.4" data-path="la-trasformazione-logit.html"><a href="la-trasformazione-logit.html"><i class="fa fa-check"></i><b>8.4</b> La trasformazione logit</a></li>
<li class="chapter" data-level="8.5" data-path="dagli-istogrammi-alle-densitÃ .html"><a href="dagli-istogrammi-alle-densitÃ .html"><i class="fa fa-check"></i><b>8.5</b> Dagli istogrammi alle densitÃ </a></li>
<li class="chapter" data-level="8.6" data-path="funzione-di-densitÃ -di-probabilitÃ .html"><a href="funzione-di-densitÃ -di-probabilitÃ .html"><i class="fa fa-check"></i><b>8.6</b> Funzione di densitÃ  di probabilitÃ </a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="exp-val-and-variance-rv.html"><a href="exp-val-and-variance-rv.html"><i class="fa fa-check"></i><b>9</b> Valore atteso e varianza</a>
<ul>
<li class="chapter" data-level="9.1" data-path="valore-atteso.html"><a href="valore-atteso.html"><i class="fa fa-check"></i><b>9.1</b> Valore atteso</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="valore-atteso.html"><a href="valore-atteso.html#interpretazione"><i class="fa fa-check"></i><b>9.1.1</b> Interpretazione</a></li>
<li class="chapter" data-level="9.1.2" data-path="valore-atteso.html"><a href="valore-atteso.html#proprietÃ -del-valore-atteso"><i class="fa fa-check"></i><b>9.1.2</b> ProprietÃ  del valore atteso</a></li>
<li class="chapter" data-level="9.1.3" data-path="valore-atteso.html"><a href="valore-atteso.html#variabili-casuali-continue"><i class="fa fa-check"></i><b>9.1.3</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="varianza-1.html"><a href="varianza-1.html"><i class="fa fa-check"></i><b>9.2</b> Varianza</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="varianza-1.html"><a href="varianza-1.html#formula-alternativa-per-la-varianza"><i class="fa fa-check"></i><b>9.2.1</b> Formula alternativa per la varianza</a></li>
<li class="chapter" data-level="9.2.2" data-path="varianza-1.html"><a href="varianza-1.html#variabili-casuali-continue-1"><i class="fa fa-check"></i><b>9.2.2</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="deviazione-standard.html"><a href="deviazione-standard.html"><i class="fa fa-check"></i><b>9.3</b> Deviazione standard</a></li>
<li class="chapter" data-level="9.4" data-path="standardizzazione.html"><a href="standardizzazione.html"><i class="fa fa-check"></i><b>9.4</b> Standardizzazione</a></li>
<li class="chapter" data-level="9.5" data-path="momenti-di-variabili-casuali.html"><a href="momenti-di-variabili-casuali.html"><i class="fa fa-check"></i><b>9.5</b> Momenti di variabili casuali</a></li>
<li class="chapter" data-level="9.6" data-path="funzione-di-ripartizione.html"><a href="funzione-di-ripartizione.html"><i class="fa fa-check"></i><b>9.6</b> Funzione di ripartizione</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="distr-rv-discr.html"><a href="distr-rv-discr.html"><i class="fa fa-check"></i><b>10</b> Distribuzioni di v.c. discrete</a>
<ul>
<li class="chapter" data-level="10.1" data-path="una-prova-bernoulliana.html"><a href="una-prova-bernoulliana.html"><i class="fa fa-check"></i><b>10.1</b> Una prova Bernoulliana</a></li>
<li class="chapter" data-level="10.2" data-path="una-sequenza-di-prove-bernoulliane.html"><a href="una-sequenza-di-prove-bernoulliane.html"><i class="fa fa-check"></i><b>10.2</b> Una sequenza di prove Bernoulliane</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="una-sequenza-di-prove-bernoulliane.html"><a href="una-sequenza-di-prove-bernoulliane.html#valore-atteso-e-deviazione-standard"><i class="fa fa-check"></i><b>10.2.1</b> Valore atteso e deviazione standard</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuzione-di-poisson.html"><a href="distribuzione-di-poisson.html"><i class="fa fa-check"></i><b>10.3</b> Distribuzione di Poisson</a></li>
<li class="chapter" data-level="10.4" data-path="alcune-proprietÃ -della-variabile-di-poisson.html"><a href="alcune-proprietÃ -della-variabile-di-poisson.html"><i class="fa fa-check"></i><b>10.4</b> Alcune proprietÃ  della variabile di Poisson</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-5.html"><a href="considerazioni-conclusive-5.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="distr-rv-cont.html"><a href="distr-rv-cont.html"><i class="fa fa-check"></i><b>11</b> Distribuzioni di v.c. continue</a>
<ul>
<li class="chapter" data-level="11.1" data-path="distribuzione-normale.html"><a href="distribuzione-normale.html"><i class="fa fa-check"></i><b>11.1</b> Distribuzione Normale</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="distribuzione-normale.html"><a href="distribuzione-normale.html#limite-delle-distribuzioni-binomiali"><i class="fa fa-check"></i><b>11.1.1</b> Limite delle distribuzioni binomiali</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="normal-random-walk.html"><a href="normal-random-walk.html"><i class="fa fa-check"></i><b>11.2</b> La Normale prodotta con una simulazione</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="normal-random-walk.html"><a href="normal-random-walk.html#concentrazione"><i class="fa fa-check"></i><b>11.2.1</b> Concentrazione</a></li>
<li class="chapter" data-level="11.2.2" data-path="normal-random-walk.html"><a href="normal-random-walk.html#funzione-di-ripartizione-1"><i class="fa fa-check"></i><b>11.2.2</b> Funzione di ripartizione</a></li>
<li class="chapter" data-level="11.2.3" data-path="normal-random-walk.html"><a href="normal-random-walk.html#distribuzione-normale-standard"><i class="fa fa-check"></i><b>11.2.3</b> Distribuzione Normale standard</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="teorema-del-limite-centrale.html"><a href="teorema-del-limite-centrale.html"><i class="fa fa-check"></i><b>11.3</b> Teorema del limite centrale</a></li>
<li class="chapter" data-level="11.4" data-path="distribuzione-chi-quadrato.html"><a href="distribuzione-chi-quadrato.html"><i class="fa fa-check"></i><b>11.4</b> Distribuzione Chi-quadrato</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="distribuzione-chi-quadrato.html"><a href="distribuzione-chi-quadrato.html#proprietÃ -1"><i class="fa fa-check"></i><b>11.4.1</b> ProprietÃ </a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="distribuzione-t-di-student.html"><a href="distribuzione-t-di-student.html"><i class="fa fa-check"></i><b>11.5</b> Distribuzione <span class="math inline">\(t\)</span> di Student</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="distribuzione-t-di-student.html"><a href="distribuzione-t-di-student.html#proprietÃ -2"><i class="fa fa-check"></i><b>11.5.1</b> ProprietÃ </a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="funzione-beta-di-eulero.html"><a href="funzione-beta-di-eulero.html"><i class="fa fa-check"></i><b>11.6</b> Funzione beta di Eulero</a></li>
<li class="chapter" data-level="11.7" data-path="distribuzione-beta.html"><a href="distribuzione-beta.html"><i class="fa fa-check"></i><b>11.7</b> Distribuzione Beta</a></li>
<li class="chapter" data-level="11.8" data-path="distribuzione-di-cauchy.html"><a href="distribuzione-di-cauchy.html"><i class="fa fa-check"></i><b>11.8</b> Distribuzione di Cauchy</a></li>
<li class="chapter" data-level="11.9" data-path="distribuzione-log-normale.html"><a href="distribuzione-log-normale.html"><i class="fa fa-check"></i><b>11.9</b> Distribuzione log-normale</a></li>
<li class="chapter" data-level="11.10" data-path="distribuzione-di-pareto.html"><a href="distribuzione-di-pareto.html"><i class="fa fa-check"></i><b>11.10</b> Distribuzione di Pareto</a></li>
</ul></li>
<li class="part"><span><b>Inferenza statistica bayesiana</b></span></li>
<li class="chapter" data-level="12" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html"><i class="fa fa-check"></i><b>12</b> Inferenza bayesiana</a>
<ul>
<li class="chapter" data-level="12.1" data-path="modellizzazione-bayesiana.html"><a href="modellizzazione-bayesiana.html"><i class="fa fa-check"></i><b>12.1</b> Modellizzazione bayesiana</a></li>
<li class="chapter" data-level="12.2" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html"><i class="fa fa-check"></i><b>12.2</b> Inferenza bayesiana come un problema inverso</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html#notazione"><i class="fa fa-check"></i><b>12.2.1</b> Notazione</a></li>
<li class="chapter" data-level="12.2.2" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html#funzioni-di-probabilitÃ "><i class="fa fa-check"></i><b>12.2.2</b> Funzioni di probabilitÃ </a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="la-regola-di-bayes-1.html"><a href="la-regola-di-bayes-1.html"><i class="fa fa-check"></i><b>12.3</b> La regola di Bayes</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="la-regola-di-bayes-1.html"><a href="la-regola-di-bayes-1.html#un-esempio-di-aggiornamento-bayesiano"><i class="fa fa-check"></i><b>12.3.1</b> Un esempio di aggiornamento bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="modello-probabilistico.html"><a href="modello-probabilistico.html"><i class="fa fa-check"></i><b>12.4</b> Modello probabilistico</a></li>
<li class="chapter" data-level="12.5" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html"><i class="fa fa-check"></i><b>12.5</b> Distribuzioni a priori</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#tipologie-di-distribuzioni-a-priori"><i class="fa fa-check"></i><b>12.5.1</b> Tipologie di distribuzioni a priori</a></li>
<li class="chapter" data-level="12.5.2" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#selezione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>12.5.2</b> Selezione della distribuzione a priori</a></li>
<li class="chapter" data-level="12.5.3" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#la-distribuzione-a-priori-per-i-dati-di-zetschefuture2019"><i class="fa fa-check"></i><b>12.5.3</b> La distribuzione a priori per i dati di <span class="citation">Zetsche, BÃ¼rkner, and Renneberg (<span>2019</span>)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="verosimiglianza.html"><a href="verosimiglianza.html"><i class="fa fa-check"></i><b>12.6</b> Verosimiglianza</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="verosimiglianza.html"><a href="verosimiglianza.html#la-stima-di-massima-verosimiglianza"><i class="fa fa-check"></i><b>12.6.1</b> La stima di massima verosimiglianza</a></li>
<li class="chapter" data-level="12.6.2" data-path="verosimiglianza.html"><a href="verosimiglianza.html#la-log-verosimiglianza"><i class="fa fa-check"></i><b>12.6.2</b> La log-verosimiglianza</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="sec:const-normaliz-bino23.html"><a href="sec:const-normaliz-bino23.html"><i class="fa fa-check"></i><b>12.7</b> La verosimiglianza marginale</a></li>
<li class="chapter" data-level="12.8" data-path="distribuzione-a-posteriori.html"><a href="distribuzione-a-posteriori.html"><i class="fa fa-check"></i><b>12.8</b> Distribuzione a posteriori</a></li>
<li class="chapter" data-level="12.9" data-path="distribuzione-predittiva-a-priori.html"><a href="distribuzione-predittiva-a-priori.html"><i class="fa fa-check"></i><b>12.9</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="12.10" data-path="distribuzione-predittiva-a-posteriori.html"><a href="distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>12.10</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-6.html"><a href="considerazioni-conclusive-6.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chapter-ppc.html"><a href="chapter-ppc.html"><i class="fa fa-check"></i><b>13</b> Distribuzione predittiva a posteriori</a>
<ul>
<li class="chapter" data-level="13.1" data-path="la-distribuzione-dei-possibili-valori-futuri.html"><a href="la-distribuzione-dei-possibili-valori-futuri.html"><i class="fa fa-check"></i><b>13.1</b> La distribuzione dei possibili valori futuri</a></li>
<li class="chapter" data-level="13.2" data-path="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"><a href="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>13.2</b> Metodi MCMC per la distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="13.3" data-path="posterior-predictive-checks.html"><a href="posterior-predictive-checks.html"><i class="fa fa-check"></i><b>13.3</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-7.html"><a href="considerazioni-conclusive-7.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html"><i class="fa fa-check"></i><b>14</b> Modello Normale-Normale</a>
<ul>
<li class="chapter" data-level="14.1" data-path="distribuzione-normale-normale-con-varianza-nota.html"><a href="distribuzione-normale-normale-con-varianza-nota.html"><i class="fa fa-check"></i><b>14.1</b> Distribuzione Normale-Normale con varianza nota</a></li>
<li class="chapter" data-level="14.2" data-path="il-modello-normale-con-stan.html"><a href="il-modello-normale-con-stan.html"><i class="fa fa-check"></i><b>14.2</b> Il modello Normale con Stan</a></li>
<li class="chapter" data-level="14.3" data-path="il-modello-normale-con-quap.html"><a href="il-modello-normale-con-quap.html"><i class="fa fa-check"></i><b>14.3</b> Il modello normale con <code>quap()</code></a></li>
<li class="chapter" data-level="14.4" data-path="il-modello-normale-con-brmsbrm.html"><a href="il-modello-normale-con-brmsbrm.html"><i class="fa fa-check"></i><b>14.4</b> Il modello normale con <code>brms::brm()</code></a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-8.html"><a href="considerazioni-conclusive-8.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="regr-models-intro.html"><a href="regr-models-intro.html"><i class="fa fa-check"></i><b>15</b> Introduzione al modello lineare</a>
<ul>
<li class="chapter" data-level="15.1" data-path="la-funzione-lineare.html"><a href="la-funzione-lineare.html"><i class="fa fa-check"></i><b>15.1</b> La funzione lineare</a></li>
<li class="chapter" data-level="15.2" data-path="lerrore-di-misurazione.html"><a href="lerrore-di-misurazione.html"><i class="fa fa-check"></i><b>15.2</b> Lâerrore di misurazione</a></li>
<li class="chapter" data-level="15.3" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html"><i class="fa fa-check"></i><b>15.3</b> Una media per ciascuna osservazione</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore"><i class="fa fa-check"></i><b>15.3.1</b> Relazione lineare tra la media <span class="math inline">\(y \mid x\)</span> e il predittore</a></li>
<li class="chapter" data-level="15.3.2" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html#il-modello-lineare"><i class="fa fa-check"></i><b>15.3.2</b> Il modello lineare</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-9.html"><a href="considerazioni-conclusive-9.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="simbologia-di-base.html"><a href="simbologia-di-base.html"><i class="fa fa-check"></i><b>A</b> Simbologia di base</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="la-regola-di-bayes" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> La regola di Bayes</h2>
<p>Il teorema di Bayes rappresenta uno dei fondamenti della teoria della
probabilitÃ  e della statistica. Lo presentiamo qui considerando un
caso specifico per poi descriverlo nella sua forma piÃ¹ generale.</p>
<p>Sia <span class="math inline">\(\{F_1, F_2\}\)</span> una partizione dello spazio campionario <span class="math inline">\(\Omega\)</span>.
Consideriamo un terzo evento <span class="math inline">\(E \subset \Omega\)</span> con probabilitÃ  non
nulla di cui si conoscono le probabilitÃ  condizionate rispetto ad <span class="math inline">\(F_1\)</span>
e a <span class="math inline">\(F_2\)</span>, ovvero <span class="math inline">\(P(E \mid F_1)\)</span> e <span class="math inline">\(P(E \mid F_2)\)</span>. Ã chiaro per le
ipotesi fatte che se si verifica <span class="math inline">\(E\)</span> deve anche essersi verificato
almeno uno degli eventi <span class="math inline">\(F_1\)</span> e <span class="math inline">\(F_2\)</span>. Supponendo che si sia verificato
lâevento <span class="math inline">\(E\)</span>, ci chiediamo: qual Ã¨ la probabilitÃ  che si sia verificato
<span class="math inline">\(F_1\)</span> piuttosto che <span class="math inline">\(F_2\)</span>?</p>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-31-1.png" width="45%" style="display: block; margin: auto;" /></p>
<p>Per rispondere alla domanda precedente scriviamo:</p>
<p><span class="math display">\[
\begin{split}
P(F_1 \mid E) &amp;= \frac{P(E \cap F_1)}{P(E)}\notag\\
              &amp;= \frac{P(E \mid F_1)P(F_1)}{P(E)}.
\end{split}
\]</span></p>
<p>Sapendo che <span class="math inline">\(E = (E \cap F_1) \cup (E \cap F_2)\)</span> e che <span class="math inline">\(F_1\)</span> e <span class="math inline">\(F_2\)</span> sono eventi disgiunti, ovvero <span class="math inline">\(F_1 \cap F_2 = \emptyset\)</span>, ne segue che possiamo calcolare <span class="math inline">\(P(E)\)</span> utilizzando il teorema della probabilitÃ  totale:</p>
<p><span class="math display">\[
\begin{split}
P(E) &amp;= P(E \cap F_1) + P(E \cap F_2)\notag\\
     &amp;= P(E \mid F_1)P(F_1) + P(E \mid F_2)P(F_2).
\end{split}
\]</span></p>
<p>
Sostituendo il risultato precedente nella formula della probabilitÃ  condizionata <span class="math inline">\(P(F_1 \mid E)\)</span> otteniamo:</p>
<p><span class="math display" id="eq:bayes1">\[\begin{equation}
P(F_1 \mid E) = \frac{P(E \mid F_1)P(F_1)}{P(E \mid F_1)P(F_1) + P(E \mid F_2)P(F_2)}.
\tag{6.3}
\end{equation}\]</span></p>
<p>
La <a href="la-regola-di-bayes.html#eq:bayes1">(6.3)</a> si generalizza facilmente al caso di piÃ¹ di due eventi disgiunti, come indicato di seguito.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-38" class="theorem"><strong>Teorema 6.2  </strong></span>Sia <span class="math inline">\(E\)</span> un evento contenuto in <span class="math inline">\(F_1 \cup \dots \cup F_k\)</span>, dove gli eventi <span class="math inline">\(F_j, j=1, \dots, k\)</span> sono a due a due incompatibili e necessari. Allora per ognuno dei suddetti eventi <span class="math inline">\(F_j\)</span> vale la seguente formula:</p>
<p><span class="math display" id="eq:bayes2">\[\begin{equation}
P(F_j \mid E) = \frac{P(E \mid F_j)P(F_j)}{\sum_{j=1}^{k}P(F_j)P(E \mid F_j)}.
\tag{6.4}
\end{equation}\]</span></p>
</div>
<p>
La <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> prende il nome di <em>Teorema di Bayes</em> e mostra che la conoscenza del verificarsi dellâevento <span class="math inline">\(E\)</span> modifica la probabilitÃ  che abbiamo attribuito allâevento <span class="math inline">\(F_j\)</span>. Nella <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> la probabilitÃ  condizionata <span class="math inline">\(P(F_j \mid E)\)</span> prende il nome di probabilitÃ  <em>a posteriori</em> dellâevento <span class="math inline">\(F_j\)</span>: il termine âa posterioriâ sta a significare âdopo che Ã¨ noto che si Ã¨ verificato lâevento <span class="math inline">\(E\)</span>â. Nel capitolo <a href="#chapter-intro-bayes-inference"><strong>??</strong></a> estenderemo questa discussione mostrando come la <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> possa essere formulata in un modo piÃ¹ generale, ovvero in modo tale che non faccia riferimento unicamente alla probabilitÃ  di eventi, ma bensÃ¬ anche alle funzioni di densitÃ  di probabilitÃ .</p>
<div class="remark">
<p><span id="unlabeled-div-39" class="remark"><em>Remark</em>. </span>Qual Ã¨ la pronuncia di âBayesianâ? Per saperlo possiamo seguire <a href="https://bayes-rules.github.io/posts/fun/">questo link</a>.</p>
</div>
<div id="le-probabilita-come-grado-di-fiducia" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Le probabilitaÌ come grado di fiducia</h3>
<p>Il teorema di Bayes rende esplicito il motivo per cui la probabilitÃ  non puÃ² essere pensata come uno stato oggettivo, quanto piuttosto come unâinferenza soggettiva e condizionata. Il denominatore del membro di destra della <a href="la-regola-di-bayes.html#eq:bayes2">(6.4)</a> eÌ un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantitÃ : <span class="math inline">\(P(F_j\)</span>) e <span class="math inline">\(P(E \mid F_j)\)</span>. La probabilitÃ  <span class="math inline">\(P(F_j\)</span>) eÌ la probabilitÃ  <em>probabilitÃ  a priori</em> (<em>prior</em>) dellâevento <span class="math inline">\(F_j\)</span> e rappresenta lâinformazione che lâagente bayesiano possiede a proposito dellâevento <span class="math inline">\(F_j\)</span>. Diremo che <span class="math inline">\(P(F_j)\)</span> codifica il grado di fiducia che lâagente ripone in <span class="math inline">\(F_j\)</span>, sul quale non possiamo porre vincoli di alcun tipo. La probabilitÃ  condizionata <span class="math inline">\(P(E \mid F_j)\)</span> rappresenta invece la verosimiglianza di <span class="math inline">\(F_j\)</span> e ci dice quantâÃ¨ plausibile che si verifichi lâevento <span class="math inline">\(E\)</span> condizionatemente al fatto che si sia verificato <span class="math inline">\(F_j\)</span>.</p>
<p>Nellâinterpretazione bayesiana <span class="math inline">\(P(F_j)\)</span> rappresenta un giudizio personale dellâagente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. Il teorema di Bayes descrive la regola che lâagente deve seguire per aggiornare il suo grado di fiducia in <span class="math inline">\(F_j\)</span> alla luce di un ulteriore evento <span class="math inline">\(E\)</span>. Per questo motivo abbiamo chiamato <span class="math inline">\(P(F_j \mid E)\)</span> probabilitÃ  a posteriori: essa rappresenta infatti la nuova probabilitÃ  che lâagente assegna ad <span class="math inline">\(F_j\)</span> affinchÃ© rimanga consistente con le nuove informazioni fornitegli da <span class="math inline">\(E\)</span>.</p>
<p>La probabilitÃ  a posteriori dipende sia da <span class="math inline">\(E\)</span>, sia dalla conoscenza a priori dellâagente <span class="math inline">\(P(F_j)\)</span>. In questo senso Ã¨ chiaro come non abbia senso parlare di una probabilitÃ  oggettiva: per il teorema di Bayes la probabilitÃ  Ã¨ definita condizionatamente alla probabilitÃ  a priori, la quale a sua volta, per definizione, Ã¨ unâassegnazione soggettiva. Ne segue pertanto che ogni probabilitÃ  debba essere una rappresentazione del grado di fiducia (soggettiva) dellâagente.</p>
<p>Se ogni assegnazione probabilistica rappresenta uno stato di conoscenza, eÌ altresiÌ vero che un particolare stato di conoscenza eÌ arbitrario e dunque non deve esserci necessariamente accordo a priori tra diversi agenti. Tuttavia, alla luce di nuove informazioni, la teoria delle probabilitÃ  ci fornisce uno strumento che consente lâaggiornamento dello stato di conoscenza in un modo razionale.</p>
</div>
<div id="aggiornamento-bayesiano" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Aggiornamento bayesiano</h3>
<p>Il teorema di Bayes consente di modificare una credenza a priori in maniera dinamica, via via che nuove evidenze vengono raccolte, in modo tale da formulare una credenza a posteriori la quale non Ã¨ mai definitiva, ma puÃ² sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama <em>aggiornamento bayesiano</em>.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-40" class="exercise"><strong>Esercizio 6.3  </strong></span>Supponiamo che, per qualche strano errore di produzione, una fabbrica
produca due tipi di monete. Il primo tipo di monete ha la caratteristica
che, quando una moneta viene lanciata, la probabilitÃ  di osservare
lâesito âtestaâ Ã¨ 0.6. Per semplicitÃ , sia <span class="math inline">\(\theta\)</span> la probabilitÃ  di
osservare lâesito âtestaâ. Per una moneta del primo tipo, dunque,
<span class="math inline">\(\theta = 0.6\)</span>. Per una moneta del secondo tipo, invece, la probabilitÃ 
di produrre lâesito âtestaâ Ã¨ 0.4. Ovvero, <span class="math inline">\(\theta = 0.4\)</span>.</p>
<p>Noi possediamo una moneta, ma non sappiamo se Ã¨ del primo tipo o del secondo tipo. Sappiamo solo che il 75% delle monete sono del primo tipo e il 25% sono del secondo tipo. Sulla base di questa conoscenza <em>a priori</em> â ovvero sulla base di una conoscenza ottenuta senza avere eseguito
lâesperimento che consiste nel lanciare la moneta una serie di volte per
osservare gli esiti prodotti â possiamo dire che la probabilitÃ  di una
prima ipotesi, secondo la quale <span class="math inline">\(\theta = 0.6\)</span>, Ã¨ 3 volte piÃ¹ grande
della probabilitÃ  di una seconda ipotesi, secondo la quale
<span class="math inline">\(\theta = 0.4\)</span>. Senza avere eseguito alcun esperimento casuale con la
moneta, questo Ã¨ quello che sappiamo.</p>
<p>Ora immaginiamo di lanciare una moneta due volte e di ottenere il
risultato seguente: <span class="math inline">\(\{T, C\}\)</span>. Quello che ci chiediamo Ã¨: sulla base di
questa evidenza, come cambiano le probabilitÃ  che associamo alle due
ipotesi? In altre parole, ci chiediamo qual Ã¨ la probabilitÃ  di ciascuna
ipotesi alla luce dei dati che sono stati osservati: <span class="math inline">\(P(H \mid y)\)</span>,
laddove <span class="math inline">\(y\)</span> sono i dati osservati. Tale probabilitÃ  si chiama
probabilitÃ  a posteriori. Inoltre, se confrontiamo le due ipotesi, ci
chiediamo quale valore assuma il rapporto <span class="math inline">\(\frac{P(H_1 \mid y)}{P(H_2 \mid y)}\)</span>.
Tale rapporto ci dice quanto Ã¨ piÃ¹ probabile <span class="math inline">\(H_1\)</span> rispetto ad <span class="math inline">\(H_2\)</span>, alla luce dei dati osservati. Infine, ci chiediamo come cambia il rapporto definito sopra, quando osserviamo via via nuovi risultati prodotti dal lancio della moneta.</p>
<p>Definiamo il problema in maniera piÃ¹ chiara. Conosciamo le probabilitÃ  a priori, ovvero <span class="math inline">\(P(H_1) = 0.75\)</span> e <span class="math inline">\(P(H_1) = 0.25\)</span>. Quello che vogliamo conoscere sono le probabilitÃ  a posteriori <span class="math inline">\(P(H_1 \mid y)\)</span> e <span class="math inline">\(P(H_2 \mid y)\)</span>. Per trovare le probabilitÃ  a posteriori applichiamo il teorema di Bayes:</p>
<p><span class="math display">\[
\begin{split}
P(H_1 \mid y) &amp;= \frac{P(y \mid H_1) P(H_1)}{P(y)} \\
&amp;= \frac{P(y \mid H_1) P(H_1)}{P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2)},
\end{split}
\]</span></p>
<p>laddove lo sviluppo del denominatore deriva da unâapplicazione del teorema della probabilitÃ  totale.
Inoltre,</p>
<p><span class="math display">\[
P(H_2 \mid y) = \frac{P(y \mid H_2) P(H_2)}{P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2)}.
\]</span></p>
<p>Se consideriamo lâipotesi <span class="math inline">\(H_1\)</span> = âla probabilitÃ  di testa Ã¨ 0.6â, allora
la verosimiglianza dei dati <span class="math inline">\(\{T, C\}\)</span>, ovvero la probabilitÃ  di osservare questa specifica sequenza di T e C, Ã¨ uguale a <span class="math inline">\(0.6 \times 0.4 = 0.24.\)</span>
Dunque, <span class="math inline">\(P(y \mid H_1) = 0.24\)</span>.</p>
<p>Se invece consideriamo lâipotesi <span class="math inline">\(H_2\)</span> = âla probabilitÃ  di testa Ã¨ 0.4â, allora la verosimiglianza dei dati <span class="math inline">\(\{T, C\}\)</span> Ã¨ <span class="math inline">\(0.4 \times 0.6 = 0.24\)</span>, ovvero, <span class="math inline">\(P(y \mid H_2) = 0.24\)</span>. In base alle due ipotesi <span class="math inline">\(H_1\)</span> e <span class="math inline">\(H_2\)</span>, dunque, i dati osservati hanno la
medesima plausibilitÃ  di essere osservati.
Per semplicitÃ , calcoliamo anche</p>
<p><span class="math display">\[
\begin{split}
P(y) &amp;= P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2) \\
&amp;= 0.24 \cdot 0.75 + 0.24 \cdot 0.25 \\
&amp;= 0.24.
\end{split}
\]</span></p>
<p>Le probabilitÃ  a posteriori diventano:</p>
<p><span class="math display">\[
\begin{split}
P(H_1 \mid y) &amp;= \frac{P(y \mid H_1) P(H_1)}{P(y)}\\
&amp;= \frac{0.24 \cdot 0.75}{0.24} \\
&amp;= 0.75,
\end{split}
\]</span></p>
<p><span class="math display">\[
\begin{split}
P(H_2 \mid y) &amp;= \frac{P(y \mid H_2) P(H_2)}{P(y)} \\
&amp;= \frac{0.24 \cdot 0.25}{0.24} \\
&amp;= 0.25.
\end{split}
\]</span></p>
<p>Possiamo dunque concludere dicendo che, sulla base dei dati osservati, lâipotesi <span class="math inline">\(H_1\)</span> ha una probabilitÃ  3 volte maggiore di essere vera dellâipotesi <span class="math inline">\(H_2\)</span>.</p>
<p>Ã tuttavia possibile raccogliere piÃ¹ evidenze e, sulla base di esse, le probabilitÃ  a posteriori cambieranno. Supponiamo di lanciare la moneta una terza volta e di osservare croce. I nostri dati dunque sono <span class="math inline">\(\{T, C, C\}\)</span>.</p>
<p>Di conseguenza, <span class="math inline">\(P(y \mid H_1) = 0.6 \cdot 0.4 \cdot 0.4 = 0.096\)</span> e <span class="math inline">\(P(y \mid H_2) = 0.4 \cdot 0.6 \cdot 0.6 = 0.144\)</span>.
Ne segue che le probabilitÃ  a posteriori diventano:</p>
<p><span class="math display">\[
\begin{split}
P(H_1 \mid y) &amp;= \frac{P(y \mid H_1) P(H_1)}{P(y)} \\
&amp;= \frac{0.096 \cdot 0.75}{0.096 \cdot 0.75 + 0.144 \cdot 0.25} \\
&amp;= 0.667,
\end{split}
\]</span></p>
<p><span class="math display">\[
\begin{split}
P(H_2 \mid y) &amp;= \frac{P(y \mid H_2) P(H_2)}{P(y)} \\
&amp;= \frac{0.144 \cdot 0.25}{0.096 \cdot 0.75 + 0.144 \cdot 0.25} \\
&amp;= 0.333.
\end{split}
\]</span></p>
<p>In queste circostanze, le evidenze che favoriscono <span class="math inline">\(H_1\)</span> nei confronti
di <span class="math inline">\(H_2\)</span> sono solo pari ad un fattore di 2.</p>
<p>Se otteniamo ancora croce in un quarto lancio della moneta, i nostri
dati diventano: <span class="math inline">\(\{T, C, C, C\}\)</span>.
Ripetendo il ragionamento fatto sopra,
<span class="math inline">\(P(y \mid H_1) = 0.6 \cdot 0.4 \cdot 0.4 \cdot 0.4 = 0.0384\)</span> e
<span class="math inline">\(P(y \mid H_2) = 0.4 \cdot 0.6 \cdot 0.6 \cdot 0.6 = 0.0864\)</span>.
Dunque</p>
<p><span class="math display">\[\begin{equation}
P(H_1 \mid y) = \frac{0.0384 \cdot 0.75}{0.0384 \cdot 0.75 + 0.0864 \cdot 0.25} = 0.571,\notag
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
P(H_2 \mid y) = \frac{0.0864 \cdot 0.25}{0.0384 \cdot 0.75 + 0.0864 \cdot 0.25} = 0.429.\notag
\end{equation}\]</span></p>
<p>e le evidenze a favore di <span class="math inline">\(H_1\)</span> si riducono a 1.33. Se si ottenesse un
altro esito croce in un sesto lancio della moneta, lâipotesi <span class="math inline">\(H2\)</span>
diventerebbe piÃ¹ probabile dellâipotesi <span class="math inline">\(H_1\)</span>.</p>
<p>In conclusione, questo esercizio ci fa capire come sia possibile aggiornare le nostre credenze sulla base delle evidenze disponibili, ovvero come sia possibile passare da un grado di conoscenza del mondo a priori a una conoscenza a posteriori.
Se prima di lanciare la moneta ritenevamo che lâipotesi <span class="math inline">\(H_1\)</span> fosse tre volte piÃ¹ plausibile dellâipotesi <span class="math inline">\(H_2\)</span>, dopo avere osservato uno specifico campione di dati siamo giunti alla conclusione opposta.
Il processo di aggiornamento bayesiano, dunque, ci fornisce un metodo per modificare il livello di fiducia in una data ipotesi, alla luce di nuove informazioni.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="il-teorema-della-probabilitÃ -totale.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="considerazioni-conclusive-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/ds4psy/edit/master/017_bayes_theorem.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ds4psy.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
