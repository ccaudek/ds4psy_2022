% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  11pt,
]{krantz}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmonofont[Scale=0.775]{MesloLGS NF}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Data Science per psicologi},
  pdfauthor={Corrado Caudek},
  colorlinks=true,
  linkcolor={Maroon},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.33,0.33,0.33}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.61,0.61,0.61}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.14,0.14,0.14}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.06,0.06,0.06}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.27,0.27,0.27}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.43,0.43,0.43}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0,0,0}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.5,0.5,0.5}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\defaultfontfeatures{Scale=MatchLowercase}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\ifxetex
  \usepackage{letltxmacro}
  \setlength{\XeTeXLinkMargin}{1pt}
  \LetLtxMacro\SavedIncludeGraphics\includegraphics
  \def\includegraphics#1#{% #1 catches optional stuff (star/opt. arg.)
    \IncludeGraphicsAux{#1}%
  }%
  \newcommand*{\IncludeGraphicsAux}[2]{%
    \XeTeXLinkBox{%
      \SavedIncludeGraphics#1{#2}%
    }%
  }%
\fi

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\newcommand{\E}{\mathbb{E}} % Define expected value operator
\DeclareMathOperator{\Var}{\mathbb{V}} % Define variance operator
\DeclareMathOperator{\SD}{SD} % Define sd operator
\DeclareMathOperator{\Cov}{Cov} % Define covariance operator
\DeclareMathOperator{\Corr}{Corr} % Define correlation operator
\DeclareMathOperator{\Me}{Me} % Define mediane operator
\DeclareMathOperator{\Mo}{Mo} % Define mode operator
\DeclareMathOperator{\Bin}{Bin} % Define binomial operator
\DeclareMathOperator{\Bernoulli}{Bernoulli} % Define Bernoulli operator
\DeclareMathOperator{\Poi}{Poi} % Define Poisson operator
\DeclareMathOperator{\Uniform}{Uniform} % Define Uniform operator
\DeclareMathOperator{\Cauchy}{Cauchy} % Define Cauchy operator
\DeclareMathOperator{\elpd}{elpd} % Define elpd operator
\DeclareMathOperator{\lppd}{lppd} % Define lppd operator
\DeclareMathOperator{\LOO}{LOO} % Define LOO operator
\DeclareMathOperator{\Ber}{\mathscr{B}} % Define Bernoulli operator
\DeclareMathOperator{\B}{B} % beta function
% \mbox{B}(a, b) % beta function
% \mbox{Beta}(a, b) % beta distribution
\newcommand{\R}{\textsf{R}} % Define R programming language symbol
\newcommand{\Real}{\mathbb{R}} % Define real number operator
\newcommand{\Prob}{\mathscr{P}}
\DeclareMathOperator{\argmin}{arg\,min} % thin space, limits on side in displays
\DeclareMathOperator{\argmax}{arg\,max} % no space, limits on side in displays

\raggedbottom % allow variable (ragged) site heights
\frenchspacing

\usepackage[
 labelfont=bf,
 font={small, it}
]{caption}
\usepackage{upquote} % print correct quotes in verbatim-environments
\usepackage{empheq}
\usepackage{xfrac}

\usepackage{polyglossia}
\setmainlanguage{italian}

% \DeclareMathSizes{10}{9}{7}{5}

\frontmatter
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Data Science per psicologi}
\author{Corrado Caudek}
\date{2022-01-20}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{corollary}{Corollario}[chapter]
\newtheorem{proposition}{Proposizione}[chapter]
\newtheorem{conjecture}{Congettura}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definizione}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Esempio}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Esercizio}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hypothesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Osservazione}
\newtheorem*{solution}{Soluzione}
\begin{document}
\maketitle

\cleardoublepage\newpage\thispagestyle{empty}\null
% \cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}
\begin{center}
\Large{Psicometria -- AA 2021/2022}

\vskip20pt

\includegraphics{images/confounding_variables.png}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\hypertarget{prefazione}{%
\chapter*{Prefazione}\label{prefazione}}


\emph{Data Science per psicologi} contiene il materiale delle lezioni dell'insegnamento di \emph{Psicometria B000286} (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell'Università degli Studi di Firenze. \emph{Psicometria} si propone di fornire agli studenti un'introduzione all'analisi dei dati in psicologia. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data science, ovvero un insieme di conoscenze/competenze che si pongono all'intersezione tra statistica (ovvero, richiedono la capacità di comprendere teoremi statistici) e informatica (ovvero, richiedono la capacità di sapere utilizzare un software).

\hypertarget{la-psicologia-e-la-data-science}{%
\section*{La psicologia e la Data science}\label{la-psicologia-e-la-data-science}}


Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questo Capitolo. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero Data science e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: ``perché dobbiamo perdere tanto tempo a studiare queste cose quando in realtà quello che ci interessa è tutt'altro?'' Questa è una bella domanda.

C'è una ragione molto semplice che dovrebbe farci capire perché la Data science è così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia \emph{gli individui} ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall'ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l'oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data science in psicologia: perché la Data science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici.

Sono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il ``lavoro sporco'' (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli ``tecnici'' della Data science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data science. Le tematiche della Data science non possono essere ignorate né dai ricercatori in psicologia né da coloro che svolgono la professione di psicologo al di fuori dell'Università. Infatti, anche i professionisti al di fuori dall'università non possono fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po' di Data science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo.

Le considerazioni precedenti cercano di chiarire il seguente punto: la Data science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di Data science è un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data science e verrà adottato un punto di vista bayesiano, che corrisponde all'approccio più recente e sempre più diffuso in psicologia.

\hypertarget{come-studiare}{%
\section*{Come studiare}\label{come-studiare}}


Il giusto metodo di studio per prepararsi all'esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l'esame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell'esame.

La prima fase dello studio, che è sicuramente individuale, è quella in cui è necessario acquisire le conoscenze teoriche relative ai problemi che saranno presentati all'esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (\(\textsf{R}\)) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso ci aiuta a capire meglio.

\hypertarget{sviluppare-un-metodo-di-studio-efficace}{%
\section*{Sviluppare un metodo di studio efficace}\label{sviluppare-un-metodo-di-studio-efficace}}


Avendo insegnato molte volte in passato un corso introduttivo di analisi dei dati ho notato nel corso degli anni che gli studenti con l'atteggiamento mentale che descriverò qui sotto generalmente ottengono ottimi risultati. Alcuni studenti sviluppano naturalmente questo approccio allo studio, ma altri hanno bisogno di fare uno sforzo per maturarlo. Fornisco qui sotto una breve descrizione del ``metodo di studio'' che, nella mia esperienza, è il più efficace per affrontare le richieste di questo insegnamento.

\begin{itemize}
\tightlist
\item
  Dedicate un tempo sufficiente al materiale di base, apparentemente facile; assicuratevi di averlo capito bene. Cercate le lacune nella vostra comprensione. Leggere presentazioni diverse dello stesso materiale (in libri o articoli diversi) può fornire nuove intuizioni.
\item
  Gli errori che facciamo sono i nostri migliori maestri. Istintivamente cerchiamo di dimenticare subito i nostri errori. Ma il miglior modo di imparare è apprendere dagli errori che commettiamo. In questo senso, una soluzione corretta è meno utile di una soluzione sbagliata. Quando commettiamo un errore questo ci fornisce un'informazione importante: ci fa capire qual è il materiale di studio sul quale dobbiamo ritornare e che dobbiamo capire meglio.
\item
  C'è ovviamente un aspetto ``psicologico'' nello studio. Quando un esercizio o problema ci sembra incomprensibile, la cosa migliore da fare è dire: ``mi arrendo'', ``non ho idea di cosa fare!''. Questo ci rilassa: ci siamo già arresi, quindi non abbiamo niente da perdere, non dobbiamo più preoccuparci. Ma non dobbiamo fermarci qui. Le cose ``migliori'' che faccio (se ci sono) le faccio quando non ho voglia di lavorare. Alle volte, quando c'è qualcosa che non so fare e non ho idea di come affontare, mi dico: ``oggi non ho proprio voglia di fare fatica'', non ho voglia di mettermi nello stato mentale per cui ``in 10 minuti devo risolvere il problema perché dopo devo fare altre cose''. Però ho voglia di \emph{divertirmi} con quel problema e allora mi dedico a qualche aspetto ``marginale'' del problema, che so come affrontare, oppure considero l'aspetto più difficile del problema, quello che non so come risolvere, ma invece di cercare di risolverlo, guardo come altre persone hanno affrontato problemi simili, opppure lo stesso problema in un altro contesto. Non mi pongo l'obiettivo ``risolvi il problema in 10 minuti'', ma invece quello di farmi un'idea ``generale'' del problema, o quello di capire un caso più specifico e più semplice del problema. Senza nessuna pressione. Infatti, in quel momento ho deciso di non lavorare (ovvero, di non fare fatica). Va benissimo se ``parto per la tangente'', ovvero se mi metto a leggere del materiale che sembra avere poco a che fare con il problema centrale (le nostre intuizioni e la nostra curiosità solitamente ci indirizzano sulla strada giusta). Quando faccio così, molto spesso trovo la soluzione del problema che mi ero posto e, paradossalmente, la trovo in un tempo minore di quello che, in precedenza, avevo dedicato a ``lavorare'' al problema. Allora perché non faccio sempre così? C'è ovviamente l'aspetto dei ``10 minuti'' che non è sempre facile da dimenticare. Sotto pressione, possiamo solo agire in maniera automatica, ovvero possiamo solo applicare qualcosa che già sappiamo fare. Ma se dobbiamo imparare qualcosa di nuovo, la pressione è un impedimento.
\item
  È utile farsi da soli delle domande sugli argomenti trattati, senza limitarsi a cercare di risolvere gli esercizi che vengono assegnati. Quando studio qualcosa mi viene in mente: ``se questo è vero, allora deve succedere quest'altra cosa''. Allora verifico se questo è vero, di solito con una simulazione. Se i risultati della simulazione sono quelli che mi aspetto, allora vuol dire che ho capito. Se i risultati sono diversi da quelli che mi aspettavo, allora mi rendo conto di non avere capito e ritorno indietro a studiare con più attenzione la teoria che pensavo di avere capito -- e ovviamente mi rendo conto che c'era un aspetto che avevo frainteso. Questo tipo di verifica è qualcosa che dobbiamo fare da soli, in prima persona: nessun altro può fare questo al posto nostro.
\item
  Non aspettatevi di capire tutto la prima volta che incontrate un argomento nuovo.\footnote{Ricordatevi inoltre che gli individui tendono a sottostimare la propria capacità di apprendere \citep{horn2021underestimating}.} È utile farsi una nota mentalmente delle lacune nella vostra comprensione e tornare su di esse in seguito per carcare di colmarle. L'atteggiamento naturale, quando non capiamo i dettagli di qualcosa, è quello di pensare: ``non importa, ho capito in maniera approssimativa questo punto, non devo preoccuparmi del resto''. Ma in realtà non è vero: se la nostra comprensione è superficiale, quando il problema verrà presentato in una nuova forma, non riusciremo a risolverlo. Per cui i dubbi che ci vengono quando studiamo qualcosa sono il nostro alleato più prezioso: ci dicono esattamente quali sono gli aspetti che dobbiamo approfondire per potere migliorare la nostra preparazione.
\item
  È utile sviluppare una visione d'insieme degli argomenti trattati, capire l'obiettivo generale che si vuole raggiungere e avere chiaro il contributo che i vari pezzi di informazione forniscono al raggiungimento di tale obiettivo. Questa organizzazione mentale del materiale di studio facilita la comprensione. È estremamente utile creare degli schemi di ciò che si sta studiando. Non aspettate che sia io a fornirvi un riepilogo di ciò che dovete imparare: sviluppate da soli tali schemi e tali riassunti.
\item
  Tutti noi dobbiamo imparare l'arte di trovare le informazioni, non solo nel caso di questo insegnamento. Quando vi trovate di fronte a qualcosa che non capite, o ottenete un oscuro messaggio di errore da un software, ricordatevi: ``Google is your friend''!
\end{itemize}

\begin{flushright}
Corrado Caudek\\
Marzo 2022 \end{flushright}

\mainmatter

\hypertarget{part-il-confronto-bayesiano-di-modelli}{%
\part{Il confronto bayesiano di modelli}\label{part-il-confronto-bayesiano-di-modelli}}

\hypertarget{ch:entropy}{%
\chapter{Entropia}\label{ch:entropy}}

Il principio base del metodo scientifico è la \emph{replicabilità} delle osservazioni: le osservazioni che non possono essere replicate sono poco interessanti. Parallelamente, una caratteristica fondamentale di un modello scientifico è la \emph{generalizzabilità}: se un modello è capace di descrivere soltanto le proprietà di uno specifico campione di osservazioni, allora è poco utile. Ma come è possibile valutare la generalizzabilità di un modello statistico? Questa è la domanda a cui cercheremo di rispondere in questa parte della dispensa. In questo Capitolo inizieremo questa discussione introducendo il concetto di entropia.

\hypertarget{la-generalizzabilituxe0-dei-modelli}{%
\section{La generalizzabilità dei modelli}\label{la-generalizzabilituxe0-dei-modelli}}

Secondo \citet{Johnson2022bayesrules}, nel valutare un modello, il ricercatore deve porsi tre domande critiche.

\begin{itemize}
\item
  Quali conseguenze più ampie derivano dall'inferenza? Come e chi ha raccolto i dati? Colui che svolge la ricerca otterrebbe di benefici manipolando i dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla società? Quali pregiudizi o strutture di potere possono essere coinvolti in questa analisi?
\item
  Che tipo di distorsioni sistematiche potrebbero essere presenti nell'analisi statistica? Ricordiamo la famosa citazione di George Box: ``Tutti i modelli sono sbagliati, ma alcuni sono utili''. È dunque importante sapere quanto è sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che è stato ipotizzato è adeguato per il fenomeno in esame?
\item
  Quanto è accurato il modello? Quanto sono lontane dalla realtà le previsioni del modello?
\end{itemize}

Per approfondire questi temi, si rinvia al testo di \citet{Johnson2022bayesrules}. Qui ci concentreremo su uno dei temi critici relativa alla validità di un modello, ovvero sul tema della generalizzabilità del modello.

Nella scienza l'utilità di una teoria viene verificata esaminando la corrispondenza tra predizioni teoriche e osservazioni. Se vi sono discrepanze significative tra predizioni e osservazioni ciò suggerisce che la teoria, o nella nostra visione più ristretta, il modello statistico, è poco utile. Il problema della capacità predittiva del modello non riguarda soltanto l'adeguatezza del modello in riferimento ad uno specifico campione di dati, ma riguarda anche la capacità di un modello statistico sviluppato in un campione di dati di ben adattarsi ad altri campioni della stessa popolazione.

In generale, i modelli statistici tendono a non generalizzarsi bene a un nuovo campione; questo perché sfruttano le caratteristiche specifiche dei dati del campione e tendono a produrre risultati eccessivamente ottimistici (cioè le dimensioni dell'effetto) che sovrastimano la dimensione dell'effetto atteso sia nella popolazione che in nuovi campioni. Benché i problemi della generalizzabilità dei modelli e il metodo chiave per valutarli -- ovvero, la convalida incrociata (\emph{cross-validation}) -- siano stati discussi sin dagli esordi della letteratura psicometrica \citep{lord1950efficiency}, tali temi sono stati sottovalutati nella formazione psicologica contemporanea e nella ricerca. Tuttavia, questi concetti diventeranno sempre più importanti considerata l'enfasi corrente sulla necessità di condurre ricerche replicabili. Un'introduzione a questi temi è fornita, da esempio, da \citet{song2021making}. Nello specifico, \citet{song2021making} mostrano che un modello che viene adattato a un campione (\emph{campione di calibrazione}) non si generalizza bene a un altro campione (\emph{campione di convalida}): la capacità predittiva del modello è minore quando il modello viene applicato al campione di convalida piuttosto che al campione di calibrazione. Questo problema è detto \emph{sovra-adattamento} (\emph{overfitting}). In generale, \citet{song2021making} mostrano come la capacità di generalizzazione del modello diminuisce (a) all'aumentare della complessità del modello, (b) al diminuire dell'ampiezza del campione di calibrazione, e (c) al diminuire della dimensione dell'effetto nella popolazione.

Sebbene i modelli statistici producono comunemente un sovra-adattamento, è anche possibile che essi producano un \emph{sotto-adattamento} (\emph{underfitting}) dei dati. Tale mancanza di adattamento è dovuta dalla variabilità campionaria e dalla complessità del modello. Il sotto-adattamento porta ad un \(R^2\) basso e ad un \emph{MSE} alto, sia nei campioni di calibrazione che in quelli di convalida. Per questo motivo, la scarsa generalizzabilità del modello può essere dovuta sia al sovra-adattamento che al sotto-adattamento del modello.

Per aumentarne la capacità di generalizzazione del modello devono essere soddisfatte tre condizioni: (a) campioni di calibrazione grandi, (b) dimensioni dell'effetto non piccole nella popolazione, e (c) modelli che non siano inutilmente complessi. Tuttavia, nella ricerca psicologica queste tre condizioni sono difficili da soddisfare: l'aumento della dimensione del campione spesso richiede l'utilizzo di maggiori risorse, la dimensione di un dato effetto nella popolazione non è soggetta alla discrezione dei ricercatori e la complessità del modello è spesso guidata da motivazioni teoriche. Pertanto, negli studi psicologici la generalizzabilità dei modelli è spesso problematica. Ciò rende necessario che il ricercatore fornisca informazioni aggiuntive relative alla capacità del modello di generalizzarsi a nuovi campioni. L'obiettivo di questa parte della dispensa è di descrivere come questo possa essere fatto utilizzando l'approccio bayesiano.

\hypertarget{capacituxe0-predittiva}{%
\section{Capacità predittiva}\label{capacituxe0-predittiva}}

Nel framework bayesiano il problema della generalizzabilità di un modello viene affrontato valutando la capacità predittiva del modello, laddove per capacità predittiva si intende la capacità di un modello, i cui parametri sono stati stimati usando le informazioni di un campione, di ben adattarsi ad un campione di osservazioni future. In questo Capitolo cercheremo di rispondere a tre domande.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Quali criteri consentono di valutare la capacità predittiva di un modello?
\item
  Come quantificare la capacità predittiva di un modello usando solo un campione di osservazioni?
\item
  Come confrontare le capacità predittive di modelli diversi?
\end{enumerate}

\hypertarget{il-rasoio-di-ockham}{%
\section{Il rasoio di Ockham}\label{il-rasoio-di-ockham}}

Il problema di scegliere il modello più adatto a spiegare un fenomeno di interesse è uno dei più importanti problemi in campo scientifico. I ricercatori si chiedono: il modello è completo? È necessario aggiungere un nuovo parametro al modello? Come può essere migliorato il modello? Se ci sono modelli diversi, qual'è il modello migliore?

Per rispondere a queste domande è possibile usare il rasoio di Ockham: \emph{frustra fit per plura quod potest fieri per pauciora} (``si fa inutilmente con molte cose ciò che si può fare con poche cose''). Parafrasando la massima si potrebbe dire: se due modelli descrivono i dati egualmente bene, viene sempre preferito il modello più semplice. Questo è il principio che sta alla base della ricerca scientifica.

Il rasoio di Ockham, però, non consente sempre di scegliere tra modelli alternativi. Se due modelli fanno le stesse predizioni ma differiscono in termini di complessità --- per esempio, relativamente al numero di parametri di cui sono costituiti --- allora è facile decidere: viene preferito il modello più semplice, anche perché, pragmaticamente, è il più facile da usare. Tuttavia, in generale, i modelli differiscono sia per complessità (ovvero, per il numero di parametri) che per accuratezza (ovvero, per la grandezza degli errori di predizione). In tali circostanze il rasoio di Ockham non è sufficiente: non consente infatti di trovare un equilibrio tra accuratezza e semplicità.

In questo Capitolo ci chiederemo come sia possibile misurare l'accuratezza predittiva di un modello. Ciò ci consentirà, in seguito, di usare il rasoio di Ockham: a parità di accuratezza, sarà possibile scegliere il modello più semplice. Ma nella pratica scientifica non si sacrifica mai l'accuratezza per la semplicità: il criterio prioritario è sempre l'accuratezza.

Secondo \citet{McElreath_rethinking}, la selezione tra modelli deve evitare due opposti errori: il sovra-adattamento e il sotto-adattamento. Tale problema va sotto il nome di \emph{bias-variance trade-off}: il sotto-adattamento, infatti, porta a distorsioni (\emph{bias}) nella stima dei parametri, mentre il sovra-adattamento porta a previsioni scadenti in campioni futuri. Spesso l'incertezza relativa alla scelta del modello (sotto-adattamento versus sovra-adattamento) passa inosservata ma il suo impatto può essere drammatico. Secondo \citet{hoeting1999bayesian}, \emph{``Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are.}

In questo Capitolo esamineremo alcune tecniche bayesiane che possono essere utilizzate per operare una selezione tra modelli alternativi, tenendo sotto controllo i pericoli del sovra-adattamento e del sotto-adattamento. In particolare, ci chiederemo quale, tra due o più modelli, sia quello da preferire in base al criterio della capacità predittiva.

\hypertarget{stargazing}{%
\subsection{Stargazing}\label{stargazing}}

Nella pratica concreta della ricerca, il metodo più comune per la selezione tra modelli alternativi utilizza i test di ipotesi statistiche di stampo frequentista. Questo metodo viene chiamato \emph{stargazing}, poiché richiede soltanto l'esame degli asterischi (\(**\)) che si trovano nell'output di un software statistico (gli asterischi marcano i coefficienti del modello che sono ``statisticamente significativi''): alcuni ricercatori ritengono che il modello con più stelline sia anche il modello migliore. Questo però non è vero. Al di là dei problemi legati ai test dell'ipotesi nulla, è sicuramente un errore usare i test di significatività per la selezione di modelli: i valori-\emph{p} non consentono di trovare un equilibrio tra \emph{underfitting} e \emph{overfitting}. Infatti, le variabili che migliorano la capacità predittiva di un modello non sono sempre statisticamente significative; d'altra parte, le variabili statisticamente significative non sempre migliorano la capacità predittiva di un modello.

Quando ci chiediamo quale, tra modelli alternativi, è il modello che meglio rappresenta il ``vero'' processo di generazione dei dati, ci troviamo di fronte al problema di quantificare il grado di ``vicinanza'' di un modello al ``vero'' processo di generazione dei dati. Si noti che, in tale confronto, facciamo riferimento sia alla famiglia distributiva così come ai valori dei parametri. Ad esempio, il modello \(y_i \sim \mathcal{N}(5, 3)\) è diverso dal modello \(y_i \sim \mathcal{N}(5, 6)\), ed è anche diverso dal modello \(y_i \sim \Gamma(2, 2)\). I primi due modelli appartengono alla stessa famiglia distributiva ma differiscono nei termini dei valori dei parametri; gli ultimi due modelli appartengono a famiglie distributive diverse (gaussiano vs.~Gamma). Per misurare il grado di ``vicinanza'' tra due modelli, \(\mathcal{M}_1\) e \(\mathcal{M}_2\), la metrica di gran lunga più popolare è la \emph{divergenza di Kullback-Leibler}. Per chiarire questo concetto è però prima necessario introdurre la nozione di entropia.

\hypertarget{la-misura-del-disordine}{%
\section{La misura del disordine}\label{la-misura-del-disordine}}

Se vogliamo ottenere una comprensione intuitiva del concetto di entropia\footnote{La nozione di entropia fu introdotta agli inizi del XIX secolo nel campo della termodinamica classica; il secondo principio della termodinamica è infatti basato sul concetto di entropia che, in generale, è assunto come una misura del disordine di un sistema fisico. Successivamente Boltzmann fornì una definizione statistica di entropia. Nel 1948 Shannon impiegò la nozione di entropia nell'ambito della teoria delle comunicazioni.} possiamo pensare a quant'è informativa una distribuzione. Maggiore è l'entropia di una distribuzione, meno informativa sarà quella distribuzione e più uniformemente verranno assegnate le probabilità agli eventi. In altri termini, ottenere la risposta di ``42'' è più informativo della risposta ``42 \(\pm\) 5'', che a sua volta è più informativo della risposta ``un numero qualsiasi''. L'entropia quantifica questa osservazione qualitativa.

Il concetto di entropia si applica sia alle distribuzioni continue sia a quelle discrete, ma è più facile da capire usando le distribuzioni discrete. Negli esempi successivi vedremo alcuni esempi applicati al caso discreto, ma gli stessi concetti si applicano al caso continuo.

\hypertarget{entropia-di-un-singolo-evento}{%
\subsection{Entropia di un singolo evento}\label{entropia-di-un-singolo-evento}}

Il concetto di entropia può essere usato per descrivere la quantità di informazione fornita da un evento. L'intuizione che sta alla base del concetto di entropia è che l'informazione fornita da un evento descrive la sorpresa suscitata dall'evento: gli eventi rari (a bassa probabilità) sono più sorprendenti -- e quindi forniscono più informazione -- degli eventi comuni (ad alta probabilità). In altre parole,

\begin{itemize}
\tightlist
\item
  un evento a bassa probabilità è sorprendente e fornisce molta informazione;
\item
  un evento ad alta probabilità è poco o per niente sorprendente e fornisce poca (o nessuna) informazione.
\end{itemize}

È possibile quantificare l'informazione fornita dal verificarsi di un evento mediante la probabilità di quell'evento. Una tale quantità di informazione è chiamata ``informazione di Shannon'', ``auto-informazione'' o semplicemente ``informazione'' e, per un evento discreto \(x\), può essere calcolata come:

\[
\text{informazione}(x) = -\log_2 p(x),
\]

dove \(\log_2\) è il logaritmo in base 2 e \(p(x)\) è la probabilità dell'evento \(x\).

La scelta del logaritmo in base 2 significa che l'unità di misura dell'informazione è il bit (cifre binarie). Questo può essere interpretato dicendo che l'informazione misura il numero di bit richiesti per rappresentare un evento.\footnote{È possibile pensare all'entropia nei termini del numero di domande sì/no che devono essere poste per ridurre l'incertezza. Per esempio, se in un certo giorno ci può essere solo sole o pioggia, per ridurre l'incertezza, a fine giornata chiediamo: ``ha piovuto?'' La risposta (sì/no) ad una singola domanda elimina l'incertezza, e quindi l'informazione ottenuta (ovvero, la riduzione dell'incertezza) è uguale ad 1 bit. Se in una certa giornata ci potrebbero essere sole, pioggia o neve, per ridurre l'incertezza sono necessarie due domande: ``c'era sole?''; ``ha piovuto?'' In questo secondo caso, l'informazione ottenuta (ovvero, la riduzione dell'incertezza) è uguale ad 2 bit. Usando un logaritmo in base 2, dunque, l'entropia può essere interpretata come il numero minimo di bit necessari per codificare la quantità di informazione nei dati.} Solitamente, si denota la quantità di informazione con \(h()\):

\[
h(x) = -\log p(x).
\]

Il segno negativo garantisce che il risultato sia sempre positivo o zero. L'informazione è zero quando la probabilità dell'evento è 1.0, ovvero quando l'evento è certo (assenza di sorpresa).

\begin{example}
Consideriamo il lancio di una moneta equilibrata. La probabilità di testa (e croce) è 0.5. La quantità di informazione di ottenere ``testa'' è dunque

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(}\FloatTok{0.5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

Per rappresentare questo evento abbiamo bisogno di 1 bit di informazione. Se la stessa moneta venisse lanciata \(n\) volte, la quantità di informazione necessaria per rappresentare questo evento (ovvero, questa sequenza di lanci) sarebbe pari a \(n\) bit. Se la moneta non è equilibrata e la probabilità di testa è 0.1, allora l'evento ``testa'' è più raro e richiede più di 3 bit di informazione:

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(}\FloatTok{0.1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 3.322}
\end{Highlighting}
\end{Shaded}

Consideriamo ora il lancio di un dado. Ci possiamo chiedere quanta informazione sia fornita, ad esempio, dall'evento ``esce il valore 6''. Dato che la probabilità di ottenere un 6 è più piccola della probabilità di ottenere ``testa'' nel lancio di una moneta, ci possiamo aspettare, nel lancio del dado, una maggiore sorpresa, ovvero una maggiore quantità di informazione. La quantità di informazione dell'evento ``esce un 6'' nel lancio di un dado

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 2.585}
\end{Highlighting}
\end{Shaded}

è infatti più del doppio della quantità di informazione dell'evento ``esce testa'' nel lancio di una moneta.
\end{example}

\begin{example}
Nella figura successiva viene esaminata la relazione tra probabilità e informazione, per valori di probabilità nell'intervallo tra 0 e 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{1000}\NormalTok{)}
\NormalTok{h }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(p)}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{tibble}\NormalTok{(p, h), }\FunctionTok{aes}\NormalTok{(p, h)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Probabilità"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Informazione"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-6-1} \end{center}

La figura mostra che questa relazione non è lineare, è infatti leggermente sublineare. Questo ha senso dato che abbiamo usato una funzione logaritmica.
\end{example}

\hypertarget{entropia-di-una-variabile-casuale}{%
\subsection{Entropia di una variabile casuale}\label{entropia-di-una-variabile-casuale}}

Possiamo estendere questa discussione pensando ad un insieme di eventi, ovvero ad una distribuzione. Nella teoria della probabilità, per fare riferimento ad un insieme di eventi e alle associate probabilità, usiamo la nozione di variabile casuale. L'entropia quantifica l'informazione che viene fornita da una variabile casuale.

\begin{definition}
Sia \(Y = y_1, \dots, y_n\) una variabile casuale e \(p_t(y)\) una distribuzione di probabilità su \(Y\). Si definisce la sua entropia (detta di Shannon) come:

\begin{equation}
H(Y) = - \sum_{i=1}^n p_t(y_i) \cdot \log_2 p_t(y_i).
\label{eq:entropy}
\end{equation}
\end{definition}

Per interpretare la \eqref{eq:entropy}, consideriamo un esempio discusso da \citet{martin2022bayesian}.

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{images/entropy_example} 

}

\caption{Funzioni di massa di probabilità e associata entropia.}\label{fig:entropy-example}
\end{figure}

Nella figura \ref{fig:entropy-example} sono rappresentate sei distribuzioni. viene anche riportato il valore di entropia di ciascuna distribuzione. La distribuzione con il picco più pronunciato o con la dispersione minore è \texttt{q}, e questa è la distribuzione con il valore di entropia più basso tra le sei distribuzioni considerate. La distribuzione \texttt{q\ \textasciitilde{}\ binom(n\ =\ 10,\ p\ =\ 0.75)}, e quindi ci sono 11 possibili eventi. \texttt{qu} è una distribuzione uniforme con gli stessi 11 possibili eventi. Possiamo vedere che l'entropia di \texttt{qu} è maggiore di quella di \texttt{q}. Infatti, se calcoliamo l'entropia di distribuzioni binomiali con \(n = 10\) e valori diversi di \(p\) ci possiamo rendere conto che nessuno di tali valori ha un'entropia maggiore di \texttt{qu}. Abbiamo bisogno di aumentare \(n ≈ 3\) volte per trovare la prima distribuzione binomiale con entropia maggiore di \texttt{qu}. Passiamo alla riga successiva. Generiamo la distribuzione \texttt{r} prendendo \texttt{q} e spostandolo a destra e quindi normalizzando (per garantire che la somma di tutte le probabilità sia 1). Poiché \texttt{r} ha una dispersione maggiore di \texttt{q}, la sua entropia è maggiore. \texttt{ru} è la distribuzione uniforme con lo stesso numero di possibili eventi di \texttt{r} (22) -- si noti che sono stati inclusi come possibili valori anche quelli nella valle tra i due picchi. Ancora una volta l'entropia della versione uniforme è quella con l'entropia più grande.

Gli esempi discussi finora sembrano suggerire che l'entropia sia proporzionale alla varianza di una distribuzione. Verifichiamo questa intuizione esaminiamo le ultime due distribuzioni della figura \ref{fig:entropy-example}. La distribuzione \texttt{s} è simile a \texttt{r} ma è presente una maggiore separazione tra i due picchi della distribuzione -- dunque, la dispersione aumenta. Ciò nonostante, l'entropia resta invariata. Quindi la relazione tra entropia e varianza non è così semplice come sembrava. Il risultato che abbiamo trovato può essere spiegato dicendo che, nel calcolo dell'entropia, non vengono considerati gli eventi con probabilità nulla (quindi, nell'esempio, è stato possibile aumentare la varianza della distribuzione senza cambiare l'entropia). La distribuzione \texttt{su} è stata costruita sostituendo i due picchi in \texttt{s} con \texttt{qu} (e normalizzando). Possiamo vedere che \texttt{su} ha un'entropia minore di \texttt{ru}, anche se \texttt{su} ha una dispersione maggiore di \texttt{ru}. Questo è dovuto al fatto che \texttt{su} distribuisce la probabilità totale tra un numero minore di eventi (22) di \texttt{ru} (che ne conta 23); quindi è sensato che \texttt{su} abbia un'entropia minore di \texttt{ru}.

Per chi fosse interessato, il codice Python usato per generare la figura \ref{fig:entropy-example} è riportato qui sotto.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ scipy}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{x }\OperatorTok{=} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{26}\NormalTok{)}
\NormalTok{q\_pmf }\OperatorTok{=}\NormalTok{ scipy.stats.binom(}\DecValTok{10}\NormalTok{, }\FloatTok{0.75}\NormalTok{).pmf(x)}
\NormalTok{qu\_pmf }\OperatorTok{=}\NormalTok{ scipy.stats.randint(}\DecValTok{0}\NormalTok{, np.}\BuiltInTok{max}\NormalTok{(np.nonzero(q\_pmf))}\OperatorTok{+}\DecValTok{1}\NormalTok{).pmf(x) }
\NormalTok{r\_pmf }\OperatorTok{=}\NormalTok{ (q\_pmf }\OperatorTok{+}\NormalTok{ np.roll(q\_pmf, }\DecValTok{12}\NormalTok{)) }\OperatorTok{/} \DecValTok{2}
\NormalTok{ru\_pmf }\OperatorTok{=}\NormalTok{ scipy.stats.randint(}\DecValTok{0}\NormalTok{, np.}\BuiltInTok{max}\NormalTok{(np.nonzero(r\_pmf))}\OperatorTok{+}\DecValTok{1}\NormalTok{).pmf(x) }
\NormalTok{s\_pmf }\OperatorTok{=}\NormalTok{ (q\_pmf }\OperatorTok{+}\NormalTok{ np.roll(q\_pmf, }\DecValTok{15}\NormalTok{)) }\OperatorTok{/} \DecValTok{2}
\NormalTok{su\_pmf }\OperatorTok{=}\NormalTok{ (qu\_pmf }\OperatorTok{+}\NormalTok{ np.roll(qu\_pmf, }\DecValTok{15}\NormalTok{)) }\OperatorTok{/} \DecValTok{2}

\NormalTok{\_, ax }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{5}\NormalTok{), sharex}\OperatorTok{=}\VariableTok{True}\NormalTok{, sharey}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{  constrained\_layout}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{ax }\OperatorTok{=}\NormalTok{ np.ravel(ax)}
\NormalTok{zipped }\OperatorTok{=} \BuiltInTok{zip}\NormalTok{([q\_pmf, qu\_pmf, r\_pmf, ru\_pmf, s\_pmf, su\_pmf], }
\NormalTok{  [}\StringTok{"q"}\NormalTok{, }\StringTok{"qu"}\NormalTok{, }\StringTok{"r"}\NormalTok{, }\StringTok{"ru"}\NormalTok{, }\StringTok{"s"}\NormalTok{, }\StringTok{"su"}\NormalTok{])}
\ControlFlowTok{for}\NormalTok{ idx, (dist, label) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(zipped):}
\NormalTok{    ax[idx].vlines(x, }\DecValTok{0}\NormalTok{, dist, label}\OperatorTok{=}\SpecialStringTok{f"H = }\SpecialCharTok{\{}\NormalTok{scipy}\SpecialCharTok{.}\NormalTok{stats}\SpecialCharTok{.}\NormalTok{entropy(dist)}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}\NormalTok{) }
\NormalTok{    ax[idx].set\_title(label)}
\NormalTok{    ax[idx].legend(loc}\OperatorTok{=}\DecValTok{1}\NormalTok{, handlelength}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{example}
Consideriamo un esempio riguardante le previsioni del tempo. Supponiamo che le probabilità di pioggia e sole siano, rispettivamente, \(p_1 = 0.3\) e \(p_2 = 0.7\). Quindi

\[
H(p) = − [p(y_1) \log_2 p(y_1) + p(y_2) \log_2 p(y_2)] \approx 0.61.
\]

Svolgendo i calcoli in \(\R\) abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{ , }\FloatTok{0.7}\NormalTok{)}
\SpecialCharTok{{-}}\FunctionTok{sum}\NormalTok{(p}\SpecialCharTok{*}\FunctionTok{log}\NormalTok{(p))}
\CommentTok{\#\textgreater{} [1] 0.6109}
\end{Highlighting}
\end{Shaded}

Se però viviamo a Las Vegas, allora le probabilità di pioggia e sole saranno qualcosa come \(p(y_1) = 0.01\) e \(p(y_2) = 0.99\). In questo secondo caso, l'entropia è 0.06, ovvero, molto minore di prima. Infatti, a Las Vegas non piove quasi mai, per cui quando abbiamo imparato che, in un certo giorno, non ha piovuto, abbiamo imparato molto poco rispetto a quello che già sapevamo in precedenza.
\end{example}

\begin{example}

Abbiamo visto in precedenza che, se gli esiti possibili sono pioggia o sole con \(p(y_1) = 0.7\), \(p(y_2) = 0.3\), allora l'entropia è

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\NormalTok{(}\FloatTok{0.7} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} \FloatTok{0.3} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.3}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 0.6109}
\end{Highlighting}
\end{Shaded}

Se gli esiti possibili sono pioggia, neve o sole con \(p(y_1) = 0.7\), \(p(y_2) = 0.15\) e \(p(y_3) = 0.15\), rispettivamente, allora l'entropia sarà maggiore, ovvero pari a 0.82.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\NormalTok{(}\FloatTok{0.7} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} \FloatTok{0.15} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.15}\NormalTok{) }\SpecialCharTok{+} \FloatTok{0.15} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.15}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 0.8188}
\end{Highlighting}
\end{Shaded}

\end{example}

\hypertarget{commenti-e-considerazioni-finali}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali}}


In questo Capitolo abbiamo visto come sia possibile quantificare l'incertezza tramite l'entropia. Ma come è possibile usare l'entropia dell'informazione per specificare quanto differisce un modello dal vero meccanismo generatore dei dati? La risposta a questa domanda è fornita dalla divergenza di Kullback-Leibler (Capitolo \ref{ch:kl-div}).

\hypertarget{ch:kl-div}{%
\chapter{La divergenza di Kullback-Leibler}\label{ch:kl-div}}

È comune in statistica utilizzare una distribuzione di probabilità \(q\) per approssimare un'altra distribuzione \(p\) -- generalmente, questo viene fatto se \(p\) non è conosciuta o è troppo complessa. In questi casi possiamo chiederci quanta informazione viene perduta usando \(q\) al posto di \(p\), o equivalentemente quanta ulteriore incertezza stiamo introducendo nell'analisi statistica. La quantificazione di questo incremento di incertezza viene fornita dalla divergenza di Kullback-Leibler.

\hypertarget{la-perdita-di-informazione}{%
\section{La perdita di informazione}\label{la-perdita-di-informazione}}

Intuitivamente, per quantificare la perdita di informazione quando una distribuzione approssimata \(q\) viene usata per rappresentare la vera distribuzione \(p\) è necessaria una quantità che ha valore zero quando \(q\) è uguale a \(p\), e un valore positivo altrimenti. Seguendo la definizione \eqref{eq:entropy} di entropia, possiamo quantificare una tale perdita di informazione calcolando il valore atteso della differenza tra \(\log(p)\) e \(\log(q)\). Questa quantità è chiamata \emph{entropia relativa} o \emph{divergenza di Kullback-Leibler}:

\begin{equation}
\mathbb{KL} (p \mid\mid q) = \E (\log p - \log q)
\label{eq:kldivergence}
\end{equation}

La divergenza \(\mathbb{KL} (p \mid\mid q)\) corrisponde alla differenza media nelle probabilità logaritmiche quando \(q\) viene usato per approssimare \(p\). Poiché gli eventi si manifestano secondo \(p\), è necessario calcolare il valore atteso rispetto a \(p\). Per distribuzioni discrete abbiamo:

\begin{equation}
\mathbb{KL} (p \mid\mid q) = \sum_i^n p_i (\log p_i - \log q_i) = \sum_i^n p_i \log \frac{p_i}{q_i}
\end{equation}

Riarrangiando i termini otteniamo:

\begin{equation}
\mathbb{KL} (p \mid\mid q) = -\sum_i^n p_i (\log q_i - \log p_i),
\end{equation}

ovvero,

\begin{equation}
\mathbb{KL} (p \mid\mid q) = \underbrace{-\sum_i^n p_i \log q_i}_{H(p, q)} - \underbrace{\left(-\sum_i^n p_i \log p_i\right)}_{H(p)},
\end{equation}

laddove \(H(p)\) è l'entropia di \(p\) e \(H(p, q) = −\E [\log q]\) può essere intesa come l'entropia di \(q\), ma valutata secondo i valori di \(p\).

Riarrangiando l'equazione precedente otteniamo:

\begin{equation}
H(p, q) = H(p) + \mathbb{KL} (p \mid\mid q),
\end{equation}

il che mostra come la divergenza KL può essere interpretata come l'incremento di entropia rispetto a \(H(p)\), quando si usa \(q\) per rappresentare \(p\).

\begin{example}
\citep[da][]{McElreath_rethinking} Sia la distribuzione target \(p = \{0.3, 0.7\}\). Supponiamo che la distribuzione approssimata \(q\) possa assumere valori da \(q = \{0.01, 0.99\}\) a \(q = \{0.99, 0.01\}\). Calcoliamo la divergenza KL.

Le istruzioni \(\R\) sono le seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\OtherTok{\textless{}{-}}
  \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{p\_1 =}\NormalTok{ .}\DecValTok{3}\NormalTok{,}
    \AttributeTok{p\_2 =}\NormalTok{ .}\DecValTok{7}\NormalTok{,}
    \AttributeTok{q\_1 =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =}\NormalTok{ .}\DecValTok{01}\NormalTok{, }\AttributeTok{to =}\NormalTok{ .}\DecValTok{99}\NormalTok{, }\AttributeTok{by =}\NormalTok{ .}\DecValTok{01}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{q\_2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ q\_1}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{d\_kl =}\NormalTok{ (p\_1 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_1 }\SpecialCharTok{/}\NormalTok{ q\_1)) }\SpecialCharTok{+}\NormalTok{ (p\_2 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_2 }\SpecialCharTok{/}\NormalTok{ q\_2))}
\NormalTok{  )}

\FunctionTok{head}\NormalTok{(t)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 5}
\CommentTok{\#\textgreater{}     p\_1   p\_2   q\_1   q\_2  d\_kl}
\CommentTok{\#\textgreater{}   \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1   0.3   0.7  0.01  0.99 0.778}
\CommentTok{\#\textgreater{} 2   0.3   0.7  0.02  0.98 0.577}
\CommentTok{\#\textgreater{} 3   0.3   0.7  0.03  0.97 0.462}
\CommentTok{\#\textgreater{} 4   0.3   0.7  0.04  0.96 0.383}
\CommentTok{\#\textgreater{} 5   0.3   0.7  0.05  0.95 0.324}
\CommentTok{\#\textgreater{} 6   0.3   0.7  0.06  0.94 0.276}
\end{Highlighting}
\end{Shaded}

\noindent Nella figura seguente sull'asse delle ascisse sono rappresentati i valori \(q\) e sull'asse delle ordinante sono riportati i corrispondenti valori \(\mathbb{KL}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ q\_1, }\AttributeTok{y =}\NormalTok{ d\_kl)) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ .}\DecValTok{3}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\AttributeTok{geom =} \StringTok{"text"}\NormalTok{, }\AttributeTok{x =}\NormalTok{ .}\DecValTok{4}\NormalTok{, }\AttributeTok{y =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{label =} \StringTok{"q = p"}\NormalTok{,}
           \AttributeTok{size =} \FloatTok{3.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"q[1]"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Divergenza di q da p"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-13-1} \end{center}

Tanto meglio la distribuzione \(q\) approssima la distribuzione target tanto più piccolo è il valore di divergenza KL.
\end{example}

\begin{example}
Sia \(p\) una distribuzione binomiale di parametri \(\theta = 0.2\) e \(n = 5\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{p }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{true\_py }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\NormalTok{n, n, }\FloatTok{0.2}\NormalTok{)}
\NormalTok{true\_py}
\CommentTok{\#\textgreater{} [1] 0.4096 0.4096 0.1536 0.0256 0.0016}
\end{Highlighting}
\end{Shaded}

\noindent Sia \(q_1\) una approssimazione a \(p\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.46}\NormalTok{, }\FloatTok{0.42}\NormalTok{, }\FloatTok{0.10}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\NormalTok{q1}
\CommentTok{\#\textgreater{} [1] 0.46 0.42 0.10 0.01 0.01}
\end{Highlighting}
\end{Shaded}

Sia \(q_2\) una distribuzione uniforme:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{q2}
\CommentTok{\#\textgreater{} [1] 0.2 0.2 0.2 0.2 0.2}
\end{Highlighting}
\end{Shaded}

La divergenza KL di \(q_1\) da \(p\) è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(true\_py }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(true\_py }\SpecialCharTok{/}\NormalTok{ q1))}
\CommentTok{\#\textgreater{} [1] 0.02925}
\end{Highlighting}
\end{Shaded}

La divergenza KL di \(q_2\) da \(p\) è:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(true\_py }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(true\_py }\SpecialCharTok{/}\NormalTok{ q2))}
\CommentTok{\#\textgreater{} [1] 0.4864}
\end{Highlighting}
\end{Shaded}

È chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale \(p\), usiamo la distribuzione uniforme \(q_2\) anziché \(q_1\).
\end{example}

\hypertarget{la-divergenza-dipende-dalla-direzione}{%
\section{La divergenza dipende dalla direzione}\label{la-divergenza-dipende-dalla-direzione}}

La divergenza KL non è una vera e propria metrica: per esempio, non è simmetrica. In generale, \(\mathbb{KL}(p \mid\mid q) \neq \mathbb{KL}(q \mid\mid p)\), ovvero la \(\mathbb{KL}\) da \(p\) a \(q\) è diversa dalla \(\mathbb{KL}\) da \(q\) a \(p\).

\begin{example}

Usando le seguenti istruzioni \(\R\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{direction =} \FunctionTok{c}\NormalTok{(}\StringTok{"Da q a p"}\NormalTok{, }\StringTok{"Da p a q"}\NormalTok{),}
       \AttributeTok{p\_1 =} \FunctionTok{c}\NormalTok{(.}\DecValTok{01}\NormalTok{, .}\DecValTok{7}\NormalTok{),}
       \AttributeTok{q\_1 =} \FunctionTok{c}\NormalTok{(.}\DecValTok{7}\NormalTok{, .}\DecValTok{01}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_1,}
         \AttributeTok{q\_2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ q\_1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{d\_kl =}\NormalTok{ (p\_1 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_1 }\SpecialCharTok{/}\NormalTok{ q\_1)) }\SpecialCharTok{+}\NormalTok{ (p\_2 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_2 }\SpecialCharTok{/}\NormalTok{ q\_2)))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 6}
\CommentTok{\#\textgreater{}   direction   p\_1   q\_1   p\_2   q\_2  d\_kl}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Da q a p   0.01  0.7   0.99  0.3   1.14}
\CommentTok{\#\textgreater{} 2 Da p a q   0.7   0.01  0.3   0.99  2.62}
\end{Highlighting}
\end{Shaded}

\end{example}

\hypertarget{confronto-tra-modelli}{%
\section{Confronto tra modelli}\label{confronto-tra-modelli}}

La divergenza KL viene utilizzata nel confronto tra modelli, ovvero ci consente di quantificare l'informazione che viene perduta quando utilizziamo la distribuzione di probabilità ipotizzata da un modello, chiamiamola \(p_{\mathcal{M}}\), per approssimare la distribuzione di probabilità del vero modello generatore dei dati, \(p_t\).

Nel Capitolo \ref{ch:intro-bayes-inference} abbiamo introdotto il concetto di distribuzione predittiva a posteriori:

\[
p(\tilde{y} \mid y) = \int_\Theta p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}\!\theta .
\]

La distribuzione predittiva a posteriori descrive il tipo di dati che ci aspettiamo vengano prodotti dal modello generativo \(\mathcal{M}\), alla luce delle nostre credenze iniziali, \(p(\theta)\) e dei dati osservati \(y\). Quando valutiamo un modello ci chiediamo in che misura \(p_{\mathcal{M}}(\tilde{y} \mid y)\) approssimi \(p_t(\tilde{y})\). Cioè, ci chiediamo quanto siano simili i dati \(p_{\mathcal{M}}(\cdot)\) prodotti dal modello \(\mathcal{M}\) ai dati prodotti dal vero processo generatore dei dati \(p_t(\cdot)\).

Una misura della ``somiglianza'' tra la distribuzione \(q_{\mathcal{M}}\) ipotizzata dal modello \(\mathcal{M}\) e la distribuzione \(p_t\) del vero modello generatore dei dati è fornita dalla divergenza di Kullback-Leibler \(\mathbb{KL}(p_t \mid\mid q_{\mathcal{M}})\). Supponendo di avere \(k\) modelli della distribuzione a posteriori, \(\{q_{\mathcal{M}_1}, q_{\mathcal{M}_2}, \dots, q_{\mathcal{M}_k}\}\), e di conoscere il vero modello generatore dei dati, possiamo scrivere

\begin{align}
\mathbb{KL} (p_t \mid\mid q_{\mathcal{M}_1}) &= \E (\log p_{\mathcal{M}_0}) - \E (\log q_{\mathcal{M}_1})\notag\\
\mathbb{KL} (p_t \mid\mid q_{\mathcal{M}_2}) &= \E (\log p_t) - \E (\log q_{\mathcal{M}_2})\notag\\
&\cdots\notag\\
\mathbb{KL} (p_t \mid\mid q_{\mathcal{M}_k}) &= \E (\log p_{\mathcal{M}_0}) - \E (\log q_{\mathcal{M}_k}).
\label{eq:kl-mod-comp}
\end{align}

La \eqref{eq:kl-mod-comp} può sembrare un esercizio futile poiché nella vita reale non conosciamo il vero modello generatore dei dati. È però facile rendersi conto che, poiché \(p_t\) è la stessa per tutti i confronti, diventa possibile costruire un ordinamento dei modelli basato unicamente sul secondo termine della \eqref{eq:kl-mod-comp}, ovvero senza nessun riferimento al vero modello generatore dei dati. Per un generico modello \(\mathcal{M}\), il secondo termine della \eqref{eq:kl-mod-comp} può essere scritto come:

\begin{equation}
\E \log p_{\mathcal{M}}(y) = \int_{-\infty}^{+\infty}p_{t}(y)\log p_{\mathcal{M}}(y) \,\operatorname {d}\!y .
\label{eq:kl-div-cont-t2}
\end{equation}

\hypertarget{expected-log-predictive-density}{%
\section{Expected log predictive density}\label{expected-log-predictive-density}}

Le previsioni del modello \(\mathcal{M}\) sui nuovi dati futuri sono date dalla distribuzione predittiva a posteriori. Possiamo dunque riscrivere la \eqref{eq:kl-div-cont-t2} come

\begin{equation}
\elpd = \int_{\tilde{y}} p_{t}(\tilde{y}) \log p(\tilde{y} \mid y) \,\operatorname {d}\!\tilde{y}.
\label{eq:elpd}
\end{equation}

La \eqref{eq:elpd} è chiamata \emph{expected log predictive density} (\(\elpd\)) e fornisce la risposta al problema che ci eravamo posti: nel confronto tra modelli, come è possibile scegliere il modello più simile al vero meccanismo generatore dei dati? Possiamo pensare alla \eqref{eq:elpd} dicendo che descrive la distribuzione predittiva a posteriori del modello ponderando la verosimiglianza dei possibili (sconosciuti) dati futuri (\(\tilde{y}\)) con la vera distribuzione \(p_t\). Di conseguenza, valori \(\elpd\) più grandi identificano il modello che risulta più simile al vero meccanismo generatore dei dati.

Non dobbiamo preoccuparci di trovare una formulazione analitica della distribuzione predittiva a posteriori \(p(\tilde{y} \mid y)\) perché, come abbiamo visto nel Capitolo \ref{chapter-ppc}, è possibile approssimare tale distribuzione mediante simulazione. Notiamo però che la \eqref{eq:elpd} include un termine, \(p_t(\tilde{y})\), il quale descrive la distribuzione dei dati futuri \(\tilde{y}\) secondo il vero modello generatore dei dati. Il termine \(p_t\), ovviamente, è ignoto.\footnote{Se il modello sottostante i dati fosse noto non avremmo bisogno di cercare il modello migliore, perché \(p_t\) è il modello migliore.} Di conseguenza, la quantità \(\elpd\) non può mai essere calcolata in maniera esatta, ma può solo essere stimata. Il secondo problema di questo Capitolo è capire come la \eqref{eq:elpd} possa essere stimata utilizzando un campione di osservazioni.

\hypertarget{log-pointwise-predictive-density}{%
\subsection{Log pointwise predictive density}\label{log-pointwise-predictive-density}}

Ingenuamente, potremmo pensare di stimare la \eqref{eq:elpd} ipotizzando che la distribuzione del campione coincida con \(p_t\). Usare la distribuzione del campione come proxy del vero modello generatore dei dati (ovvero, ipotizzare che la distribuzione del campione rappresenti fedelmente \(p_t\)) comporta due conseguenze:

\begin{itemize}
\tightlist
\item
  non è necessario ponderare per \(p_t\), in quanto assumiamo che la distribuzione empirica del campione corrisponda a \(p_t\) (ciò significa assumere che i valori più comunemente osservati nel campione siano anche quelli più verosimili nella vera distribuzione \(p_t\));
\item
  dato che il campione è finito, anziché eseguire un'operazione di integrazione possiamo semplicemente sommare la densità predittiva a posteriori delle osservazioni.
\end{itemize}

Questo conduce alla seguente equazione:\footnote{In riferimento alla notazione, ricordiamo che \citet{gelman2014understanding} distinguono tra \(y^{rep}\) e \(\tilde{y}\). I valori \(y^{rep}\) corrispondono ad un'altra possibile realizzazione del medesimo modello statistico che ha prodotto \(y\) mediante determinati valori dei parametri \(\theta\) (repliche sotto lo stesso modello statistico). I valori \(\tilde{y}\) corrispondono invece ad un campione empirico di dati osservato in qualche futura occasione.}

\begin{equation}
\frac{1}{n} \sum_{i=1}^n \log p(y_i^{rep} \mid y).
\label{eq:1n-lppd}
\end{equation}

La quantità \eqref{eq:1n-lppd}, senza il passaggio finale della divisione per il numero di osservazioni, è chiamata \emph{log pointwise predictive density} (\(\lppd\))

\begin{equation}
\lppd = \sum_{i=1}^n \log p(y_i^{rep} \mid y)
\label{eq:lppd}
\end{equation}

e corrisponde alla somma delle densità predittive logaritmiche delle \(n\) osservazioni. Valori più grandi della \eqref{eq:lppd} sono da preferire perché indicano una maggiore accuratezza media. È anche comune vedere espressa la quantità precedente nei termini della \emph{devianza}, ovvero alla \(\lppd\) moltiplicata per -2. In questo secondo caso sono da preferire valori piccoli.

È importante notare che \(\lppd\) fornisce una \emph{sovrastima} della \eqref{eq:elpd}. Tale sovrastima è dovuta al fatto che, nel calcolo della \eqref{eq:lppd}, abbiamo usato \(p(y^{rep} \mid y)\) al posto di \(p(\tilde{y} \mid y)\): in altri termini, abbiamo considerato le osservazioni del campione come se fossero un nuovo campione di dati. In una serie di simulazioni, \citet{McElreath_rethinking} esamina il significato di questa sovrastima. Nelle simulazioni la devianza viene calcolata come funzione della complessità (ovvero, il numero di parametri) del modello. La simulazione mostra che \(\lppd\) aumenta al crescere del numero di parametri del modello. Ciò significa che \(\lppd\) mostra lo stesso limite del coefficiente di determinazione: aumenta all'aumentare della complessità del modello.

\begin{example}

Esaminiamo un esempio tratto da \href{https://vasishth.github.io/bayescogsci/book/expected-log-predictive-density-of-a-model.html}{Bayesian Data Analysis for Cognitive Science} nel quale la \(\elpd\) viene calcolata in forma esatta oppure mediante approssimazione. Supponiamo di disporre di un campione di \(n\) osservazioni. Supponiamo inoltre di conoscere il vero processo generativo dei dati (qualcosa che in pratica non è mai possibile), ovvero:

\[
p_t(y) = \Beta(1, 3).
\] I dati sono

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{75}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{y\_data }\OtherTok{\textless{}{-}} \FunctionTok{rbeta}\NormalTok{(n, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\FunctionTok{head}\NormalTok{(y\_data)}
\CommentTok{\#\textgreater{} [1] 0.55062 0.13346 0.80251 0.21431 0.01913 0.08677}
\end{Highlighting}
\end{Shaded}

Supponiamo inoltre di avere adattato ai dati un modello bayesiano \(\mathcal{M}\) e di avere ottenuto la distribuzione a posteriori per i parametri del modello. Inoltre, supponiamo di avere derivato la forma analitica della distribuzione predittiva a posteriori per il modello:

\[
p(y^{rep} \mid y) \sim \Beta(2, 2).
\]

Questa distribuzione ci dice quanto sono credibili i possibili dati futuri.

Conoscendo la vera distribuzione dei dati \(p_t(y)\) possiamo calcolare in forma esatta la quantità \(\elpd\), ovvero

\[
\elpd = \int_{y^{rep}}p_{t}(y^{rep})\log p(y^{rep} \mid y) \,\operatorname {d}\!y^{rep}.
\]

Svolgiamo i calcoli in \(\R\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# True distribution}
\NormalTok{p\_t }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) }\FunctionTok{dbeta}\NormalTok{(y, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\CommentTok{\# Predictive distribution}
\NormalTok{p }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) }\FunctionTok{dbeta}\NormalTok{(y, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\CommentTok{\# Integration}
\NormalTok{integrand }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) }\FunctionTok{p\_t}\NormalTok{(y) }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FunctionTok{p}\NormalTok{(y))}
\FunctionTok{integrate}\NormalTok{(}\AttributeTok{f =}\NormalTok{ integrand, }\AttributeTok{lower =} \DecValTok{0}\NormalTok{, }\AttributeTok{upper =} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} {-}0.3749 with absolute error \textless{} 6.8e{-}07}
\end{Highlighting}
\end{Shaded}

Tuttavia, in pratica non conosciamo mai \(p_t(y)\). Quindi approssimiamo \(\elpd\) usando la \eqref{eq:elpd}:

\[
\frac{1}{n} \sum_{i=1}^n \log p(y_i \mid y).
\]

Così facendo, e svolgendo i calcoli in \(\R\), otteniamo un valore diverso da quello trovato in precedenza:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{/}\NormalTok{n }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(}\FunctionTok{log}\NormalTok{(}\FunctionTok{p}\NormalTok{(y\_data)))}
\CommentTok{\#\textgreater{} [1] {-}0.3639}
\end{Highlighting}
\end{Shaded}

\end{example}

\hypertarget{commenti-e-considerazioni-finali-1}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-1}}


Dato che non conosciamo il vero meccanismo generatore dei dati \(p\), possiamo usare la distribuzione dei dati osservata come proxy per la vera distribuzione \(p\). Quindi, invece di ponderare la distribuzione predittiva in base alla densità reale di tutti i possibili dati futuri, utilizziamo semplicemente le \(n\) osservazioni che abbiamo. Possiamo farlo perché assumiamo che le nostre osservazioni costituiscano un campione dalla vera distribuzione dei dati: in base a questa ipotesi, nel campione ci aspettiamo di osservare più frequentemente quelle osservazioni che hanno una maggiore verosimiglianza nella vera distribuzione \(p\). È così possibile giungere ad una stima numerica della \(\elpd\) chiamata \emph{log pointwise predictive density} (\(\lppd\)).

\hypertarget{ch:info-criterion}{%
\chapter{Criterio di informazione e convalida incrociata}\label{ch:info-criterion}}

Nel Capitolo precedente abbiamo visto che la \eqref{eq:lppd} fornisce una sovrastima della \(\elpd\). Il modo migliore per stimare \(\elpd\) è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare \(\elpd\) sul nuovo campione. Questa procedura è chiamata \emph{out-of-sample validation}. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della \(\elpd\) che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:

\begin{itemize}
\tightlist
\item
  l'introduzione di un fattore di correzione;
\item
  la convalida incrociata cosiddetta K-fold.
\end{itemize}

Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell'informazione e alla procedura della convalida incrociata.

\hypertarget{aic-dic-e-waic}{%
\section{AIC, DIC e WAIC}\label{aic-dic-e-waic}}

Allo scopo di evitare la sovrastima della \eqref{eq:lppd}, le statistiche \emph{Akaike Information Criterion} (AIC), \emph{Deviance Information Criterion} (DIC) e \emph{Widely Applicable Information Criterion} (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un'approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC.

\hypertarget{criterio-dinformazione-di-akaike}{%
\subsection{Criterio d'informazione di Akaike}\label{criterio-dinformazione-di-akaike}}

Il criterio d'informazione di Akaike (in inglese \emph{Akaike information criterion}, indicato come AIC) fornisce un metodo molto semplice per approssimare \(\elpd\).

\begin{definition}
Il criterio d'informazione di Akaike è definito come

\begin{equation}
AIC = -2 \log p(y \mid \hat{\theta}_{MLE}) + 2k,
\end{equation}

dove \(k\) è il numero di parametri stimati nel modello e \(p(y \mid \hat{\theta}_{MLE})\) è il valore massimizzato della funzione di verosimiglianza del modello stimato.
\end{definition}

Dividendo per -2, otteniamo \(\elpd_{AIC}\):

\begin{equation}
\widehat{\elpd}_{AIC} = \log p(y \mid \hat{\theta}_{MLE}) - k,
\end{equation}

dove \(k\) è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.

AIC è di interesse principalmente storico e produce una approssimazione attendibile di \(\elpd\) quando:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  le distribuzioni a priori sono non informative;
\item
  la distribuzione a posteriori è approssimativamente gaussiana multivariata;
\item
  la dimensione \(n\) del campione è molto maggiore del numero \(k\) dei parametri.
\end{enumerate}

\begin{example}
Per meglio comprendere la statistica \(\widehat{\elpd}_{AIC}\), esaminiamo un esempio discusso da \citet{gelman2014understanding}. Sia \(y_1, \dots, y_n \sim \mathcal{N}(\mu, 1)\) un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa \(p(\theta) \propto 1\), la stima di massima verosimiglianza è \(\bar{y}\). La verosimiglianza è

\[
f(Y \mid \mu, \sigma) = \prod_{i=1}^n f(y \mid \mu, \sigma)
\]

e la log-verosimiglianza diventa

\[
\ell(Y \mid \mu, \sigma) = \sum_{i=1}^n \log (f(y \mid \mu, \sigma)).
\] Ovvero,

\begin{align}
\ell(Y \mid \mu, \sigma) &= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi\sigma^2 }}}\exp \left(-{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma^{2}}}\right) \right)\notag\\
&= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \sum_{i=1}^n{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma ^{2}}} \notag\\
&= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag \\
&= \sum_{i=1}^n \log (1) - \sum_{i=1}^n\log \sqrt{2\pi \sigma^2} - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&= - \sum_{i=1}^n\frac{1}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&= - \frac{n}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2}. \notag
\end{align}

Se \(y \sim \mathcal{N}(\mu, 1)\), usando lo stimatore di massima verosimiglianza per \(\mu\), la log-verosimiglianza diventa

\begin{align}
\log p(y \mid \hat{\theta}_{MLE}) &= -\frac{n}{2} \log (2\pi) - \frac{1}{2}\sum_{i=1}^n (y_i - \bar{y})^2 \notag\\
&= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2,
\end{align}

dove \(s_y^2\) è la varianza campionaria.

Nel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui

\begin{align}
\widehat{\elpd}_{AIC} &= \log p(y \mid \hat{\theta}_{MLE}) - k \notag \\
&= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2 - 1.
\end{align}
\end{example}

\hypertarget{convalida-incrociata-k-fold}{%
\section{Convalida incrociata K-fold}\label{convalida-incrociata-k-fold}}

La sovrastima della \eqref{eq:lppd} può anche essere evitata usando una tecnica chiamata \emph{K-fold cross-validation}. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata \emph{fold}) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell'accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all'altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (\(n\)) quante sono le singole osservazioni. Questa strategia è chiamata \emph{leave-one-out cross-validation} (LOO-CV).

\hypertarget{importance-sampling}{%
\subsection{Importance sampling}\label{importance-sampling}}

La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato \emph{Pareto-smoothed importance sampling cross-validation} {[}PSIS; \citet{vehtari2017practical}{]}. Tralasciando qui i dettagli matematici, l'intuizione di base è che PSIS fa leva sul punteggio di ``importanza'' posseduto da ciascuna osservazione all'interno della distribuzione a posteriori. Per ``importanza'' si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un'osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un'osservazione poco importante, la distribuzione a posteriori cambia poco. L'``importanza'' così intesa viene chiamata ``peso'' (\emph{weight}) e tali pesi vengono utilizzati per stimare l'accuratezza \emph{out-of-sample} del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza \emph{out-of-sample} che evita la sovrastima della \eqref{eq:lppd}. Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.

Valori \(\widehat{\elpd}_{\LOO}\) più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare \(\widehat{\elpd}\), è possibile usare la quantità \(-2 \cdot \widehat{\elpd}\), la quale è chiamata \emph{LOO Information Criterion} (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire.

La quantità \(\widehat{\elpd}_{\LOO}\) viene calcolata dai pacchetti \texttt{loo} e \texttt{brms} ed è chiamata \texttt{elpd\_loo} o \texttt{elpd\_kfold}. È anche possibile calcolare la differenza della quantità \texttt{elpd\_loo} per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza.

\hypertarget{confronto-tra-aic-e-loo-cv}{%
\section{Confronto tra AIC e LOO-CV}\label{confronto-tra-aic-e-loo-cv}}

Per fare un esempio, faremo qui un confronto tra \(\widehat{\elpd}_{AIC}\) e \(\widehat{\elpd}_{LOO-CV}\). Esaminiamo nuovamente l'associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da \citet{gelman2020regression}. Una tale relazione può essere descritta da un modello di regressione nel quale la \(y\) corrisponde al QI dei figli e la \(x\) al QI delle madri.

<<<<<<< HEAD
Leggiamo i dati in \R:
=======
Per facilitare la trattazione, le variabili casuali assumono solo valori numerici. Per lo specifico lancio della moneta in questione, diciamo, ad esempio, che la variabile casuale \(Y\) assume il valore 1 se esce testa e il valore 0 se esce croce.

\hypertarget{eventi-e-probabilituxe0}{%
\subsection{Eventi e probabilità}\label{eventi-e-probabilituxe0}}

Nella teoria delle probabilità il risultato ``testa'' nel lancio di una moneta è chiamato \emph{evento}.\footnote{Per un ripasso delle nozioni di base della teoria degli insiemi, si veda l'Appendice \ref{insiemistica}.} Ad esempio, \(Y\) = 1 denota l'evento in cui il lancio di una moneta produce come risultato testa.

Il funzionale \(Pr[·]\) definisce la probabilità di un evento. Ad esempio, per il lancio di una moneta equilibrata, la probabilità dell'evento ``il risultato del lancio della moneta è testa'' è scritta come

\[
Pr[Y = 1] = 0.5.
\] Se la moneta è equilibrata dobbiamo anche avere \(Pr[Y = 0] = 0.5\). I due eventi \emph{Y} = 1 e \(Y\) = 0 sono \emph{mutuamente esclusivi} nel senso che non possono entrambi verificarsi contemporaneamente. Nella notazione probabilistica,

\[
Pr[Y = 1\; e \; Y = 0] = 0.
\] Gli eventi \(Y\) = 1 e \(Y\) = 0 di dicono \emph{esaustivi}, nel senso che almeno uno di essi deve verificarsi e nessun altro tipo di evento è possibile. Nella notazione probabilistica,

\[
Pr[Y = 1\; o \; Y = 0] = 1.
\] Il connettivo logico ``e'' specifica eventi \emph{congiunti}, ovvero eventi che possono verificarsi contemporaneamente (eventi \emph{compatibili}) e per i quali, perciò, la probabilità della loro congiunzione è \(Pr(A \; e \; B) > 0\). Il connettivo logico ``o'' specifica eventi \emph{disgiunti}, ovvero eventi che non possono verificarsi contemporaneamente (eventi \emph{incompatibili}) e per i quali, perciò, la probabilità della loro congiunzione è \(P(A \; e \; B) = 0\).

\hypertarget{spazio-campionario-e-risultati-possibili}{%
\section{Spazio campionario e risultati possibili}\label{spazio-campionario-e-risultati-possibili}}

Anche se il lancio di una moneta produce sempre uno specifico risultato nel mondo reale, noi possiamo anche immaginare i possibili risultati alternativi che si sarebbero potuti osservare. Quindi, anche se in uno specifico lancio la moneta dà testa (\(Y\) = 1), possiamo immaginare la possibilità che il lancio possa avere prodotto croce (\(Y\) = 0). Tale ragionamento controfattuale è la chiave per comprendere la teoria delle probabilità e l'inferenza statistica.

I risultati possibili che si possono osservare come conseguenza del lancio di una moneta determinano i valori possibili che la variabile casuale può assumere. L'insieme di tutti i risultati possibili è chiamato \emph{spazio campionario}. Lo spazio campionario può essere concettualizzato come un'urna contenente una pallina per ogni possibile risultato del lancio della moneta. Su ogni pallina è scritto il valore della variabile casuale. Uno specifico lancio di una moneta -- ovvero, l'osservazione di uno specifico valore di una variabile casuale -- è chiamato \emph{esperimento casuale}.

Il lancio di un dado ci fornisce l'esempio di un altro esperimento casuale. Supponiamo di essere interessati all'evento ``il lancio del dado produce un numero dispari''. Un \emph{evento} seleziona un sottoinsieme dello spazio campionario: in questo caso, l'insieme dei risultati \(\{1, 3, 5\}\). Se esce 3, per esempio, diciamo che si è verificato l'evento ``dispari'' (ma l'evento ``dispari'' si sarebbe anche verificato anche se fosse uscito 1 o 5).

\hypertarget{usare-la-simulazione-per-stimare-le-probabilituxe0}{%
\section{Usare la simulazione per stimare le probabilità}\label{usare-la-simulazione-per-stimare-le-probabilituxe0}}

I metodi basati sulla simulazione ci consentono di stimare le probabilità degli eventi in un modo diretto se siamo in grado di generare realizzazioni molteplici e casuali delle variabili casuali coinvolte nelle definizioni degli eventi. Per simulare il lancio di una moneta equilibrata in R iniziamo a definire un vettore che contiene i possibili risultati del lancio della moneta (ovvero i possibili valori della variabile casuale \(Y\)):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coin }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\noindent L'estrazione casuale di uno di questi due possibili valori (ovvero, la simulazione di uno specifico lancio di una moneta) si realizza con la funzione \texttt{sample()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(coin, }\AttributeTok{size =} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0}
\end{Highlighting}
\end{Shaded}

\noindent In maniera equivalente, lo stesso risultato si ottiene mediante l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

Supponiamo di ripetere questo esperimento casuale 100 volte e di registrare i risultati così ottenuti. La stima della probabilità dell'evento \(Pr[Y = 1]\) è data dalla frequenza relativa del numero di volte in cui abbiamo osservato l'evento di interesse (\(Y = 1\)):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, M)}
\ControlFlowTok{for}\NormalTok{ (m }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M) \{}
\NormalTok{  y[m] }\OtherTok{=} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{\}}
\NormalTok{estimate }\OtherTok{=} \FunctionTok{sum}\NormalTok{(y) }\SpecialCharTok{/}\NormalTok{ M}

\FunctionTok{cat}\NormalTok{(}\StringTok{"estimated Pr[Y = 1] ="}\NormalTok{, estimate)}
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5}
\end{Highlighting}
\end{Shaded}

\noindent Ripetiamo questa procedura 10 volte.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flip\_coin }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(M) \{}
\NormalTok{  y }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, M)}
  \ControlFlowTok{for}\NormalTok{ (m }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M) \{}
\NormalTok{    y[m] }\OtherTok{=} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{  \}}
\NormalTok{  estimate }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y) }\SpecialCharTok{/}\NormalTok{ M}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"estimated Pr[Y = 1] ="}\NormalTok{, estimate, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
  \FunctionTok{flip\_coin}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\NormalTok{\}}
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.3 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.7 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.6 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.8 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5}
\end{Highlighting}
\end{Shaded}

\noindent Dato che la moneta è equilibrata, la stima delle probabilità dell'evento \(Pr[Y = 1]\) è simile a al valore che ci aspettiamo (\(Pr[Y = 1]\) = 0.5), ma il risultato ottenuto nelle varie simulazioni non è sempre esatto. Proviamo ad aumentare il numero di lanci in ciascuna simulazione:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
  \FunctionTok{flip\_coin}\NormalTok{(}\DecValTok{100}\NormalTok{)}
\NormalTok{\}}
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.44 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.53 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.43 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.58 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.41 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.51 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.49 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.57}
\end{Highlighting}
\end{Shaded}

\noindent In questo secondo caso, gli errori tendono ad essere più piccoli della simulazione precedente. Cosa succede se in ciascuna simulazione esaminiamo i risultati di 10,000 lanci della moneta?

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
  \FunctionTok{flip\_coin}\NormalTok{(}\FloatTok{1e4}\NormalTok{)}
\NormalTok{\}}
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5029 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4886 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4956 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.49 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5032 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.5051 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4928 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4968 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4991 }
\CommentTok{\#\textgreater{} estimated Pr[Y = 1] = 0.4976}
\end{Highlighting}
\end{Shaded}

\noindent Ora le stime ottenute sono molto vicine alla vera probabilità che vogliamo stimare (cioè 0.5, perché la moneta è equilibrata). I risultati delle simulazioni precedenti pongono dunque il problema di determinare quale sia il numero di lanci di cui abbiamo bisogno per assicurarci che le stime siano accurate (ovvero, vicine al valore corretto della probabilità)

\hypertarget{la-legge-dei-grandi-numeri}{%
\section{La legge dei grandi numeri}\label{la-legge-dei-grandi-numeri}}

La visualizzazione mediante grafici contribuisce alla comprensione dei concetti della statistica e della teoria delle probabilità. Un modo per descrivere ciò che accade all'aumentare del numero \(M\) di ripetizioni del lancio della moneta consiste nel registrare la stima della probabilità dell'evento \(Pr[Y = 1]\) in funzione del numero di ripetizioni dell'esperimento casuale per ogni \(m \in 1 : M.\) Un grafico dell'andamento della stima di \(Pr[Y = 1]\) in funzione di \(m\) si ottiene nel modo seguente.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nrep }\OtherTok{\textless{}{-}} \FloatTok{1e4}
\NormalTok{estimate }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, nrep)}
\NormalTok{flip\_coin }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(m) \{}
\NormalTok{  y }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(m, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{  phat }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y) }\SpecialCharTok{/}\NormalTok{ m}
\NormalTok{  phat}
\NormalTok{\}}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nrep) \{}
\NormalTok{  estimate[i] }\OtherTok{\textless{}{-}} \FunctionTok{flip\_coin}\NormalTok{(i)}
\NormalTok{\}}
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{n =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nrep, }
\NormalTok{  estimate}
\NormalTok{)}
\NormalTok{d }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ n, }\AttributeTok{y =}\NormalTok{ estimate)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Numero di lanci della moneta"}\NormalTok{, }
    \AttributeTok{y =} \StringTok{"Stima Pr[Y = 1]"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/legge-grandi-n-1-1} 

}

\caption{Stima della probabilità di successo in funzione del numero di lanci di una moneta.}\label{fig:legge-grandi-n-1}
\end{figure}

Dato che il grafico \ref{fig:legge-grandi-n-1} su una scala lineare non rivela chiaramente l'andamento della simulazione, utilizzeremo invece un grafico in cui sull'asse \(x\) è stata imposta una scala logaritmica. Con l'asse \(x\) su scala logaritmica, i valori tra 1 e 10 vengono tracciati all'incirca con la stessa ampiezza come nel caso dei valori tra 50 e 700, eccetera.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ n, }\AttributeTok{y =}\NormalTok{ estimate)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_log10}\NormalTok{(}
    \AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{200}\NormalTok{, }
               \DecValTok{700}\NormalTok{, }\DecValTok{2500}\NormalTok{, }\DecValTok{10000}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Numero di lanci della moneta"}\NormalTok{, }
    \AttributeTok{y =} \StringTok{"Stima Pr[Y = 1]"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/legge-grandi-n-2-1} 

}

\caption{Stima della probabilità di successo in funzione del numero di lanci di una moneta -- scala logaritmica.}\label{fig:legge-grandi-n-2}
\end{figure}

La \emph{legge dei grandi numeri} ci dice che all'aumentare del numero di ripetizioni dell'esperimento casuale la media dei risultati ottenuti tenderà ad avvicinarsi al valore atteso man mano che verranno eseguite più prove. Nel caso presente, la figura \ref{fig:legge-grandi-n-2} mostra appunto che, all'aumentare del numero \emph{M} di lanci della moneta, la stima di \(Pr[Y = 1]\) tende a convergere al vero valore di 0.5.

\hypertarget{variabili-casuali-multiple}{%
\section{Variabili casuali multiple}\label{variabili-casuali-multiple}}

Le variabili casuali non esistono isolatamente. Abbiamo iniziato con una singola variabile casuale \emph{Y} che rappresenta il risultato di un singolo, specifico lancio di una moneta equlibrata. Ma supponiamo ora di lanciare la moneta tre volte. Ciò suggerisce che possiamo avere le variabili casuali \(Y_1 , Y_2 , Y_3\) che rappresentano i risultati di ciascuno dei lanci. Possiamo assumere che ogni lancio sia indipendente, ovvero che non dipenda dal risultato degli altri lanci. Ognuna di queste variabili \(Y_n\) per \(n \in 1:3\) ha \(Pr[Y_n =1]=0.5\) e \(Pr[Y_n =0]=0.5\). Possiamo combinare più variabili casuali usando le operazioni aritmetiche. Se \(Y_1 , Y_2, Y_3\) sono variabili casuali che rappresentano tre lanci di una moneta equilibrata (o un lancio di tre monete equilibrate), possiamo definire la somma di tali variabili casuali come

\[
Z = Y_1 + Y_2 + Y_3.
\] \noindent Possiamo simulare i valori assunti dalla variabile casuale \emph{Z} simulando i valori di \(Y_1, Y_2, Y_3\) per poi sommarli.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y1 }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{y2 }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{y3 }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\FunctionTok{c}\NormalTok{(y1, y2, y3)}
\CommentTok{\#\textgreater{} [1] 0 0 1}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{c}\NormalTok{(y1, y2, y3))}
\FunctionTok{cat}\NormalTok{(}\StringTok{"z ="}\NormalTok{, z, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} z = 1}
\end{Highlighting}
\end{Shaded}

\noindent ovvero,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{) \{}
\NormalTok{  y[i] }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{\}}
\NormalTok{y}
\CommentTok{\#\textgreater{} [1] 1 0 0}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"z ="}\NormalTok{, z, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} z = 1}
\end{Highlighting}
\end{Shaded}

\noindent oppure, ancora più semplicemente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{y}
\CommentTok{\#\textgreater{} [1] 0 1 1}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"z ="}\NormalTok{, z, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\CommentTok{\#\textgreater{} z = 2}
\end{Highlighting}
\end{Shaded}

\noindent Possiamo ripetere questa simulazione \(M = 1e5\) volte:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \FloatTok{1e5}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, M)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M) \{}
\NormalTok{  y }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{  z[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\noindent e calcolare una stima della probabilità che la variabile casuale \(Z\) assuma i valori 0, 1, 2, 3:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{table}\NormalTok{(z) }\SpecialCharTok{/}\NormalTok{ M}
\CommentTok{\#\textgreater{} z}
\CommentTok{\#\textgreater{}      0      1      2      3 }
\CommentTok{\#\textgreater{} 0.1256 0.3750 0.3749 0.1245}
\end{Highlighting}
\end{Shaded}

Nel caso di 4 monete equilibrate, avremo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \FloatTok{1e5}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, M)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{M) \{}
\NormalTok{  y }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{  z[i] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y)}
\NormalTok{\}}
\FunctionTok{table}\NormalTok{(z) }\SpecialCharTok{/}\NormalTok{ M}
\CommentTok{\#\textgreater{} z}
\CommentTok{\#\textgreater{}       0       1       2       3       4 }
\CommentTok{\#\textgreater{} 0.06213 0.25019 0.37400 0.25097 0.06271}
\end{Highlighting}
\end{Shaded}

Viene detta \emph{variabile casuale discreta} una variabile casuale le cui modalità possono essere costituite solo da numeri interi:

\[
\mathbb{Z} = \dots, -2, -1, 0, 1, 2, \dots
\]

\hypertarget{sec:fun-mass-prob}{%
\section{Funzione di massa di probabilità}\label{sec:fun-mass-prob}}

È conveniente avere una funzione che associa ogni possibile valore di una variabile casuale alla sua probabilità. In generale, ciò è possibile se e solo se la variabile casuale è discreta, così com'è stata definita nel Paragrafo precedente.

Ad esempio, se consideriamo \(Z = Y_1 + \dots + Y_4\) come il numero di risultati ``testa'' in 4 lanci della moneta, allora possiamo definire la seguente funzione:

\[
\begin{array}{rclll}
p_Z(0) & = & 1/16 & & \mathrm{TTTT}
\\
p_Z(1) & = & 4/16 & & \mathrm{HTTT, THTT, TTHT, TTTH}
\\
p_Z(2) & = & 6/16 & & \mathrm{HHTT, HTHT, HTTH, THHT, THTH, TTTH}
\\
p_Z(3) & = & 4/16 & & \mathrm{HHHT, HHTH, HTHH, THHH}
\\
p_Z(4) & = & 1/16 & & \mathrm{HHHH}
\end{array}
\]

Il lancio di quattro monete può produrre sedici possibili risultati. Dato che i lanci sono indipendenti e le monete sono equilibrate, ogni possibile risultato è ugualmente probabile. Nella tabella in alto, le sequenze dei risultati possibili del lancio delle 4 monete sono riportate nella colonna più a destra. Le probabilità si ottengono dividendo il numero di sequenze che producono lo stesso numero di eventi testa per il numero dei risultati possibili.

La funzione \(p_Z\) è stata costruita per mappare un valore \(u\) per \(Z\) alla probabilità dell'evento \(Z = u\). Convenzionalmente, queste probabilità sono scritte come

\[
p_Z(z) = \mbox{Pr}[Z = z].
\]

La parte a destra dell'uguale si può leggere come: ``la probabilità che la variabile casuale \(Z\) assuma il valore \(z\)''.

Una funzione definita come sopra è detta \emph{funzione di massa di probabilità} della variabile casuale \(Z\). Ad ogni variabile casuale discreta è associata un'unica funzione di massa di probabilità.

Una rappresentazione grafica della stima della funzione di massa di probabilità per l'esperimento casuale del lancio di quattro monete equilibrate è fornita nella figura \ref{fig:barplot-mdf-4coins}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{M }\OtherTok{\textless{}{-}} \FloatTok{1e5}
\NormalTok{nflips }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{u }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(M, nflips, }\FloatTok{0.5}\NormalTok{)}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\NormalTok{nflips}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, nflips}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{0}\SpecialCharTok{:}\NormalTok{nflips)}
\NormalTok{  y[n }\SpecialCharTok{+} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(u }\SpecialCharTok{==}\NormalTok{ n) }\SpecialCharTok{/}\NormalTok{ M}
\NormalTok{bar\_plot }\OtherTok{\textless{}{-}}
  \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{Z =}\NormalTok{ x, }\AttributeTok{count =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ Z, }\AttributeTok{y =}\NormalTok{ count)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}
    \AttributeTok{breaks =} \DecValTok{0}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \StringTok{"Probabilità stimata Pr[Z = z]"}
\NormalTok{)}
\NormalTok{bar\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/barplot-mdf-4coins-1} 

}

\caption{Grafico di $M = 100\,000$ simulazioni della funzione di massa di probabilità di una variabile casuale definita come il numero di teste in quattro lanci di una moneta equilibrata.}\label{fig:barplot-mdf-4coins}
\end{figure}

Se \(A\) è un sottoinsieme della variabile casuale \(Z\), allora denotiamo con \(P_{z}(A)\) la probabilità assegnata ad \(A\) dalla distribuzione \(P_{z}\). Mediante una distribuzione di probabilità \(P_{z}\) è dunque possibile determinare la probabilità di ciascun sottoinsieme \(A \subset Z\) come

\[
P_{z}(A) = \sum_{z \in A} P_{z}(Z).
\]

\begin{example}
Nel caso dell'esempio discusso nella Sezione \ref{sec:fun-mass-prob}, la probabilità che la variabile casuale \(Z\) sia un numero dispari è \[
Pr(\text{Z è un numero dispari}) = P_{z}(Z = 1) + P_{z}(Z = 3) = \frac{4}{16} + \frac{4}{16} = \frac{1}{2}.
\]
\end{example}

\hypertarget{commenti-e-considerazioni-finali-4}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-4}}


In questo capitolo abbiamo visto come si costruisce lo spazio campionario di un esperimento casuale, quali sono le proprietà di base della probabilità e come si assegnano le probabilità agli eventi definiti sopra uno spazio campionario discreto. Abbiamo anche introdotto le nozioni di ``variabile casuale'', ovvero di una variabile che prende i suoi valori casualmente. E abbiamo descritto il modo di specificare la probabilità con cui sono presi i differenti valori, ovvero la funzione di distribuzione probabilistica \(F(X) = Pr(X < x)\), e la funzione di massa di probabilità. Le procedure di analisi dei dati psicologici che discuteremo in seguito faranno un grande uso di questi concetti e della notazione qui introdotta.

\hypertarget{chapter-prob-cond}{%
\chapter{Probabilità condizionata}\label{chapter-prob-cond}}

Il fondamento della statistica bayesiana è il teorema di Bayes e il fondamento del teorema di Bayes è la probabilità condizionata. In questo capitolo, inizieremo a presentare la probabilità condizionata. Nel Capitolo successivo, partendo dalla definizione di probabilità condizionata, deriveremo il teorema di Bayes.

\hypertarget{probabilituxe0-condizionata-su-altri-eventi}{%
\section{Probabilità condizionata su altri eventi}\label{probabilituxe0-condizionata-su-altri-eventi}}

L'attribuzione di una probabilità ad un evento è sempre condizionata dalle conoscenze che abbiamo a disposizione. Per un determinato stato di conoscenze, attribuiamo ad un dato evento una certa probabilità di verificarsi; ma se il nostro stato di conoscenze cambia, allora cambierà anche la probabilità che attribuiremo all'evento in questione.

La probabilità condizionata è una componente essenziale del ragionamento scientifico dato che chiarisce come sia possibile incorporare le evidenze disponibili, in maniera logica e coerente, nella nostra conoscenza del mondo. Infatti, si può pensare che tutte le probabilità siano probabilità condizionate, anche se l'evento condizionante non è sempre esplicitamente menzionato. Consideriamo il seguente problema.

\begin{exercise}

Supponiamo che lo screening per la diagnosi precoce del tumore mammario si avvalga di test che sono accurati al 90\%, nel senso che il 90\% delle donne con cancro e il 90\% delle donne senza cancro saranno classificate correttamente. Supponiamo che l'1\% delle donne sottoposte allo screening abbia effettivamente il cancro al seno. Ci chiediamo: qual è la probabilità che una donna scelta casualmente abbia una mammografia positiva e, se ce l'ha, qual è la probabilità che abbia davvero il cancro?

Per risolvere questo problema, supponiamo che il test in questione venga somministrato ad un grande campione di donne, diciamo a 1000 donne. Di queste 1000 donne, 10 (ovvero, l'1\%) hanno il cancro al seno. Per queste 10 donne, il test darà un risultato positivo in 9 casi (ovvero, nel 90\% dei casi). Per le rimanenti 990 donne che non hanno il cancro al seno, il test darà un risultato positivo in 99 casi (se la probabilità di un vero positivo è del 90\%, la probabilità di un falso positivo è del 10\%). Questa situazione è rappresentata nella figura \ref{fig:mammografia}. Combinando questi due risultati, vediamo che il test dà un risultato positivo per 9 donne che hanno effettivamente il cancro al seno e per 99 donne che non ce l'hanno, per un totale di 108 risultati positivi. Dunque, la probabilità di ottenere un risultato positivo al test è \(\frac{108}{1000}\) = 11\%. Ma delle 108 donne che hanno ottenuto un risultato positivo al test, solo 9 hanno il cancro al seno. Dunque, la probabilità di avere il cancro, dato un risultato positivo al test, è pari a \(\frac{9}{108}\) = 8\%.

\begin{figure}[h]

{\centering \includegraphics[width=0.67\linewidth]{images/mammografia} 

}

\caption{Rappresentazione ad albero che riporta le frequenze attese dei risultati di una mammografia in un campione di 1,000 donne.}\label{fig:mammografia}
\end{figure}

\end{exercise}

Nell'esercizio precedente, la probabilità dell'evento ``ottenere un risultato positivo al test'' è una probabilità non condizionata, mentre la probabilità dell'evento ``avere il cancro al seno, dato che il test ha dato un risultato positivo'' è una probabilità condizionata. In termini generali, la probabilità condizionata \(P(A \mid B)\) rappresenta la probabilità che si verifichi l'evento \(A\) sapendo che si è verificato l'evento \(B\) (oppure: la probabilità di \(A\) in una prova valida solo se si verifica anche \(B\)). Ciò ci conduce alla seguente definizione.

\begin{definition}
Dato un qualsiasi evento \(A\), si chiama \emph{probabilità condizionata} di \(A\) dato \(B\) il numero

\begin{equation}
P(A \mid B) = \frac{P(A \cap B)}{P(B)}, \quad \text{con}\, P(B) > 0,
\label{eq:probcond}
\end{equation}

dove \(P(A\cap B)\) è la probabilità congiunta dei due eventi, ovvero la probabilità che si verifichino entrambi.
\end{definition}

Dalla definizione di probabilità condizionata è possibile esprimere la probabilità congiunta come prodotto di due probabilità, una condizionata e una marginale (regola moltiplicativa, o della catena). Per esempio se conosciamo la probabilità marginale \(P(B)\) e la probabilità condizionata \(P(A \mid B)\) otteniamo

\begin{equation}
P(A \cap B) = P(B)P(A \mid B),
\label{eq:probcondinv}
\end{equation}

mentre se conosciamo la probabilità marginale \(P(A)\) e la probabilità condizionata \(P(B \mid A)\) otteniamo

\[
P(A \cap B) = P(A)P(B \mid A).
\]

\begin{exercise}
Da un mazzo di 52 carte (13 carte per ciascuno dei 4 semi) ne viene estratta 1 in modo casuale. Qual è la probabilità che esca una figura di cuori? Sapendo che la carta estratta ha il seme di cuori, qual è la probabilità che il valore numerico della carta sia 7, 8 o 9?

Ci sono 13 carte di cuori, dunque la risposta alla prima domanda è 1/4. Per rispondere alla seconda domanda consideriamo solo le 13 carte di cuori; la probabilità cercata è dunque 3/13.
\end{exercise}

\hypertarget{la-fallacia-del-condizionale-trasposto}{%
\subsection{La fallacia del condizionale trasposto}\label{la-fallacia-del-condizionale-trasposto}}

Un errore comune che si commette è quello di credere che \(P(A \mid B)\) sia uguale a \(P(B \mid A)\). Tale fallacia ha particolare risalto in ambito forense tanto che è conosciuta con il nome di ``fallacia del procuratore''. In essa, una piccola probabilità dell'evidenza, data l'innocenza, viene erroneamente interpretata come la probabilità dell'innocenza, data l'evidenza.

Consideriamo il caso di un esame del DNA. Un esperto forense potrebbe affermare, ad esempio, che ``se l'imputato è innocente, c'è solo una possibilità su un miliardo che vi sia una corrispondenza tra il suo DNA e il DNA trovato sulla scena del crimine''. Ma talvolta questa probabilità è erroneamente interpretata come avesse il seguente significato: ``date le prove del DNA, c'è solo una possibilità su un miliardo che l'imputato sia innocente''.

Le considerazioni precedenti risultano più chiare se facciamo nuovamente riferimento all'esercizio sul tumore mammario descritto sopra. In tale esercizio abbiamo visto come la probabilità di cancro dato un risultato positivo al test sia uguale a 0.08. Tale probabilità è molto diversa dalla probabilità di un risultato positivo al test data la presenza del cancro. Infatti, questa seconda probabilità è uguale a 0.90 ed è descritta nel problema come una delle caratteristiche del test in questione.

\hypertarget{legge-della-probabilituxe0-composta}{%
\section{Legge della probabilità composta}\label{legge-della-probabilituxe0-composta}}

Il teorema della probabilità composta deriva dal concetto di probabilità condizionata per cui la probabilità che si verifichino due eventi \(A_i\) e \(A_j\) è pari alla probabilità di uno dei due eventi moltiplicato con la probabilità dell'altro evento condizionato al verificarsi del primo.

L'equazione \eqref{eq:probcondinv} si estende al caso di \(n\) eventi \(A_1, \dots, A_n\) nella forma seguente:

\begin{equation}
\begin{split}
P(A_1 \cap A_2 \cap \dots\cap A_n) = {}& P(A_1)P(A_2 \mid A_1)P(A_3 \mid A_1 \cap A_2) \dots\\
 & P(A_n \mid A_1 \cap A_2 \cap \dots \cap A_{n-1})
\end{split}
\label{eq:probcomposte}
\end{equation}

la quale esprime in forma generale la legge della probabilità composta.

\begin{exercise}
Da un'urna contenente 6 palline bianche e 4 nere si estrae una pallina per volta, senza reintrodurla nell'urna. Indichiamo con \(B_i\) l'evento: ``esce una pallina bianca alla \(i\)-esima estrazione'' e con \(N_i\) l'estrazione di una pallina nera. L'evento: ``escono due palline bianche nelle prime due estrazioni'' è rappresentato dalla intersezione \(\{B_1 \cap B_2\}\) e la sua probabilità vale, per la~\eqref{eq:probcondinv}

\[
P(B_1 \cap B_2) = P(B_1)P(B_2 \mid B_1).
\]

\(P(B_1)\) vale 6/10, perché nella prima estrazione \(\Omega\) è costituito da 10 elementi: 6 palline bianche e 4 nere. La probabilità condizionata \(P(B_2 \mid B_1)\) vale 5/9, perché nella seconda estrazione, se è verificato l'evento \(B_1\), lo spazio campionario consiste di 5 palline bianche e 4 nere. Si ricava pertanto:

\[
P(B_1 \cap B_2) = \frac{6}{10} \cdot \frac{5}{9} = \frac{1}{3}.
\]

In modo analogo si ha che

\[
P(N_1 \cap N_2) = P(N_1)P(N_2 \mid N_1) = \frac{4}{10} \cdot \frac{3}{9} = \frac{4}{30}.
\]

Se l'esperimento consiste nell'estrazione successiva di 3 palline, la probabilità che queste siano tutte bianche vale, per la \eqref{eq:probcomposte}:

\[
P(B_1 \cap B_2 \cap B_3)=P(B_1)P(B_2 \mid B_1)P(B_3 \mid B_1 \cap B_2),
\]

dove la probabilità \(P(B_3 \mid B_1 \cap B_2)\) si calcola supponendo che si sia verificato l'evento condizionante \(\{B_1 \cap B_2\}\). Lo spazio campionario per questa probabilità condizionata è costituito da 4 palline bianche e 4 nere, per cui \(P(B_3 \mid B_1 \cap B_2) = 1/2\) e quindi:

\[
P (B_1 \cap B_2 \cap B_3) = \frac{6}{10}\cdot\frac{5}{9} \cdot\frac{4}{8}  = \frac{1}{6}.
\]

La probabilità dell'estrazione di tre palline nere è invece:

\[
\begin{aligned}
P(N_1 \cap N_2 \cap N_3) &= P(N_1)P(N_2 \mid N_1)P(N_3 \mid N_1 \cap N_2)\notag\\ 
&= \frac{4}{10} \cdot \frac{3}{9} \cdot \frac{2}{8} = \frac{1}{30}.\notag
\end{aligned}
\]
\end{exercise}

\hypertarget{lindipendendenza-stocastica}{%
\section{L'indipendendenza stocastica}\label{lindipendendenza-stocastica}}

Un concetto molto importante per le applicazioni statistiche della probabilità è quello dell'indipendenza stocastica. La definizione \eqref{eq:probcond} esprime il concetto intuitivo di indipendenza di un evento da un altro, nel senso che il verificarsi di \(A\) non influisce sulla probabilità del verificarsi di \(B\), ovvero non la condiziona. Infatti, per la definizione \eqref{eq:probcond} di probabilità condizionata, si ha che, se \(A\) e \(B\) sono due eventi indipendenti, risulta:

\[
P(A \mid B) = \frac{P(A)P(B)}{P(B)} = P(A).\notag
\]

Possiamo dunque dire che due eventi \(A\) e \(B\) sono indipendenti se

\[
\begin{split}
P(A \mid B) &= P(A), \\
P(B \mid A) &= P(B).
\end{split}
\]

\begin{exercise}
Nel lancio di due dadi non truccati, si considerino gli eventi: \emph{A} = \{esce un 1 o un 2 nel primo lancio\} e \emph{B} = \{il punteggio totale è 8\}. Gli eventi \emph{A} e \emph{B} sono indipendenti?

Rappresentiamo qui sotto lo spazio campionario dell'esperimento casuale.

\begin{figure}[h]

{\centering \includegraphics[width=0.7\linewidth]{images/sampling-space-dice} 

}

\caption{Rappresentazione dello spazio campionario dei risultati dell'esperimento casuale corrispondente al lancio di due dadi bilanciati. Sono evidenziati gli eventi elementari che costituiscono l'evento A: esce un 1 o un 2 nel primo lancio.}\label{fig:sampling-space-dice}
\end{figure}

Gli eventi \emph{A} e \emph{B} non sono statisticamente indipendenti. Infatti, le loro probabilità valgono \emph{P}(A) = 12/36 e \emph{P}(B) = 5/36 e la probabilità della loro intersezione è

\[
P(A \cap B) = 1/36 = 3/108 \neq P(A)P(B) = 5/108.
\]
\end{exercise}

\begin{remark}
Si noti che il concetto di indipendenza è del tutto differente da quello di incompatibilità. Due eventi \emph{A} e \emph{B} incompatibili (per i quali si ha \(A \cap B = \emptyset\)) sono statisticamente dipendenti, poiché il verificarsi dell'uno esclude il verificarsi dell'altro: \(P(A \cap B)=0 \neq P(A)P(B)\).
\end{remark}

Si noti inoltre che, se due eventi con probabilità non nulla sono statisticamente indipendenti, la legge delle probabilità totali espressa dalla~\eqref{eq:probunione}

\begin{equation}
P(A \cup B) = P(A) + P(B) - P(A \cap B)
\label{eq:probunione}
\end{equation}

si modifica nella relazione seguente:

\begin{equation}
P(A \cup B) = P(A) + P(B) - P(A)P(B).
\end{equation}

\hypertarget{commenti-e-considerazioni-finali-5}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-5}}


La probabilità condizionata è importante perché ci fornisce uno strumento per precisare il concetto di indipendenza statistica. Una delle domande più importanti delle analisi statistiche è infatti quella che si chiede se due variabili sono associate tra loro oppure no. In questo Capitolo abbiamo discusso il concetto di indipendenza (come contrapposto al concetto di associazione -- si veda il Capitolo \ref{chapter-descript}). In seguito vedremo come sia possibile fare inferenza sull'associazione tra variabili.

\hypertarget{chapter-teo-bayes}{%
\chapter{Il teorema di Bayes}\label{chapter-teo-bayes}}

Questo Capitolo presenterà il teorema di Bayes per calcolare la probabilità degli eventi riferiti a esperimenti casuali, ossia esperimenti di cui non si può prevedere il risultato finale ma di cui si conoscono tutti i possibili risultati. Prima di esaminare il teorema di Bayes verrà introdotta una sua componente, ovvero il teorema della probabilità totale.

\hypertarget{il-teorema-della-probabilituxe0-totale}{%
\section{Il teorema della probabilità totale}\label{il-teorema-della-probabilituxe0-totale}}

Il teorema della probabilità totale fa uso della legge della probabilità composta \eqref{eq:probcomposte}. Lo discuteremo qui considerando il caso di una partizione dello spazio campionario in tre sottoinsiemi, ma è facile estendere tale discussione al caso di una partizione in un qualunque numero di sottoinsiemi.

\begin{theorem}
Sia \(\{F_1, F_2, F_3\}\) una partizione dello spazio campionario \(\Omega\). Se \(E\) è un qualunque altro evento, allora:

\begin{equation}
P(E) = P(E \cap F_1) + P(E \cap F_2) + P(E \cap F_3) \notag
\label{eq:prob-total-1a}
\end{equation}

ovvero

\begin{equation}
P(E) = P(E \mid F_1) P(F_1) + P (E \mid F_2) P(F_2) + P(E \mid F_3) P(F_3).
\label{eq:prob-total-1b}
\end{equation}
\end{theorem}

Il teorema della probabilità totale afferma che, se l'evento \(E\) è costituito da tutti gli eventi elementari in \(E \cap F_1\), \(E \cap F_2\) e \(E \cap F_3\), allora la probabilità \(P(E)\) è data dalla somma delle probabilità di questi tre eventi (figura \ref{fig:tikz-prob-tot}).

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/tikz-prob-tot-1} 

}

\caption{Partizione dello spazio campionario $\Omega$.}\label{fig:tikz-prob-tot}
\end{figure}

\begin{exercise}
Si considerino tre urne, ciascuna delle quali contiene 100 palline:

\begin{itemize}
\tightlist
\item
  Urna 1: 75 palline rosse e 25 palline blu,
\item
  Urna 2: 60 palline rosse e 40 palline blu,
\item
  Urna 3: 45 palline rosse e 55 palline blu.
\end{itemize}

\noindent Una pallina viene estratta a caso da un'urna anch'essa scelta a caso. Qual è la probabilità che la pallina estratta sia di colore rosso?

Sia \(R\) l'evento ``la pallina estratta è rossa'' e sia \(U_i\) l'evento che corrisponde alla scelta dell'\(i\)-esima urna. Sappiamo che

\[
P(R \mid U_1) = 0.75, \quad P(R \mid U_2) = 0.60, \quad P(R \mid U_3) = 0.45.
\]

Gli eventi \(U_1\), \(U_2\) e \(U_3\) costituiscono una partizione dello spazio campionario in quanto \(U_1\), \(U_2\) e \(U_3\) sono eventi mutualmente esclusivi ed esaustivi, \(P(U_1 \cup U_2 \cup U_3) = 1.0\). In base al teorema della probabilità totale, la probabilità di estrarre una pallina rossa è

\[
\begin{split}
P(R) &= P(R \mid U_1)P(U_1)+P(R \mid U_2)P(U_2)+P(R \mid U_3)P(U_3) \\
&= 0.75 \cdot \frac{1}{3}+0.60 \cdot \frac{1}{3}+0.45 \cdot \frac{1}{3} \\
&=0.60.
\end{split}
\]
\end{exercise}

\begin{exercise}
Consideriamo un'urna che contiene 5 palline rosse e 2 palline verdi. Due palline vengono estratte, una dopo l'altra. Vogliamo sapere la probabilità dell'evento ``la seconda pallina estratta è rossa''.

Lo spazio campionario è \(\Omega = \{RR, RV, VR, VV\}\). Chiamiamo \(R_1\) l'evento ``la prima pallina estratta è rossa'', \(V_1\) l'evento ``la prima pallina estratta è verde'', \(R_2\) l'evento ``la seconda pallina estratta è rossa'' e \(V_2\) l'evento ``la seconda pallina estratta è verde''. Dobbiamo trovare \(P(R_2)\) e possiamo risolvere il problema usando il teorema della probabilità totale \eqref{eq:prob-total-1b}:

\[
\begin{split}
P(R_2) &= P(R_2 \mid R_1) P(R_1) + P(R_2 \mid V_1)P(V_1)\\
&= \frac{4}{6} \cdot \frac{5}{7} + \frac{5}{6} \cdot \frac{2}{7} \\
&= \frac{30}{42} = \frac{5}{7}.
\end{split}
\]

Se la prima estrazione è quella di una pallina rossa, nell'urna restano 4 palline rosse e due verdi, dunque, la probabilità che la seconda estrazione produca una pallina rossa è uguale a 4/6. La probabilità di una pallina rossa nella prima estrazione è 5/7. Se la prima estrazione è quella di una pallina verde, nell'urna restano 5 palline rosse e una pallina verde, dunque, la probabilità che la seconda estrazione produca una pallina rossa è uguale a 5/6. La probabilità di una pallina verde nella prima estrazione è 2/7.
\end{exercise}

\hypertarget{la-regola-di-bayes}{%
\section{La regola di Bayes}\label{la-regola-di-bayes}}

Il teorema di Bayes rappresenta uno dei fondamenti della teoria della probabilità e della statistica. Lo presentiamo qui considerando un caso specifico per poi descriverlo nella sua forma più generale.

Sia \(\{F_1, F_2\}\) una partizione dello spazio campionario \(\Omega\). Consideriamo un terzo evento \(E \subset \Omega\) con probabilità non nulla di cui si conoscono le probabilità condizionate rispetto ad \(F_1\) e a \(F_2\), ovvero \(P(E \mid F_1)\) e \(P(E \mid F_2)\). È chiaro per le ipotesi fatte che se si verifica \(E\) deve anche essersi verificato almeno uno degli eventi \(F_1\) e \(F_2\). Supponendo che si sia verificato l'evento \(E\), ci chiediamo: qual è la probabilità che si sia verificato \(F_1\) piuttosto che \(F_2\)?

\begin{figure}[h]

{\centering \includegraphics[width=0.45\linewidth]{ds4psy_files/figure-latex/unnamed-chunk-30-1} 

}

\end{figure}

Per rispondere alla domanda precedente scriviamo:

\[
\begin{split}
P(F_1 \mid E) &= \frac{P(E \cap F_1)}{P(E)}\notag\\
              &= \frac{P(E \mid F_1)P(F_1)}{P(E)}.
\end{split}
\]

Sapendo che \(E = (E \cap F_1) \cup (E \cap F_2)\) e che \(F_1\) e \(F_2\) sono eventi disgiunti, ovvero \(F_1 \cap F_2 = \emptyset\), ne segue che possiamo calcolare \(P(E)\) utilizzando il teorema della probabilità totale:

\[
\begin{split}
P(E) &= P(E \cap F_1) + P(E \cap F_2)\notag\\
     &= P(E \mid F_1)P(F_1) + P(E \mid F_2)P(F_2).
\end{split}
\]

\noindent Sostituendo il risultato precedente nella formula della probabilità condizionata \(P(F_1 \mid E)\) otteniamo:

\begin{equation}
P(F_1 \mid E) = \frac{P(E \mid F_1)P(F_1)}{P(E \mid F_1)P(F_1) + P(E \mid F_2)P(F_2)}.
\label{eq:bayes1}
\end{equation}

\noindent La \eqref{eq:bayes1} si generalizza facilmente al caso di più di due eventi disgiunti, come indicato di seguito.

\begin{theorem}
Sia \(E\) un evento contenuto in \(F_1 \cup \dots \cup F_k\), dove gli eventi \(F_j, j=1, \dots, k\) sono a due a due incompatibili e necessari. Allora per ognuno dei suddetti eventi \(F_j\) vale la seguente formula:

\begin{equation}
P(F_j \mid E) = \frac{P(E \mid F_j)P(F_j)}{\sum_{j=1}^{k}P(F_j)P(E \mid F_j)}.
\label{eq:bayes2}
\end{equation}
\end{theorem}

\noindent La \eqref{eq:bayes2} prende il nome di \emph{Teorema di Bayes} e mostra che la conoscenza del verificarsi dell'evento \(E\) modifica la probabilità che abbiamo attribuito all'evento \(F_j\). Nella \eqref{eq:bayes2} la probabilità condizionata \(P(F_j \mid E)\) prende il nome di probabilità \emph{a posteriori} dell'evento \(F_j\): il termine ``a posteriori'' sta a significare ``dopo che è noto che si è verificato l'evento \(E\)''. Nel capitolo \ref{chapter-intro-bayes-inference} estenderemo questa discussione mostrando come la \eqref{eq:bayes2} possa essere formulata in un modo più generale, ovvero in modo tale che non faccia riferimento unicamente alla probabilità di eventi, ma bensì anche alle funzioni di densità di probabilità.

\begin{remark}
Qual è la pronuncia di ``Bayesian''? Per saperlo possiamo seguire \href{https://bayes-rules.github.io/posts/fun/}{questo link}.
\end{remark}

\hypertarget{le-probabilita-come-grado-di-fiducia}{%
\subsection{Le probabilità come grado di fiducia}\label{le-probabilita-come-grado-di-fiducia}}

Il teorema di Bayes rende esplicito il motivo per cui la probabilità non può essere pensata come uno stato oggettivo, quanto piuttosto come un'inferenza soggettiva e condizionata. Il denominatore del membro di destra della \eqref{eq:bayes2} è un semplice fattore di normalizzazione. Nel numeratore compaiono invece due quantità: \(P(F_j\)) e \(P(E \mid F_j)\). La probabilità \(P(F_j\)) è la probabilità \emph{probabilità a priori} (\emph{prior}) dell'evento \(F_j\) e rappresenta l'informazione che l'agente bayesiano possiede a proposito dell'evento \(F_j\). Diremo che \(P(F_j)\) codifica il grado di fiducia che l'agente ripone in \(F_j\), sul quale non possiamo porre vincoli di alcun tipo. La probabilità condizionata \(P(E \mid F_j)\) rappresenta invece la verosimiglianza di \(F_j\) e ci dice quant'è plausibile che si verifichi l'evento \(E\) condizionatemente al fatto che si sia verificato \(F_j\).

Nell'interpretazione bayesiana \(P(F_j)\) rappresenta un giudizio personale dell'agente e non esistono criteri esterni che possano determinare se tale giudizio sia coretto o meno. Il teorema di Bayes descrive la regola che l'agente deve seguire per aggiornare il suo grado di fiducia in \(F_j\) alla luce di un ulteriore evento \(E\). Per questo motivo abbiamo chiamato \(P(F_j \mid E)\) probabilità a posteriori: essa rappresenta infatti la nuova probabilità che l'agente assegna ad \(F_j\) affinché rimanga consistente con le nuove informazioni fornitegli da \(E\).

La probabilità a posteriori dipende sia da \(E\), sia dalla conoscenza a priori dell'agente \(P(F_j)\). In questo senso è chiaro come non abbia senso parlare di una probabilità oggettiva: per il teorema di Bayes la probabilità è definita condizionatamente alla probabilità a priori, la quale a sua volta, per definizione, è un'assegnazione soggettiva. Ne segue pertanto che ogni probabilità debba essere una rappresentazione del grado di fiducia (soggettiva) dell'agente.

Se ogni assegnazione probabilistica rappresenta uno stato di conoscenza, è altresì vero che un particolare stato di conoscenza è arbitrario e dunque non deve esserci necessariamente accordo a priori tra diversi agenti. Tuttavia, alla luce di nuove informazioni, la teoria delle probabilità ci fornisce uno strumento che consente l'aggiornamento dello stato di conoscenza in un modo razionale.

\hypertarget{aggiornamento-bayesiano}{%
\subsection{Aggiornamento bayesiano}\label{aggiornamento-bayesiano}}

Il teorema di Bayes consente di modificare una credenza a priori in maniera dinamica, via via che nuove evidenze vengono raccolte, in modo tale da formulare una credenza a posteriori la quale non è mai definitiva, ma può sempre essere aggiornata in base alle nuove evidenze disponibili. Questo processo si chiama \emph{aggiornamento bayesiano}.

\begin{exercise}
Supponiamo che, per qualche strano errore di produzione, una fabbrica produca due tipi di monete. Il primo tipo di monete ha la caratteristica che, quando una moneta viene lanciata, la probabilità di osservare l'esito ``testa'' è 0.6. Per semplicità, sia \(\theta\) la probabilità di osservare l'esito ``testa''. Per una moneta del primo tipo, dunque, \(\theta = 0.6\). Per una moneta del secondo tipo, invece, la probabilità di produrre l'esito ``testa'' è 0.4. Ovvero, \(\theta = 0.4\).

Noi possediamo una moneta, ma non sappiamo se è del primo tipo o del secondo tipo. Sappiamo solo che il 75\% delle monete sono del primo tipo e il 25\% sono del secondo tipo. Sulla base di questa conoscenza \emph{a priori} -- ovvero sulla base di una conoscenza ottenuta senza avere eseguito l'esperimento che consiste nel lanciare la moneta una serie di volte per osservare gli esiti prodotti -- possiamo dire che la probabilità di una prima ipotesi, secondo la quale \(\theta = 0.6\), è 3 volte più grande della probabilità di una seconda ipotesi, secondo la quale \(\theta = 0.4\). Senza avere eseguito alcun esperimento casuale con la moneta, questo è quello che sappiamo.

Ora immaginiamo di lanciare una moneta due volte e di ottenere il risultato seguente: \(\{T, C\}\). Quello che ci chiediamo è: sulla base di questa evidenza, come cambiano le probabilità che associamo alle due ipotesi? In altre parole, ci chiediamo qual è la probabilità di ciascuna ipotesi alla luce dei dati che sono stati osservati: \(P(H \mid y)\), laddove \(y\) sono i dati osservati. Tale probabilità si chiama probabilità a posteriori. Inoltre, se confrontiamo le due ipotesi, ci chiediamo quale valore assuma il rapporto \(\frac{P(H_1 \mid y)}{P(H_2 \mid y)}\). Tale rapporto ci dice quanto è più probabile \(H_1\) rispetto ad \(H_2\), alla luce dei dati osservati. Infine, ci chiediamo come cambia il rapporto definito sopra, quando osserviamo via via nuovi risultati prodotti dal lancio della moneta.

Definiamo il problema in maniera più chiara. Conosciamo le probabilità a priori, ovvero \(P(H_1) = 0.75\) e \(P(H_1) = 0.25\). Quello che vogliamo conoscere sono le probabilità a posteriori \(P(H_1 \mid y)\) e \(P(H_2 \mid y)\). Per trovare le probabilità a posteriori applichiamo il teorema di Bayes:

\[
\begin{split}
P(H_1 \mid y) &= \frac{P(y \mid H_1) P(H_1)}{P(y)} \\
&= \frac{P(y \mid H_1) P(H_1)}{P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2)},
\end{split}
\]

laddove lo sviluppo del denominatore deriva da un'applicazione del teorema della probabilità totale. Inoltre,

\[
P(H_2 \mid y) = \frac{P(y \mid H_2) P(H_2)}{P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2)}.
\]

Se consideriamo l'ipotesi \(H_1\) = ``la probabilità di testa è 0.6'', allora la verosimiglianza dei dati \(\{T, C\}\), ovvero la probabilità di osservare questa specifica sequenza di T e C, è uguale a \(0.6 \times 0.4 = 0.24.\) Dunque, \(P(y \mid H_1) = 0.24\).

Se invece consideriamo l'ipotesi \(H_2\) = ``la probabilità di testa è 0.4'', allora la verosimiglianza dei dati \(\{T, C\}\) è \(0.4 \times 0.6 = 0.24\), ovvero, \(P(y \mid H_2) = 0.24\). In base alle due ipotesi \(H_1\) e \(H_2\), dunque, i dati osservati hanno la medesima plausibilità di essere osservati. Per semplicità, calcoliamo anche

\[
\begin{split}
P(y) &= P(y \mid H_1) P(H_1) + P(y \mid H_2) P(H_2) \\
&= 0.24 \cdot 0.75 + 0.24 \cdot 0.25 \\
&= 0.24.
\end{split}
\]

Le probabilità a posteriori diventano:

\[
\begin{split}
P(H_1 \mid y) &= \frac{P(y \mid H_1) P(H_1)}{P(y)}\\
&= \frac{0.24 \cdot 0.75}{0.24} \\
&= 0.75,
\end{split}
\]

\[
\begin{split}
P(H_2 \mid y) &= \frac{P(y \mid H_2) P(H_2)}{P(y)} \\
&= \frac{0.24 \cdot 0.25}{0.24} \\
&= 0.25.
\end{split}
\]

Possiamo dunque concludere dicendo che, sulla base dei dati osservati, l'ipotesi \(H_1\) ha una probabilità 3 volte maggiore di essere vera dell'ipotesi \(H_2\).

È tuttavia possibile raccogliere più evidenze e, sulla base di esse, le probabilità a posteriori cambieranno. Supponiamo di lanciare la moneta una terza volta e di osservare croce. I nostri dati dunque sono \(\{T, C, C\}\).

Di conseguenza, \(P(y \mid H_1) = 0.6 \cdot 0.4 \cdot 0.4 = 0.096\) e \(P(y \mid H_2) = 0.4 \cdot 0.6 \cdot 0.6 = 0.144\). Ne segue che le probabilità a posteriori diventano:

\[
\begin{split}
P(H_1 \mid y) &= \frac{P(y \mid H_1) P(H_1)}{P(y)} \\
&= \frac{0.096 \cdot 0.75}{0.096 \cdot 0.75 + 0.144 \cdot 0.25} \\
&= 0.667,
\end{split}
\]

\[
\begin{split}
P(H_2 \mid y) &= \frac{P(y \mid H_2) P(H_2)}{P(y)} \\
&= \frac{0.144 \cdot 0.25}{0.096 \cdot 0.75 + 0.144 \cdot 0.25} \\
&= 0.333.
\end{split}
\]

In queste circostanze, le evidenze che favoriscono \(H_1\) nei confronti di \(H_2\) sono solo pari ad un fattore di 2.

Se otteniamo ancora croce in un quarto lancio della moneta, i nostri dati diventano: \(\{T, C, C, C\}\). Ripetendo il ragionamento fatto sopra, \(P(y \mid H_1) = 0.6 \cdot 0.4 \cdot 0.4 \cdot 0.4 = 0.0384\) e \(P(y \mid H_2) = 0.4 \cdot 0.6 \cdot 0.6 \cdot 0.6 = 0.0864\). Dunque

\begin{equation}
P(H_1 \mid y) = \frac{0.0384 \cdot 0.75}{0.0384 \cdot 0.75 + 0.0864 \cdot 0.25} = 0.571,\notag
\end{equation}

\begin{equation}
P(H_2 \mid y) = \frac{0.0864 \cdot 0.25}{0.0384 \cdot 0.75 + 0.0864 \cdot 0.25} = 0.429.\notag
\end{equation}

e le evidenze a favore di \(H_1\) si riducono a 1.33. Se si ottenesse un altro esito croce in un sesto lancio della moneta, l'ipotesi \(H2\) diventerebbe più probabile dell'ipotesi \(H_1\).

In conclusione, questo esercizio ci fa capire come sia possibile aggiornare le nostre credenze sulla base delle evidenze disponibili, ovvero come sia possibile passare da un grado di conoscenza del mondo a priori a una conoscenza a posteriori. Se prima di lanciare la moneta ritenevamo che l'ipotesi \(H_1\) fosse tre volte più plausibile dell'ipotesi \(H_2\), dopo avere osservato uno specifico campione di dati siamo giunti alla conclusione opposta. Il processo di aggiornamento bayesiano, dunque, ci fornisce un metodo per modificare il livello di fiducia in una data ipotesi, alla luce di nuove informazioni.
\end{exercise}

\hypertarget{commenti-e-considerazioni-finali-6}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-6}}


Il teorema di Bayes costituisce il fondamento dell'approccio più moderno della statistica, quello appunto detto bayesiano. Chi usa il teorema di Bayes non è, solo per questo motivo, ``bayesiano'': ci vuole ben altro. Ci vuole un modo diverso per intendere il significato della probabilità e un modo diverso per intendere gli obiettivi dell'inferenza statistica. In anni recenti, una gran parte della comunità scientifica ha riconosciuto all'approccio bayesiano il merito di consentire lo sviluppo di modelli anche molto complessi (intrattabili in base all'approccio frequentista) senza richiedere, d'altra parte, conoscenze matematiche troppo avanzate all'utente. Per questa ragione l'approccio bayesiano sta prendendo sempre più piede, anche in psicologia.

\hypertarget{chapter-prob-congiunta}{%
\chapter{Probabilità congiunta}\label{chapter-prob-congiunta}}

Per descrivere la relazione tra due variabili casuali è necessario calcolare la \emph{covarianza} e la \emph{correlazione}. Il calcolo di questi due indici richiede la conoscenza della funzione di probabilità congiunta. Obiettivo di questo Capitolo è descrivere la funzione di probabilità congiunta di due variabili casuali; esamineremo in dettaglio il caso discreto.

\hypertarget{funzione-di-probabilituxe0-congiunta}{%
\section{Funzione di probabilità congiunta}\label{funzione-di-probabilituxe0-congiunta}}

Dopo aver trattato della distribuzione di probabilità di una variabile casuale, la quale associa ad ogni evento elementare dello spazio campionario uno ed un solo numero reale, è naturale estendere questo concetto al caso di due o più variabili casuali. Iniziamo a descrivere il caso discreto con un esempio. Consideriamo l'esperimento casuale corrispondente al lancio di tre monete equilibrate. Lo spazio campionario è

\[
\Omega = \{TTT, TTC, TCT, CTT, CCT, CTC, TCC, CCC\}.
\]

Dato che i tre lanci sono tra loro indipendenti, non c'è ragione di aspettarsi che uno degli otto risultati possibili dell'esperimento sia più probabile degli altri, dunque possiamo associare a ciascuno degli otto eventi elementari dello spazio campionario la stessa probabilità, ovvero 1/8.

Siano \(X \in \{0, 1, 2, 3\}\) = ``numero di realizzazioni con il risultato testa nei tre lanci'' e \(Y \in \{0, 1\}\) = ``numero di realizzazioni con il risultato testa nel primo lancio'' due variabili casuali definite sullo spazio campionario \(\Omega\). Indicando con T = `testa' e C = `croce', si ottiene la situazione riportata nella tabella \ref{tab:tre-monete-distr-cong-1}.

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:tre-monete-distr-cong-1} Spazio campionario dell'esperimento consistente nel lancio di tre monete equilibrate su cui sono state definite le variabili aleatorie \(X\) e \(Y\).}\tabularnewline
\toprule
\(\omega\) & \(X\) & \(Y\) & \(P(\omega)\) \\
\midrule
\endfirsthead
\toprule
\(\omega\) & \(X\) & \(Y\) & \(P(\omega)\) \\
\midrule
\endhead
\(\omega_1\) = TTT & 3 & 1 & 1/8 \\
\(\omega_2\) = TTC & 2 & 1 & 1/8 \\
\(\omega_3\) = TCT & 2 & 1 & 1/8 \\
\(\omega_4\) = CTT & 2 & 0 & 1/8 \\
\(\omega_5\) = CCT & 1 & 0 & 1/8 \\
\(\omega_6\) = CTC & 1 & 0 & 1/8 \\
\(\omega_7\) = TCC & 1 & 1 & 1/8 \\
\(\omega_8\) = CCC & 0 & 0 & 1/8 \\
\bottomrule
\end{longtable}

Ci poniamo il problema di associare un livello di probabilità ad ogni coppia \((x, y)\) definita su \(\Omega\). La coppia \((X = 0, Y = 0)\) si realizza in corrispondenza di un solo evento elementare, ovvero CCC; avrà dunque una probabilità pari a \(P(X=0, Y=0) = P(CCC) = 1/8\). Nel caso della coppia \((X = 1, Y = 0)\) ci sono due eventi elementari che danno luogo al risultato considerato, ovvero, CCT e CTC; la probabilità \(P(X=1, Y=0)\) sarà dunque data dalla probabilità dell'unione dei due eventi elementari, cioé \(P(X=1, Y=0) = P(CCT \:\cup\: CTC) = 1/8 + 1/8 = 1/4\). Sono riportati qui sotto i calcoli per tutti i possibili valori di \(X\) e \(Y\).

\begin{align}
P(X = 0, Y = 0) &= P(\omega_8 = CCC) = 1/8; \notag\\
P(X = 1, Y = 0) &= P(\omega_5 = CCT) + P(\omega_6 = CTC) = 2/8; \notag\\
P(X = 1, Y = 1) &= P(\omega_7 = TCC) = 1/8; \notag\\
P(X = 2, Y = 0) &= P(\omega_4 = CTT) = 1/8; \notag\\
P(X = 2, Y = 1) &= P(\omega_3 = TCT) + P(\omega_2 = TTC) = 2/8; \notag\\
P(X = 3, Y = 1) &= P(\omega_1 = TTT) = 1/8; \notag
\end{align}

Le probabilità così trovate sono riportate nella tabella \ref{tab:ditr-cong-biv-1} la quale descrive la distribuzione di probabilità congiunta delle variabili casuali \(X\) = ``numero di realizzazioni con il risultato testa nei tre lanci'' e \(Y\) = ``numero di realizzazioni con il risultato testa nel primo lancio'' per l'esperimento casuale consistente nel lancio di tre monete equilibrate.

\begin{longtable}[]{@{}ccc@{}}
\caption{\label{tab:ditr-cong-biv-1} Distribuzione di probabilità congiunta per i risultati dell'esperimento consistente nel lancio di tre monete equilibrate.}\tabularnewline
\toprule
\(x / y\) & 0 & 1 \\
\midrule
\endfirsthead
\toprule
\(x / y\) & 0 & 1 \\
\midrule
\endhead
0 & 1/8 & 0 \\
1 & 2/8 & 1/8 \\
2 & 1/8 & 2/8 \\
3 & 0 & 1/8 \\
\bottomrule
\end{longtable}

In generale, possiamo dire che, dato uno spazio campionario discreto \(\Omega\), è possibile associare ad ogni evento elementare \(\omega_i\) dello spazio campionario una coppia di numeri reali \((x, y)\), essendo \(x = X(\omega)\) e \(y = Y(\omega)\), il che ci conduce alla seguente definizione.

\begin{definition}
Siano \(X\) e \(Y\) due variabili casuali. La funzione che associa ad ogni coppia \((x, y)\) un livello di probabilità prende il nome di funzione di probabilità congiunta:

\[
P(x, y) = P(X = x, Y = y).
\]
\end{definition}

\noindent Il termine ``congiunta'' deriva dal fatto che questa probabilità è legata al verificarsi di una coppia di valori, il primo associato alla variabile casuale \(X\) ed il secondo alla variabile casuale \(Y\). Nel caso di due sole variabili casuali si parla di distribuzione bivariata, mentre nel caso di più variabili casuali si parla di distribuzione multivariata.

\hypertarget{proprietuxe0}{%
\subsection{Proprietà}\label{proprietuxe0}}

Una distribuzione di massa di probabilità congiunta bivariata deve soddisfare due proprietà:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(0 \leq P(x_i, y_j) \leq 1\);
\item
  la probabilità totale deve essere uguale a \(1.0\). Tale proprietà può essere espressa nel modo seguente
\end{enumerate}

\[
\sum_{i} \sum_{j} P(x_i, y_j) = 1.0.
\]

\hypertarget{eventi}{%
\subsection{Eventi}\label{eventi}}

Si noti che dalla probabilità congiunta possiamo calcolare la probabilità di qualsiasi evento definito in base alle variabili aleatorie \(X\) e \(Y\). Per capire come questo possa essere fatto, consideriamo nuovamente l'esperimento casuale discusso in precedenza.

\begin{exercise}
Per la distribuzione di massa di probabilità congiunta riportata nella tabella precedente si trovi la probabilità dell'evento \(X+Y \leq 1\).

Per trovare la probabilità richiesta dobbiamo semplicemente sommare le probabilità associate a tutte le coppie \((x,y)\) che soddisfano la condizione \(X+Y \leq 1\), ovvero

\begin{equation}
P_{XY}(X+Y \leq 1) = P_{XY}(0, 0) + P_{XY}(1, 0)= 3/8.\notag
\end{equation}
\end{exercise}

\hypertarget{regola-della-catena}{%
\subsection{Regola della catena}\label{regola-della-catena}}

Regola della catena permette il calcolo di qualsiasi membro della distribuzione congiunta di un insieme di variabili casuali utilizzando solo le probabilità condizionate.

\begin{definition}
Dati due eventi \(A\) e \(B\), la regola della catena afferma che

\[
P(A \cap B) = P(A)P(B \mid A).
\]
\end{definition}

Nel caso di 4 eventi, per esempio, la regola della catena diventa

\[
P(A_1, A_2, A_3, A_4) = P(A_1) P(A_2 \mid A_1) P(A_3 \mid A_1, A_2) P(A_4 \mid A_1, A_2, A_3).
\]

\hypertarget{funzioni-di-probabilituxe0-marginali}{%
\subsection{Funzioni di probabilità marginali}\label{funzioni-di-probabilituxe0-marginali}}

La distribuzione marginale di un sottoinsieme di variabili casuali è la distribuzione di probabilità delle variabili contenute nel sottoinsieme. Come spiegato da \href{https://it.wikipedia.org/wiki/Distribuzione_marginale}{Wikipedia}: \emph{il termine variabile marginale è usato per riferirsi a quelle variabili nel sottoinsieme delle variabili che vengono trattenute ovvero utilizzate. Questo termine, marginale, è attribuito ai valori ottenuti ad esempio sommando in una tabella di valori lungo le righe oppure lungo le colonne, trascrivendo il risultato appunto a margine rispettivamente della riga o colonna sommata.{[}1{]} La distribuzione delle variabili marginali (la distribuzione marginale) è ottenuta mediante marginalizzazione sopra le variabili da ``scartare'', e le variabili scartate sono dette fuori marginalizzate.}

Nel caso di due variabili casuali discrete \(X\) e \(Y\) di cui conosciamo la cui distribuzione congiunta, la distribuzione marginale di \(X\) è calcolata sommando o integrando la distribuzione di probabilità congiunta sopra \(Y\). La funzione di massa di probabilità marginale \(P(X=x)\) è

\begin{equation}
P(X = x) = \sum_y P(X, Y = y) = \sum_y P(X \mid Y = y) P(Y = y),
\end{equation}

dove \(P(X = x,Y = y)\) è la distribuzione congiunta di \(X, Y\), mentre \(P(X = x \mid Y = y)\) è la distribuzione condizionata di \(X\) dato \(Y\). In questo caso, la variabile \(Y\) è stata marginalizzata. Le probabilità bivariate marginali e congiunte per variabili casuali discrete sono spesso mostrate come tabelle di contingenza.

Si noti che \(P(X = x)\) e \(P(Y = y)\) sono normalizzate:

\[
\sum_x P(X=x) = 1.0, \quad \sum_y P(Y=y) = 1.0.
\]

\begin{exercise}

Per l'esperimento casuale consistente nel lancio di tre monete equilibrate, si calcolino le probabilità marginali di \(X\) e \(Y\).

Nell'ultima colonna a destra e nell'ultima riga in basso della tabella \ref{tab:ditr-cong-biv} sono riportate le distribuzioni di probabilità marginali di \(X\) e \(Y\). \(P_X\) si ottiene sommando su ciascuna riga fissata la colonna \(j\), \(P_X(X = j) = \sum_y p_{xy}(x = j, y)\). \(P_Y\) si trova sommando su ciascuna colonna fissata la riga \(i,\) \(P_Y (Y = i) = \sum_x p_{xy}(x, y = i)\).

\begin{longtable}[]{@{}cccc@{}}
\caption{\label{tab:ditr-cong-biv} Distribuzione di probabilità congiunta \(p(x,y)\) per i risultati dell'esperimento consistente nel lancio di tre monete equilibrate e probabilità marginali \(P(x)\) e \(P(y)\).}\tabularnewline
\toprule
\(x / y\) & 0 & 1 & \(P(x)\) \\
\midrule
\endfirsthead
\toprule
\(x / y\) & 0 & 1 & \(P(x)\) \\
\midrule
\endhead
0 & 1/8 & 0 & 1/8 \\
1 & 2/8 & 1/8 & 3/8 \\
2 & 1/8 & 2/8 & 3/8 \\
3 & 0 & 1/8 & 1/8 \\
\(P(y)\) & 4/8 & 4/8 & 1.0 \\
\bottomrule
\end{longtable}

\end{exercise}

\hypertarget{indipendenza-stocastica}{%
\section{Indipendenza stocastica}\label{indipendenza-stocastica}}

Ora abbiamo tutti gli strumenti per dare una precisa definizione statistica al concetto di indipendenza. La definizione proposta sarà necessariamente coerente con la definizione di indipendenza che abbiamo usato fino ad ora. Ma, espressa in questi nuovi termini, potrà essere utilizzata in indagini probabilistiche e statistiche più complesse. Ricordiamo che gli eventi \(A\) e \(B\) si dicono indipendenti se \(P (A \cap B)\, = P(A) P(B)\). Diciamo quindi che \(X\) e \(Y\) sono indipendenti se qualsiasi evento definito da \(X\) è indipendente da qualsiasi evento definito da \(Y\). La definizione formale che garantisce che ciò accada è la seguente.

\begin{definition}
Le variabili aleatorie \(X\) e \(Y\) sono indipendenti se la loro distribuzione congiunta è il prodotto delle rispettive distribuzioni marginali:

\begin{equation}
P(X, Y)\, = P_X(x)P_Y(y).
\end{equation}
\end{definition}

Nel caso discreto, dunque, l'indipendenza implica che la probabilità riportata in ciascuna cella della tabella di probabilità congiunta deve essere uguale al prodotto delle probabilità marginali di riga e di colonna:

\[
P(x_i, y_i)\, = P_X(x_i) P_Y(y_i).
\]

\begin{exercise}
Per la situazione rappresentata nella tabella \ref{tab:ditr-cong-biv} le variabili casuali \(X\) e \(Y\) sono indipendenti?

Nella tabella le variabili casuali \(X\) e \(Y\) non sono indipendenti: le probabilità congiunte non sono ricavabili dal prodotto delle marginali. Per esempio, nessuna delle probabilità marginali è uguale a \(0\) per cui nessuno dei valori dentro la tabella (probabilità congiunte) che risulta essere uguale a \(0\) può essere il prodotto delle probabilità marginali.
\end{exercise}

\hypertarget{anticipazione}{%
\section{Anticipazione}\label{anticipazione}}

Nella trattazione della statistca bayesiana useremo spesso il concetto di ``marginalizzazione'' e vedremo spesso equazioni come la seguente:

\begin{equation}
p(y) = \int_{\theta} p(y, \theta) = \int_{\theta} p(y \mid \theta) p(\theta),
\end{equation}

laddove \(y\) e \(\theta\) sono due variabili casuali continue -- nello specifico, con \(y\) denoteremo i dati e con \(\theta\) i parametri di un modello statistico. Per ora, possiamo pensare a \(y\) e \(\theta\) come a due variabili casuali qualsiasi.

La \eqref{eq:ex-marginalization} descrive la distribuzione marginale di \(y\). In questa forma, l'equazione potrebbe essere difficile da capire. Per una maggiore comprensione, consideriamo il caso discreto. Nell'equazione corrispondente al caso discreto semplicemente sostituiamo l'integrale con una somma:

\begin{equation}
p(y) = \sum_{\theta} p(y, \theta) = \sum_{\theta} p(y \mid \theta) p(\theta).
\label{eq:ex-marginalization}
\end{equation}

Esaminiamo ora un esempio numerico. Siano \(y\) e \(\theta\) due variabili discrete aventi la distribuzione di massa di probabilità congiunta riportata nella tabella \ref{tab:ex-marg}.

\begin{longtable}[]{@{}cccl@{}}
\caption{\label{tab:ex-marg} Distribuzione di probabilità congiunta \(p(y, \theta)\) per due variabili casuali discrete.}\tabularnewline
\toprule
\(y / \theta\) & 0 & 1 & \(p(y)\) \\
\midrule
\endfirsthead
\toprule
\(y / \theta\) & 0 & 1 & \(p(y)\) \\
\midrule
\endhead
0 & 0.1 & 0.2 & 0.3 \\
1 & 0.3 & 0.4 & 0.7 \\
\(p(\theta)\) & 0.4 & 0.6 & 1.0 \\
\bottomrule
\end{longtable}

Sappiamo che \(p(y) = \{0.3, 0.7\}\). Applicando la \eqref{eq:ex-marginalization}, questo risultato si trova nel modo seguente:

\[
\begin{pmatrix}
    0.1 / 0.4 \\
    0.3 / 0.4
\end{pmatrix} \cdot 0.4 +
\begin{pmatrix}
    0.2 / 0.6 \\
    0.4 / 0.6
\end{pmatrix} \cdot 0.6 =
\begin{pmatrix}
    0.3 \\
   0.7
\end{pmatrix}.
\]

Possiamo pensare al caso continuo indicato nella \eqref{eq:ex-marginalization} come all'estensione dell'esempio presente ad un numero infinito di valori \(\theta\).

\hypertarget{commenti-e-considerazioni-finali-7}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-7}}


La funzione di probabilità congiunta tiene simultaneamente conto del comportamento di due variabili casuali \(X\) e \(Y\) e di come esse si influenzano reciprocamente. In particolare, si osserva che se le due variabili non si influenzano, cioè se sono statisticamente indipendenti, allora la distribuzione di massa di probabilità congiunta si ottiene come prodotto delle funzioni di probabilità marginali di \(X\) e \(Y\): \(P_{X, Y}(x, y) = P_X(x) P_Y(y)\).

\hypertarget{chapter-intro-density-function}{%
\chapter{Funzione di densità di probabilità}\label{chapter-intro-density-function}}

Finora abbiamo considerato solo variabili casuali discrete, cioè variabili che assumono solo valori interi. Ma cosa succede se vogliamo usare variabili casuali per rappresentare lunghezze o volumi o distanze una qualsiasi delle altre proprietà continue nel mondo fisico (o psicologico)? È necessario generalizzare l'approccio usato finora.

Le variabili casuali continue assumono valori reali. L'insieme dei numeri reali è \emph{non numerabile} perché è più grande dell'insieme degli interi.\footnote{Georg Cantor dimostrò che era impossibile mappare uno a uno i reali negli interi, dimostrando così che l'insieme dei reali è non numerabile.} Le leggi della probabilità sono le stessa per le variabili casuali discrete e quelle continue. La nozione di funzione di massa di probabilità, invece, deve essere sostituita dal suo equivalente continuo, ovvero dalla funzione di densità di probabilità. Lo scopo di questo Capitolo è quello di chiarire il significato di questa nozione, usando un approccio basato sulle simulazioni.

\hypertarget{spinner-e-variabili-casuali-continue-uniformi}{%
\section{Spinner e variabili casuali continue uniformi}\label{spinner-e-variabili-casuali-continue-uniformi}}

Consideriamo il seguente esperimento casuale. Facciamo ruotare ad alta velocità uno spinner simmetrico imperniato su un goniometro e osserviamo la posizione in cui si ferma (individuata dall'angolo acuto con segno tra il suo asse e l'asse orizzontale del goniometro). Chiamiamo \(\Theta\) la variabile casuale ``pendenza dello spinner''. Nella trattazione seguente useremo i gradi e, di conseguenza, \(\Theta \in [0, 360]\).

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{ds4psy_files/figure-latex/unnamed-chunk-31-1} 

}

\caption{Uno spinner che riposa a 36 gradi, o il dieci percento del percorso intorno al cerchio. La pendenza dello spinner può assumere qualunque valore tra 0 e 360 gradi.}\label{fig:unnamed-chunk-31}
\end{figure}

Cosa implica per \(\Theta\) dire che lo spinner è simmetrico? Possiamo dire che, in ciascuna prova, la rotazione dello spinner produce un angolo qualunque da 0 a 360 gradi. In altri termini, un valore \(\Theta\) compreso tra 0 e 36 gradi ha la stessa probabilità di essere osservato di un valore \(\Theta\) compreso tra 200 e 236 gradi. Inoltre, poiché 36 gradi è un decimo del percorso intorno al cerchio, la probabilità di ottenere un qualsiasi intervallo di 36 gradi sarà sempre uguale al 10\%. Ovvero \(\mbox{P}[0 \leq \Theta \leq 36] \ = \ \frac{1}{10}\) e \(\mbox{P}[200 \leq \Theta \leq 236] \ = \ \frac{1}{10}\).

È importante notare che le considerazioni precedenti non si riferiscono al fatto che \(\Theta\) può assumere uno specifico valore, ma piuttosto alla probabilità di osservare \(\Theta\) in un particolare intervallo di valori. In generale, la probabilità che la pendenza \(\Theta\) dello spinner cada in intervallo è la frazione del cerchio rappresentata dall'intervallo, cioè,

\[
\mbox{P}[\theta_1 \leq \Theta \leq \theta_2] = \frac{\theta_2 - \theta_1}{360}, \qquad 0 \leq \theta_1 \leq \theta_2 \leq 360.
\]

La ragione di questo è che le variabili casuali continue non hanno una massa di probabilità. Invece, una massa di probabilità viene assegnata alla realizzazione della variabile casuale in un intervallo di valori.

\hypertarget{il-paradosso-delle-variabili-casuali-continue}{%
\subsection{Il paradosso delle variabili casuali continue}\label{il-paradosso-delle-variabili-casuali-continue}}

Nel nostro esempio, la pendenza dello spinner è esattamente 36 gradi; ma avrebbe potuto anche essere 36.0376531 gradi o qualunque altro valore in quell'intorno. Qual è la probabilità che la pendenza dello spinner sia esattamente 36? Paradossalmente, la risposta è zero:

\[
\mbox{P}[\Theta = 36] = 0.
\]

Infatti, se la probabilità di un qualunque valore fosse maggiore di zero, ogni altro possibile valore dovrebbe avere la stessa probabilità, dato che abbiamo assumiamo che tutti i valori \(\Theta\) sono egualmente probabili. Ma se poi andiamo a sommare tutte queste probabilità il totale diventerà maggiore di uno, il che non è possibile.

Nel caso delle variabili casuali continue dobbiamo dunque rinunciare a qualcosa, e quel qualcosa è l'idea che, in una distribuzione continua, ciascun valore puntuale della variabile casuale possa avere una massa di probabilità maggiore di zero. Il paradosso sorge perché una realizzazione della variabile casuale conrtinua produce sempre un qualche numero, ma ciscuno di tali numeri ha probabilità nulla.

\hypertarget{la-funzione-di-ripartizione-per-una-variabile-casuale-continua}{%
\section{La funzione di ripartizione per una variabile casuale continua}\label{la-funzione-di-ripartizione-per-una-variabile-casuale-continua}}

Supponiamo che \(\Theta \sim \mbox{uniform}(0, 360)\) sia la pendenza dello spinner. La funzione di ripartizione (ovvero, la distribuzione cumulativa) è definita esattamente come nel caso delle variabili casuali discrete:

\[
F_{\Theta}(\theta) = \mbox{P}[\Theta \leq \theta].
\]

Cioè, è la probabilità che la variabile casuale \(\Theta\) assuma un valore minore di o uguale a \(\theta\). In questo caso, poiché si presume che lo spinner sia simmetrico, la funzione di distribuzione cumulativa è

\[
F_{\Theta}(\theta) = \frac{\theta}{360}.
\]

Questa è una funzione lineare di \(\theta\), cioè \(\frac{1}{360} \times \theta\), come indicato dal grafico della figura \ref{fig:spinner-cdf}.

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/spinner-cdf-1} 

}

\caption{Funzione di distribuzione cumulativa per l'angolo $\theta$ (in gradi) risultante da una rotazione di uno spinner simmetrico. La linea tratteggiata mostra il valore a 180 gradi, che corrisponde ad una probabilità di 0.5, e la linea tratteggiata a 270 gradi, che corrisponde ad una probabilità di 0.75.}\label{fig:spinner-cdf}
\end{figure}

Possiamo verificare questo risultato mediante simulazione. Per stimare la funzione di ripartizione, simuliamo \(M\) valori \(\theta^{(m)}\) e poi li ordiniamo in ordine crescente.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(M, }\DecValTok{0}\NormalTok{, }\DecValTok{360}\NormalTok{)}
\NormalTok{theta\_asc }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(theta)}
\NormalTok{prob }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{:}\NormalTok{M) }\SpecialCharTok{/}\NormalTok{ M}
\NormalTok{unif\_cdf\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{theta =}\NormalTok{ theta\_asc,}
  \AttributeTok{prob =}\NormalTok{ prob}
\NormalTok{)}
\NormalTok{unif\_cdf\_plot }\OtherTok{\textless{}{-}}
\NormalTok{  unif\_cdf\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta, }\AttributeTok{y =}\NormalTok{ prob)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{90}\NormalTok{, }\DecValTok{180}\NormalTok{, }\DecValTok{270}\NormalTok{, }\DecValTok{360}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{, }\FloatTok{1.0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{expression}\NormalTok{(theta)) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\FunctionTok{expression}\NormalTok{(F[Theta](theta)))}
\NormalTok{unif\_cdf\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/unnamed-chunk-32-1} 

}

\caption{Grafico della funzione di ripartizione di una variabile casuale $\Theta$ che rappresenta il risultato di una rotazione di uno spinner simmetrico. Come previsto, tale funzione è una semplice funzione lineare perché la variabile sottostante $\Theta$ ha una distribuzione uniforme.}\label{fig:unnamed-chunk-32}
\end{figure}

Anche con \emph{M} = 1000, tale grafico è praticamente indistinguibile da quello prodotto per via analitica.

Come nel caso delle variabili casuali discrete, la funzione di ripartizione può essere utilizzata per calcolare le probabilità che la variabile casuale assuma valori in un intervallo. Ad esempio

\begin{align}
\mbox{P}[180 < \Theta \leq 270] &= \mbox{P}[\Theta \leq 270] \ - \ \mbox{P}[\Theta \leq 180] \notag\\
&= F_{\Theta}(270) - F_{\Theta}(180)\notag\\
&= \frac{3}{4} - \frac{1}{2} \notag\\
&= \frac{1}{4}.\noindent
\end{align}

\hypertarget{la-distribuzione-uniforme}{%
\section{La distribuzione uniforme}\label{la-distribuzione-uniforme}}

Dopo avere visto come generare numeri casuali uniformi da 0 a 360, consideriamo ora una variabile casuale che assume valori nell'intervallo da 0 a 1. Chiamiamo tale variabile casuale \(\Theta\) e assumiamo che abbia una distribuzione continua uniforme sull'intervallo {[}0, 1{]}:

\[
\Theta \sim Uniform(0, 1).
\]

Poiché le probabilità assumono valori nell'intervallo {[}0, 1{]}, possiamo pensare a \(\Theta\) come ad un valore di probabilità preso a caso in ciascuna realizzazione dell'esperimento casuale.

La distribuzione uniforme è la più semplice delle distribuzioni di densità di probabilità. Per chiarire le proprietà di tale distribuzione, iniziamo con una simulazione e generiamo 10,000 valori casuali di \(\Theta\). I primi 10 di tali valori sono stampati qui di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{logit }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{log}\NormalTok{(x }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ x))}
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(M)}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FunctionTok{logit}\NormalTok{(theta)}
\ControlFlowTok{for}\NormalTok{ (m }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)}
  \FunctionTok{print}\NormalTok{(alpha[m])}
\CommentTok{\#\textgreater{} [1] {-}2.053}
\CommentTok{\#\textgreater{} [1] 0.4993}
\CommentTok{\#\textgreater{} [1] 0.4443}
\CommentTok{\#\textgreater{} [1] 0.5039}
\CommentTok{\#\textgreater{} [1] 1.823}
\CommentTok{\#\textgreater{} [1] 0.5767}
\CommentTok{\#\textgreater{} [1] {-}4.647}
\CommentTok{\#\textgreater{} [1] {-}1.194}
\CommentTok{\#\textgreater{} [1] 0.6905}
\CommentTok{\#\textgreater{} [1] 0.05702}
\end{Highlighting}
\end{Shaded}

Creaiamo ora un istogramma che descrive la distribuzione delle 10,000 realizzazioni \(\Theta\) che abbiamo trovato:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_prob\_unif }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{theta =}\NormalTok{ theta)}
\NormalTok{unif\_prob\_plot }\OtherTok{\textless{}{-}}
  \FunctionTok{ggplot}\NormalTok{(df\_prob\_unif, }\FunctionTok{aes}\NormalTok{(theta)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{binwidth =} \DecValTok{1} \SpecialCharTok{/} \DecValTok{34}\NormalTok{, }\AttributeTok{center =} \DecValTok{1} \SpecialCharTok{/} \DecValTok{68}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{,}
    \AttributeTok{size =} \FloatTok{0.25}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.25}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.75}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{lim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1300}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{500}\NormalTok{, }\DecValTok{1000}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(Theta, }\StringTok{" \textasciitilde{} Uniform(0, 1)"}\NormalTok{)))}
\NormalTok{unif\_prob\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/unnamed-chunk-34-1} 

}

\caption{Istogramma di $10\,000$ realizzazioni $\Theta \sim \mbox{Uniform}(0, 1)$. }\label{fig:unnamed-chunk-34}
\end{figure}

È chiaro che, all'aumentare del numero delle realizzazioni \(\Theta\), il profilo dell'istogramma tenderà a diventare una linea retta. Ciò significa che la funzione di densità di una variabile casuale uniforme continua è una costante. Cioè, se \(\Theta \sim \mbox{Uniform} (a, b)\), allora \(p_{\Theta}(\theta) = c\), dove \(c\) è una costante.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{uniform\_pdf\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{p\_y =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{uniform\_pdf\_plot }\OtherTok{\textless{}{-}}
  \FunctionTok{ggplot}\NormalTok{(uniform\_pdf\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ y, }\AttributeTok{y =}\NormalTok{ p\_y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"\#333333"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{color =} \StringTok{"\#333333"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"a"}\NormalTok{, }\StringTok{"b"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}
    \AttributeTok{lim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{),}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"0"}\NormalTok{, }\StringTok{"c"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{expression}\NormalTok{(theta)) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(p[Theta], }\StringTok{"("}\NormalTok{, theta, }\StringTok{" | a, b)"}\NormalTok{))) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{0}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{xend =} \DecValTok{0}\NormalTok{, }\AttributeTok{yend =} \DecValTok{1}\NormalTok{),}
    \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{xend =} \DecValTok{1}\NormalTok{, }\AttributeTok{yend =} \DecValTok{1}\NormalTok{),}
    \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{0}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{xend =} \DecValTok{1}\NormalTok{, }\AttributeTok{yend =} \DecValTok{0}\NormalTok{),}
    \AttributeTok{linetype =} \StringTok{"dotted"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \SpecialCharTok{{-}}\FloatTok{0.25}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{xend =} \DecValTok{0}\NormalTok{, }\AttributeTok{yend =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{xend =} \FloatTok{1.25}\NormalTok{, }\AttributeTok{yend =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{0}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{),}
    \AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{shape =} \DecValTok{21}\NormalTok{,}
    \AttributeTok{fill =} \StringTok{"\#ffffe6"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{0}\NormalTok{),}
    \AttributeTok{size =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{shape =} \DecValTok{21}\NormalTok{,}
    \AttributeTok{fill =} \StringTok{"\#ffffe6"}
\NormalTok{  )}
\NormalTok{uniform\_pdf\_plot}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-35-1} \end{center}

\noindent Dal grafico vediamo che l'area sottesa alla funzione di densità è \((b - a)\times c\). Dato che tale area deve essere unitaria, ovvero, \((b - a) \times c = 1\), possiamo trovare \(c\) dividendo entrambi i termini per \(b - a\),

\[
c  = \frac{\displaystyle{1}}{\displaystyle b - a}.
\]

Ovvero, se \(\Theta \sim \mbox{Uniform}(a, b)\), allora

\[
p_{\Theta}(\theta) = \mbox{Uniform}(\theta \mid a, b),
\]

laddove

\[
\mbox{Uniform}(\theta \mid a, b) = \frac{1}{b - a}.
\]

In conclusione, la densità di una variabile casuale uniforme continua non dipende da \(\theta\) --- è costante e identica per ogni possibile valore \(\theta\).\footnote{Per comodità, possiamo assumere che i valori impossibili di \(\theta\) abbiano una densità uguale a zero.} Vedremo nel prossimo Paragrafo che, eseguendo una trasformazione su questa variabile casuale uniforme, possiamo creare altre variabili casuali di interesse.

\begin{exercise}
Si consideri una variabile casuale uniforme \(X\) definita sull'intervallo {[}0, 100{]}. Si trovi la probabilità \(P(20 < X < 60)\).

Per trovare la soluzione è sufficiente calcolare l'area di un rettangolo di base \(60 - 20 = 40\) e di altezza 1/100. La probabilità cercata è dunque \(P(20 < X < 60) = 40 \cdot 0.01 = 0.4\).
\end{exercise}

\hypertarget{dagli-istogrammi-alle-densituxe0}{%
\section{Dagli istogrammi alle densità}\label{dagli-istogrammi-alle-densituxe0}}

Non esiste l'equivalente di una funzione di massa di probabilità per le variabili casuali continue. Esiste invece una \emph{funzione di densità di probabilità} la quale, nei termini di una simulazione, può essere concepita nel modo seguente: avendo a disposizione un numero enorme di casi, quando l'intervallo \(\Delta\) di ciascuna classe \(\rightarrow\) 0, la spezzata tende a diventare una curva continua. Tale curva continua \(f(x)\) è detta funzione di densità di probabilità.

Come si trasformano gli istogrammi all'aumentare del numero di osservazioni? Nei grafici seguenti, la numerosità cresce da \(10\) a \(1\,000\,000\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df\_log\_odds\_growth }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (log10M }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{) \{}
\NormalTok{  M }\OtherTok{\textless{}{-}} \DecValTok{10}\SpecialCharTok{\^{}}\NormalTok{log10M}
\NormalTok{  alpha }\OtherTok{\textless{}{-}} \FunctionTok{logit}\NormalTok{(}\FunctionTok{runif}\NormalTok{(M))}
\NormalTok{  df\_log\_odds\_growth }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(}
\NormalTok{    df\_log\_odds\_growth,}
    \FunctionTok{data.frame}\NormalTok{(}
      \AttributeTok{alpha =}\NormalTok{ alpha,}
      \AttributeTok{M =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{sprintf}\NormalTok{(}\StringTok{"M = \%d"}\NormalTok{, M), M)}
\NormalTok{    )}
\NormalTok{  )}
\NormalTok{\}}
\NormalTok{log\_odds\_growth\_plot }\OtherTok{\textless{}{-}}
\NormalTok{  df\_log\_odds\_growth }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(alpha)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{bins =} \DecValTok{75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{M, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}
    \AttributeTok{lim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{8.5}\NormalTok{, }\FloatTok{8.5}\NormalTok{), }\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(Phi, }\StringTok{" = "}\NormalTok{, }\FunctionTok{logit}\NormalTok{(Theta)))) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"proportion of draws"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{panel.spacing.x =} \FunctionTok{unit}\NormalTok{(}\DecValTok{2}\NormalTok{, }\StringTok{"lines"}\NormalTok{),}
    \AttributeTok{panel.spacing.y =} \FunctionTok{unit}\NormalTok{(}\DecValTok{2}\NormalTok{, }\StringTok{"lines"}\NormalTok{)}
\NormalTok{  )}
\NormalTok{log\_odds\_growth\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{ds4psy_files/figure-latex/unnamed-chunk-36-1} 

}

\caption{Istogramma di $M$ campioni casuali $\Theta \sim \mbox{Uniform}(0, 1)$ trasformati in valori $\Phi = \mbox{logit}(\Theta).$ Il profilo limite dell'istogramma è evidenziato nella figura in basso a destra che è stata costruita usando $1\,000\,000$ di osservazioni.}\label{fig:unnamed-chunk-36}
\end{figure}

In un istogramma, l'area di ciascuna barra è proporzionale alla frequenza relativa delle osservazioni in quel'intervallo. Perché tutti gli intervalli hanno la stessa ampiezza, anche l'altezza di ciascuna barra sarà proporzionale alla frequenza relativa delle osservazioni in quel'intervallo.

Nella simulazione, possiamo pensare all'area di ciascuna barra dell'istogramma come alla stima della probabilità che la variabile casuale assuma un valore compreso nell'intervallo considerato. All'aumentare del numero \(M\) di osservazioni, le probabilità stimate si avvicinano sempre di più ai veri valori della probabilità. All'aumentare del numero degli intervalli (quando l'ampiezza \(\Delta\) dell'intervallo \(\rightarrow\) 0), il profilo dell'istogramma tende a diventare una curva continua. Tale curva continua è la funzione di densità di probabilità della variabile casuale. Per l'esempio presente, con \(M =1\,000\,000\), otteniamo il grafico riportato nella figura \ref{fig:hist-dens-example}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \FloatTok{1e6}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \FunctionTok{logit}\NormalTok{(}\FunctionTok{runif}\NormalTok{(M))}
\NormalTok{density\_limit\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{alpha =}\NormalTok{ alpha)}
\NormalTok{density\_limit\_plot }\OtherTok{\textless{}{-}}
\NormalTok{  density\_limit\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(alpha)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \AttributeTok{stat =} \StringTok{"density"}\NormalTok{, }\AttributeTok{n =} \DecValTok{75}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{size =} \FloatTok{0.15}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}
    \AttributeTok{fun =}\NormalTok{ dlogis,}
    \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{location =} \DecValTok{0}\NormalTok{, }\AttributeTok{scale =} \DecValTok{1}\NormalTok{),}
    \AttributeTok{col =} \StringTok{"black"}\NormalTok{,}
    \AttributeTok{size =} \FloatTok{0.3}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}
    \AttributeTok{lim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{, }\DecValTok{9}\NormalTok{),}
    \AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{4}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}
    \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(Phi, }\StringTok{" = "}\NormalTok{, }\FunctionTok{logit}\NormalTok{(Theta)))}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Frequenza relativa"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}
    \AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{(),}
    \AttributeTok{axis.ticks.y =} \FunctionTok{element\_blank}\NormalTok{()}
\NormalTok{  )}
\NormalTok{density\_limit\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{ds4psy_files/figure-latex/hist-dens-example-1} 

}

\caption{Istogramma di $M = 1\,000\,000$ campioni casuali $\Theta \sim \mbox{Uniform}(0,1)$ trasformati in valori $\Phi = \mbox{logit}(\Theta)$. La spezzata nera congiunge i punti centrali superiori delle barre dell'istogramma. Nel limite, quando il numero di osservazioni e di barre tende all'infinito, tale spezzata approssima la funzione di densità di probabilità della variabile casuale.}\label{fig:hist-dens-example}
\end{figure}

Nella statistica descrittiva abbiamo già incontrato una rappresentazione che ha lo stesso significato della funzione di densità, ovvero il kernel density plot. La stima della densità del kernel (KDE), infatti, è un modo non parametrico per stimare la funzione di densità di probabilità di una variabile casuale.

\hypertarget{funzione-di-densituxe0-di-probabilituxe0}{%
\section{Funzione di densità di probabilità}\label{funzione-di-densituxe0-di-probabilituxe0}}

Per descrivere le probabilità che possono essere associate ad una variabile casuale continua \(X\) è necessario definire una funzione \(p(X)\) che deve soddisfare le seguenti due proprietà:

\begin{itemize}
\item
  \(p(x) \geq 0, \forall x\), ovvero, l'ordinata della funzione di densità è 0 o positiva;
\item
  \(\int_{-\infty}^{\infty} p(x) \,\operatorname {d}\!x = 1\), ovvero, l'area sottesa dalla \(p(x)\) è unitaria\footnote{Per quel che riguarda la notazione dell'integrale, ovvero \(\int_x \,\operatorname {d}\!x\), rimando alla discussione di S.P. Thompson: \url{https://calculusmadeeasy.org/1.html}};
\item
  \(p(a < x < b) = \int_a^b p(x) \,\operatorname {d}\!x\), se \(a \leq b\), ovvero, l'area sottesa dalla \(p(y)\) tra due punti \(a\) e \(b\) corrisponde alla probabilità che la v.c. \(x\) assuma un valore compresto tra questi due estremi.
\end{itemize}

\emph{Interpretazione.} È possibile che \(p(x) > 1\), quindi una densità di probabilità non può essere interpretata come una probabilità. Piuttosto, la densità \(p(x)\) può essere utilizzata per confrontare la plausibilità relativa di diversi valori \(X\). Considerata una variabile casuale \(X\) di cui è disponibile un insieme di realizzazioni, tanto maggiore è \(p(x_k)\) rispetto a \(p(x_l)\), tanto più grande sarà la nostra certezza che valori nell'intorno di \(x_k\) verranno osservati con maggiore frequenza di valori nell'intorno di \(x_l\).

\hypertarget{exp-val-and-variance-rv}{%
\chapter{Valore atteso e varianza}\label{exp-val-and-variance-rv}}

Spesso risulta utile fornire una rappresentazione sintetica della distribuzione di una variabile casuale attraverso degli indicatori caratteristici piuttosto che fare riferimento ad una sua rappresentazione completa mediante la funzione di ripartizione, o la funzione di massa o di densità di probabilità. Una descrizione più sintetica di una variabile casuale, tramite pochi valori, ci consente di cogliere le caratteristiche essenziali della distribuzione, quali: la posizione, cioè il baricentro della distribuzione di probabilità; la variabilità, cioè la dispersione della distribuzione di probabilità attorno ad un centro; la forma della distribuzione di probabilità, considerando la simmetria e la curtosi (pesantezza delle code). In questo Capitolo introdurremo quegli indici sintetici che descrivono il centro di una distribuzione di probabilità e la sua variabilità.

\hypertarget{valore-atteso}{%
\section{Valore atteso}\label{valore-atteso}}

Quando vogliamo conoscere il comportamento tipico di una variabile casuale spesso vogliamo sapere qual è il suo ``valore tipico''. La nozione di ``valore tipico'', tuttavia, è ambigua. Infatti, essa può essere definita in almeno tre modi diversi:

\begin{itemize}
\tightlist
\item
  la \emph{media} (somma dei valori divisa per il numero dei valori),
\item
  la \emph{mediana} (il valore centrale della distribuzione, quando la variabile è ordinata in senso crescente o decrescente),
\item
  la \emph{moda} (il valore che ricorre più spesso).
\end{itemize}

Per esempio, la media di \(\{3, 1, 4, 1, 5\}\) è \(\frac{3+1+4+1+5}{5} = 2.8\), la mediana è \(3\) e la moda è \(1\). Tuttavia, la teoria delle probabilità si occupa di variabili casuali piuttosto che di sequenze di numeri. Diventa dunque necessario precisare che cosa intendiamo per ``valore tipico'' quando facciamo riferimento alle variabili casuali. Giungiamo così alla seguente definizione.

\begin{definition}
Sia \(Y\) è una variabile casuale discreta che assume i valori \(y_1, \dots, y_n\) con distribuzione \(p(y)\), ossia

\[
P(Y = y_i) = p(y_i),
\]

per definizione il \emph{valore atteso} di \(Y\), \(\E(Y)\), è

\begin{equation}
\E(Y) = \sum_{i=1}^n y_i \cdot p(y_i).
\label{eq:expval-discr}
\end{equation}
\end{definition}

A parole: il valore atteso (o speranza matematica, o aspettazione, o valor medio) di una variabile casuale è definito come la somma di tutti i valori che la variabile casuale può prendere, ciascuno pesato dalla probabilità con cui il valore è preso.

\begin{exercise}
Calcoliamo il valore atteso della variabile casuale \(Y\) corrispondente al lancio di una moneta equilibrata (testa: \emph{Y} = 1; croce: \emph{Y} = 0).

\[
\E(Y) = \sum_{i=1}^{2} y_i \cdot P(y_i) = 0 \cdot \frac{1}{5} + 1 \cdot \frac{1}{5} = 0.5.
\]
\end{exercise}

\begin{exercise}
Supponiamo ora che \emph{Y} sia il risultato del lancio di un dado equilibrato. Il valore atteso di \emph{Y} diventa:

\[
\E(Y) = \sum_{i=1}^{6} y_i \cdot P(y_i) = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + \dots + 6 \cdot \frac{1}{6} = \frac{21}{6} = 3.5.
\]
\end{exercise}

\hypertarget{interpretazione}{%
\subsection{Interpretazione}\label{interpretazione}}

Che interpretazione può essere assegnata alla nozione di valore atteso? Bruno de Finetti adottò lo stesso termine di \emph{previsione} (e lo stesso simbolo) tanto per la probabilità che per la speranza matematica. Si può pertanto dire che, dal punto di vista bayesiano, la speranza matematica è l'estensione naturale della nozione di probabilità soggettiva.

\hypertarget{proprietuxe0-del-valore-atteso}{%
\subsection{Proprietà del valore atteso}\label{proprietuxe0-del-valore-atteso}}

La proprietà più importante del valore atteso è la linearità: il valore atteso di una somma di variabili casuali è uguale alla somma dei lori rispettivi valori attesi:

\begin{equation}
\E(X + Y) = \E(X) + \E(Y).
\label{eq:prop-expval-linearity}
\end{equation}

La \eqref{eq:prop-expval-linearity} sembra ragionevole quando \(X\) e \(Y\) sono indipendenti, ma è anche vera quando \(X\) e \(Y\) sono associati. Abbiamo anche che

\begin{equation}
\E(cY) = c \E(Y).
\label{eq:prop-expval-const}
\end{equation}

La \eqref{eq:prop-expval-const} ci dice che possiamo estrarre una costante dall'operatore di valore atteso. Tale proprietà si estende a qualunque numero di variabili casuali. Infine, se due variabili casuali \(X\) e \(Y\) sono indipendenti, abbiamo che

\begin{equation}
\E(X Y) = \E(X) \E(Y). 
\label{eq:expval-prod-ind-rv}
\end{equation}

\begin{exercise}
Si considerino le seguenti variabili casuali: \(Y\), ovvero il numero che si ottiene dal lancio di un dado equilibrato, e \(Y\), il numero di teste prodotto dal lancio di una moneta equilibrata. Poniamoci il problema di trovare il valore atteso di \(X+Y\).

Per risolvere il problema iniziamo a costruire lo spazio campionario dell'esperimento casuale consistente nel lancio di un dado e di una moneta.

\begin{longtable}[]{@{}ccccccc@{}}
\toprule
\(x/ y\) & 1 & 2 & 3 & 4 & 5 & 6 \\
\midrule
\endhead
0 & (0, 1) & (0, 2) & (0, 3) & (0, 4) & (0, 5) & (0, 6) \\
1 & (1, 1) & (1, 2) & (1, 3) & (1, 4) & (1, 5) & (1, 6) \\
\bottomrule
\end{longtable}

\noindent ovvero

\begin{longtable}[]{@{}ccccccc@{}}
\toprule
\(x/ y\) & 1 & 2 & 3 & 4 & 5 & 6 \\
\midrule
\endhead
0 & 1 & 2 & 3 & 4 & 5 & 6 \\
1 & 2 & 3 & 4 & 5 & 6 & 7 \\
\bottomrule
\end{longtable}

\noindent Il risultato del lancio del dado è indipendente dal risultato del lancio della moneta. Pertanto, ciascun evento elementare dello spazio campionario avrà la stessa probabilità di verificarsi, ovvero \(Pr(\omega) = \frac{1}{12}\). Il valore atteso di \(X+Y\) è dunque uguale a:

\[
\E(X+Y) = 1 \cdot \frac{1}{12} + 2 \cdot \frac{1}{12} + \dots + 7 \cdot \frac{1}{12} = 4.0.
\]

Lo stesso risultato si ottiene nel modo seguente:

\[
\E(X+Y) = \E(X) + E(Y) = 3.5 + 0.5 = 4.0.
\]
\end{exercise}

\begin{exercise}
Si considerino le variabili casuali \(X\) e \(Y\) definite nel caso del lancio di tre monete equilibrate, dove \(X\) conta il numero delle teste nei tre lanci e \(Y\) conta il numero delle teste al primo lancio. Si calcoli il valore atteso del prodotto delle variabili casuali \(X\) e \(Y\).

La distribuzione di probabilità congiunta \(P(X, Y)\) è fornita nella tabella seguente.

\begin{longtable}[]{@{}cccc@{}}
\toprule
\(x/ y\) & 0 & 1 & \(p(Y)\) \\
\midrule
\endhead
0 & 1/8 & 0 & 1/8 \\
1 & 2/8 & 1/8 & 3/8 \\
2 & 1/8 & 2/8 & 3/8 \\
3 & 0 & 1/8 & 1/8 \\
\(p(y)\) & 4/8 & 4/8 & 1.0 \\
\bottomrule
\end{longtable}

\noindent Il calcolo del valore atteso di \(XY\) si riduce a

\[
\E(XY) = 1 \cdot \frac{1}{8} + 2 \cdot \frac{2}{8} + 3 \cdot \frac{1}{8} = 1.0.
\]

Si noti che le variabili casuali \(Y\) e \(Y\) non sono indipendenti. Dunque non possiamo usare la proprietà \ref{thm:prodindrv}. Infatti, il valore atteso di \(X\) è

\[
\E(X) = 1 \cdot \frac{3}{8} + 2 \cdot \frac{3}{8} + 3 \cdot \frac{1}{8} = 1.5
\]

e il valore atteso di \(Y\) è

\[
\E(Y) = 0 \cdot \frac{4}{8} + 1 \cdot \frac{4}{8} = 0.5.
\] Dunque

\[
1.5 \cdot 0.5 \neq 1.0.
\]
\end{exercise}

\hypertarget{variabili-casuali-continue}{%
\subsection{Variabili casuali continue}\label{variabili-casuali-continue}}

Nel caso di una variabile casuale continua \(Y\) il valore atteso diventa:

\begin{equation}
\E(Y) = \int_{-\infty}^{+\infty} y p(y) \,\operatorname {d}\!y
\label{eq:def-ev-rv-cont}
\end{equation}

Anche in questo caso il valore atteso è una media ponderata della \(y\), nella quale ciascun possibile valore \(y\) è ponderato per il corrispondente valore della densità \(p(y)\). Possiamo leggere l'integrale pensando che \(y\) rappresenti l'ampiezza delle barre infinitamente strette di un istogramma, con la densità \(p(y)\) che corrisponde all'altezza di tali barre e la notazione \(\int_{-\infty}^{+\infty}\) che corrisponde ad una somma.

Un'altra misura di tendenza centrale delle variabili casuali continue è la moda. La moda della \(Y\) individua il valore \(y\) più plausibile, ovvero il valore \(y\) che massimizza la funzione di densità \(p(y)\):

\begin{equation}
\Mo(Y) = \argmax_y p(y).
\label{eq:def-mode}
\end{equation}

\hypertarget{varianza-1}{%
\section{Varianza}\label{varianza-1}}

La seconda più importante proprietà di una variabile casuale, dopo che conosciamo il suo valore atteso, è la \emph{varianza}.

\begin{definition}
Se \(Y\) è una variabile casuale discreta con distribuzione \(p(y)\), per definizione la varianza di \(Y\), \(\Var(Y)\), è

\begin{equation}
\Var(Y) = \E\Big[\big(Y - \E(Y)\big)^2\Big].
\label{eq:def-var-rv}
\end{equation}
\end{definition}

A parole: la varianza è la deviazione media quadratica della variabile dalla sua media.\footnote{Data una variabile casuale \(Y\) con valore atteso \(\E(Y)\), le ``distanze'' tra i valori di \(Y\) e il valore atteso \(\E(Y)\) definiscono la variabile casuale \(Y - \E(Y)\) chiamata \emph{scarto}, oppure \emph{deviazione} oppure \emph{variabile casuale centrata}. La variabile \(Y - \E(Y)\) equivale ad una traslazione di sistema di riferimento che porta il valore atteso nell'origine degli assi. Si può dimostrare facilmente che il valore atteso della variabile scarto \(Y - \E(Y)\) vale zero, dunque la media di tale variabile non può essere usata per quantificare la ``dispersione'' dei valori di \(Y\) relativamente al suo valore medio. Occorre rendere sempre positivi i valori di \(Y - \E(Y)\) e tale risultato viene ottenuto considerando la variabile casuale \(\left(Y - \E(Y)\right)^2\).} Se denotiamo \(\E(Y) = \mu\), la varianza \(\Var(Y)\) diventa il valore atteso di \((Y - \mu)^2\).

\begin{exercise}
Posta \(S\) uguale alla somma dei punti ottenuti nel lancio di due dadi equilibrati, poniamoci il problema di calcolare la varianza di \(S\).

La variabile casuale \(S\) ha la seguente distribuzione di probabilità:

\begin{longtable}[]{@{}cccccccccccc@{}}
\toprule
\(s\) & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\
\midrule
\endhead
\(P(S = s)\) & \(\frac{1}{36}\) & \(\frac{2}{36}\) & \(\frac{3}{36}\) & \(\frac{4}{36}\) & \(\frac{5}{36}\) & \(\frac{6}{36}\) & \(\frac{5}{36}\) & \(\frac{4}{36}\) & \(\frac{3}{36}\) & \(\frac{2}{36}\) & \(\frac{1}{36}\) \\
\bottomrule
\end{longtable}

\noindent Essendo \(\E(S) = 7\), la varianza diventa

\begin{align}
\Var(S) &= \sum \left(S- \mathbb{E}(S)\right)^2 \cdot P(S) \notag\\
&= (2 - 7)^2 \cdot 0.0278 + (3-7)^2 \cdot 0.0556 + \dots + (12 - 7)^2 \cdot 0.0278 \notag\\
&= 5.8333.\notag
\end{align}
\end{exercise}

\hypertarget{formula-alternativa-per-la-varianza}{%
\subsection{Formula alternativa per la varianza}\label{formula-alternativa-per-la-varianza}}

C'è un modo più semplice per calcolare la varianza:

\begin{align}
\E\Big[\big(X - \E(Y)\big)^2\Big] &= \E\big(X^2 - 2X\E(Y) + \E(Y)^2\big)\notag\\
&= \E(Y^2) - 2\E(Y)\E(Y) + \E(Y)^2,\notag
\end{align}

dato che \(\E(Y)\) è una costante; pertanto

\begin{equation}
\Var(Y) = \E(Y^2) - \big(\E(Y) \big)^2.
\label{eq:def-alt-var-rv}
\end{equation}

A parole: la varianza è la media dei quadrati meno il quadrato della media.

\begin{exercise}
Consideriamo la variabile casuale \(Y\) che corrisponde al numero di teste che si osservano nel lancio di una moneta truccata con probabilità di testa uguale a 0.8. Il valore atteso di \(Y\) è

\[
\E(Y) = 0 \cdot 0.2 + 1 \cdot 0.8 = 0.8.
\] Usando la formula tradizionale della varianza otteniamo:

\[
\Var(Y) = (0 - 0.8)^2 \cdot 0.2 + (1 - 0.8)^2 \cdot 0.8 = 0.16.
\] Lo stesso risultato si trova con la formula alternativa della varianza. Il valore atteso di \(Y^2\) è

\[
\E(Y^2) = 0^2 \cdot 0.2 + 1^2 * 0.8 = 0.8.
\] e la varianza diventa

\[
\Var(Y) = \E(Y^2) - \big(\E(Y) \big)^2 = 0.8 - 0.8^2 = 0.16.
\]
\end{exercise}

\hypertarget{variabili-casuali-continue-1}{%
\subsection{Variabili casuali continue}\label{variabili-casuali-continue-1}}

Nel caso di una variabile casuale continua \(Y\), la varianza diventa:

\begin{equation}
\Var(Y) = \int_{-\infty}^{+\infty} \large[y - \E(Y)\large]^2 p(y) \,\operatorname {d}\!y
\label{eq:def-var-rv-cont}
\end{equation}

Come nel caso discreto, la varianza di una v.c. continua \(y\) misura approssimativamente la distanza al quadrato tipica o prevista dei possibili valori \(y\) dalla loro media.

\hypertarget{deviazione-standard}{%
\section{Deviazione standard}\label{deviazione-standard}}

Quando lavoriamo con le varianze, i termini sono innalzati al quadrato e quindi i numeri possono diventare molto grandi (o molto piccoli). Per trasformare nuovamente i valori nell'unità di misura della scala originaria si prende la radice quadrata. Il valore risultante viene chiamato \emph{deviazione standard} e solitamente è denotato dalla lettera greca \(\sigma\).

\begin{definition}
Si definisce scarto quadratico medio (o deviazione standard o scarto tipo) la radice quadrata della varianza:

\begin{equation}
\sigma_Y = \sqrt{\Var(Y)}.
\label{eq:def-sd}
\end{equation}
\end{definition}

Interpretiamo la deviazione standard di una variabile casuale come nella statistica descrittiva: misura approssimativamente la distanza tipica o prevista dei possibili valori \(y\) dalla loro media.

\begin{exercise}
Per i dadi equilibrati dell'esempio precedente, la deviazione standard della variabile casuale \(S\) è uguale a \(\sqrt{5.833} = 2.415\).
\end{exercise}

\hypertarget{standardizzazione}{%
\section{Standardizzazione}\label{standardizzazione}}

\begin{definition}
Data una variabile casuale \(Y\), si dice variabile standardizzata di \(Y\) l'espressione

\begin{equation}
Z = \frac{Y - \E(Y)}{\sigma_Y}.
\label{eq:standardization}
\end{equation}
\end{definition}

Solitamente, una variabile standardizzata viene denotata con la lettera \(Z\).

\hypertarget{momenti-di-variabili-casuali}{%
\section{Momenti di variabili casuali}\label{momenti-di-variabili-casuali}}

\begin{definition}
Si chiama \emph{momento} di ordine \(q\) di una v.c. \(X\), dotata di densità \(p(x)\), la quantità

\begin{equation}
\E(X^q) = \int_{-\infty}^{+\infty} x^q p(x) \; dx.
\end{equation}

Se \(X\) è una v.c. discreta, i suoi momenti valgono:

\begin{equation}
\E(X^q) = \sum_i x_i^q p(x_i).
\end{equation}
\end{definition}

I momenti sono importanti parametri indicatori di certe proprietà di \(X\). I più noti sono senza dubbio quelli per \(q = 1\) e \(q = 2\). Il momento del primo ordine corrisponde al valore atteso di \(X\). Spesso i momenti di ordine superiore al primo vengono calcolati rispetto al valor medio di \(X\), operando una traslazione \(x_0 = x − \E(X)\) che individua lo scarto dalla media. Ne deriva che il momento centrale di ordine 2 corrisponde alla varianza.

\hypertarget{funzione-di-ripartizione}{%
\section{Funzione di ripartizione}\label{funzione-di-ripartizione}}

Il concetto di funzione di ripartizione è molto importante nella teoria della probabilità, sia nel caso discreto, sia in quello continuo. L'insieme \(\{\omega: Y \leq y\}\) è un evento in \(\Omega\) e si può scrivere \((Y \leq y)\). A tale evento è possibile assegnare una probabilità \(P(Y \leq y)\) che, al variare di \(y \in \mathbb{R}\), definisce la funzione di ripartizione della variabile casuale \(Y\).

\begin{definition}
Si chiama \emph{funzione di ripartizione} o \emph{funzione di distribuzione} della variabile casuale \(X\) la funzione \(F(X)\) definita da

\begin{equation}
F(X) \triangleq P(X \le x), \qquad x \in \mathbb{R}.
\label{eq:funrip}
\end{equation}
\end{definition}

Detto a parole: la funzione di distribuzione cumulata, o funzione di ripartizione di \(X\), misura la probabilità che \(X\) assuma valori minori o uguali al valore \(x\).

La funzione di ripartizione è sempre non negativa, monotona non decrescente tra \(0\) e \(1\), tale che:

\[
\lim_{x \to -\infty} F_x(X) = F_X(-\infty) = 0, \quad \lim_{x \to +\infty} F_X(X) = F_X(+\infty) = 1.
\]

\begin{exercise}
Consideriamo l'esperimento casuale corrispondente al lancio di due monete. Sia \(X\) il numero di volte in cui esce testa. La distribuzione di probabilità di \(X\) è:

\[
P(X) = 
\begin{cases}
    0, & 0.25,\\
    1, & 0.50,\\
    2, & 0.25.
\end{cases}
\] La funzione di ripartizione di \(X\) è:

\[
    F(X) = 
\begin{cases}
    0,   & \text{se } x < 0,\\
    1/4, & \text{se } 0 \leq x < 1,\\
    3/4, & \text{se } 1 \leq x < 2,\\
     1,  & \text{se } 2 \leq x.
\end{cases}
\]

Il valore della funzione di ripartizione in corrispondenza di \(x = 1.5\), ad esempio, è:

\[
F(1.5) = P(X \leq 1.5) = P(X=0) + P(X=1) = \frac{1}{4} + \frac{2}{4} = \frac{3}{4}.
\]
\end{exercise}

\mainmatter

\hypertarget{part-distribuzioni-teoriche-di-probabilituxe0}{%
\part{Distribuzioni teoriche di probabilità}\label{part-distribuzioni-teoriche-di-probabilituxe0}}

\hypertarget{distr-rv-discr}{%
\chapter{Distribuzioni di v.c. discrete}\label{distr-rv-discr}}

In questo Capitolo verranno esaminate le principali distribuzioni di probabilità delle variabili casuali discrete. Un esperimento casuale che può dare luogo a solo due possibili esiti (successo, insuccesso) è modellabile con una variabile casuale di Bernoulli. Una sequenza di prove di Bernoulli costituisce un processo Bernoulliano. Il numero di successi dopo \(n\) prove di Bernoulli corrisponde ad una variabile casuale che segue la legge binomiale. La distribuzione binomiale risulta da un insieme di prove di Bernoulli solo se il numero totale \(n\) è fisso per disegno. Se il numero di prove è esso stesso una variabile casuale, allora il numero di successi nella corrispondente sequenza di prove bernoulliane segue al distribuzione di Poisson.

\hypertarget{una-prova-bernoulliana}{%
\section{Una prova Bernoulliana}\label{una-prova-bernoulliana}}

Se un esperimento casuale ha solo due esiti possibili, allora le repliche indipendenti di questo esperimento sono chiamate ``prove Bernoulliane'' (il lancio di una moneta è il tipico esempio).

\begin{definition}
Viene detta variabile di Bernoulli una variabile casuale discreta \(Y = \{0, 1\}\) con la seguente distribuzione di probabilità:

\[
P(Y \mid \theta) =
  \begin{cases}
    \theta     & \text{se $Y = 1$}, \\
    1 - \theta & \text{se $Y = 0$},
  \end{cases}
\]

con \(0 \leq \theta \leq 1\). Convenzionalmente l'evento \(\{Y = 1\}\) con probabilità \(\theta\) viene chiamato ``successo'' mentre l'evento \(\{Y = 0\}\) con probabilità \(1-\theta\) viene chiamato ``insuccesso''.
\end{definition}

Applicando l'operatore di valore atteso e di varianza, otteniamo

\begin{align}
\E(Y) &= 0 \cdot Pr(Y=0) + 1 \cdot Pr(Y=1) = \theta, \\
\Var(Y) &= (0 - \theta)^2 \cdot Pr(Y=0) + (1 - \theta)^2 \cdot rP(Y=1) = \theta(1-\theta).
\label{eq:ev-var-bern}
\end{align}

Scriviamo \(Y \sim \mathcal{B}(\theta)\) per indicare che la variabile casuale \(Y\) ha una distribuzione Bernoulliana di parametro \(\theta\).

\begin{exercise}
Nel caso del lancio di una moneta equilibrata la variabile casuale di Bernoulli assume i valori \(0\) e \(1\). La distribuzione di massa di probabilità è pari a \(\frac{1}{2}\) in corrispondenza di entrambi iv valori. La funzione di distribuzione vale \(\frac{1}{2}\) per \(Y = 0\) e \(1\) per \(Y = 1\).
\end{exercise}

\hypertarget{una-sequenza-di-prove-bernoulliane}{%
\section{Una sequenza di prove Bernoulliane}\label{una-sequenza-di-prove-bernoulliane}}

La distribuzione binomiale è rappresentata dall'elenco di tutti i possibili numeri di successi \(Y = \{0, 1, 2, \dots n\}\) che possono essere osservati in \(n\) prove Bernoulliane indipendenti di probabilità \(\theta\), a ciascuno dei quali è associata la relativa probabilità. Esempi di una distribuzione binomiale sono i risultati di una serie di lanci di una stessa moneta o di una serie di estrazioni da un'urna (con reintroduzione). La distribuzione binomiale di parametri \(n\) e \(\theta\) è in realtà una famiglia di distribuzioni: al variare dei parametri \(\theta\) e \(n\) variano le probabilità.

\begin{definition}
La probabilità di ottenere \(y\) successi e \(n-y\) insuccessi in \(n\) prove Bernoulliane è data dalla distribuzione binomiale:

\begin{align}
P(Y=y) &= \binom{n}{y} \theta^{y} (1-\theta)^{n-y} \notag \\
&= \frac{n!}{y!(n-y)!} \theta^{y} (1-\theta)^{n-y}, 
\label{eq:binomialdistribution}
\end{align}

dove \(n\) = numero di prove Bernoulliane, \(\theta\) = probabilità di successo in ciascuna prova e \(y\) = numero di successi.
\end{definition}

\begin{proof}
La \eqref{eq:binomialdistribution} può essere derivata nel modo seguente. Indichiamo con \(S\) il successo e con \(I\) l'insuccesso di ciascuna prova. Una sequenza di \(n\) prove Bernoulliane darà come esito una sequenza di \(n\) elementi \(S\) e \(I\). Ad esempio, una sequenza che contiene \(y\) successi è la seguente:

\[
\overbrace{SS\dots S}^\text{$y$ volte} \overbrace{II\dots I}^\text{$n-y$ volte}
\] Essendo \(\theta\) la probabilità di \(S\) e \(1-\theta\) la probabilità di \(I\), la probabilità di ottenere la specifica sequenza riportata sopra è

\begin{equation}
\overbrace{\theta \theta\dots \theta}^\text{$y$ volte} \overbrace{(1-\theta)(1-\theta)\dots (1-\theta)}^\text{$n-y$ volte} = \theta^y \cdot (1-\theta)^{n-y}.
\label{eq:demo-bino-kernel}
\end{equation}

Non siamo però interessati alla probabilità di una \emph{specifica} sequenza di \(S\) e \(I\) ma, bensì, alla probabilità di osservare una \emph{qualsiasi} sequenza di \(y\) successi in \(n\) prove. In altre parole, vogliamo la probabilità dell'unione di tutti gli eventi corrispondenti a \(y\) successi in \(n\) prove.

È immediato notare che una qualsiasi altra sequenza contenente esattamente \(y\) successi avrà sempre come probabilità \(\theta^y \cdot (1-\theta)^{n-y}\): il prodotto infatti resta costante anche se cambia l'ordine dei fattori.\footnote{Viene detta \emph{scambiabilità} la proprietà per cui l'ordine con cui compiamo le osservazioni è irrilevante per l'assegnazione delle probabilità.} Per trovare il risultato cercato dobbiamo moltiplicare la \eqref{eq:demo-bino-kernel} per il numero di sequenze possibili di \(y\) successi in \(n\) prove.

Il numero di sequenze che contengono esattamente \(y\) successi in \(n\) prove. La risposta è fornita dal coefficiente binomiale\footnote{La derivazione della formula del coefficiente binomiale è fornita nell'Appendice \ref{derivazione-coef-binom}.}:

\begin{equation}
\binom{n}{y} = \frac{n!}{y!(n-y)!},
\label{eq:binomial-coefficient}
\end{equation}

dove il simbolo \(n!\) si legge \(n\) fattoriale ed è uguale al prodotto di \(n\) numeri interi decrescenti a partire da \(n\). Per definizione \(0! = 1\).

Essendo la probabilità dell'unione di \(K\) elementi incompatibili uguale alla somma delle loro rispettive probabilità, e dato che le sequenze di \(y\) successi in \(n\) prove hanno tutte la stessa probabilità, per trovare la formula della distributione binomiale \eqref{eq:binomialdistribution} è sufficiente moltiplicare la \eqref{eq:demo-bino-kernel} per la \eqref{eq:binomial-coefficient}.
\end{proof}

La distribuzione di probabilità di alcune distribuzioni binomiali, per due valori di \(n\) e \(\theta\), è fornita nella figura \ref{fig:example-binomial-distr}.

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/example-binomial-distr-1} 

}

\caption{Alcune distribuzioni binomiali. Nella figura, il parametro $\theta$ è indicato con $p$.}\label{fig:example-binomial-distr}
\end{figure}

\begin{exercise}

Usando la \eqref{eq:binomialdistribution}, si trovi la probabilità di \(y = 2\) successi in \(n = 4\) prove Bernoulliane indipendenti con \(\theta = 0.2\)

\[
\begin{aligned}
P(Y=2) &= \frac{4!}{2!(4-2)!} 0.2^{2} (1-0.2)^{4-2} \notag  \\
 &= \frac{4 \cdot 3 \cdot 2 \cdot 1}{(2 \cdot 1)(2 \cdot 1)}
0.2^{2} 0.8^{2} = 0.1536. \notag
\end{aligned}
\]

Ripetendo i calcoli per i valori \(y = 0, \dots, 4\) troviamo la distribuzione binomiale di parametri \(n = 4\) e \(\theta = 0.2\):

\begin{longtable}[]{@{}cc@{}}
\toprule
y & P(Y = y) \\
\midrule
\endhead
0 & 0.4096 \\
1 & 0.4096 \\
2 & 0.1536 \\
3 & 0.0256 \\
4 & 0.0016 \\
sum & 1.0 \\
\bottomrule
\end{longtable}

Lo stesso risultato si ottiene usando la sequente istruzione \R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.4096 0.4096 0.1536 0.0256 0.0016}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\begin{exercise}

Lanciando \(5\) volte una moneta onesta, qual è la probabilità che esca testa almeno tre volte?

In \R, la soluzione si trova con

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.5}
\end{Highlighting}
\end{Shaded}

Alternativamente, possiamo trovare la probabilità dell'evento complementare a quello definito dalla funzione di ripartizione calcolata mediante \texttt{pbinom()}, ovvero

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pbinom}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.5}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{valore-atteso-e-deviazione-standard}{%
\subsection{Valore atteso e deviazione standard}\label{valore-atteso-e-deviazione-standard}}

La media (numero atteso di successi in \(n\) prove) e la deviazione standard di una distribuzione binomiale sono molto semplici:

\begin{align}
\mu    &= n\theta,  \notag \\
\sigma &= \sqrt{n\theta(1-\theta)}.
\end{align}

\begin{proof}
Essendo \(Y\) la somma di \(n\) prove Bernoulliane indipendenti \(Y_i\), è facile vedere che \begin{align}
\E(Y) &= \E \left( \sum_{i=1}^n Y_i \right) = \sum_{i=1}^n \E(Y_i) = n\theta, \\
\Var(Y) &= \Var \left( \sum_{i=1}^n Y_i \right) = \sum_{i=1}^n \Var(Y_i) = n \theta (1-\theta).
\end{align}
\end{proof}

\begin{exercise}
Si trovino il valore atteso e la varianza del lancio di quattro monete con probabilità di successo pari a \(\theta = 0.2\).

Il valore atteso è \(\mu = n\theta = 4 \cdot 0.2 = 0.8.\) Ciò significa che, se l'esperimento casuale venisse ripetuto infinite volte, l'esito testa verrebbe osservato un numero medio di volte pari a 0.8. La varianza è \(n \theta (1-\theta) = 4 \cdot(1 - 0.2) = 0.8\).\footnote{L'eguaglianza di \(\mu\) e \(\sigma\) è solo una peculiarità di questo esempio.}
\end{exercise}

\hypertarget{distribuzione-di-poisson}{%
\section{Distribuzione di Poisson}\label{distribuzione-di-poisson}}

La distribuzione di Poisson è una distribuzione di probabilità discreta che esprime le probabilità per il numero di eventi che si verificano successivamente ed indipendentemente in un dato intervallo di tempo, sapendo che mediamente se ne verifica un numero \(\lambda\). La distribuzione di Poisson serve dunque per contare il numero di volte in cui un evento ha luogo in un determinato intervallo di tempo. La stessa distribuzione può essere estesa anche per contare gli eventi che hanno luogo in una determinata porzione di spazio.

\begin{definition}
La distribuzione di Poisson può essere intesa come limite della distribuzione binomiale, dove la probabilità di successo \(\theta\) è pari a \(\frac{\lambda}{n}\) con \(n\) che tende a \(\infty\):

\begin{equation}
\lim_{y \rightarrow \infty} \binom{n}{y} \theta^y (1-\theta)^{n-y} = \frac{\lambda^y}{y!}e^{-\lambda}.
\end{equation}
\end{definition}

Alcune distribuzioni di Poisson sono riportate nella figura \ref{fig:examples-poisson-distrib}.

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/examples-poisson-distrib-1} 

}

\caption{Alcune distribuzioni di Poisson.}\label{fig:examples-poisson-distrib}
\end{figure}

\begin{exercise}

Supponiamo che un evento accada 300 volte all'ora e si vuole determinare la probabilità che in un minuto accadano esattamente 3 eventi.

Il numero medio di eventi in un minuto è pari a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lambda }\OtherTok{\textless{}{-}} \DecValTok{300} \SpecialCharTok{/} \DecValTok{60}
\NormalTok{lambda}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

\noindent Quindi la probabilità che in un minuto si abbiano 3 eventi è pari a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{(lambda}\SpecialCharTok{\^{}}\NormalTok{y }\SpecialCharTok{/} \FunctionTok{factorial}\NormalTok{(y)) }\SpecialCharTok{*} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{lambda)}
\CommentTok{\#\textgreater{} [1] 0.1404}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\begin{exercise}

Per i dati dell'esempio precedente, si trovi la probabilità che un evento accada almeno 8 volte in un minuto.

La probabilità cercata è

\[
p(y \geq 8) = 1 - p (y \leq 7) = 1- \sum_{i = 0}^7 \frac{\lambda^7}{7!}e^{-\lambda},
\] \noindent con \(\lambda = 5\).

Svolgendo i calcoli in \R otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{ppois}\NormalTok{(}\AttributeTok{q =} \DecValTok{7}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.1334}
\FunctionTok{ppois}\NormalTok{(}\AttributeTok{q =} \DecValTok{7}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{5}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.1334}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\begin{exercise}

Sapendo che un evento avviene in media 6 volte al minuto, si calcoli (a) la probabilità di osservare un numero di eventi uguale o inferiore a 3 in un minuto, e (b) la probabilità di osservare esattamente 2 eventi in 30 secondi.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\tightlist
\item
  In questo caso \(\lambda = 6\) e la probabilità richiesta è
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppois}\NormalTok{(}\AttributeTok{q =} \DecValTok{3}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{6}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.1512}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  In questo caso \(\lambda = 6 / 2\) e la probabilità richiesta è
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dpois}\NormalTok{(}\AttributeTok{x =} \DecValTok{2}\NormalTok{, }\AttributeTok{lambda =} \DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.224}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{alcune-proprietuxe0-della-variabile-di-poisson}{%
\section{Alcune proprietà della variabile di Poisson}\label{alcune-proprietuxe0-della-variabile-di-poisson}}

\begin{itemize}
\item
  Il valore atteso, la moda e la varianza della variabile di Poisson sono uguali a \(\lambda\).
\item
  La somma \(Y_1 + \dots + Y_n\) di \(n\) variabili casuali indipendenti con distribuzioni di Poisson di parametri \(\lambda_{1},\dots,\lambda_{n}\) segue una distribuzione di Poisson di parametro \(\lambda = \lambda_{1}+\dots+\lambda_{n}\).
\item
  La differenze di due variabili di Poisson non è una variabile di Poisson. Basti infatti pensare che può assumere valori negativi.
\end{itemize}

\hypertarget{commenti-e-considerazioni-finali-8}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-8}}


La distribuzione binomiale è una distribuzione di probabilità discreta che descrive il numero di successi in un processo di Bernoulli, ovvero la variabile aleatoria \(Y = Y_1 + \dots + Y_n\) che somma \(n\) variabili casuali indipendenti di uguale distribuzione di Bernoulli \(\mathcal{B}(\theta)\), ognuna delle quali può fornire due soli risultati: il successo con probabilità \(\theta\) e il fallimento con probabilità \(1 - \theta\).

La distribuzione binomiale è molto importante per le sue molte applicazioni. Nelle presenti dispense, dedicate all'analisi bayesiana, è soprattutto importante perché costituisce il fondamento del caso più semplice del cosiddetto ``aggiornamento bayesiano'', ovvero il caso Beta-Binomiale. Il modello Beta-Binomiale ci fornirà infatti un esempio paradigmatico dell'approccio bayesiano all'inferenza e sarà trattato in maniera analitica. È dunque importante che le proprietà della distribuzione binomiale risultino ben chiare.

\hypertarget{distr-rv-cont}{%
\chapter{Distribuzioni di v.c. continue}\label{distr-rv-cont}}

Dopo avere introdotto con una simulazione il concetto di funzione di densità nel Capitolo \ref{chapter-intro-density-function}, prendiamo ora in esame alcune delle densità di probabilità più note. La più importante di esse è sicuramente la distribuzione Normale.

\hypertarget{distribuzione-normale}{%
\section{Distribuzione Normale}\label{distribuzione-normale}}

Non c'è un'unica distribuzione Normale, ma ce ne sono molte. Tali distribuzioni sono anche dette ``gaussiane'' in onore di Carl Friedrich Gauss (uno dei più grandi matematici della storia il quale, tra le altre cose, scoprì l'utilità di tale funzione di densità per descrivere gli errori di misurazione). Adolphe Quetelet, il padre delle scienze sociali quantitative, fu il primo ad applicare tale densità alle misurazioni dell'uomo. Karl Pearson usò per primo il termine ``distribuzione Normale'' anche se ammise che questa espressione ``ha lo svantaggio di indurre le persone a credere che le altre distribuzioni, in un senso o nell'altro, non siano normali.''

\hypertarget{limite-delle-distribuzioni-binomiali}{%
\subsection{Limite delle distribuzioni binomiali}\label{limite-delle-distribuzioni-binomiali}}

Iniziamo con un un breve excursus storico. Nel 1733, Abraham de Moivre notò che, aumentando il numero di prove in una distribuzione binomiale, la distribuzione risultante diventava quasi simmetrica e a forma campanulare. Con 10 prove e una probabilità di successo di 0.9 in ciascuna prova, la distribuzione è chiaramente asimmetrica.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{10}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(x, N, }\FloatTok{0.9}\NormalTok{)}
\NormalTok{binomial\_limit\_plot }\OtherTok{\textless{}{-}}
  \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}
    \AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{size =} \FloatTok{0.2}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Binomial(y | 10, 0.9)"}\NormalTok{)}
\NormalTok{binomial\_limit\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/unnamed-chunk-45-1} 

}

\caption{Probabilità del numero di successi in $N = 10$ prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione $\Bin(y \mid 10, 0.9)$. Con solo dieci prove, la distribuzione è fortemente asimmetrica negativa.}\label{fig:unnamed-chunk-45}
\end{figure}

Ma se aumentiamo il numero di prove di un fattore di 100 a \emph{N} = 1000, senza modificare la probabilità di successo di 0.9, la distribuzione assume una forma campanulare quasi simmetrica. Dunque, de Moivre scoprì che, quando \emph{N} è grande, la funzione Normale (che introdurremo qui sotto), nonostante sia la densità di v.a. continue, fornisce una buona approssimazione alla funzione di massa di probabilità binomiale.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{1000}
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{1000}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(x, N, }\FloatTok{0.9}\NormalTok{)}
\NormalTok{binomial\_limit\_plot }\OtherTok{\textless{}{-}}
  \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{size =} \FloatTok{0.2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Binomial(y | 1000, 0.9)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\DecValTok{850}\NormalTok{, }\DecValTok{950}\NormalTok{)}
\NormalTok{binomial\_limit\_plot}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/unnamed-chunk-46-1} 

}

\caption{Probabilità del numero di successi in $N = 1000$ prove bernoulliane indipendenti, ciascuna con una probabilità di successo di 0.90. Il risultato è una distribuzione $\Bin(y \mid 1000, 0.9)$. Con mille prove, la distribuzione è quasi simmetrica a forma campanulare.}\label{fig:unnamed-chunk-46}
\end{figure}

La distribuzione Normale fu scoperta da Gauss nel 1809 e, storicamente, è intimamente legata al metodo dei minimi quadrati -- si veda l'Appendice \ref{gauss-normale}. Il Paragrafo successivo illustra come si possa giungere alla Normale mediante una simulazione.

\hypertarget{normal-random-walk}{%
\section{La Normale prodotta con una simulazione}\label{normal-random-walk}}

\citet{McElreath_rethinking} presenta un esempio che illustra come sia possibile giungere alla distribuzione Normale mediante una simulazione. Supponiamo che vi siano mille persone tutte allineate su una linea di partenza. Quando viene dato un segnale, ciascuna persona lancia una moneta e fa un passo in avanti oppure all'indietro a seconda che sia uscita testa o croce. Supponiamo che la lunghezza di ciascun passo vari da 0 a 1 metro. Ciascuna persona lancia una moneta 16 volte e dunque compie 16 passi.

Alla conclusione di queste passeggiate casuali (\emph{random walk}) non possiamo sapere con esattezza dove si troverà ciascuna persona, ma possiamo conoscere con certezza le caratteristiche della distribuzione delle mille distanze dall'origine. Per esempio, possiamo predire in maniera accurata la proporzione di persone che si sono spostate in avanti oppure all'indietro. Oppure, possiamo predire accuratamente la proporzione di persone che si troveranno ad una certa distanza dalla linea di partenza (es., a 1.5 m dall'origine).

Queste predizioni sono possibili perché tali distanze si distribuiscono secondo la legge Normale. È facile simulare questo processo usando \R. I risultati della simulazione sono riportati nella figura \ref{fig:rw-normal-4816}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pos }\OtherTok{\textless{}{-}}
  \FunctionTok{replicate}\NormalTok{(}\DecValTok{100}\NormalTok{, }\FunctionTok{runif}\NormalTok{(}\DecValTok{16}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rbind}\NormalTok{(}\DecValTok{0}\NormalTok{, .) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{step =} \DecValTok{0}\SpecialCharTok{:}\DecValTok{16}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(key, value, }\SpecialCharTok{{-}}\NormalTok{step) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{person =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{100}\NormalTok{, }\AttributeTok{each =} \DecValTok{17}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(person) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{position =} \FunctionTok{cumsum}\NormalTok{(value)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}

\FunctionTok{ggplot}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ pos,}
  \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ step, }\AttributeTok{y =}\NormalTok{ position, }\AttributeTok{group =}\NormalTok{ person)}
\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{16}\NormalTok{), }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =}\NormalTok{ person }\SpecialCharTok{\textless{}} \DecValTok{2}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ person }\SpecialCharTok{\textless{}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_color\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"gray"}\NormalTok{, }\StringTok{"black"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_alpha\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/} \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}
    \StringTok{"Numero di passi"}\NormalTok{,}
    \AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{16}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y =} \StringTok{"Posizione"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/rw-normal-4816-1} 

}

\caption{Passeggiata casuale di 4, 8 e 16 passi. La spezzata nera indica la media delle distanze dall'origine come funzione del numero di passi.}\label{fig:rw-normal-4816}
\end{figure}

Un kernel density plot delle distanze ottenute dopo 4, 8 e 16 passi è riportato nella figura \ref{fig:rw-normal-3panels}. Nel pannello di destra, al kernel density plot è stata sovrapposta una densità Normale di opportuni parametri (linea tratteggiata).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}}
\NormalTok{  pos }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(step }\SpecialCharTok{==} \DecValTok{4}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ position)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{stat =} \StringTok{"density"}\NormalTok{, }\AttributeTok{color =} \StringTok{"black"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"4 passi"}\NormalTok{)}

\NormalTok{p2 }\OtherTok{\textless{}{-}}
\NormalTok{  pos }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(step }\SpecialCharTok{==} \DecValTok{8}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ position)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{outline.type =} \StringTok{"full"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title =} \StringTok{"8 passi"}\NormalTok{)}

\NormalTok{sd }\OtherTok{\textless{}{-}}
\NormalTok{  pos }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(step }\SpecialCharTok{==} \DecValTok{16}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{sd =} \FunctionTok{sd}\NormalTok{(position)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pull}\NormalTok{(sd)}

\NormalTok{p3 }\OtherTok{\textless{}{-}}
\NormalTok{  pos }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(step }\SpecialCharTok{==} \DecValTok{16}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ position)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}
    \AttributeTok{fun =}\NormalTok{ dnorm,}
    \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =}\NormalTok{ sd),}
    \AttributeTok{linetype =} \DecValTok{2}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{color =} \StringTok{"black"}\NormalTok{, }\AttributeTok{alpha =} \DecValTok{1} \SpecialCharTok{/} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"16 passi"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Densità"}
\NormalTok{  )}

\NormalTok{(p1 }\SpecialCharTok{|}\NormalTok{ p2 }\SpecialCharTok{|}\NormalTok{ p3) }\SpecialCharTok{\&} \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/rw-normal-3panels-1} 

}

\caption{Kernel density plot dei risultati della passeggiata casuale riportata nella figura precente, dopo 4, 8 e 16 passi. Nel pannello di destra, una densità Normale di opportuni parametri è sovrapposta all'istogramma lisciato.}\label{fig:rw-normal-3panels}
\end{figure}

Questa simulazione mostra che qualunque processo nel quale viene sommato un certo numero di valori casuali, tutti provenienti dalla medesima distribuzione, converge ad una distribuzione Normale. Non importa quale sia la forma della distribuzione di partenza: essa può essere uniforme, come nell'esempio presente, o di qualunque altro tipo. La forma della distribuzione da cui viene realizzato il campionamento determina la velocità della convergenza alla Normale. In alcuni casi la convergenza è lenta; in altri casi la convergenza è molto rapida (come nell'esempio presente).

Da un punto di vista formale, diciamo che una variabile casuale continua \(Y\) ha una distribuzione Normale se la sua densità è

\begin{equation}
f(y; \mu, \sigma) = {1 \over {\sigma\sqrt{2\pi} }} \exp \left\{-\frac{(y -  \mu)^2}{2 \sigma^2} \right\},
\label{eq:normal-formula}
\end{equation}

dove \(\mu \in \mathbb{R}\) e \(\sigma > 0\) sono i parametri della distribuzione.

La densità normale è unimodale e simmetrica con una caratteristica forma a campana e con il punto di massima densità in corrispondenza di \(\mu\).

Il significato dei parametri \(\mu\) e \(\sigma\) che appaiono nella \eqref{eq:normal-formula} viene chiarito dalla dimostrazione che

\begin{equation}
\E(X) = \mu, \qquad \Var(X) = \sigma^2.
\end{equation}

La rappresentazione grafica di quattro densità Normali tutte con media 0 e con deviazioni standard 0.25, 0.5, 1 e 2 è fornita nella figura \ref{fig:gaussian-plot-demo}.

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/gaussian-plot-demo-1} 

}

\caption{Alcune distribuzioni Normali.}\label{fig:gaussian-plot-demo}
\end{figure}

\hypertarget{concentrazione}{%
\subsection{Concentrazione}\label{concentrazione}}

È istruttivo osservare il grado di concentrazione della distribuzione Normale attorno alla media:

\begin{align}
P(\mu - \sigma < X < \mu + \sigma) &= P (-1 < Z < 1) \simeq 0.683, \notag\\
P(\mu - 2\sigma < X < \mu + 2\sigma) &= P (-2 < Z < 2) \simeq 0.956, \notag\\
P(\mu - 3\sigma < X < \mu + 3\sigma) &= P (-3 < Z < 3) \simeq 0.997. \notag
\end{align}

\noindent Si noti come un dato la cui distanza dalla media è superiore a 3 volte la deviazione standard presenti un carattere di eccezionalità perché meno del 0.3\% dei dati della distribuzione Normale presentano questa caratteristica.

Per indicare la distribuzione Normale si usa la notazione \(\mathcal{N}(\mu, \sigma)\).

\hypertarget{funzione-di-ripartizione-1}{%
\subsection{Funzione di ripartizione}\label{funzione-di-ripartizione-1}}

Il valore della funzione di ripartizione di \(Y\) nel punto \(y\) è l'area sottesa alla curva di densità \(f(y)\) nella semiretta \((-\infty, y]\). Non esiste alcuna funzione elementare per la funzione di ripartizione

\begin{equation}
F(y) = \int_{-\infty}^y {1 \over {\sigma\sqrt{2\pi} }} \exp \left\{-\frac{(y - \mu)^2}{2\sigma^2} \right\} dy, 
\end{equation}

pertanto le probabilità \(P(Y < y)\) vengono calcolate mediante integrazione numerica approssimata. I valori della funzione di ripartizione di una variabile casuale Normale sono dunque forniti da un software.

\begin{exercise}

Usiamo \R per calcolare la funzione di ripartizione della Normale. La funzione \texttt{pnorm(q,\ mean,\ sd)} restituisce la funzione di ripartizione della Normale con media \texttt{mean} e deviazione standard \texttt{sd}, ovvero l'area sottesa alla funzione di densità di una Normale con media \texttt{mean} e deviazione standard \texttt{sd} nell'intervallo \([-\infty, q]\).

Per esempio, in precedenza abbiamo detto che il 68\% circa dell'area sottesa ad una Normale è compresa nell'intervallo \(\mu \pm \sigma\). Verifichiamo per la distribuzione del QI \(\sim \mathcal{N}(\mu = 100, \sigma = 15)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{100}\SpecialCharTok{+}\DecValTok{15}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{100{-}15}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.6827}
\end{Highlighting}
\end{Shaded}

Il 95\% dell'area è compresa nell'intervallo \(\mu \pm 1.96 \cdot\sigma\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{100} \SpecialCharTok{+} \FloatTok{1.96} \SpecialCharTok{*} \DecValTok{15}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{100} \SpecialCharTok{{-}} \FloatTok{1.96} \SpecialCharTok{*} \DecValTok{15}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.95}
\end{Highlighting}
\end{Shaded}

Quasi tutta la distribuzione è compresa nell'intervallo \(\mu \pm 3 \cdot\sigma\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\DecValTok{100} \SpecialCharTok{+} \DecValTok{3} \SpecialCharTok{*} \DecValTok{15}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{100} \SpecialCharTok{{-}} \DecValTok{3} \SpecialCharTok{*} \DecValTok{15}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9973}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{distribuzione-normale-standard}{%
\subsection{Distribuzione Normale standard}\label{distribuzione-normale-standard}}

La distribuzione Normale di parametri \(\mu = 0\) e \(\sigma = 1\) viene detta \emph{distribuzione Normale standard}. La famiglia Normale è l'insieme avente come elementi tutte le distribuzioni Normali con parametri \(\mu\) e \(\sigma\) diversi. Tutte le distribuzioni Normali si ottengono dalla Normale standard mediante una trasformazione lineare: se \(Y \sim \mathcal{N}(\mu_Y, \sigma_Y)\) allora

\begin{equation}
X = a + b Y \sim \mathcal{N}(\mu_X = a+b \mu_Y, \sigma_X = \left|b\right|\sigma_Y).
\end{equation}

L'area sottesa alla curva di densità di \(\mathcal{N}(\mu, \sigma)\) nella semiretta \((-\infty, y]\) è uguale all'area sottesa alla densità Normale standard nella semiretta \((-\infty, z]\), in cui \(z = (y -\mu_Y )/\sigma_Y\) è il punteggio standard di \(Y\). Per la simmetria della distribuzione, l'area sottesa nella semiretta \([1, \infty)\) è uguale all'area sottesa nella semiretta \((-\infty, 1]\) e quest'ultima coincide con \(F(-1)\). Analogamente, l'area sottesa nell'intervallo \([y_a, y_b]\), con \(y_a < y_b\), è pari a \(F(z_b) - F(z_a)\), dove \(z_a\) e \(z_b\) sono i punteggi standard di \(y_a\) e \(y_b\).

Si ha anche il problema inverso rispetto a quello del calcolo delle aree: dato un numero \(0 \leq p \leq 1\), il problema è quello di determinare un numero \(z \in \mathbb{R}\) tale che \(P(Z < z) = p\). Il valore \(z\) cercato è detto \emph{quantile} di ordine \(p\) della Normale standard e può essere trovato mediante un software.

\begin{exercise}
Supponiamo che l'altezza degli individui adulti segua la distribuzione Normale di media \(\mu = 1.7\) m e deviazione standard \(\sigma = 0.1\) m. Vogliamo sapere la proporzione di individui adulti con un'altezza compresa tra \(1.7\) e \(1.8\) m.

Il problema ci chiede di trovare l'area sottesa alla distribuzione \(\mathcal{N}(\mu = 1.7, \sigma = 0.1)\) nell'intervallo \([1.7, 1.8]\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{seq}\NormalTok{(}\FloatTok{1.4}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{100}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =} \FloatTok{1.7}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.1}\NormalTok{))}

\FunctionTok{ggplot}\NormalTok{(df, }\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_area}\NormalTok{(}\AttributeTok{fill =} \StringTok{"sky blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{gghighlight}\NormalTok{(x }\SpecialCharTok{\textless{}} \FloatTok{1.8} \SpecialCharTok{\&}\NormalTok{ x }\SpecialCharTok{\textgreater{}} \FloatTok{1.7}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Altezza"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Densità"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-50-1} \end{center}

\noindent La risposta si trova utilizzando la funzione di ripartizione \(F(X)\) della legge \(\mathcal{N}(1.7, 0.1)\) in corrispondenza dei due valori forniti dal problema: \(F(X = 1.8) - F(X = 1.7)\). Utilizzando la seguente istruzione

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.8}\NormalTok{, }\FloatTok{1.7}\NormalTok{, }\FloatTok{0.1}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.7}\NormalTok{, }\FloatTok{1.7}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.3413}
\end{Highlighting}
\end{Shaded}

otteniamo il \(31.43\%\).

In maniera equivalente, possiamo standardizzare i valori che delimitano l'intervallo considerato e utilizzare la funzione di ripartizione della normale standardizzata. I limiti inferiore e superiore dell'intervallo sono

\[
z_{\text{inf}} = \frac{1.7 - 1.7}{0.1} = 0, \quad z_{\text{sup}} = \frac{1.8 - 1.7}{0.1} = 1.0,
\]

quindi otteniamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pnorm}\NormalTok{(}\FloatTok{1.0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{{-}} \FunctionTok{pnorm}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.3413}
\end{Highlighting}
\end{Shaded}

Il modo più semplice per risolvere questo problema resta comunque quello di rendersi conto che la probabilità richiesta non è altro che la metà dell'area sottesa dalle distribuzioni Normali nell'intervallo \([\mu - \sigma, \mu + \sigma]\), ovvero \(0.683/2\).
\end{exercise}

\hypertarget{funzione-di-ripartizione-della-normale-standard-e-funzione-logistica}{%
\subsubsection{Funzione di ripartizione della normale standard e funzione logistica}\label{funzione-di-ripartizione-della-normale-standard-e-funzione-logistica}}

Si noti che la funzione logistica (in blu), pur essendo del tutto diversa dalla Normale dal punto di vista formale, assomiglia molto alla Normale standard quando le due cdf hanno la stessa varianza.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ pnorm) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}
    \AttributeTok{fun =}\NormalTok{ plogis,}
    \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{scale =} \FloatTok{0.56}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-53-1} \end{center}

\hypertarget{teorema-del-limite-centrale}{%
\section{Teorema del limite centrale}\label{teorema-del-limite-centrale}}

Laplace dimostrò il teorema del limite centrale (TLC) nel 1812. Il TLC ci dice che se prendiamo una sequenza di variabili casuali indipendenti e le sommiamo, tale somma tende a distribuirisi come una Normale. Il TLC specifica inoltre, sulla base dei valori attesi e delle varianze delle v.c. che vengono sommate, quali saranno i parametri della distribuzione Normale così ottenuta.

\begin{theorem}
Si supponga che \(Y = Y_1, Y_2, \ldots, Y_N\) sia una sequenza di v.a. i.i.d. con \(\E(Y_n) = \mu\) e \(\SD(Y_n) = \sigma\). Si definisca una nuova v.c. come la media di \(Y\):

\[
Z = \frac{1}{N} \sum_{n=1}^N Y_n.
\]

Con \(N \rightarrow \infty\), \(Z\) tenderà ad una Normale con lo stesso valore atteso di \(Y_n\) e una deviazione standard che sarà più piccola della deviazione standard originaria di un fattore pari a \(\sqrt{\frac{1}{\sqrt{N}}}\):

\begin{equation}
p_Z(z) \rightarrow \mathcal{N}\left(z \ \Bigg| \ \mu, \, \frac{1}{\sqrt{N}} \cdot \sigma \right).
\end{equation}
\end{theorem}

Il TLC può essere generalizzato a variabili che non hanno la stessa distribuzione purché siano indipendenti e abbiano aspettative e varianze finite.

Molti fenomeni naturali, come l'altezza dell'uomo adulto di entrambi i sessi, sono il risultato di una serie di effetti additivi relativamente piccoli, la cui combinazione porta alla normalità, indipendentemente da come gli effetti additivi sono distribuiti. In pratica, questo è il motivo per cui la distribuzione normale ha senso come rappresentazione di molti fenomeni naturali.

\hypertarget{distribuzione-chi-quadrato}{%
\section{Distribuzione Chi-quadrato}\label{distribuzione-chi-quadrato}}

Dalla Normale deriva la distribuzione \(\chi^2\). La distribuzione \(\chi^2_{~k}\) con \(k\) gradi di libertà descrive la variabile casuale

\[
Z_1^2 + Z_2^2 + \dots + Z_k^2,
\]

dove \(Z_1, Z_2, \dots, Z_k\) sono variabili casuali i.i.d. con distribuzione Normale standard \(\mathcal{N}(0, 1)\). La variabile casuale chi-quadrato dipende dal parametro intero positivo \(\nu = k\) che ne identifica il numero di gradi di libertà. La densità di probabilità di \(\chi^2_{~\nu}\) è

\[
f(x) = C_{\nu} x^{\nu/2-1} \exp (-x/2), \qquad \text{se } x > 0,
\]

dove \(C_{\nu}\) è una costante positiva.

La figura \ref{fig:alcune-chi-quadrato} mostra alcune distribuzioni Chi-quadrato variando il parametro \(\nu\).

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/alcune-chi-quadrato-1} 

}

\caption{Alcune distribuzioni Chi-quadrato.}\label{fig:alcune-chi-quadrato}
\end{figure}

\hypertarget{proprietuxe0-1}{%
\subsection{Proprietà}\label{proprietuxe0-1}}

\begin{itemize}
\item
  La distribuzione di densità \(\chi^2_{~\nu}\) è asimmetrica.
\item
  Il valore atteso di una variabile \(\chi^2_{~\nu}\) è uguale a \(\nu\).
\item
  La varianza di una variabile \(\chi^2_{~\nu}\) è uguale a \(2\nu\).
\item
  Per \(k \rightarrow \infty\), la \(\chi^2_{~\nu} \rightarrow \mathcal{N}\).
\item
  Se \(X\) e \(Y\) sono due variabili casuali chi-quadrato indipendenti con \(\nu_1\) e \(\nu_2\) gradi di libertà, ne segue che \(X + Y \sim \chi^2_m\), con \(m = \nu_1 + \nu_2\). Tale principio si estende a qualunque numero finito di variabili casuali chi-quadrato indipendenti.
\end{itemize}

\begin{exercise}

Usiamo \(\R\) per disegnare la densità chi-quadrato con 3 gradi di libertà dividendo l'area sottesa alla curva di densità in due parti uguali.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{15.0}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{100}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{dchisq}\NormalTok{(x, }\DecValTok{3}\NormalTok{))}

\FunctionTok{ggplot}\NormalTok{(df, }\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_area}\NormalTok{(}\AttributeTok{fill =} \StringTok{"sky blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{gghighlight}\NormalTok{(x }\SpecialCharTok{\textless{}} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"V.a. chi{-}quadrato con 3 gradi di libertà"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Densità"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-54-1} \end{center}

\end{exercise}

\hypertarget{distribuzione-t-di-student}{%
\section{\texorpdfstring{Distribuzione \(t\) di Student}{Distribuzione t di Student}}\label{distribuzione-t-di-student}}

Dalle distribuzioni Normale e Chi quadrato deriva un'altra distribuzione molto nota, la \(t\) di Student. Se \(Z \sim \mathcal{N}\) e \(W \sim \chi^2_{~\nu}\) sono due variabili casuali indipendenti, allora il rapporto

\begin{equation}
T = \frac{Z}{\Big( \frac{W}{\nu}\Big)^{\frac{1}{2}}}
\end{equation}

definisce la distribuzione \(t\) di Student con \(\nu\) gradi di libertà. Si usa scrivere \(T \sim t_{\nu}\). L'andamento della distribuzione \(t\) di Student è simile a quello della distribuzione Normale, ma ha una maggiore dispersione (ha le code più pesanti di una Normale, ovvero ha una varianza maggiore di 1).

La figura \ref{fig:alcune-t-student} mostra alcune distribuzioni \(t\) di Student variando il parametro \(\nu\).

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/alcune-t-student-1} 

}

\caption{Alcune distribuzioni $t$ di Student.}\label{fig:alcune-t-student}
\end{figure}

\hypertarget{proprietuxe0-2}{%
\subsection{Proprietà}\label{proprietuxe0-2}}

La variabile casuale \(t\) di Student soddisfa le seguenti proprietà:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Per \(\nu \rightarrow \infty\), \(t_{\nu}\) tende alla normale standard \(\mathcal{N}(0, 1)\).
\item
  La densità della \(t_{\nu}\) è una funzione simmetrica con valore atteso nullo.
\item
  Per \(\nu > 2\), la varianza della \(t_{\nu}\) vale \(\nu/(\nu - 2)\); pertanto è sempre maggiore di 1 e tende a 1 per \(\nu \rightarrow \infty\).
\end{enumerate}

\hypertarget{funzione-beta-di-eulero}{%
\section{Funzione beta di Eulero}\label{funzione-beta-di-eulero}}

La funzione beta di Eulero è una funzione matematica, \emph{non} una densità di probabilità. La menzioniamo qui perché viene utilizzata nella distribuzione Beta. La funzione beta si può scrivere in molti modi diversi; per i nostri scopi la scriveremo così:

\begin{equation}
B(\alpha, \beta) = \frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha + \beta)}\,,
\end{equation}

dove \(\Gamma(x)\) è la funzione Gamma, ovvero il fattoriale discendente, cioè \begin{equation}
x(x-1)(x-2)\ldots (x-n+1)\notag\,.
\end{equation}

\hypertarget{distribuzione-beta}{%
\section{Distribuzione Beta}\label{distribuzione-beta}}

Una distribuzione che viene usata per modellare percentuali e proporzioni è la distribuzione Beta in quanto è definita sull'intervallo \((0; 1)\) -- ma non include i valori 0 o 1. La distribuzione Beta è una distribuzione estremamente flessibile e può assumere molti tipi di forme diverse (un'illustrazione è fornita dalla seguente \href{https://en.wikipedia.org/wiki/File:PDF_of_the_Beta_distribution.gif}{GIF animata}). Una definizione formale è la seguente.

\begin{definition}
Sia \(\pi\) una variabile casuale che può assumere qualsiasi valore compreso tra 0 e 1, cioè \(\pi \in [0, 1]\). Diremo che \(\pi\) segue la distribuzione Beta di parametri \(\alpha\) e \(\beta\), \(\pi \sim \text{Beta}(\alpha, \beta)\), se la sua densità è

\begin{align}
\text{Beta}(\pi \mid \alpha, \beta) &= \frac{1}{B(\alpha, \beta)}\pi^{\alpha-1} (1-\pi)^{\beta-1}\notag\\ 
&=  \frac{\Gamma(\alpha+ \beta)}{\Gamma(\alpha)\Gamma(\beta)}\pi^{\alpha-1} (1-\pi)^{\beta-1} \quad \text{per } \pi \in [0, 1]\,,
\label{eq:beta-distr-formula}
\end{align}

laddove \(B(\alpha, \beta)\) è la funzione beta.
\end{definition}

I termini \(\alpha\) e \(\beta\) sono i parametri della distribuzione Beta e devono essere entrambi positivi. Tali parametri possono essere interpretati come l'espressione delle nostre credenze a priori relative ad una sequenza di prove Bernoulliane Il parametro \(\alpha\) rappresenta il numero di ``successi'' e il parametro \(\beta\) il numero di ``insuccessi'':

\begin{equation}
\frac{\text{Numero di successi}}{\text{Numero di successi} + \text{Numero di insuccessi}} = \frac{\alpha}{\alpha + \beta}\notag\,.
\end{equation}

Il rapporto \(\frac{1}{B(\alpha, \beta)} = \frac{\Gamma(\alpha+b)}{\Gamma(\alpha)\Gamma(\beta)}\) è una costante di normalizzazione:

\begin{equation}
\int_0^1 \pi^{\alpha-1} (1-\pi)^{\beta-1} = \frac{\Gamma(\alpha+b)}{\Gamma(\alpha)\Gamma(\beta)}\,.
\end{equation}

Il valore atteso, la moda e la varianza di una distribuzione Beta sono dati dalle seguenti equazioni:

\begin{equation}
\E(\pi) = \frac{\alpha}{\alpha+\beta}\,,
\label{eq:beta-mean}
\end{equation}

\begin{equation}
\Mo(\pi) = \frac{\alpha-1}{\alpha+\beta-2}\,,
\label{eq:beta-mode}
\end{equation}

\begin{equation}
\Var(\pi) = \frac{\alpha \beta}{(\alpha+\beta)^2 (\alpha+\beta+1)}\,.
\label{eq:beta-var}
\end{equation}

\begin{remark}

Attenzione alle parole: in questo contesto, il termine ``beta'' viene utilizzato con tre significati diversi:

\begin{itemize}
\item
  la distribuzione di densità Beta,
\item
  la funzione matematica beta,
\item
  il parametro \(\beta\).
\end{itemize}

\end{remark}

Al variare di \(\alpha\) e \(\beta\) si ottengono molte distribuzioni di forma diversa; per \(\alpha = \beta = 1\) si ha la densità uniforme. Vari esempi di distribuzioni Beta sono mostrati nella figura \ref{fig:some-beta-distr}.

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/some-beta-distr-1} 

}

\caption{Alcune distribuzioni Beta.}\label{fig:some-beta-distr}
\end{figure}

Si può ottenere una rappresentazione grafica della distribuzione \(\mbox{Beta}(\pi \mid \alpha, \beta)\) con la funzione \texttt{plot\_beta()} del pacchetto \texttt{bayesrules}. Per esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{plot\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-55-1} \end{center}

La funzione \texttt{bayesrules::summarize\_beta()} ci restituisce la media, moda e varianza della distribuzione Beta. Per esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{summarize\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{12}\NormalTok{)}
\CommentTok{\#\textgreater{}     mean    mode      var      sd}
\CommentTok{\#\textgreater{} 1 0.1429 0.08333 0.008163 0.09035}
\end{Highlighting}
\end{Shaded}

\begin{exercise}
Nel disturbo depressivo la recidiva è definita come la comparsa di un nuovo episodio depressivo che si manifesta dopo un prolungato periodo di recupero (6-12 mesi) con stato di eutimia (umore relativamente normale). Supponiamo che una serie di studi mostri una comparsa di recidiva in una proporzione che va dal 20\% al 60\% dei casi, con una media del 40\% \citep[per una recente discussione, si veda][]{nuggerud2020analysis}. Sulla base di queste ipotetiche informazioni, è possibile usare la distribuzione Beta per rappresentare le nostre credenze a priori relativamente alla probabilità di recidiva. Per fare questo dobbiamo trovare i parametri della distribuzione Beta tali per cui la massa della densità sia compresa tra 0.2 e 0.6, con la media in corrispondenza di 0.4. Procedendo per tentativi ed errori, ed usando la funzione \texttt{bayesrules::plot\_beta()}, un risultato possibile è \(\Beta(16, 24)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find\_pars }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(ev, n) \{}
\NormalTok{  a }\OtherTok{\textless{}{-}}\NormalTok{ ev }\SpecialCharTok{*}\NormalTok{ n}
\NormalTok{  b }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{{-}}\NormalTok{ a}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{round}\NormalTok{(a), }\FunctionTok{round}\NormalTok{(b)))}
\NormalTok{\}}

\NormalTok{pars }\OtherTok{\textless{}{-}} \FunctionTok{find\_pars}\NormalTok{(.}\DecValTok{4}\NormalTok{, }\DecValTok{40}\NormalTok{)}
\NormalTok{pars}
\CommentTok{\#\textgreater{} [1] 16 24}
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{plot\_beta}\NormalTok{(pars[}\DecValTok{1}\NormalTok{], pars[}\DecValTok{2}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-57-1} \end{center}

La media della distribuzione a priori diventa:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{16} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{16} \SpecialCharTok{+} \DecValTok{24}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.4}
\end{Highlighting}
\end{Shaded}

e la moda è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{16} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{16} \SpecialCharTok{+} \DecValTok{24} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.3947}
\end{Highlighting}
\end{Shaded}

Inoltre, la deviazione standard della distribuzione a priori diventa

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{((}\DecValTok{16} \SpecialCharTok{*} \DecValTok{24}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{16} \SpecialCharTok{+} \DecValTok{24}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{16} \SpecialCharTok{+} \DecValTok{24} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)))}
\CommentTok{\#\textgreater{} [1] 0.07651}
\end{Highlighting}
\end{Shaded}

uguale a circa 8 punti percentuali. Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{summarize\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{16}\NormalTok{, }\AttributeTok{beta =} \DecValTok{24}\NormalTok{)}
\CommentTok{\#\textgreater{}   mean   mode      var      sd}
\CommentTok{\#\textgreater{} 1  0.4 0.3947 0.005854 0.07651}
\end{Highlighting}
\end{Shaded}

Questo significa che le nostre credenze a priori rispetto la possibilità di recidiva tendono a deviare di circa 8 punti percentuali rispetto alla media della distribuzione a priori che corrisponde circa a 0.40.
\end{exercise}

\hypertarget{distribuzione-di-cauchy}{%
\section{Distribuzione di Cauchy}\label{distribuzione-di-cauchy}}

La distribuzione di Cauchy è un caso speciale della distribuzione di \(t\) di Student con 1 grado di libertà. È definita da una densità di probabilità che corrisponde alla funzione, dipendente da due parametri \(\theta\) e \(d\) (con la condizione \(d > 0\)),

\begin{equation}
f(x; \theta, d) = \frac{1}{\pi d} \frac{1}{1 + \left(\frac{x - \theta}{d} \right)^2},
\end{equation}

dove \(\theta\) è la mediana della distribuzione e \(d\) ne misura la larghezza a metà altezza.

\hypertarget{distribuzione-log-normale}{%
\section{Distribuzione log-normale}\label{distribuzione-log-normale}}

Sia \(y\) una variabile casuale avente distribuzione normale con media \(\mu\) e varianza \(\sigma^2\). Definiamo poi una nuova variabile casuale \(x\) attraverso la relazione

\[
x = e^y \quad \Longleftrightarrow \quad y = \log x.
\] Il dominio di definizione della \(x\) è il semiasse \(x > 0\) e la densità di probabilità \(f(x)\) è data da

\begin{equation}
f(x) = \frac{1}{\sigma \sqrt{2 \pi}} \frac{1}{x} \exp \left\{-\frac{(\log x -  \mu)^2}{2 \sigma^2} \right\}.
\end{equation}

Questa funzione di densità si chiama log-normale.

Il valore atteso e la varianza di una distribuzione log-normale sono dati dalle seguenti equazioni:

\begin{equation}
\E(x) = \exp \left\{\mu + \frac{\sigma^2}{2} \right\}.
\end{equation}

\begin{equation}
\Var(x) = \exp \left\{2 \mu + \sigma^2 \right\} \left(\exp \left\{\sigma^2 \right\}  -1\right).
\end{equation}

Si può dimostrare che il prodotto di variabili casuali log-normali ed indipendenti segue una distribuzione log-normale.

\hypertarget{distribuzione-di-pareto}{%
\section{Distribuzione di Pareto}\label{distribuzione-di-pareto}}

La distribuzione paretiana (o distribuzione di Pareto) è una distribuzione di probabilità continua e così chiamata in onore di Vilfredo Pareto. La distribuzione di Pareto è una distribuzione di probabilità con legge di potenza utilizzata nella descrizione di fenomeni sociali e molti altri tipi di fenomeni osservabili. Originariamente applicata per descrivere la distribuzione del reddito in una società, adattandosi alla tendenza che una grande porzione di ricchezza è detenuta da una piccola frazione della popolazione, la distribuzione di Pareto è diventata colloquialmente nota e indicata come il principio di Pareto, o ``regola 80-20''. Questa regola afferma che, ad esempio, l'80\% della ricchezza di una società è detenuto dal 20\% della sua popolazione. Viene spesso applicata nello studio della distribuzione del reddito, della dimensione dell'impresa, della dimensione di una popolazione e nelle fluttuazioni del prezzo delle azioni.

La densità di una distribuzione di Pareto è

\[
f(x)=(x_m/x)^\alpha,
\]

dove \(x_m\) (parametro di scala) è il minimo (necessariamente positivo) valore possibile di \(X\) e \(\alpha\) è un parametro di forma.

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-62-1} \end{center}

\noindent La distribuzione di Pareto ha una asimmetria positiva. Il supporto della distribuzione di Pareto è la retta reale positiva. Tutti i valori devono essere maggiori del parametro di scala \(x_m\), che è in realtà un parametro di soglia.

\mainmatter

\hypertarget{part-inferenza-statistica-bayesiana}{%
\part{Inferenza statistica bayesiana}\label{part-inferenza-statistica-bayesiana}}

\hypertarget{ch:intro-bayes-inference}{%
\chapter{Inferenza bayesiana}\label{ch:intro-bayes-inference}}

La moderna statistica bayesiana viene per lo più eseguita utilizzando un linguaggio di programmazione probabilistico implementato su computer. Ciò ha cambiato radicalmente il modo in cui venivano eseguite le statistiche bayesiane anche fin pochi decenni fa. La complessità dei modelli che possiamo costruire è aumentata e la barriera delle competenze matematiche e computazionali che sono richieste è diminuita. Inoltre, il processo di modellazione iterativa è diventato, sotto molti aspetti, molto più facile da eseguire. Anche se formulare modelli statistici complessi è diventato più facile che mai, la statistica è un campo pieno di sottigliezze che non scompaiono magicamente utilizzando potenti metodi computazionali. Pertanto, avere una buona preparazione sugli aspetti teorici, specialmente quelli rilevanti nella pratica, è estremamente utile per applicare efficacemente i metodi statistici.

\hypertarget{modellizzazione-bayesiana}{%
\section{Modellizzazione bayesiana}\label{modellizzazione-bayesiana}}

Seguendo \citep{martin2022bayesian}, possiamo descrivere il processo della modellazione bayesiana distinguendo 3 passaggi.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Dati alcuni dati e alcune ipotesi su come questi dati potrebbero essere stati generati, progettiamo un modello combinando e trasformando variabili casuali.
\item
  Usiamo il teorema di Bayes per condizionare i nostri modelli ai dati disponibili. Chiamiamo questo processo ``inferenza'' e come risultato otteniamo una distribuzione a posteriori. Ci auguriamo che i dati riducano l'incertezza per i possibili valori dei parametri, sebbene questo non sia garantito per nessun modello bayesiano.
\item
  Critichiamo il modello verificando se il modello abbia senso utilizzando criteri diversi, inclusi i dati e la nostra conoscenza del dominio. Poiché generalmente siamo incerti sui modelli stessi, a volte confrontiamo diversi modelli.
\end{enumerate}

Questi 3 passaggi vengono eseguiti in modo iterativo e danno luogo a quello che si chiama un ``flusso di lavoro bayesiano'' (\emph{bayesian workflow}).

\begin{remark}
Un modello è uno strumento concettuale che viene utilizzato per risolvere uno specifico problema. In quanto tale, è generalmente più conveniente parlare dell'adeguatezza del modello a un dato problema che di determinare la sua intrinseca correttezza. I modelli esistono esclusivamente come l'ausilio per il raggiungimento di un qualche ulteriore obiettivo. Il problema che i modelli bayesiani cercano di risolvere è quello dell'inferenza\footnote{In termini colloquiali, l'inferenza può essere descritta come la capacità di giungere a conclusioni basate su evidenze e ragionamenti. L'inferenza bayesiana è una particolare forma di inferenza statistica basata sulla combinazione di distribuzioni di probabilità che ha il fine di ottenere altre distribuzioni di probabilità. Nello specifico, la regola di Bayes ci fornisce un metodo per giungere alla quantificazione della plausibilità di una teoria alla luce dei dati osservati.}.
\end{remark}

I modelli bayesiani, computazionali o meno, hanno due caratteristiche distintive:

\begin{itemize}
\tightlist
\item
  Le quantità incognite sono descritte utilizzando le distribuzioni di probabilità. Queste quantità incognite sono chiatame parametri.
\item
  Il teorema di Bayes viene utilizzato per aggiornare i valori dei parametri condizionati ai dati. Possiamo anche concepire questo processo come una riallocazione delle probabilità.
\end{itemize}

\hypertarget{inferenza-bayesiana-come-un-problema-inverso}{%
\section{Inferenza bayesiana come un problema inverso}\label{inferenza-bayesiana-come-un-problema-inverso}}

In questo capitolo ci focalizzeremo sul passaggio 2 descritto sopra. Nello specifico, descrivemo in dettaglio il significato dei tre i termini a destra del segno di uguale nella formula di Bayes: la distribuzione a priori e la funzione di verosimiglianza al numeratore, e la verosimiglianza marginale al denominatore.

\hypertarget{notazione}{%
\subsection{Notazione}\label{notazione}}

Per fissare la notazione, nel seguito \(y\) rappresenterà i dati e \(\theta\) rappresenterà i parametri incogniti di un modello statistico. Sia \(y\) che \(\theta\) saranno concepiti come delle variabili casuali.\footnote{Nell'approccio bayesiano si fa riferimento ad un modello probabilistico \(f(y \mid \theta)\) rappresentativo del fenomeno d'interesse noto a meno del valore assunto dal parametro (o dei parametri) che lo caratterizza. Si fa inoltre riferimento ad una distribuzione congiunta (di massa o di densità di probabilità) \(f(y, \theta)\). Entrambi gli argomenti della funzione \(y\) e \(\theta\) hanno natura di variabili casuali, laddove la nostra incertezza relativa a \(y\) è dovuta alla naturale variabilità del fenomeno indagato (\emph{variabilità aleatoria}), mentre la nostra incertezza relativa a \(\theta\) è dovuta alla mancata conoscenza del suo valore numerico (\emph{variabilità epistemica}).} Con \(x\) verranno invece denotate le quantità note, come ad esempio i predittori del modello lineare. Per rappresentare in un modo conciso i modelli probabilistici viene usata una notazione particolare. Ad esempio, invece di scrivere \(p(\theta) = \mbox{Beta}(1, 1)\) scriviamo \(\theta \sim \mbox{Beta}(1, 1)\). Il simbolo ``\(\sim\)'' viene spesso letto ``è distribuito come''. Possiamo anche pensare che significhi che \(\theta\) costituisce un campione casuale estratto dalla distribuzione Beta(1, 1). Allo stesso modo, ad esempio, la verosimiglianza del modello binomiale può essere scritta come \(y \sim \text{Bin}(n, \theta)\).

\hypertarget{funzioni-di-probabilituxe0}{%
\subsection{Funzioni di probabilità}\label{funzioni-di-probabilituxe0}}

Una caratteristica attraente della statistica bayesiana è che la nostra credenza ``a posteriori'' viene sempre descritta mediante una distribuzione. Questo fatto ci consente di fare affermazioni probabilistiche sui parametri, come ad esempio: ``la probabilità che un parametro sia positivo è 0.35''; oppure, ``il valore più probabile di \(\theta\) è 12 e abbiamo probabilità del 50\% che \(\theta\) sia compreso tra 10 e 15''. Inoltre, possiamo pensare alla distribuzione a posteriori come alla logica conseguenza della combinazione di un modello con i dati; quindi, abbiamo la garanzia che le affermazioni probabilistiche associate alla distribuzione a posteriori siano matematicamente coerenti. Dobbiamo solo ricordare che tutte queste belle proprietà matematiche sono valide solo nel mondo platonico delle idee dove esistono oggetti matematici come sfere, distribuzioni gaussiane e catene di Markov. Quando passiamo dalla purezza della matematica al disordine della matematica applicata al mondo reale, dobbiamo sempre tenere a mente che i nostri risultati sono condizionati, non solo dai dati, ma anche dai modelli. Di conseguenza, dati errati e/o modelli errati conducono facilmente a conclusioni prive di senso, anche se matematicamente coerenti. È dunque necessario conservare sempre una sana quota di scetticismo relativamente ai nostri dati, modelli e risultati \citep{martin2022bayesian}.

Avendo detto questo, nell'aggiornamento bayesiano (dai dati ai parametri) vengono utilizzate le seguenti distribuzioni di probabilità (o di massa di probabilità):

\begin{itemize}
\tightlist
\item
  la \emph{distribuzione a priori} \(p(\theta)\) --- la credenza iniziale (prima di avere osservato i dati \(Y = y\)) riguardo a \(\theta\);
\item
  la \emph{funzione di verosimiglianza} \(p(y \mid \theta)\) --- quanto sono compatibili i dati osservati \(Y = y\) con i diversi valori possibili di \(\theta\)?
\item
  la \emph{verosimiglianza marginale} \(p(y)\) --- costante di normalizzazione: qual è la probabilità complessiva di osservare i dati \(Y = y\)? In termini formali:
\end{itemize}

\[
p(y) = \int_\theta p(y, \theta) \,\operatorname {d}\!\theta = \int_\theta p(y \mid \theta) p(\theta) \,\operatorname {d}\!\theta.
\]

\begin{itemize}
\tightlist
\item
  la \emph{distribuzione a posteriori} \(p(\theta \mid y)\) --- la nuova credenza relativa alla credibilità di ciascun valore \(\theta\) dopo avere osservato i dati \(Y = y\).
\end{itemize}

\hypertarget{la-regola-di-bayes-1}{%
\section{La regola di Bayes}\label{la-regola-di-bayes-1}}

Assumendo un modello statistico, la formula di Bayes consente di giungere alla distribuzione a posteriori \(p(\theta \mid y)\) per il parametro di interesse \(\theta\), come indicato dalla seguente catena di equazioni\footnote{In realtà, avremmo dovuto scrivere \(p(\theta \mid y, \mathcal{M})\), in quanto non condizioniamo la stima di \(\theta\) solo rispetto ai dati \(y\) ma anche ad un modello probabilistico \(\mathcal{M}\) che viene assunto quale meccanismo generatore dei dati. Per semplicità di notazione, omettiamo il riferimento a \(\mathcal{M}\).}:

\begin{align}
p(\theta \mid y)  &= \displaystyle \frac{p(\theta,y)}{p(y)}
 \ \ \ \ \ \mbox{ [def. prob. condizionata]}
\\
&= \displaystyle \frac{p(y \mid \theta) \, p(\theta)}{p(y)}
 \ \ \ \ \ \mbox{ [legge prob. composta]}
\\
&=  \displaystyle \frac{p(y \mid\theta) \, p(\theta)}
                        {\int_{\Theta} p(y,\theta) \, \,\operatorname {d}\!\theta}
 \ \ \ \ \ \mbox{ [legge prob. totale]}
\\
&= \displaystyle \frac{p(y \mid\theta) \, p(\theta)}
                        {\int_{\Theta} p(y \mid\theta) \, p(\theta) \, \,\operatorname {d}\!\theta}
 \ \ \ \ \ \mbox{ [legge prob. composta]}
\\
& \propto \displaystyle p(y \mid\theta) \, p(\theta)
\label{eq:bayesmodel}
\end{align}

La regola di Bayes ``inverte'' la probabilità della distribuzione a posteriori \(p(\theta \mid y)\), esprimendola nei termini della funzione di verosimiglianza \(p(y \mid \theta)\) e della distribuzione a priori \(p(\theta)\). L'ultimo passo è importante per la stima della distribuzione a posteriori mediante i metodi Monte Carlo a catena di Markov, in quanto per questi metodi richiedono soltanto che le funzioni di probabilità siano definite a meno di una costante di proporzionalità. In altri termini, per la maggior parte degli scopi dell'inferenza inversa, è sufficiente calcolare la densità a posteriori non normalizzata, ovvero è possibile ignorare il denominatore bayesiano \(p(y)\). La distribuzione a posteriori non normalizzata, dunque, si riduce al prodotto della varosimiglianza e della distribuzione a priori.

Possiamo dire che la regola di Bayes viene usata per aggiornare le credenze a priori su \(\theta\) (ovvero, la distribuzione a priori) in modo tale da produrre le nuove credenze a posteriori \(p(\theta \mid y)\) che combinano le informazioni fornite dai dati \(y\) con le credenze precedenti. La distribuzione a posteriori riflette dunque l'aggiornamento delle credenze del ricercatore alla luce dei dati. La distribuzione a posteriori \(p(\theta \mid y)\) contiene tutta l'informazione riguardante il parametro \(\theta\) e viene utilizzata per produrre indicatori sintetici, per la determinazione di stime puntuali o intervallari, e per la verifica d'ipotesi.

La \eqref{eq:bayesmodel} rende evidente che, in ottica bayesiana, la quantità di interesse \(\theta\) non è fissata (come nell'impostazione frequentista), ma è una variabile casuale la cui distribuzione di probabilità è influenzata sia dalle informazioni a priori sia dai dati a disposizione. In altre parole, nell'approccio bayesiano non esiste un valore vero di \(\theta\), ma invece lo scopo è quello di fornire invece un giudizio di probabilità (o di formulare una ``previsione'', nel linguaggio di de Finetti). Prima delle osservazioni, sulla base delle nostre conoscenze assegnamo a \(\theta\) una distribuzione a priori di probabilità. Dopo le osservazioni, correggiamo il nostro giudizio e assegniamo a \(\theta\) una distribuzione a posteriori di probabilità.

\hypertarget{modello-probabilistico}{%
\section{Modello probabilistico}\label{modello-probabilistico}}

Poniamoci il problema di analizzare i dati riportati da \citet{zetschefuture2019} (si veda l'appendice \ref{appendix:future-exp}). Tali dati possono essere considerati la manifestazione di una variabile casuale Bernoulliana e corrispondono a 23 ``successi'' in 30 prove. Se i dati rappresentano una proporzione allora, quale meccanismo generatore dei dati, possiamo adottare un modello probabilistico binomiale:

\begin{equation}
y  \sim \mbox{Bin}(n, \theta),
\label{eq:binomialmodel}
\end{equation}

laddove \(\theta\) è la probabiltà che una prova Bernoulliana assuma il valore 1 e \(n\) corrisponde al numero di prove Bernoulliane. Questo modello assume che le prove Bernoulliane \(y_i\) che costituiscono il campione \(y\) siano tra loro indipendenti e che ciascuna abbia la stessa probabilità \(\theta \in [0, 1]\) di essere un ``successo'' (valore 1). In altre parole, il modello generatore dei dati avrà una funzione di massa di probabilità

\[
p(y \mid \theta)
\ = \
\mbox{Bin}(y \mid n, \theta).
\]

Nei capitoli precedenti è stato mostrato come, sulla base del modello binomiale, sia possibile assegnare una probabilità a ciascun possibile valore \(y \in \{0, 1, \dots, n\}\) \emph{assumendo noto il valore del parametro} \(\theta\). Ma ora abbiamo il problema inverso, ovvero quello di fare inferenza su \(\theta\) alla luce dei dati campionari \(y\). In altre parole, riteniamo di conoscere il modello probabilistico che ha generato i dati, ma di tale modello non conosciamo i parametri: vogliamo dunque ottenere informazioni su \(\theta\) avendo osservato i dati \(y\).

Nel modello probabilistico che stiamo esaminando, il termine \(n\) viene trattato come una costante nota e \(\theta\) come una \emph{variabile casuale}. Dato che \(\theta\) è incognito, ma abbiamo a disposione i dati \(y\), svolgeremo l'inferenza su \(\theta\) mediante la regola di Bayes per determinare la distribuzione a posteriori \(p(\theta \mid y)\).

\begin{remark}
Si noti che il modello probabilistico \eqref{eq:binomialmodel} non spiega perché, in ciascuna realizzazione, \(Y\) assuma un particolare valore. Questo modello deve piuttosto essere inteso come un costrutto matematico che ha lo scopo di riflettere alcune proprietà del processo corrispondente ad una sequenza di prove Bernoulliane. Una parte del lavoro della ricerca in tutte le scienze consiste nel verificare le assunzioni dei modelli e, se necessario, nel migliorare i modelli dei fenomeni considerati. Un modello viene giudicato in relazione al suo obiettivo. Se l'obiettivo del modello molto semplice che stiamo discutendo è quello di prevedere la proporzione di casi nei quali \(y_i = 1\), \(i = 1, \dots, n\), allora un modello con un solo parametro come quello che abbiamo introdotto sopra può essere sufficiente. Ma l'evento \(y_i=1\) (supponiamo: superare l'esame di Psicometria, oppure risultare positivi al COVID-19) dipende da molti fattori e se vogliamo rendere conto di una tale complessità, un modello come quello che stiamo discutendo qui certamente non sarà sufficiente. In altre parole, modelli sempre migliori vengono proposti, laddove ogni successivo modello è migliore di quello precedente in quanto ne migliora le capacità di previsione, è più generale, o è più elegante. Per concludere, un modello è un costrutto matematico il cui scopo è quello di rappresentare un qualche aspetto della realtà. Il valore di un tale strumento dipende dalla sua capacità di ottenere lo scopo per cui è stato costruito.
\end{remark}

\hypertarget{distribuzioni-a-priori}{%
\section{Distribuzioni a priori}\label{distribuzioni-a-priori}}

Quando adottiamo un approccio bayesiano, i parametri della distribuzione di riferimento non venono considerati come delle costanti incognite ma bensì vengono trattati come variabili casuali e, di conseguenza, i parametri assumono una particolare distribuzione che nelle statistica bayesiana viene definita come ``a priori''. I parametri (o il parametro), che possiamo indicare con \(\theta\), possono assumere delle distribuzioni a priori differenti; a seconda delle informazioni disponibili bisogna cercare di assegnare una distribuzione di \(\theta\) in modo tale che venga assegnata una probabilità maggiore a quei valori che si ritengono più plausibili per \(\theta\).

La distribuzione a priori sui valori dei parametri \(p(\theta)\) è parte integrante del modello statistico. Ciò implica che due modelli bayesiani possono condividere la stessa funzione di verosimiglianza, ma tuttavia devono essere considerati come modelli diversi se specificano diverse distribuzioni a priori. Ciò significa che, quando diciamo ``Modello binomiale'', intendiamo in realtà un'intera classe di modelli, ovvero tutti i possibili modelli che hanno la stessa verosimiglianza ma diverse distribuzioni a priori su \(\theta\).

Nell'analisi dei dati bayesiana, la distribuzione a priori \(p(\theta)\) codifica le credenze del ricercatore a proposito dei valori dei parametri, prima di avere osservato i dati. Idealmente, le credenze a priori che supportano la specificazione di una distribuzione a priori dovrebbero essere supportate da una qualche motivazione, come ad esempio i risultati di ricerche precedenti, o altre motivazioni giustificabili.

Quando una nuova osservazione (p.~es., vedo un cigno bianco) corrisponde alle mie credenze precedenti (p.~es., la maggior parte dei cigni sono bianchi) la nuova osservazione rafforza le mie credenze precedenti: più nuove osservazioni raccolgo (p.~es., più cigni bianchi vedo), più forti diventano le mie credenze precedenti. Tuttavia, quando una nuova osservazione (p.~es., vedo un cigno nero) non corrisponde alle mie credenze precedenti, ciò contribuisce a diminuire la certezza che attribuisco alle mie credenze: tanto maggiori diventano le osservazioni non corrispondenti alle mie credenze (p.~es., più cigni neri vedo ), tanto più si indeboliscono le mie credenze. Fondamentalmente, tanto più forti sono le mie credenze precedenti, di tante più osservazioni incompatibili (ad esempio, cigni neri) ho bisogno per cambiare idea.

Pertanto, da una prospettiva bayesiana, l'incertezza intorno ai parametri di un modello \emph{dopo} aver visto i dati (ovvero le distribuzioni a posteriori) deve includere anche le credenze precedenti. Se questo modo di ragionare vi sembra molto intuitivo, non è una coincidenza: vi sono infatti diverse teorie psicologiche che prendono l'aggiornamento bayesiano come modello di funzionamento di diversi processi cognitivi.

\hypertarget{tipologie-di-distribuzioni-a-priori}{%
\subsection{Tipologie di distribuzioni a priori}\label{tipologie-di-distribuzioni-a-priori}}

Possiamo distinguere tra diverse distribuzioni a priori in base a quanto fortemente impegnano il ricercatore a ritenere come plausibile un particolare intervallo di valori dei parametri. Il caso più estremo è quello che rivela una totale assenza di conoscenze a priori, il che conduce alle \emph{distribuzioni a priori non informative}, ovvero quelle che assegnano lo stesso livello di credibilità a tutti i valori dei parametri. Le distribuzioni a priori informative, d'altra parte, possono essere \emph{debolmente informative} o \emph{fortemente informative}, a seconda della forza della credenza che esprimono. Il caso più estremo di credenza a priori è quello che riassume il punto di vista del ricercatore nei termini di un \emph{unico valore} del parametro, il che assegna tutta la probabilità (massa o densità) su di un singolo valore di un parametro. Poiché questa non è più una distribuzione di probabilità, sebbene ne soddisfi la definizione, in questo caso si parla di una \emph{distribuzione a priori degenerata}.

La figura seguente mostra esempi di distribuzioni a priori non informative, debolmente o fortemente informative, così come una distribuzione a priori espressa nei termini di un valore puntuale per il modello Binomiale. Le distribuzione a priori illustrate di seguito sono le seguenti:

\begin{itemize}
\tightlist
\item
  \emph{non informativa} : \(\theta_c \sim \mbox{Beta}(1,1)\);
\item
  \emph{debolmente informativa} : \(\theta_c \sim \mbox{Beta}(5,2)\);
\item
  \emph{fortemente informativa} : \(\theta_c \sim \mbox{Beta}(50,20)\);
\item
  \emph{valore puntuale} : \(\theta_c \sim \mbox{Beta}(\alpha, \beta)\) con \(\alpha, \beta \rightarrow \infty\) e \(\frac{\alpha}{\beta} = \frac{5}{2}\).
\end{itemize}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/ch-03-02-models-types-of-priors-1} 

}

\caption{Esempi di distribuzioni a priori per il parametro $\theta_c$ nel Modello Binomiale.}\label{fig:ch-03-02-models-types-of-priors}
\end{figure}

\hypertarget{selezione-della-distribuzione-a-priori}{%
\subsection{Selezione della distribuzione a priori}\label{selezione-della-distribuzione-a-priori}}

La selezione delle distribuzioni a priori è stata spesso vista come una delle scelte più importanti che un ricercatore fa quando implementa un modello bayesiano in quanto può avere un impatto sostanziale sui risultati finali. La soggettività delle distribuzioni a priori è evidenziata dai critici come un potenziale svantaggio dei metodi bayesiani. A questa critica, \citet{vandeSchoot2021modelling} rispondono dicendo che, al di là della scelta delle distribuzioni a priori, ci sono molti elementi del processo di inferenza statistica che sono soggettivi, ovvero la scelta del modello statistico e le ipotesi sulla distribuzione degli errori. In secondo luogo, \citet{vandeSchoot2021modelling} notano come le distribuzioni a priori svolgono due importanti ruoli statistici: quello della ``regolarizzazione della stima'', ovvero, il processo che porta ad indebolire l'influenza indebita di osservazioni estreme, e quello del miglioramento dell'efficienza della stima, ovvero, la facilitazione dei processi di calcolo numerico di stima della distribuzione a posteriori. L'effetto della distribuzione a priori sulla distribuzione a posteriori verrà discusso nel Capitolo \ref{chapter-balance}.

\hypertarget{la-distribuzione-a-priori-per-i-dati-di-zetschefuture2019}{%
\subsection{\texorpdfstring{La distribuzione a priori per i dati di \citet{zetschefuture2019}}{La distribuzione a priori per i dati di @zetschefuture2019}}\label{la-distribuzione-a-priori-per-i-dati-di-zetschefuture2019}}

In un problema concreto di analisi dei dati, la scelta della distribuzione a priori dipende dalle credenze a priori che vogliamo includere nell'analisi dei dati. Se non abbiamo alcuna informazione a priori, potremmo pensare di usare una distribuzione a priori uniforme, ovvero una Beta di parametri \(\alpha=1\) e \(\beta=1\). Questa, tuttavia, è una cattiva idea perché il risultato ottenuto non è invariante a seconda della trasformazione della scala dei dati (ad esempio, se esprimiamo l'altezza in cm piuttosto che in m). Il problema della \emph{riparametrizzazione} verrà discusso nel Capitolo ?? \textbf{TODO}. È invece raccomandato usare una distribuzione a priori poco informativa, come ad esempio \(\mbox{Beta}(2, 2)\).

Nella presente discussione, per fare un esempio, quale distribuzione a priori useremo una \(\mbox{Beta}(2, 10)\), ovvero:

\[
p(\theta) = \frac{\Gamma(12)}{\Gamma(2)\Gamma(10)}\theta^{2-1} (1-\theta)^{10-1}.
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{plot\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{mode =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-63-1} \end{center}

\noindent La \(\mbox{Beta}(2, 10)\) esprime la credenza che \(\theta\) assume valori \(< 0.5\), con il valore più plausibile pari a circa 0.1. Questo è assolutamente implausibile, nel caso dell'esempio in discussione. Adotteremo una tale distribuzione a priori solo per scopi didattici, per esplorare le conseguenze di tale scelta (molto più sensato sarebbe stato usare \(\mbox{Beta}(2, 2)\)).

\hypertarget{verosimiglianza}{%
\section{Verosimiglianza}\label{verosimiglianza}}

Oltre alla distribuzione a priori di \(\theta\), nel numeratore della regola di Bayes troviamo la funzione di verosimigliana. Iniziamo dunque con una definizione.

\begin{definition}
La \emph{funzione di verosimiglianza} \(\mathcal{L}(\theta \mid y) = f(y \mid \theta), \theta \in \Theta,\) è la funzione di massa o di densità di probabilità dei dati \(y\) vista come una funzione del parametro sconosciuto (o dei parametri sconosciuti) \(\theta\).
\end{definition}

Detto in altre parole, le funzioni di verosimiglianza e di (massa o densità di) probabilità sono formalmente identiche, ma è completamente diversa la loro interpretazione. Nel caso della funzione di massa o di densità di probabilità la distribuzione del vettore casuale delle osservazioni campionarie \(y\) dipende dai valori assunti dal parametro (o dai parametri) \(\theta\); nel caso della la funzione di verosimiglianza la credibilità assegnata a ciascun possibile valore \(\theta\) viene determinata avendo acquisita l'informazione campionaria \(y\) che rappresenta l'elemento condizionante. In altri termini, la funzione di verosimiglianza è lo strumento che consente di rispondere alla seguente domanda: avendo osservato i dati \(y\), quanto risultano (relativamente) credibili i diversi valori del parametro \(\theta\)?

Spesso per indicare la verosimiglianza si scrive \(\mathcal{L}(\theta)\) se è chiaro a quali valori \(y\) ci si riferisce. La verosimiglianza \(\mathcal{L}\) è una curva (in generale, una superficie) nello spazio \(\Theta\) del parametro (in generale, dei parametri) che riflette la credibilità relativa dei valori \(\theta\) alla luce dei dati osservati.

Notiamo un punto importante: la funzione \(\mathcal{L}(\theta \mid y)\) non è una funzione di densità. Infatti, essa non racchiude un'area unitaria.

In conclusione, la funzione di verosimiglianza descrive in termini relativi il sostegno empirico che \(\theta \in \Theta\) riceve da \(y\). Infatti, la funzione di verosimiglianza assume forme diverse al variare di \(y\) (lasciamo come esercizio da svolgere la verifica di questa affermazione).

\hypertarget{la-stima-di-massima-verosimiglianza}{%
\subsection{La stima di massima verosimiglianza}\label{la-stima-di-massima-verosimiglianza}}

La funzione di verosimiglianza rappresenta la ``credibilità relativa'' dei valori del parametro di interesse. Ma qual è il valore più credibile? Se utilizziamo soltanto la funzione di verosimiglianza, allora la risposta è data dalla stima di massima verosimiglinza.

\begin{definition}
Un valore di \(\theta\) che massimizza \(\mathcal{L}(\theta \mid y)\) sullo spazio parametrico \(\Theta\) è detto \emph{stima di massima verosimiglinza} (s.m.v.) di \(\theta\) ed è indicato con \(\hat{\theta}\):

\begin{equation}
\hat{\theta} = \argmax_{\theta \in \Theta} \mathcal{L}(\theta).
\end{equation}
\end{definition}

Il paradigma frequentista utilizza la funzione di verosimiglianza quale unico strumento per giungere alla stima del valore più credibile del parametro sconosciuto \(\theta\). Tale stima corrisponde al punto di massimo della funzione di verosimiglianza. In base all'approccio bayesiano, invece, il valore più credibile del parametro sconosciuto \(\theta\), anziché alla s.m.v., corrisponde invece alla moda (o media, o mediana) della distribuzione a posteriori \(p(\theta \mid y)\) che si ottiene combinando la verosimiglianza \(p(y \mid \theta)\) con la distribuzione a priori \(p(\theta)\). Per un approfondimento della stima di massima verosimiglianza si veda l'Appendice \ref{appendix:max-like}.

\hypertarget{la-log-verosimiglianza}{%
\subsection{La log-verosimiglianza}\label{la-log-verosimiglianza}}

Dal punto di vista pratico risulta più conveniente utilizzare, al posto della funzione di verosimiglianza, il suo logaritmo naturale, ovvero la funzione di log-verosimiglianza:

\begin{equation}
\ell(\theta) = \log \mathcal{L}(\theta).
\end{equation}

Poiché il logaritmo è una funzione strettamente crescente (usualmente si considera il logaritmo naturale), allora \(\mathcal{L}(\theta)\) e \(\ell(\theta)\) assumono il massimo (o i punti di massimo) in corrispondenza degli stessi valori di \(\theta\):

\[
\hat{\theta} = \argmax_{\theta \in \Theta} \ell(\theta) = \argmax_{\theta \in \Theta} \mathcal{L}(\theta).
\]

Per le proprietà del logaritmo, si ha

\begin{equation}
\ell(\theta) = \log \left( \prod_{i = 1}^n f(y \mid \theta) \right) = \sum_{i = 1}^n \log f(y \mid \theta).
\end{equation}

Si noti che non è necessario lavorare con i logaritmi, ma è fortemente consigliato. Il motivo è che i valori della verosimiglianza, in cui si moltiplicano valori di probabilità molto piccoli, possono diventare estremamente piccoli -- qualcosa come \(10^{-34}\). In tali circostanze, non è sorprendente che i programmi dei computer mostrino problemi di arrotondamento numerico. Le trasformazioni logaritmiche risolvono questo problema.

\begin{remark}
Seguendo una pratica comune, in questa dispensa spesso useremo la notazione \(p(\cdot)\) per rappresentare due quantità differenti, ovvero la funzione di verosimiglianza e la distribuzione a priori. Questo piccolo abuso di notazione riflette il seguente punto di vista: anche se la verosimiglianza non è una funzione di densità di probabilità, noi non vogliamo stressare questo aspetto, ma vogliamo piuttosto pensare alla verosimiglianza e alla distribuzione a priori come a due elementi che sono egualmente necessari per calcolare la distribuzione a posteriori. In altri termini, per così dire, questa notazione assegna lo stesso status epistemologico alle due diverse quantità che si trovano al numeratore della regola di Bayes.
\end{remark}

\begin{exercise}
Per i dati di \citet{zetschefuture2019}, ovvero 23 ``successi'' in 30 prove, si trovi e si interpreti la funzione di verosimiglianza.
\end{exercise}

Per i dati di \citet{zetschefuture2019} la funzione di verosimiglianza corrisponde alla funzione binomiale di parametro \(\theta \in [0, 1]\) sconosciuto. Abbiamo osservato un ``successo'' 23 volte in 30 ``prove'', dunque, \(y = 23\) e \(n = 30\). La funzione di verosimiglianza diventa

\begin{equation}
\mathcal{L}(\theta \mid y) = \frac{(23 + 7)!}{23!7!} \theta^{23} + (1-\theta)^7.
\label{eq:likebino23}
\end{equation}

Per costruire la funzione di verosimiglianza dobbiamo applicare la \eqref{eq:likebino23} tante volte, cambiando ogni volta il valore \(\theta\) ma \emph{tenendo sempre costante il valore dei dati}. Per esempio, se poniamo \(\theta = 0.1\)

\[
\mathcal{L}(\theta \mid y) = \frac{(23 + 7)!}{23!7!} 0.1^{23} + (1-0.1)^7
\]

otteniamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{23}\NormalTok{, }\DecValTok{30}\NormalTok{, }\FloatTok{0.1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 9.737e{-}18}
\end{Highlighting}
\end{Shaded}

Se poniamo \(\theta = 0.2\)

\[
\mathcal{L}(\theta \mid y) = \frac{(23 + 7)!}{23!7!} 0.2^{23} + (1-0.2)^7
\]

otteniamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{23}\NormalTok{, }\DecValTok{30}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 3.581e{-}11}
\end{Highlighting}
\end{Shaded}

e così via. La figura \ref{fig:likefutexpect} --- costruita utilizzando 100 valori equispaziati \(\theta \in [0, 1]\) --- fornisce una rappresentazione grafica della funzione di verosimiglianza.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{30}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{23}
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{100}\NormalTok{)}
\NormalTok{like }\OtherTok{\textless{}{-}} \FunctionTok{choose}\NormalTok{(n, y) }\SpecialCharTok{*}\NormalTok{ theta}\SpecialCharTok{\^{}}\NormalTok{y }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta)}\SpecialCharTok{\^{}}\NormalTok{(n }\SpecialCharTok{{-}}\NormalTok{ y)}
\FunctionTok{tibble}\NormalTok{(theta, like) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta, }\AttributeTok{y =}\NormalTok{ like)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{L}\NormalTok{(theta)),}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(}\StringTok{"Valori possibili di"} \SpecialCharTok{\textasciitilde{}}\NormalTok{ theta)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/likefutexpect-1} 

}

\caption{Funzione di verosimiglianza nel caso di 23 successi in 30 prove.}\label{fig:likefutexpect}
\end{figure}

Come possiamo interpretare la curva che abbiamo ottenuto? Per alcuni valori \(\theta\) la funzione di verosimiglianza assume valori piccoli; per altri valori \(\theta\) la funzione di verosimiglianza assume valori più grandi. Questi ultimi sono i valori di \(\theta\) ``più credibili'' e il valore 23/30 è il valore più credibile di tutti. La funzione di verosimiglianza di \(\theta\) valuta la compatibilità dei dati osservati \(Y = y\) con i diversi possibili valori \(\theta\). In termini più formali possiamo dire che la funzione di verosimiglianza ha la seguente interpretazione: sulla base dei dati, \(\theta_1 \in \Theta\) è più credibile di \(\theta_2 \in \Theta\) come indice del modello probabilistico generatore delle osservazioni se \(\mathcal{L}(\theta_1) > \mathcal{L}(\theta_1)\).

\hypertarget{sec:const-normaliz-bino23}{%
\section{La verosimiglianza marginale}\label{sec:const-normaliz-bino23}}

Per il calcolo di \(p(\theta \mid y)\) è necessario dividere il prodotto tra la distribuzione a priori e la verosimiglianza per una costante di normalizzazione. Tale costante di normalizzazione, detta \emph{verosimiglianza marginale}, ha lo scopo di fare in modo che \(p(\theta \mid y)\) abbia area unitaria.

Si noti che il denominatore della regola di Bayes (ovvero la verosimiglianza marginale) è sempre espresso nei termini di un integrale. Tranne in pochi casi particolari, tale integrale non ha una soluzione analitica. Per questa ragione, l'inferenza bayesiana procede calcolando una approssimazione della distribuzione a posteriori mediante metodi numerici.

\begin{exercise}
Si trovi la verosimiglianza maginale per i dati di \citet{zetschefuture2019}.

Supponiamo che nel numeratore bayesiano la verosimiglianza sia moltiplicata per una distribuzione uniforme, \(\mbox{Beta}(1, 1)\). In questo caso, il prodotto si riduce alla funzione di verosimiglianza. In riferimento ai dati di \citet{zetschefuture2019}, la costante di normalizzazione per si ottiene semplicemente marginalizzando la funzione di verosimiglianza \(p(y = 23, n = 30 \mid \theta)\) sopra \(\theta\), ovvero risolvendo l'integrale:

\begin{equation}
p(y = 23, n = 30) = \int_0^1 \binom{30}{23} \theta^{23} (1-\theta)^{7} \,\operatorname {d}\!\theta.
\label{eq:intlikebino23}
\end{equation}

Una soluzione numerica si trova facilmente usando \(\R\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{like\_bin }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(theta) \{}
  \FunctionTok{choose}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{23}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ theta}\SpecialCharTok{\^{}}\DecValTok{23} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta)}\SpecialCharTok{\^{}}\DecValTok{7}
\NormalTok{\}}
\FunctionTok{integrate}\NormalTok{(like\_bin, }\AttributeTok{lower =} \DecValTok{0}\NormalTok{, }\AttributeTok{upper =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{value}
\CommentTok{\#\textgreater{} [1] 0.03226}
\end{Highlighting}
\end{Shaded}

La derivazione analitica della costante di normalizzazione qui discussa è fornita nell'Appendice \ref{appendix:const-norm-bino23}.
\end{exercise}

\hypertarget{distribuzione-a-posteriori}{%
\section{Distribuzione a posteriori}\label{distribuzione-a-posteriori}}

La distribuzione a postreriori si trova applicando il teorema di Bayes:

\[
\text{probabilità a posteriori} = \frac{\text{probabilità a priori} \cdot \text{verosimiglianza}}{\text{costante di normalizzazione}}
\]

Ci sono due metodi principali per calcolare la distribuzione a posteriori \(p(\theta \mid y)\):

\begin{itemize}
\item
  una precisa derivazione matematica formulata nei termini della distribuzione a priori coniugata alla distribuzione a posteriori (si veda il Capitolo \ref{chapter-distr-coniugate}); tale procedura però ha un'applicabilità molto limitata;
\item
  un metodo approssimato, molto facile da utilizzare in pratica, che dipende da metodi Monte Carlo basati su Catena di Markov (MCMC); questo problema verrà discusso nel Capitolo ??
\end{itemize}

Una volta trovata la distribuzione a posteriori, possiamo usarla per derivare altre quantità di interesse. Questo viene generalmente ottenuto calcolando il valore atteso:

\[
J = \int f(\theta) p(\theta \mid y) \,\operatorname {d}\!y
\]

Se \(f(\cdot)\) è la funzione identità, ad esempio, \(J\) risulta essere la media di \(\theta\):

\[
\bar{\theta} = \int_{\Theta} \theta p(\theta \mid y) \,\operatorname {d}\!\theta .
\]

\hypertarget{distribuzione-predittiva-a-priori}{%
\section{Distribuzione predittiva a priori}\label{distribuzione-predittiva-a-priori}}

La distribuzione a posteriori è l'oggetto centrale nella statistica bayesiana, ma non è l'unico. Oltre a fare inferenze sui valori dei parametri, potremmo voler fare inferenze sui dati. Questo può essere fatto calcolando la \emph{distribuzione predittiva a priori}:

\begin{equation}
p(y^*) = \int_\Theta p(y^* \mid \theta) p(\theta) \,\operatorname {d}\!\theta .
\label{eq:prior-pred-distr}
\end{equation}

La \eqref{eq:prior-pred-distr} descrive la distribuzione prevista dei dati in base al modello (che include la distribuzione a priori e la verosimiglianza). Questi sono i dati \(y^*\) che ci aspettiamo, dato il modello, prima di avere osservato i dati del campione.

Possiamo utilizzare campioni dalla distribuzione predittiva a priori per valutare e calibrare i modelli utilizzando le nostre conoscenze dominio-specifiche. Ad esempio, ci potremmo chiedere: ``È sensato che un modello dell'altezza umana preveda che un essere umano sia alto -1.5 metri?''. Già prima di misurare una singola persona, possiamo renderci conto dell'assurdità di questa domanda. Se la distribuzione prevista dei dati consente domande di questo tipo, è chiaro che il modello deve essere riformulato.

\begin{remark}
Si dice comunemente che l'adozione di una prospettiva probabilistica per la modellazione conduce all'idea che i modelli generano dati. Se i modelli generano dati, possiamo creare modelli adatti per i nostri dati solo pensando a come i dati potrebbero essere stati generati. Inoltre, questa idea non è solo un concetto astratto. Assume una concreta nella forma della distribuzione predittiva a priori. Se la distribuzione predittiva a priori non ha senso, come abbiamo detto sopra, diventa necessario riformulare il modello.
\end{remark}

\hypertarget{distribuzione-predittiva-a-posteriori}{%
\section{Distribuzione predittiva a posteriori}\label{distribuzione-predittiva-a-posteriori}}

Un'altra quantità utile da calcolare è la distribuzione predittiva a posteriori:

\begin{equation}
p(\tilde{y} \mid y) = \int_\Theta p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}\!\theta .
\label{eq:post-pred-distr}
\end{equation}

Questa è la distribuzione dei dati attesi futuri \(\tilde{y}\) alla luce della distribuzione a posteriori \(p(\theta \mid y)\), che a sua volta è una conseguenza del modello (distribuzione a priori e verosimiglianza) e dei dati osservati. In altre parole, questi sono i dati che il modello si aspetta dopo aver osservato i dati \(y\). Dalla \eqref{eq:post-pred-distr} possiamo vedere che le previsioni sui dati attesi futuri sono calcolate integrando (o marginalizzando) sulla distribuzione a posteriori dei parametri. Di conseguenza, le previsioni calcolate in questo modo incorporano l'incertezza relativa alla stima dei parametri del modello.

\hypertarget{commenti-e-considerazioni-finali-9}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-9}}


Questo Capitolo ha brevemente passato in rassegna alcuni concetti di base dell'inferenza statistica bayesiana. In base all'approccio bayesiano, invece di dire che il parametro di interesse di un modello statistico ha un valore vero ma sconosciuto, diciamo che, prima di eseguire l'esperimento, è possibile assegnare una distribuzione di probabilità, che chiamano stato di credenza, a quello che è il vero valore del parametro. Questa distribuzione a priori può essere nota (per esempio, sappiamo che la distribuzione dei punteggi del QI è normale con media 100 e deviazione standard 15) o può essere del tutto arbitraria. L'inferenza bayesiana procede poi nel modo seguente: si raccolgono alcuni dati e si calcola la probabilità dei possibili valori del parametro alla luce dei dati osservati e delle credenze a priori. Questa nuova distribuzione di probabilità è chiamata ``distribuzione a posteriori'' e riassume l'incertezza dell'inferenza. I concetti importanti che abbiamo appreso in questo Capitolo sono quelli di distribuzione a priori, verosimiglianza, verosimiglianza marginale e distribuzione a posteriori. Questi sono i concetti fondamentali della statistica bayesiana.

\hypertarget{chapter-distr-coniugate}{%
\chapter{Distribuzioni a priori coniugate}\label{chapter-distr-coniugate}}

Obiettivo di questo Capitolo è fornire un esempio di derivazione della distribuzione a posteriori scegliendo quale distribuzione a priori una distribuzione coniugata. Esamineremo qui il modello Beta-Binomiale.

\hypertarget{pensare-a-una-proporzione-in-termini-soggettivi}{%
\section{Pensare a una proporzione ``in termini soggettivi''}\label{pensare-a-una-proporzione-in-termini-soggettivi}}

Nei problemi tradizionali di teoria delle probabilità ci sono molti esempi che riguardano l'estrazizone di palline colorate da un'urna. In questi esempi, ci viene fornito il numero di palline di vari colori nell'urna e ci viene chiesto di calcolare le probabilità di vari eventi. Ad esempio, in una scatola ci sono 40 palline bianche e 20 rosse. Se estrai due palline a caso, qual è la probabilità che entrambe siano bianche?

L'approccio bayesiano considera uno scenario diverso: quello in cui non conosciamo le proporzioni delle palline colorate nell'urna. Cioè, nell'esempio precedente, sappiamo solo che ci sono due tipi di palline colorate nell'urna, ma non sappiamo che 40 palline su 60 sono bianche (proporzione di bianco = \(2/3\)) e 20 delle 60 palline sono rosse (proporzione di rosso = \(1/3\)). Ci poniamo la seguente domanda: è possibile inferire le proporzioni cercate estraendo un campione di palline dall'urna e osservando i colori delle palline nel campione? Espresso in questo modo, questo diventa un problema di inferenza statistica, perché stiamo cercando di inferire la proporzione \(\pi\) della popolazione sulla base di un campione casuale della popolazione. Per continuare con l'esempio precedente, quello che ci chiediamo è: come è possibile inferire \(\pi\), la proporzione di palline rosse nella popolazione, in base al numero (per esempio, 10) di palline rosse e bianche che osserviamo nel campione?

Le proporzioni assomigliano alle probabilità. Ricordiamo che sono state proposte tre diverse interpretazioni del concetto di una probabilità.

\begin{itemize}
\tightlist
\item
  Il punto di vista classico: è necessario enumerare tutti gli eventi elementari dello spazio campionario in cui ogni risultato è ugualmente probabile.
\item
  Il punto di vista frequentista: è necessario ripetere l'esperimento esperimento casuale (cioè l'estrazione del campione) molte volte in condizioni identiche.
\item
  La visione soggettiva: è necessario esprimere la propria opinione sulla probabilità di un evento unico e irripetibile.
\end{itemize}

La visione classica non sembra potere funzionare qui, perché sappiamo solo che ci sono due tipi di palline colorate e il numero totale di palline è 60. Anche se estraiamo un campione di 10 palline, possiamo solo osservare la proporzione di palline rosse palline nel campione. Non c'è modo per stabilire quali sono le proprietà dello spazio campionario in cui ogni risultato è ugualmente probabile.

La visione frequentista potrebbe funzionare nel caso presente. Possiamo considerare il processo del campionamento (cioè l'estrazione di un campione casuale di 10 palline dall'urna) come un esperimento casuale che produce una proporzione campionaria \(p\). Potremmo quindi pensare di ripetere l'esperimento molte volte nelle stesse condizioni, ottenere molte proporzioni campionarie \(p\) e riassumere poi in qualche modo questa distribuzione di statistiche campionarie. Ripetendo l'esperimento casuale tante volte è possibile ottenere una stima abbastanza accurata della proporzione \(\pi\) di palline rosse nell'urna. Questo processo è fattibile, ma è però noioso, dispendioso in termini di tempo e soggetto a errori.

La visione soggettivista concepisce invece la probabilità sconosciuta \(\pi\) come un'opinione soggettiva di cui possiamo essere più o meno sicuri. Abbiamo visto in precedenza come questa opinione soggettiva dipende da due fonti di evidenza: le nostre credenze iniziali e le nuove informazioni fornite dai dati che abbiamo osservato. Vedremo in questo capitolo come sia possibile combinare le credenze iniziali rispetto al possibile valore \(\pi\) con le evidenza fornite dai dati per giungere ad una credenza a posteriori su \(\pi\). Se le nostre credenze a priori sono espresse nei termini di una distribuzione Beta, allora è possibile derivare le proprietà della distribuzione a priori per via analitica. Questo capitolo ha lo scopo di mostrare come questo possa essere fatto.

\hypertarget{il-denominatore-bayesiano}{%
\section{Il denominatore bayesiano}\label{il-denominatore-bayesiano}}

In termini generali possiamo dire che, in un problema bayesiano, i dati \(y\) provengono da una distribuzione \(p(y \mid \theta)\) e al parametro \(\theta\) viene assegnata una distribuzione a priori \(p(\theta)\). La scelta della distribuzione a priori ha importanti conseguenze di tipo computazionale. Infatti, a meno di non utilizzare particolari forme analitiche, risulta impossibile ottenere espressioni esplicite per la distribuzione a posteriori. Ciò dipende dall'espressione a denominatore della formula di Bayes

\begin{equation}
p(\theta \mid y) = \frac{p(\theta) p(y \mid \theta)}{\int p(\theta) p(y \mid \theta) \,\operatorname {d}\! \theta} \notag
\end{equation}

il cui calcolo, in generale, non è eseguibile in modo analitico in forma chiusa. Una soluzione analitica dell'integrale al denominatore della regola di Bayes è possibile solo se vengono usate distribuzioni provenienti da famiglie coniugate.

\begin{definition}
Una distribuzione di probabilità a priori \(p(\theta)\) si dice \emph{coniugata} al modello usato se la distribuzione a priori e la distribuzione a posteriori hanno la stessa forma funzionale. Dunque, le due distribuzioni differiscono solo per il valore dei parametri.
\end{definition}

\noindent Ad esempio, se la verosimiglianza è Poisson e la distribuzione a priori è Gamma, allora anche la distribuzione a posteriori sarà una distribuzione Gamma. Da un punto di vista puramente matematico, le distribuzioni a priori coniugate sono la scelta più conveniente in quanto ci consentono di calcolare analiticamente la distribuzione a posteriori con ``carta e penna'', senza la necessità di ricorrere a calcoli complessi. Da una prospettiva computazionale moderna, però, le distribuzioni a priori coniugate generalmente non sono migliori delle alternative, dato che i moderni metodi computazionali ci consentono di eseguire l'inferenza praticamente con qualsiasi scelta delle distribuzioni a priori, e non solo con quelle che sono matematicamente convenienti. Tuttavia, le famiglie coniugate offronto un utile ausilio didattico nello studio dell'inferenza bayesiana (e anche in alcune situazioni in cui è necessario utilizzare espressioni analitiche per la distribuzione a posteriori). Questo è il motivo per cui le esamineremo qui. Nello specifico, esamineremo quello che viene chiamato il caso Beta-Binomiale.

\hypertarget{chapter-distr-priori-coniugate}{%
\section{Il modello Beta-Binomiale}\label{chapter-distr-priori-coniugate}}

Per fare un esempio concreto, consideriamo nuovamente i dati di \citet{zetschefuture2019}: nel campione di 30 partecipanti clinici le aspettative future di 23 partecipanti risultano distorte negativamente e quelle di 7 partecipanti risultano distorte positivamente. Nel seguito, indicheremo con \(\theta\) la probabilità che le aspettative di un paziente clinico siano distorte negativamente. Ci poniamo il problema di ottenere una stima a posteriori di \(\theta\) avendo osservato 23 ``successi'' in 30 prove.

I dati osservati (\(y = 23\)) possono essere considerati la manifestazione di una variabile casuale Bernoulliana. In tali circostanze, esiste una famiglia di distribuzioni che, qualora venga scelta per la distribuzione a priori, fa sì che la distribuzione a posteriori abbia la stessa forma funzionale della distribuzione a priori. Questo consente una soluzione analitica dell'integrale che compare a denominatore nella formula di Bayes. Nel caso presente, la famiglia di distribuzioni che ha questa proprietà è la distribuzione Beta.

\hypertarget{parametri-della-distribuzione-beta}{%
\subsection{Parametri della distribuzione Beta}\label{parametri-della-distribuzione-beta}}

È possibile esprimere diverse credenze iniziali rispetto a \(\theta\) mediante la distribuzione Beta. Ad esempio, la scelta di una \(\mbox{Beta}(\alpha = 4, \beta = 4)\) quale distribuzione a priori per il parametro \(\theta\) corrisponde alla credenza a priori che associa all'evento ``presenza di una aspettativa futura distorta negativamente'' una grande incertezza: il valore 0.5 è il valore di \(\theta\) più plausibile, ma anche gli altri valori del parametro (tranne gli estremi) sono ritenuti piuttosto plausibili. Questa distribuzione a priori esprime la credenza che sia egualmente probabile per un'aspettativa futura essere distorta negativamente o positivamente.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"bayesrules"}\NormalTok{)}
\FunctionTok{plot\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{4}\NormalTok{, }\AttributeTok{beta =} \DecValTok{4}\NormalTok{, }\AttributeTok{mean =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{mode =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-67-1} \end{center}

Possiamo quantificare la nostra incertezza calcolando, con un grado di fiducia del 95\%, la regione nella quale, in base a tale credenza a priori, si trova il valore del parametro. Per ottenere tale intervallo di credibilità a priori, usiamo la funzione \texttt{qbeta()} di \(\R\). In \texttt{qbeta()} i parametri \(\alpha\) e \(\beta\) sono chiamati \texttt{shape1} e \texttt{shape2}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbeta}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\AttributeTok{shape1 =} \DecValTok{4}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{4}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.1841 0.8159}
\end{Highlighting}
\end{Shaded}

Se poniamo \(\alpha=10\) e \(\beta=10\), questo corrisponde ad una credenza a priori che sia egualmente probabile per un'aspettativa futura essere distorta negativamente o positivamente,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{10}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{mode =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-69-1} \end{center}

ma ora la nostra certezza a priori sul valore del parametro è maggiore, come indicato dall'intervallo al 95\%:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbeta}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\AttributeTok{shape1 =} \DecValTok{10}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.2886 0.7114}
\end{Highlighting}
\end{Shaded}

Quale distribuzione a priori dobbiamo scegliere? In un problema concreto di analisi dei dati, la scelta della distribuzione a priori dipende dalle credenze a priori che vogliamo includere nell'analisi dei dati. Se non abbiamo alcuna informazione a priori, potremmo usare \(\alpha=1\) e \(\beta=1\), che produce una distribuzione a priori uniforme. Ma l'uso di distribuzioni a priori uniformi è sconsigliato per vari motivi, inclusa l'instabilità numerica della stima dei parametri. È meglio invece usare una distribuzione a priori poco informativa, come \(\mbox{Beta}(2, 2)\).

Nella discussione successiva, solo per fare un esempio, useremo quale distribuzione a priori una \(\mbox{Beta}(2, 10)\), ovvero:

\[
p(\theta) = \frac{\Gamma(12)}{\Gamma(2)\Gamma(10)}\theta^{2-1} (1-\theta)^{10-1}.
\]

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_beta}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{mode =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-71-1} \end{center}

La \(\mbox{Beta}(2, 10)\) esprime la credenza che \(\theta < 0.5\), con il valore più plausibile pari a cicrca 0.1.

\hypertarget{la-specificazione-della-distribuzione-a-posteriori}{%
\subsection{La specificazione della distribuzione a posteriori}\label{la-specificazione-della-distribuzione-a-posteriori}}

Una volta scelta una distribuzione a priori di tipo Beta, i cui parametri rispecchiano le nostre credenze iniziali su \(\theta\), la distribuzione a posteriori viene specificata dalla formula di Bayes:

\[
\text{distribuzione a posteriori} = \frac{\text{verosimiglianza}\cdot\text{distribuzione a priori}}{\text{verosimiglianza marginale}}.
\]

Nel caso presente abbiamo

\[
p(\theta \mid n=30, y=23) = \frac{\Big[\binom{30}{23}\theta^{23}(1-\theta)^{30-23}\Big]\Big[\frac{\Gamma(12)}{\Gamma(2)\Gamma(10)}\theta^{2-1} (1-\theta)^{10-1}\Big]}{p(y = 23)},
\]

laddove \(p(y = 23)\), ovvero la verosimiglianza marginale, è una costante di normalizzazione che fa sì che l'area sottesa alla densità a posteriori sia unitaria.

Riscriviamo ora l'equazione precedente in termini generali

\[
p(\theta \mid n, y) = \frac{\Big[\binom{n}{y}\theta^{y}(1-\theta)^{n-y}\Big]\Big[\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}\theta^{a-1} (1-\theta)^{b-1}\Big]}{p(y)}
\]

e raccogliendo tutte le costanti otteniamo:

\[
p(\theta \mid n, y) =\left[\frac{\binom{n}{y}\frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)}}{p(y)}\right] \theta^{y}(1-\theta)^{n-y}\theta^{a-1} (1-\theta)^{b-1}.
\]

Se ignoriamo il termine costante all'interno della parentesi quadra

\begin{align}
p(\theta \mid n, y) &\propto \theta^{y}(1-\theta)^{n-y}\theta^{a-1} (1-\theta)^{b-1},\notag\\
&\propto \theta^{a+y-1}(1-\theta)^{b+n-y-1},\notag
\end{align}

il termine di destra dell'equazione precedente identifica il \emph{kernel} della distribuzione a posteriori e corrisponde ad una Beta \emph{non normalizzata} di parametri \(a + y\) e \(b + n - y\).

Per ottenere una distribuzione di densità, dobbiamo aggiungere una costante di normalizzazione al kernel della distribuzione a posteriori. In base alla definizione della distribuzione Beta, ed essendo \(a' = a+y\) e \(b' = b+n-y\), tale costante di normalizzazione sarà uguale a

\[
\frac{\Gamma(a'+b')}{\Gamma(a')\Gamma(b')} = \frac{\Gamma(a+b+n)}{\Gamma(a+y)\Gamma(b+n-y)}.
\]

In altri termini, la distribuzione a posteriori diventa una \(\mbox{Beta}(a+y, b+n-y)\):

\[
\mbox{Beta}(a+y, b+n-y) = \frac{\Gamma(a+b+n)}{\Gamma(a+y)\Gamma(b+n-y)} \theta^{a+y-1}(1-\theta)^{b+n-y-1}.
\]

Possiamo concludere dicendo che siamo partiti da una verosimiglianza \(\Bin(n = 30, y = 23 \mid \theta)\). Moltiplicando la verosimiglianza per la distribuzione a priori \(\theta \sim \mbox{Beta}(2, 10)\), abbiamo ottenuto la distribuzione a posteriori \(p(\theta \mid n, y) \sim \mbox{Beta}(25, 17)\). Questo è un esempio di analisi coniugata: la distribuzione a posteriori del parametro ha la stessa forma funzionale della distribuzione a priori. La presente combinazione di verosimiglianza e distribuzione a priori è chiamata caso coniugato \emph{Beta-Binomiale} ed è descritto dal seguente teorema.

\begin{theorem}
Sia data la funzione di verosimiglianza \(\Bin(n, y \mid \theta)\) e sia \(\mbox{Beta}(\alpha, \beta)\) una distribuzione a priori. In tali circostanze, la distribuzione a posteriori del parametro \(\theta\) sarà una distribuzione \(\mbox{Beta}(\alpha + y, \beta + n - y)\).
\end{theorem}

È facile calcolare il valore atteso a posteriori di \(\theta\). Essendo \(\E[\mbox{Beta}(\alpha, \beta)] = \frac{\alpha}{\alpha + \beta}\), il risultato cercato diventa

\begin{equation}
\E_{\text{post}} [\mathrm{Beta}(\alpha + y, \beta + n - y)] = \frac{\alpha + y}{\alpha + \beta +n}.
\label{eq:ev-post-beta-bin-1}
\end{equation}

\begin{exercise}

Usando le funzione \(\R\) \texttt{plot\_beta\_binomial()} e \texttt{plot\_beta\_binomial()} del pacchetto \texttt{bayesrules}, si rappresenti in maniera grafica e si descriva in forma numerica l'aggiornamento bayesiano Beta-Binomiale per i dati di \citet{zetschefuture2019}.

Per i dati in discussione, abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{y =} \DecValTok{23}\NormalTok{, }\AttributeTok{n =} \DecValTok{30}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-72-1} \end{center}

È facile replicare il grafico precedente scrivendo noi stessi una funzione, come descritto in Appendice \ref{appendix:beta-binom}. Con la funzione \texttt{plot\_beta\_binom()} e i dati usati in precedenza otteniamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_beta\_bin}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{23}\NormalTok{, }\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-74-1} \end{center}

Un sommario delle distribuzioni a priori e a posteriori si ottiene usando la funzione \texttt{summarize\_beta\_binomial()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{y =} \DecValTok{23}\NormalTok{, }\AttributeTok{n =} \DecValTok{30}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta   mean mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior     2   10 0.1667  0.1 0.010684 0.10336}
\CommentTok{\#\textgreater{} 2 posterior    25   17 0.5952  0.6 0.005603 0.07485}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\begin{exercise}

Per i dati di \citet{zetschefuture2019}, si trovino la media, la moda, la deviazione standard della distribuzione a posteriori di \(\theta\). Si trovi inoltre l'intervallo di credibilità a posteriori del 95\% per il parametro \(\theta\).

Usando la \ref{thm:beta-binom}, possiamo ottenere l'intervallo di credibilità a posteriori del 95\% per il parametro \(\theta\) come segue:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbeta}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{17}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.4450 0.7368}
\end{Highlighting}
\end{Shaded}

La media della distribuzione a posteriori è

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{25} \SpecialCharTok{/}\NormalTok{ (}\DecValTok{25} \SpecialCharTok{+} \DecValTok{17}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.5952}
\end{Highlighting}
\end{Shaded}

La moda della distribuzione a posteriori è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{25} \SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{25} \SpecialCharTok{+} \DecValTok{17} \SpecialCharTok{{-}} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.6}
\end{Highlighting}
\end{Shaded}

La deviazione standard della distribuzione a priori è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{((}\DecValTok{25} \SpecialCharTok{*} \DecValTok{17}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ ((}\DecValTok{25} \SpecialCharTok{+} \DecValTok{17}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{25} \SpecialCharTok{+} \DecValTok{17} \SpecialCharTok{+} \DecValTok{1}\NormalTok{)))}
\CommentTok{\#\textgreater{} [1] 0.07485}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\begin{exercise}

Si trovino i parametri e le proprietà della distribuzione a posteriori del parametro \(\theta\) per i dati dell'esempio relativo alla ricerca di Stanley Milgram discussa da \citet{Johnson2022bayesrules}.

Nel 1963, Stanley Milgram presentò una ricerca sulla propensione delle persone a obbedire agli ordini di figure di autorità, anche quando tali ordini possono danneggiare altre persone \citep{milgram1963behavioral}. Nell'articolo, Milgram descrive lo studio come \emph{``consist{[}ing{]} of ordering a naive subject to administer electric shock to a victim. A simulated shock generator is used, with 30 clearly marked voltage levels that range from IS to 450 volts. The instrument bears verbal designations that range from Slight Shock to Danger: Severe Shock. The responses of the victim, who is a trained confederate of the experimenter, are standardized. The orders to administer shocks are given to the naive subject in the context of a `learning experiment' ostensibly set up to study the effects of punishment on memory. As the experiment proceeds the naive subject is commanded to administer increasingly more intense shocks to the victim, even to the point of reaching the level marked Danger: Severe Shock.''}

All'insaputa del partecipante, gli shock elettrici erano falsi e l'attore stava solo fingendo di provare il dolore dello shock.

\citet{Johnson2022bayesrules} fanno inferenza sui risultati dello studio di Milgram mediante il modello Beta-Binomiale. Il parametro di interesse è \(\theta\), la probabiltà che una persona obbedisca all'autorità (in questo caso, somministrando lo shock più severo), anche se ciò significa recare danno ad altri. \citet{Johnson2022bayesrules} ipotizzano che, prima di raccogliere dati, le credenze di Milgram relative a \(\theta\) possano essere rappresentate mediante una \(\mbox{Beta}(1, 10)\). Sia \(y = 26\) il numero di soggetti che, sui 40 partecipanti allo studio, aveva accettato di infliggere lo shock più severo. Assumendo che ogni partecipante si comporti indipendentemente dagli altri, possiamo modellare la dipendenza di \(y\) da \(\theta\) usando la distribuzione binomiale. Giungiamo dunque al seguente modello bayesiano Beta-Binomiale:

\begin{align}
y \mid \theta & \sim \Bin(n = 40, \theta) \notag\\
\theta & \sim \text{Beta}(1, 10) \; . \notag
\end{align}

Usando le funzioni di \texttt{bayesrules} possiamo facilmente calcolare i parametri e le proprietà della distribuzione a posteriori:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{y =} \DecValTok{26}\NormalTok{, }\AttributeTok{n =} \DecValTok{40}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta    mean   mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior     1   10 0.09091 0.0000 0.006887 0.08299}
\CommentTok{\#\textgreater{} 2 posterior    27   24 0.52941 0.5306 0.004791 0.06922}
\end{Highlighting}
\end{Shaded}

Il processo di aggiornamento bayesiano è descritto dalla figura seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_beta\_bin}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{40}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-81-1} \end{center}

\end{exercise}

\hypertarget{principali-distribuzioni-coniugate}{%
\section{Principali distribuzioni coniugate}\label{principali-distribuzioni-coniugate}}

Esistono molte altre combinazioni simili di verosimiglianza e distribuzione a priori le quali producono una distribuzione a posteriori che ha la stessa densità della distribuzione a priori. Sono elencate qui sotto le più note coniugazioni tra modelli statistici e distribuzioni a priori.

\begin{itemize}
\tightlist
\item
  Per il modello Normale-Normale \(\mathcal{N}(\mu, \sigma^2_0)\), la distribizione iniziale è \(\mathcal{N}(\mu_0, \tau^2)\) e la distribuzione finale è \(\mathcal{N}\left(\frac{\mu_0\sigma^2 + \bar{y}n\tau^2}{\sigma^2 + n\tau^2}, \frac{\sigma^2\tau^2}{\sigma^2 + n\tau^2} \right)\).
\item
  Per il modello Poisson-gamma \(\text{Po}(\theta)\), la distribizione iniziale è \(\Gamma(\lambda, \delta)\) e la distribuzione finale è \(\Gamma(\lambda + n \bar{y}, \delta +n)\).
\item
  Per il modello esponenziale \(\text{Exp}(\theta)\), la distribizione iniziale è \(\Gamma(\lambda, \delta)\) e la distribuzione finale è \(\Gamma(\lambda + n, \delta +n\bar{y})\).
\item
  Per il modello uniforme-Pareto \(\text{U}(0, \theta)\), la distribizione iniziale è \(\mbox{Pa}(\alpha, \varepsilon)\) e la distribuzione finale è \(\mbox{Pa}(\alpha + n, \max(y_{(n)}, \varepsilon))\).
\end{itemize}

\hypertarget{commenti-e-considerazioni-finali-10}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-10}}


Lo scopo di questa discussione è stato quello di mostrare come sia possibile combinare le nostre conoscenze a priori (espresse nei termini di una densità di probabilità) con le evidenze fornite dai dati (espresse nei termini della funzione di verosimiglianza), così da determinare, mediante il teorema di Bayes, una distribuzione a posteriori, la quale condensa l'incertezza che abbiamo sul parametro \(\theta\). Per illustrare tale problema, abbiamo considerato una situazione nella quale \(\theta\) corrisponde alla probabilità di successo in una sequenza di prove Bernoulliane. Abbiamo visto come, in queste circostanze, sia ragionevole esprimere le nostre credenze a priori mediante la densità Beta, con opportuni parametri. L'inferenza rispetto ad una proporzione rappresenta un caso particolare, ovvero un caso nel quale la distribuzione a priori è Beta e la verosimiglianza è Binomiale. In tali circostanze, la distribuzione a posteriori diventa una distribuzione Beta -- questo è il cosiddetto modello Beta-Binomiale. Dato che utilizza una distribuzione a priori coniugata, dunque, il modello Beta-Binomiale rende possibile la determinazione analitica dei parametri della distribuzione a posteriori.

\hypertarget{chapter-balance}{%
\chapter{L'influenza della distribuzione a priori}\label{chapter-balance}}

La notazione \(p(\theta \mid y) \propto p(\theta) \ p(y \mid \theta)\) rende particolarmente chiaro che la distribuzione a posteriori è un ``miscuglio'' della distribuzione a priori e della verosimiglianza. Prima di preoccuparci di come calcolare la distribuzione a posteriori, cerchiamo di capire meglio cosa significa ``mescolare'' la distribuzione a priori e la verosimiglianza. Considereremo qui un esempio fornito da \citet{Johnson2022bayesrules}. Nel fumetto di Alison Bechdel \emph{The Rule}, un personaggio afferma di guardare un film solo se soddisfa le seguenti tre regole \citep{Bechdel1986dykes}:

\begin{itemize}
\tightlist
\item
  almeno due caratteri nel film devono essere donne;
\item
  queste due donne si parlano;
\item
  parlano di qualcosa altro oltre a parlare di qualche uomo.
\end{itemize}

Questi criteri costituiscono il \emph{test di Bechdel} per la rappresentazione delle donne nei film. \citet{Johnson2022bayesrules} pongono la seguente domanda ``Quale percentuale dei film che avete visto supera il test di Bechdel?''.

Sia \(\pi \in [0, 1]\) una variabile casuale che indica la proporzione sconosciuta di film che superano il test di Bechdel. Tre amiche --- la femminista, l'ignara e l'ottimista --- hanno opionioni diverse su \(\pi\). Riflettendo sui film che ha visto, la femminista capisce che nella maggioranza dei film mancano personaggi femminili forti. L'ignara non ricorda bene i film che ha visto, quindi non sa quanti film superano il test di Bechdel. Infine, l'ottimista pensa che, in generale, le donne sono ben rappresentate all'interno dei film: secondo lei quasi tutti i film superano il test di Bechdel. Le tre amiche hanno dunque tre modelli a priori diversi di \(\pi\).

Abbiamo visto in precedenza come sia possibile usare la distribuzione Beta per rappresentare le credenze a priori. Ponendo la gran parte della massa della probabilità a priori su valori \(\pi < 0.5\), la distribuzione a priori \(\text{Beta}(5, 11)\) riflette il punto di vista femminista secondo il quale la maggioranza dei film non supera il test di Bechdel. Al contrario, la \(\text{Beta}(14,1)\) pone la gran parte della massa della distribuzione a priori su valori \(\pi\) prossimi a 1, e corrisponde quindi alle credenze a priori dell'amica ottimista. Infine, una \(\text{Beta}(1 ,1)\) o \(Unif(0, 1)\), assegna lo stesso livello di plausibilità a tutti i valori \(\pi \in [0, 1]\), e corrisponde all'incertezza a priori dell'ignara.

Nell'esempio di \citet{Johnson2022bayesrules}, le tre amiche decidano di rivedere un campione di \(n\) film e di registrare \(y\), il numero di film che supera il test di Bechdel. Se \(y\) corrisponde al numero di ``successi'' in un numero fisso di \(n\) prove Bernoulliane i.i.d., allora la dipendenza di \(y\) da \(\pi\) viene specificata nei termini di un modello binomiale. Quindi, per ciascuna delle tre amiche è possibile scrivere un modello Beta-Binomiale

\begin{align}
Y \mid \pi & \sim \text{Bin}(n, \pi)  \notag\\
\pi & \sim \text{Beta}(\alpha, \beta) \notag
\end{align}

che utilizza parametri \(\alpha\) e \(\beta\) diversi per la distribuzione a priori, il che conduce a tre diverse distribuzioni a posteriori per il parametro sconosciuto \(\pi\):

\begin{equation}
\pi \mid (Y = y) \sim \text{Beta}(\alpha + y, \beta + n - y).
\end{equation}

\citet{Johnson2022bayesrules} si chiedono come le credenze a priori delle tre amiche influenzano le conclusioni a posteriori a cui esse giungono, dopo avere osservato i dati. Si chiedono inoltre in che modo la dimensione del campione moduli l'influenza della distribuzione a priori sulla distribuzione a posteriori. Per rispondere a queste domande, \citet{Johnson2022bayesrules} consideriamo tre diversi scenari:

\begin{itemize}
\tightlist
\item
  gli stessi dati osservati, ma distribuzioni a priori diverse;
\item
  dati diversi, ma la stessa distribuzione a priori;
\item
  dati diversi e distribuzioni a priori diverse.
\end{itemize}

\hypertarget{stessi-dati-ma-diverse-distribuzioni-a-priori}{%
\section{Stessi dati ma diverse distribuzioni a priori}\label{stessi-dati-ma-diverse-distribuzioni-a-priori}}

Iniziamo con lo scenario che descrive il caso in cui abbiamo gli stessi dati ma diverse distribuzioni a priori. Supponiamo che le tre amiche decidano di guardare insieme 20 film selezionati a caso:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(bechdel, }\AttributeTok{package =} \StringTok{"bayesrules"}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{84735}\NormalTok{)}
\NormalTok{bechdel\_20 }\OtherTok{\textless{}{-}}\NormalTok{ bechdel }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{sample\_n}\NormalTok{(}\DecValTok{20}\NormalTok{)}
\NormalTok{bechdel\_20 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 3 x 3}
\CommentTok{\#\textgreater{}    year title      binary}
\CommentTok{\#\textgreater{}   \textless{}dbl\textgreater{} \textless{}chr\textgreater{}      \textless{}chr\textgreater{} }
\CommentTok{\#\textgreater{} 1  2005 King Kong  FAIL  }
\CommentTok{\#\textgreater{} 2  1983 Flashdance PASS  }
\CommentTok{\#\textgreater{} 3  2013 The Purge  FAIL}
\end{Highlighting}
\end{Shaded}

\noindent Di questi 20 film, solo il 45\% (\(y\) = 9) passa il test di Bechdel:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bechdel\_20 }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  janitor}\SpecialCharTok{::}\FunctionTok{tabyl}\NormalTok{(binary) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  janitor}\SpecialCharTok{::}\FunctionTok{adorn\_totals}\NormalTok{(}\StringTok{"row"}\NormalTok{)}
\CommentTok{\#\textgreater{}  binary  n percent}
\CommentTok{\#\textgreater{}    FAIL 11    0.55}
\CommentTok{\#\textgreater{}    PASS  9    0.45}
\CommentTok{\#\textgreater{}   Total 20    1.00}
\end{Highlighting}
\end{Shaded}

Esaminiamo ora le tre distribuzioni a posteriori. Per la femminista abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{5}\NormalTok{, }\AttributeTok{beta =} \DecValTok{11}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{n =} \DecValTok{20}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-84-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{5}\NormalTok{, }\AttributeTok{beta =} \DecValTok{11}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{n =} \DecValTok{20}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta   mean   mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior     5   11 0.3125 0.2857 0.012638 0.11242}
\CommentTok{\#\textgreater{} 2 posterior    14   22 0.3889 0.3824 0.006423 0.08014}
\end{Highlighting}
\end{Shaded}

Per l'ottimista abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{n =} \DecValTok{20}
\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-86-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{n =} \DecValTok{20}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta   mean   mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior    14    1 0.9333 1.0000 0.003889 0.06236}
\CommentTok{\#\textgreater{} 2 posterior    23   12 0.6571 0.6667 0.006259 0.07911}
\end{Highlighting}
\end{Shaded}

Infine, per l'ignara troviamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{n =} \DecValTok{20}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-88-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{9}\NormalTok{, }\AttributeTok{n =} \DecValTok{20}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta   mean mode     var     sd}
\CommentTok{\#\textgreater{} 1     prior     1    1 0.5000  NaN 0.08333 0.2887}
\CommentTok{\#\textgreater{} 2 posterior    10   12 0.4545 0.45 0.01078 0.1038}
\end{Highlighting}
\end{Shaded}

Per calcolare la distribuzione a posteriori, ho qui usato le funzioni del pacchetto \texttt{bayesrules}. Ma nel caso Beta-Binomiale è facile trovafre i parametri della distribuzione a posteriori. Per esempio, nel caso dell'amica femminista, la distribuzione a posteriori è una Beta di parametri

\[
\alpha_{post} = \alpha_{prior} + y = 5+9 = 14
\] e

\[
\beta_{post} = \beta_{prior} + n - y = 11 + 20 - 9 = 22.
\]

L'aggiornamento bayesiano indica che le tre amiche ottengono valori per la media (o la moda) a posteriori per \(\pi\) molto diversi. Dunque, anche dopo avere visto 20 film, le tre amiche non si trovano d'accordo su quale sia la proporzione di film che passano il test di Bechdel.

Questo non dovrebbe sorprenderci. L'amica ottimista aveva opinioni molto forti sul valore di \(\pi\) e i \emph{pochi} nuovi dati che le sono stati forniti non sono riusciti a convincerla a cambiare idea: crede ancora che i valori \(\pi > 0.5\) siano i più plausibili. Lo stesso si può dire, all'estremo opposto, dell'amica femminista: anche lei continua a credere che i valori \(\pi < =.5\) siano i più plausibili. Infine, l'ignara non aveva nessuna opinione a priori su \(\pi\) e, anche dopo avere visto 20 film, continua a credere che il valore \(\pi\) più plausibile sia quello intermedio, nell'intorno di 0.5.

\hypertarget{dati-diversi-ma-la-stessa-distribuzione-a-priori}{%
\section{Dati diversi ma la stessa distribuzione a priori}\label{dati-diversi-ma-la-stessa-distribuzione-a-priori}}

Supponiamo ora che l'amica ottimista abbia tre amiche, Maria, Anna e Sara, tutte ottimiste come lei. L'ottimista chiede a Maria, Anna e Sara di fare loro stesse l'esperimento descritto in precedenza. Maria guarda 13 film; di questi 6 passano il test di Bechdel. Anna guarda 63 film; di questi 29 passano il test di Bechdel. Sara guarda 99 film; di questi 46 passano il test di Bechdel.

Supponiamo che Maria, Anna e Sara condividano la stessa credenza a priori su \(\pi\): ovvero, Beta(14, 1). In tali circostanze e, alla luce dei dati osservati, cosa possiamo dire delle tre distribuzioni a posteriori?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{6}\NormalTok{, }\AttributeTok{n =} \DecValTok{13}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p2 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{29}\NormalTok{, }\AttributeTok{n =} \DecValTok{63}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p3 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{46}\NormalTok{, }\AttributeTok{n =} \DecValTok{99}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p1 }\SpecialCharTok{+}\NormalTok{ p2 }\SpecialCharTok{+}\NormalTok{ p3}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics[width=0.95\linewidth]{ds4psy_files/figure-latex/unnamed-chunk-90-1} 

}

\caption{Aggiornamento bayesiano per Maria, Anna e Sara.}\label{fig:unnamed-chunk-90}
\end{figure}

Notiamo due cose. All'aumentare delle informazioni disponibili (ovvero, all'aumentare dell'ampiezza del campione), la distribuzione a posteriori si allontana sempre di più dalla distribuzione a priori, e si avvicina sempre di più alla verosimiglianza. In secondo luogo, all'aumentare dell'ampiezza del campione la varianza della distribuzione a posteriori diminuisce sempre di più --- ovvero, diminuisce l'incertezza su quelli che sono i valori \(\pi\) più plausibili.

\hypertarget{dati-diversi-e-diverse-distribuzioni-a-priori}{%
\section{Dati diversi e diverse distribuzioni a priori}\label{dati-diversi-e-diverse-distribuzioni-a-priori}}

Nella figura successiva esaminiamo le distribuzioni a posteriori che si ottengono incrociando tre diversi set di dati (\(y\) = 6, \(n\) = 13;, \(y\) = 29, \(n\) = 63; \(y\) = 66, \(n\) = 99) con tre diverse distribuzioni a priori {[}Beta(14, 1), Beta(5, 11), Beta(1, 1){]}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{6}\NormalTok{, }\AttributeTok{n =} \DecValTok{13}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p2 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{29}\NormalTok{, }\AttributeTok{n =} \DecValTok{63}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p3 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{14}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{46}\NormalTok{, }\AttributeTok{n =} \DecValTok{99}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p4 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{5}\NormalTok{, }\AttributeTok{beta =} \DecValTok{11}\NormalTok{, }\AttributeTok{y =} \DecValTok{6}\NormalTok{, }\AttributeTok{n =} \DecValTok{13}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p5 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{5}\NormalTok{, }\AttributeTok{beta =} \DecValTok{11}\NormalTok{, }\AttributeTok{y =} \DecValTok{29}\NormalTok{, }\AttributeTok{n =} \DecValTok{63}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p6 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{5}\NormalTok{, }\AttributeTok{beta =} \DecValTok{11}\NormalTok{, }\AttributeTok{y =} \DecValTok{46}\NormalTok{, }\AttributeTok{n =} \DecValTok{99}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p7 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{6}\NormalTok{, }\AttributeTok{n =} \DecValTok{13}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p8 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{29}\NormalTok{, }\AttributeTok{n =} \DecValTok{63}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{p9 }\OtherTok{\textless{}{-}}\NormalTok{ bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{1}\NormalTok{, }\AttributeTok{beta =} \DecValTok{1}\NormalTok{, }\AttributeTok{y =} \DecValTok{46}\NormalTok{, }\AttributeTok{n =} \DecValTok{99}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }
\NormalTok{(p1 }\SpecialCharTok{+}\NormalTok{ p2 }\SpecialCharTok{+}\NormalTok{ p3) }\SpecialCharTok{/}\NormalTok{ (p4 }\SpecialCharTok{+}\NormalTok{ p5 }\SpecialCharTok{+}\NormalTok{ p6) }\SpecialCharTok{/}\NormalTok{ (p7 }\SpecialCharTok{+}\NormalTok{ p8 }\SpecialCharTok{+}\NormalTok{ p9)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics[width=0.95\linewidth]{ds4psy_files/figure-latex/unnamed-chunk-91-1} 

}

\caption{Sulle colonne (a partire da sinistra) i dati utilizzati sono, rispettivamente, (y = 6, n = 13), (y = 29, n = 63) e (y = 66, n = 99). Sulle righe (a partire dall'alto), le distribuzioni a priori usate sono: Beta(14, 1), Beta(5, 11) e Beta(1, 1).}\label{fig:unnamed-chunk-91}
\end{figure}

La figura indica che, se il campione è grande, una distribuzione a priori debolmente informativa ha uno scarso effetto sulla distribuzione a posteriori. Invece, se il campione è piccolo, anche una distribuzione a priori debolmente informativa ha un grande effetto sulla distribuzione a posteriori.

La conclusione che possiamo trarre dall'esempio di \citet{Johnson2022bayesrules} è molto chiara: l'aggiornamento bayesiano può essere paragonato ai processi di ragionamento del senso comune. Quando le evidenze (i dati) sono deboli, non c'è ragione di cambiare idea (le nostre credenze ``a posreriori'' sono molto simili a ciò che pensavamo prima di avere osservato i dati). Quando le evidenze sono irrefutabili, dobbiamo cambiare idea, ovvero modellare le nostre credenze su ciò che dicono i dati, quali che siano le nostre credenze pregresse --- non fare ciò significherebbe vivere in un mondo di fantasia e avere scarsissime possibilità di sopravvivere nel mondo empirico. L'aggiornamento bayesiano esprime in maniera quantitativa e precisa ciò che ci dicono le nostre intuizioni.

Incredibilmente, però, l'approccio frequentista nega questa logica. I test frequentisti non tengono conto delle conoscenze pregresse. Dunque, se un test frequentista, calcolato su un piccolo campione (ovvero, quando i dati sono molto deboli), suggerisce che dovremmo farci un'opinione di un certo tipo sul fenomeno in esame, l'indicazione è di prendere seriamente il risultato del test \emph{quali siano le evidenze precedenti} --- le quali, possibilmente, mostrano che il risultato del test non ha alcun senso. È sorprendente che un tale modo di pensare possa essere preso sul serio nella comunità scientifica, ma vi sono alcuni ricercatori che continuano a seguire questo modo di (s)ragionare.

\hypertarget{collegare-le-intuizioni-alla-teoria}{%
\section{Collegare le intuizioni alla teoria}\label{collegare-le-intuizioni-alla-teoria}}

Il compromesso che abbiamo osservato nell'esempio precedente, che combina la distribuzione a priori con le evidenze fornite dai dati, è molto vicino alle nostre intuizioni. Ma è anche il frutto di una necessità matematica. È infatti possibile riscrivere la \eqref{eq:ev-post-beta-bin-1} nel modo seguente

\begin{align}
\E_{\text{post}} &[\text{Beta}(\alpha + y, \beta + n - y)] = \frac{\alpha + y}{\alpha + \beta +n}\notag\\ 
&= \frac{a+b}{a+b+n} \cdot \frac{a}{a+b} + \frac{n}{a+b+n} \cdot \frac{y}{n}.
\label{eq:ev-post-beta-bin}
\end{align}

Ciò indica che il valore atteso a posteriori è una media pesata fra il valore atteso a priori \(\left( \frac{\alpha}{\alpha+\beta}\right)\) e la frequenze di successi osservata \(\left(\frac{y}{n}\right)\). I pesi sono \(\left( \frac{\alpha+\beta}{\alpha+\beta+n}\right)\) e \(\left( \frac{n}{\alpha+\beta+n}\right)\). Quindi, quando \(n\) è grande rispetto ad \(\alpha + \beta\), conta molto quanto abbiamo osservato e conta poco la credenza a priori. Viceversa, quando \(n\) è piccolo rispetto a \(\alpha + \beta\), le osservazioni contano poco rispetto alla credenza a priori.

Queste osservazioni ci fanno capire come scegliere i parametri \(\alpha\) e \(\beta\): se vogliamo assumere una totale ignoranza rispetto al fenomeno in esame, la scelta coerente è \(\alpha = \beta = 1\) (ogni valore di \(\theta\) è ugualmente probabile); se invece abbiamo delle credenze a priori, allora possiamo scegliere \(\alpha\) così che sia uguale al valore atteso a priori, mentre \(\alpha + \beta\) esprime l'importanza che diamo all'informazione a priori: maggiore è il valore di \(\alpha + \beta\), tanti più dati serviranno per allontanare la distribuzione a posteriori dalla distribuzione a priori. Se \(n\) è grande, infine, la distribuzione a posteriori sarà scarsamente influenzata dalla distribuzione a priori, a meno di scelte estreme.

\hypertarget{metropolis}{%
\chapter{Approssimazione della distribuzione a posteriori}\label{metropolis}}

In questo Capitolo ci occuperemo di metodi numerici per l'approssimazione della distribuzione a posteriori.

\hypertarget{stima-della-distribuzione-a-posteriori}{%
\section{Stima della distribuzione a posteriori}\label{stima-della-distribuzione-a-posteriori}}

In un problema bayesiano i dati \(y\) provengono da una densità \(p(y \mid \theta)\) e al parametro \(\theta\) viene assegnata una densità a priori \(p(\theta)\). Dopo avere osservato un campione \(Y = y\), la funzione di verosimiglianza è uguale a \(\mathcal{L}(\theta) = p(y \mid \theta)\) e la densità a posteriori diventa

\begin{equation}
p(\theta \mid y) = \frac{p(\theta) \mathcal{L}(\theta)}{\int p(\theta) \mathcal{L}(\theta) d \theta}.
\end{equation}

Si noti che, quando usiamo il teorema di Bayes per calcolare la distribuzione a posteriori del parametro di un modello statistico, al denominatore troviamo un integrale che, nella maggior parte dei casi, non si può risolvere analiticamente. In altre parole: è possibile ottenere analiticamente la distribuzione a posteriori solo per alcune specifiche combinazioni di distribuzioni a priori e verosimiglianza, il che limita considerevolmente la flessibilità della modellizzazione. Per questa ragione, la strada principale che viene seguita nella modellistica bayesiana è quella che porta a determinare la distribuzione a posteriori non per via analitica, ma bensì mediante metodi numerici. La simulazione fornisce dunque la strategia generale del calcolo bayesiano.

Ci sono molte librerie \(\R\) o Python che consentono di stimare la distribuzione a posteriori con metodi numerici, quindi in generale è molto improbabile che un ricercatore abbia bisogno di codificare un proprio algoritmo per risolvere questo problema. Ad oggi ci sono solo due buoni motivi per scrivere il codice che ha lo scopo di approssimare la distribuzione a posteriori per via numerica: o si sta progettando un nuovo metodo che sia in grado di migliorare quelli già esistenti (questo è un tipico problema da informatici o ingegneri) o si sta imparando come funzionano i metodi attuali. Dato che il nostro obiettivo è, appunto, quello di imparare, in questo capitolo vedremo come questo problema possa essere affrontato. Nel resto della dispensa useremo invece i metodi già disponibili nelle librerie \(\R\).

In questo Capitolo esaminando tre diverse tecniche che possono essere utilizzate per calcolare per via numerica la distribuzione a posteriori:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  il metodo basato su griglia,
\item
  il metodo dell'approssimazione quadratica,
\item
  il metodo di Monte Carlo basato su Catena di Markov (MCMC).
\end{enumerate}

\hypertarget{metodo-basato-su-griglia}{%
\section{Metodo basato su griglia}\label{metodo-basato-su-griglia}}

Il metodo basato su griglia (\emph{grid-based}) è un metodo di approsimazione numerica basato su una griglia di punti uniformemente spaziati. Anche se la maggior parte dei parametri è continua (ovvero, in linea di principio ciascun parametro può assumere un numero infinito di valori), possiamo ottenere un'eccellente approssimazione della distribuzione a posteriori considerando solo una griglia finita di valori dei parametri. In un tale metodo, la densità di probabilità a posteriori può dunque essere approssimata tramite le densità di probabilità calcolate in ciascuna cella della griglia.

Il metodo basato su griglia si sviluppa in quattro fasi:

\begin{itemize}
\tightlist
\item
  fissare una griglia discreta di possibili valori \(\theta\);\footnote{È chiaro che, per ottenere buone approssimazioni, è necessaria una griglia molto densa.}
\item
  valutare la distribuzione a priori \(p(\theta)\) e la funzione di verosimiglianza \(\mathcal{L}(y \mid \theta)\) in corrispondenza di ciascun valore \(\theta\) della griglia;
\item
  ottenere un'approssimazione discreta della densità a posteriori:

  \begin{itemize}
  \tightlist
  \item
    per ciascun valore \(\theta\) della griglia, calcolare il prodotto \(p(\theta) \mathcal{L} (y \mid \theta)\);
  \item
    normalizzare i prodotti così ottenuti in modo tale che la loro somma sia 1;
  \end{itemize}
\item
  selezionare \(N\) valori casuali della griglia in modo tale da ottenere un campione casuale delle densità a posteriori normalizzate.
\end{itemize}

Possiamo migliorare l'approssimazione aumentando il numero di punti della griglia. Infatti utilizzando un numero infinito di punti si otterrebbe la descrizione esatta della distribuzione a posteriori, dovendo però pagare il costo dell'utilizzo di infinite risorse di calcolo. Il limite maggiore dell'approccio basato su griglia è che al crescere della dimensionalità \(N\) dello spazio dei parametri i punti della griglia necessari per avere una buona stima crescerebbero esponenzialmente con \(N\), rendendo questo metodo inattuabile.

\hypertarget{modello-beta-binomiale}{%
\subsection{Modello Beta-Binomiale}\label{modello-beta-binomiale}}

Per fare un esempio, consideriamo il modello Beta-Binomiale di cui conosciamo la soluzione esatta. Supponiamo di avere osservato 9 sucessi in 10 prove Bernoulliane indipendenti.\footnote{La discussione del modello Beta-Binomiale segue molto da vicino la presentazione di \citet{Johnson2022bayesrules} utilizzando anche lo stesso codice \R.} Imponiamo alla distribuzione a priori su \(\theta\) (proabilità di successo in una singola prova) una Beta(2, 2) per descrivere la nostra incertezza sul parametro prima di avere osservato i dati. Dunque, il modello diventa:

\begin{align}
Y \mid \theta & \sim \text{Bin}(10, \pi) \notag\\
\theta & \sim \mbox{Beta}(2, 2).\notag
\end{align}

In queste circostanze, l'aggiornamento bayesiano produce una distribuzione a posteriori Beta di parametri 11 (\(y + \alpha\) = 9 + 2) e 3 (\(n - y + \beta\) = 10 - 9 + 2):

\begin{equation}
\theta \mid (y = 9) \sim \mbox{Beta}(11, 3).\notag
\end{equation}

Per approssimare la distribuzione a posteriori, fissiamo una griglia di \(n = 6\) valori equispaziati: \(\theta \in \{0, 0.2, 0.4, 0.6, 0.8, 1\}\) (in seguito aumenteremo \(n\)):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid\_data }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{theta\_grid =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{1}\NormalTok{, }\AttributeTok{length =} \DecValTok{6}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In corrispondenza di ciascun valore della griglia, valutiamo la distribuzione a priori \(\mbox{Beta}(2, 2)\) e la verosimiglianza \(\Bin(10, \theta)\) con \(y = 9\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid\_data }\OtherTok{\textless{}{-}}\NormalTok{ grid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{prior =} \FunctionTok{dbeta}\NormalTok{(theta\_grid, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{),}
    \AttributeTok{likelihood =} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{, theta\_grid)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

In ciascuna cella della griglia calcoliamo poi il prodotto della verosimiglianza e della distribuzione a priori. Troviamo così un'approssimazione discreta e non normalizzata della distribuzione a posteriori (\texttt{unnormalized}). Normalizziamo infine questa approssimazione dividendo ciascun valore del vettore \texttt{unnormalized} per la somma di tutti i valori del vettore:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid\_data }\OtherTok{\textless{}{-}}\NormalTok{ grid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{unnormalized =}\NormalTok{ likelihood }\SpecialCharTok{*}\NormalTok{ prior,}
    \AttributeTok{posterior =}\NormalTok{ unnormalized }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(unnormalized)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

La somma dei valori così trovati sarà uguale a 1:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \FunctionTok{sum}\NormalTok{(unnormalized),}
    \FunctionTok{sum}\NormalTok{(posterior)}
\NormalTok{  )}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 2}
\CommentTok{\#\textgreater{}   \textasciigrave{}sum(unnormalized)\textasciigrave{} \textasciigrave{}sum(posterior)\textasciigrave{}}
\CommentTok{\#\textgreater{}                 \textless{}dbl\textgreater{}            \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1               0.318                1}
\end{Highlighting}
\end{Shaded}

Abbiamo dunque ottenuto la seguente distribuzione a posteriori discretizzata \(p(\theta \mid y)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(grid\_data, }\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 5}
\CommentTok{\#\textgreater{}   theta\_grid prior likelihood unnormalized posterior}
\CommentTok{\#\textgreater{}        \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}      \textless{}dbl\textgreater{}        \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1        0    0          0            0         0   }
\CommentTok{\#\textgreater{} 2        0.2  0.96       0            0         0   }
\CommentTok{\#\textgreater{} 3        0.4  1.44       0            0         0.01}
\CommentTok{\#\textgreater{} 4        0.6  1.44       0.04         0.06      0.18}
\CommentTok{\#\textgreater{} 5        0.8  0.96       0.27         0.26      0.81}
\CommentTok{\#\textgreater{} 6        1    0          0            0         0}
\end{Highlighting}
\end{Shaded}

La figura \ref{fig:grid-method-6points-posterior-plot} mostra un grafico della distribuzione a posteriori discretizzata che è stata ottenuta:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta\_grid, }\AttributeTok{y =}\NormalTok{ posterior)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_grid, }
      \AttributeTok{xend =}\NormalTok{ theta\_grid, }
      \AttributeTok{y =} \DecValTok{0}\NormalTok{, }
      \AttributeTok{yend =}\NormalTok{ posterior)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/grid-method-6points-posterior-plot-1} 

}

\caption{Distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per $y$ = 9 successi in 10 prove Bernoulliane, con distribuzione a priori $\mbox{Beta}(2, 2)$. È stata utilizzata una griglia di solo $n$ = 6 punti.}\label{fig:grid-method-6points-posterior-plot}
\end{figure}

L'ultimo passo della simulazione è il campionamento dalla distribuzione a posteriori discretizzata:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{84735}\NormalTok{)}
\NormalTok{post\_sample }\OtherTok{\textless{}{-}} \FunctionTok{sample\_n}\NormalTok{(}
\NormalTok{  grid\_data,}
  \AttributeTok{size =} \FloatTok{1e5}\NormalTok{,}
  \AttributeTok{weight =}\NormalTok{ posterior,}
  \AttributeTok{replace =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

È facile intuire che i valori estratti con rimessa dalla distribuzione a posteriori discretizzata saranno quasi sempre uguali a 0.6 o 0.8. Questa intuizione è confermata dal grafico \ref{fig:grid-method-6points-posterior-plot-sampling} a cui è stata sovrapposta la vera distribuzione a posteriori \(\mbox{Beta}(11, 3)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(post\_sample, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta\_grid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ..density..), }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dbeta, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\DecValTok{11}\NormalTok{, }\DecValTok{3}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{lims}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/grid-method-6points-posterior-plot-sampling-1} 

}

\caption{Campionamento dalla  distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per $y$ = 9 successi in 10 prove Bernoulliane, con distribuzione a priori $\mbox{Beta}(2, 2)$. È stata utilizzata una griglia di solo $n$ = 6 punti.}\label{fig:grid-method-6points-posterior-plot-sampling}
\end{figure}

La figura \ref{fig:grid-method-6points-posterior-plot-sampling} mostra che, con una griglia così sparsa abbiamo ottenuto una versione estremamente approssimata della vera distribuzione a posteriori. Possiamo però ottenere un risultato migliore con una griglia più fine, come indicato dalla figura \ref{fig:grid-method-100points-posterior-plot-sampling}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid\_data }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{theta\_grid =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{100}\NormalTok{)}
\NormalTok{)}
\NormalTok{grid\_data }\OtherTok{\textless{}{-}}\NormalTok{ grid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{prior =} \FunctionTok{dbeta}\NormalTok{(theta\_grid, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{),}
    \AttributeTok{likelihood =} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{9}\NormalTok{, }\DecValTok{10}\NormalTok{, theta\_grid)}
\NormalTok{  )}
\NormalTok{grid\_data }\OtherTok{\textless{}{-}}\NormalTok{ grid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{unnormalized =}\NormalTok{ likelihood }\SpecialCharTok{*}\NormalTok{ prior,}
    \AttributeTok{posterior =}\NormalTok{ unnormalized }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(unnormalized)}
\NormalTok{  )}
\NormalTok{grid\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta\_grid, }\AttributeTok{y =}\NormalTok{ posterior)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{x =}\NormalTok{ theta\_grid,}
      \AttributeTok{xend =}\NormalTok{ theta\_grid,}
      \AttributeTok{y =} \DecValTok{0}\NormalTok{,}
      \AttributeTok{yend =}\NormalTok{ posterior}
\NormalTok{    )}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/grid-method-100points-posterior-plot-sampling-1} 

}

\caption{Distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per $y$ = 9 successi in 10 prove Bernoulliane, con distribuzione a priori $\mbox{Beta}(2, 2)$. È stata utilizzata una griglia di $n$ = 100 punti.}\label{fig:grid-method-100points-posterior-plot-sampling}
\end{figure}

Campioniamo ora 10000 punti:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Set the seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{84735}\NormalTok{)}
\NormalTok{post\_sample }\OtherTok{\textless{}{-}} \FunctionTok{sample\_n}\NormalTok{(}
\NormalTok{  grid\_data,}
  \AttributeTok{size =} \FloatTok{1e4}\NormalTok{,}
  \AttributeTok{weight =}\NormalTok{ posterior,}
  \AttributeTok{replace =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Con il campionamento dalla distribuzione a posteriori discretizzata costruita mediante una griglia più densa (\(n = 100\)) otteniamo un risultato soddisfacente (figura \ref{fig:grid-method-100points-posterior-plot-and-correct-posterior}): ora la distribuzione dei valori prodotti dalla simulazione approssima molto bene la corretta distribuzione a posteriori \(p(\theta \mid y) = \mbox{Beta}(11, 3)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{post\_sample }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta\_grid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ..density..),}
    \AttributeTok{color =} \StringTok{"white"}\NormalTok{,}
    \AttributeTok{binwidth =} \FloatTok{0.05}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dbeta, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\DecValTok{11}\NormalTok{, }\DecValTok{3}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{lims}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/grid-method-100points-posterior-plot-and-correct-posterior-1} 

}

\caption{Campionamento dalla  distribuzione a posteriori discretizzata ottenuta con il metodo grid-based per $y$ = 9 successi in 10 prove Bernoulliane, con distribuzione a priori $\mbox{Beta}(2, 2)$. È stata utilizzata una griglia di $n$ = 100 punti. All'istogramma è stata sovrapposta la corretta distribuzione a posteriori, ovvero la densità $\mbox{Beta}(11, 3)$.}\label{fig:grid-method-100points-posterior-plot-and-correct-posterior}
\end{figure}

In conclusione, il metodo basato su griglia è molto intuitivo e non richiede particolari competenze di programmazione per essere implementato. Inoltre, fornisce un risultato che, per tutti gli scopi pratici, può essere considerato come un campione casuale estratto da \(p(\theta \mid y)\). Tuttavia, anche se tale metodo fornisce risultati accuratissimi, esso ha un uso limitato. A causa della \emph{maledizione della dimensionalità}\footnote{Per capire cosa sia la maledizione della dimensionalità, supponiamo di utilizzare una griglia di 100 punti equispaziati. Nel caso di un solo parametro, è necessario calcolare 100 valori. Per due parametri devono essere calcolari \(100^2\) valori. Ma già per 10 parametri è necessario calcolare \(10^{10}\) valori -- è facile capire che una tale quantità di calcoli è troppo grande anche per un computer molto potente. Per modelli che richiedono la stima di un numero non piccolo di parametri è dunque necessario procedere in un altro modo.}, tale metodo può solo essere solo nel caso di semplici modelli statistici, con non più di due parametri. Nella pratica concreta tale metodo viene dunque sostituito da altre tecniche più efficienti in quanto, anche nei più comuni modelli utilizzati in psicologia, vengono solitamente stimati centinaia se non migliaia di parametri.

\hypertarget{approssimazione-quadratica}{%
\section{Approssimazione quadratica}\label{approssimazione-quadratica}}

L'approssimazione quadratica è un altro metodo che può essere usato per superare il problema della ``maledizione della dimensionalità''. La motivazione di tale metodo è la seguente. Sappiamo che, in generale, la regione della distribuzione a posteriori che si trova in prossimità del suo massimo può essere ben approssimata dalla forma di una distribuzione Normale.\footnote{Descrivere la distribuzione a posteriori mediante la distribuzione Normale significa utilizzare un'approssimazione che viene, appunto, chiamata ``quadratica'' (tale approssimazione si dice quadratica perché il logaritmo di una distribuzione gaussiana forma una parabola e la parabola è una funzione quadratica -- dunque, mediante questa approssimazione descriviamo il logaritmo della distribuzione a posteriori mediante una parabola).}

L'approssimazione quadratica si pone due obiettivi.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Trovare la moda della distribuzione a posteriori. Ci sono varie procedure di ottimizzazione, implementate in \(\R\), in grado di trovare il massimo di una distribuzione.
\item
  Stimare la curvatura della distribuzione in prossimità della moda. Una stima della curvatura è sufficiente per trovare un'approssimazione quadratica dell'intera distribuzione. In alcuni casi, questi calcoli possono essere fatti seguendo una procedura analitica, ma solitamente vengono usate delle tecniche numeriche.
\end{enumerate}

Una descrizione della distribuzione a posteriori ottenuta mediante l'approssimazione quadratica si ottiene mediante la funzione \texttt{quap()} contenuta nel pacchetto \texttt{rethinking}:\footnote{Il pacchetto \texttt{rethinking} è stato creato da \citet{McElreath_rethinking} per accompagnare il suo testo \emph{Statistical Rethinking}\(^2\). Per l'installazione si veda \url{https://github.com/rmcelreath/rethinking}.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{suppressPackageStartupMessages}\NormalTok{(}\FunctionTok{library}\NormalTok{(}\StringTok{"rethinking"}\NormalTok{))}

\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{quap}\NormalTok{(}
  \FunctionTok{alist}\NormalTok{(}
\NormalTok{  N }\SpecialCharTok{\textasciitilde{}} \FunctionTok{dbinom}\NormalTok{(N }\SpecialCharTok{+}\NormalTok{ P, p), }\CommentTok{\# verosimiglianza binomiale}
\NormalTok{  p }\SpecialCharTok{\textasciitilde{}} \FunctionTok{dbeta}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{10}\NormalTok{) }\CommentTok{\# distribuzione a priori Beta(2, 10)}
\NormalTok{  ),}
  \AttributeTok{data =} \FunctionTok{list}\NormalTok{(}\AttributeTok{N =} \DecValTok{23}\NormalTok{, }\AttributeTok{P =} \DecValTok{7}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Un sommario dell'approssimazione quadratica è fornito da

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{precis}\NormalTok{(mod, }\AttributeTok{prob =} \FloatTok{0.95}\NormalTok{)}
\CommentTok{\#\textgreater{}   mean      sd   2.5\%  97.5\%}
\CommentTok{\#\textgreater{} p  0.6 0.07746 0.4482 0.7518}
\end{Highlighting}
\end{Shaded}

Qui sotto è fornito un confronto tra la corretta distribuzione a posteriori (linea continua) e l'approssimazione quadratica (linea trateggiata).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{23}
\NormalTok{P }\OtherTok{\textless{}{-}} \DecValTok{7}
\NormalTok{a }\OtherTok{\textless{}{-}}\NormalTok{ N }\SpecialCharTok{+} \DecValTok{2}
\NormalTok{b }\OtherTok{\textless{}{-}}\NormalTok{ P }\SpecialCharTok{+} \DecValTok{10}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dbeta}\NormalTok{(x, a, b), }\AttributeTok{from=}\DecValTok{0}\NormalTok{, }\AttributeTok{to=}\DecValTok{1}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"Densità"}\NormalTok{)}
\CommentTok{\# approssimazione quadratica}
\FunctionTok{curve}\NormalTok{(}
  \FunctionTok{dnorm}\NormalTok{(x, a}\SpecialCharTok{/}\NormalTok{(a}\SpecialCharTok{+}\NormalTok{b), }\FunctionTok{sqrt}\NormalTok{((a}\SpecialCharTok{*}\NormalTok{b)}\SpecialCharTok{/}\NormalTok{((a}\SpecialCharTok{+}\NormalTok{b)}\SpecialCharTok{\^{}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{(a}\SpecialCharTok{+}\NormalTok{b}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)))),}
  \AttributeTok{lty =} \DecValTok{2}\NormalTok{,}
  \AttributeTok{add =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-101-1} \end{center}

Il grafico precedente mostra che l'approssimazione quadratica fornisce risultati soddisfacenti. Tali risultati sono simili (o identici) a quelli ottenuti con il metodo \emph{grid-based}, con il vantaggio aggiuntivo di disporre di una serie di funzioni \(\R\) in grado di svolgere i calcoli per noi. In realtà, però, l'approssimazione quadratica è poco usata perché, per problemi complessi, è più conveniente fare ricorso ai metodi Monte Carlo basati su Catena di Markov (MCMC) che verranno descritti nel Paragrafo successivo.

\hypertarget{chapter-simulazioneMC}{%
\section{Metodo Monte Carlo}\label{chapter-simulazioneMC}}

I metodi più ampiamente adottati nell'analisi bayesiana per la costruzione della distribuzione a posteriori per modelli complessi sono i metodi di campionamento detti metodi Monte Carlo basati su catena di Markov (\emph{Markov Chain Monte Carlo}, MCMC). Tali metodi consentono di decidere quali distribuzioni a priori e quali distribuzioni di verosimiglianza usare sulla base di considerazioni teoriche soltanto, senza dovere preoccuparsi di altri vincoli. Dato che è basata su metodi computazionalmente intensivi, la stima numerica MCMC della funzione a posteriori può essere svolta soltanto mediante software. In anni recenti i metodi Bayesiani di analisi dei dati sono diventati sempre più popolari proprio perché la potenza di calcolo necessaria per svolgere tali calcoli è ora alla portata di tutti. Questo non era vero solo pochi decenni fa.

Per introdurre i metodi MCMC consideriamo il caso di una verosimiglianza Binomiale e di una distribuzione a priori Beta. Sappiamo che, in tali circostanze, viene prodotta una distribuzione a posteriori Beta (si veda il capitolo \ref{chapter-distr-coniugate}). Con una simulazione \(\R\) è dunque facile ricavare dei campioni causali dalla distribuzione a posteriori. Maggiore è il numero di campioni, migliore sarà l'approssimazione della distribuzione a posteriori.

Consideriamo nuovamente i dati di \citet{zetschefuture2019} (23 ``successi'' in 30 prove Bernoulliane) e applichiamo a quei dati lo stesso modello del Capitolo \ref{chapter-distr-coniugate}:

\begin{align}
y \mid \theta, n &\sim \Bin(y = 23, n = 30 \mid \theta) \notag\\
\theta_{prior} &\sim \mbox{Beta}(2, 10) \notag\\
\theta_{post}  &\sim \mbox{Beta}(y + a = 23 + 2 = 25, n - y + b = 30 - 23 + 10 = 17), \notag
\end{align}

Poniamoci il problema di stimare il valore della media a posteriori di \(\theta\). Nel caso presente, il risultato esatto è

\[
\bar{\theta}_{post} = \frac{\alpha}{\alpha + \beta} = \frac{25}{25 + 17} \approx 0.5952.
\] Dato che la distribuzione a posteriori di \(\theta\) è \(\mbox{Beta}(25, 17)\), possiamo estrarre un campione casuale di osservazioni da tale distribuzione e calcolare la media:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{7543897}\NormalTok{)}
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{rbeta}\NormalTok{(}\FloatTok{1e2}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{17}\NormalTok{)), }\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.587548}
\end{Highlighting}
\end{Shaded}

È ovvio che l'approssimazione migliora all'aumentare del numero di osservazioni estratte dalla distribuzione a posteriori (legge dei grandi numeri):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{rbeta}\NormalTok{(}\FloatTok{1e3}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{17}\NormalTok{)), }\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.597659}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{rbeta}\NormalTok{(}\FloatTok{1e4}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{17}\NormalTok{)), }\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.595723}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{rbeta}\NormalTok{(}\FloatTok{1e5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{17}\NormalTok{)), }\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.595271}
\end{Highlighting}
\end{Shaded}

Quando il numero di osservazioni (possiamo anche chiamarle ``campioni'') tratte dalla distribuzione a posteriori è molto grande, la distribuzione di tali campioni converge alla densità della popolazione (si veda l'Appendice \ref{integration-mc}).\footnote{Si noti, naturalmente, che il numero dei campioni di simulazione è controllato dal ricercatore; è totalmente diverso dalla dimensione del campione che è fissa ed è una proprietà dei dati.}

Inoltre, le statistiche descrittive (es. media, moda, varianza, eccetera) dei campioni estratti dalla distribuzione a posteriori convergeranno ai corrispondenti valori della distribuzione a posteriori. La figura \ref{fig:mcmc-chains-1} mostra come, all'aumentare del numero di repliche, la media, la mediana, la deviazione standard e l'asimmetria convergono ai veri valori della distribuzione a posteriori (linee rosse tratteggiate).

\begin{figure}[h]

{\centering \includegraphics[width=0.8\linewidth]{/Users/corrado/_repositories/ds4psy/images/mcmc-chains-1} 

}

\caption{Convergenza delle simulazioni Monte Carlo.}\label{fig:mcmc-chains-1}
\end{figure}

\hypertarget{metodi-mc-basati-su-catena-di-markov}{%
\section{Metodi MC basati su Catena di Markov}\label{metodi-mc-basati-su-catena-di-markov}}

Nel Paragrafo \ref{chapter-simulazioneMC} la simulazione Monte Carlo funzionava perché

\begin{itemize}
\tightlist
\item
  sapevamo che la distribuzione a posteriori era una \(\mbox{Beta}(25, 17)\),
\item
  era possibile usare le funzioni \(\R\) per estrarre campioni casuali da tale distribuzione.
\end{itemize}

Tuttavia, capita raramente di usare una distribuzione a priori coniugata alla verosimiglianza, quindi in generale le due condizioni descritte sopra non si applicano. Ad esempio, nel caso di una verosimiglianza binomiale e una distribuzione a priori Normale, la distribuzione a posteriori di \(\theta\) è

\[
p(\theta \mid y) = \frac{\mathrm{e}^{-(\theta - 1 / 2)^2} \theta^y (1 - \theta)^{n - y}} {\int_0^1 \mathrm{e}^{-(t - 1 / 2)^2} t^y (1 - t)^{n - y} dt}.
\]

Una tale distribuzione non è implementata in \(\R\) e dunque non possiamo campionare da \(p(\theta \mid y)\). Per fortuna, gli algoritmi MCMC consentono il campionamento da una distribuzione a posteriori \emph{senza che sia necessario conoscere la rappresentazione analitica di una tale distribuzione}. I metodi Monte Carlo basati su catena di Markov consentono di costruire sequenze di punti (detti catene di Markov) nello spazio dei parametri le cui densità sono proporzionali alla distribuzione a posteriori --- in altre parole, dopo aver simulato un grande numero di passi della catena si possono usare i valori così generati come se fossero un campione casuale della distribuzione a posteriori. Le tecniche MCMC sono attualmente il metodo computazionale maggiormente utilizzato per risolvere i problemi di inferenza bayesiana. Un'introduzione alle catene di Markov è fornita nell'Appendice \ref{markov-chains}.

\hypertarget{campionamento-mediante-algoritmi-mcmc}{%
\subsection{Campionamento mediante algoritmi MCMC}\label{campionamento-mediante-algoritmi-mcmc}}

Un modo generale per ottenere una catena di Markov la cui distribuzione equivale alla distribuzione a posteriori \(p(\theta \mid y)\) è quello di usare l'algoritmo di Metropolis. L'algoritmo di Metropolis è il primo algoritmo MCMC che è stato proposto, ed è applicabile ad una grande varietà di problemi inferenziali di tipo bayesiano. Tale algoritmo è stato in seguito sviluppato allo scopo di renderlo via via più efficiente. Lo presentiamo qui in una forma intuitiva.

\hypertarget{una-passeggiata-casuale-sui-numeri-naturali}{%
\subsection{Una passeggiata casuale sui numeri naturali}\label{una-passeggiata-casuale-sui-numeri-naturali}}

Per introdurre l'algoritmo di di Metropolis considereremo il campionamento da una distribuzione discreta.\footnote{Seguiamo qui la trattazione di \citet{albert2019probability}. Per una presentazione intuitiva dell'algoritmo di Metropolis, si vedano anche \citet{doing_bayesian_data_an}; \citet{McElreath_rethinking}.} Supponiamo di definire una distribuzione di probabilità discreta sugli interi \(1,\dots, K\). Scriviamo in \(\R\) la funzione \texttt{pd()} che assegna ai valori \(1,\dots, 8\) delle probabilità proporzionali a 5, 10, 4, 4, 20, 20, 12 e 5.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pd }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  values }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{5}\NormalTok{)}
  \FunctionTok{ifelse}\NormalTok{(}
\NormalTok{    x }\SpecialCharTok{\%in\%} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(values),}
\NormalTok{    values[x] }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(values),}
    \DecValTok{0}
\NormalTok{  )}
\NormalTok{\}}
\NormalTok{prob\_dist }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{,}
  \AttributeTok{prob =} \FunctionTok{pd}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La figura \ref{fig:formetropolisdistr} illustra la distribuzione di probabilità che è stata generata.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{8}
\NormalTok{prob\_dist }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ prob)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat =} \StringTok{"identity"}\NormalTok{, }\AttributeTok{width =} \FloatTok{0.06}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\StringTok{"x"}\NormalTok{, }\AttributeTok{labels =} \FunctionTok{as.character}\NormalTok{(x), }\AttributeTok{breaks =}\NormalTok{ x) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \StringTok{"Probabilità"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"X"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/formetropolisdistr-1} 

}

\caption{Distribuzione di massa di probabilità per una variabile casuale avente valori 1, 2, ..., 8.}\label{fig:formetropolisdistr}
\end{figure}

L'algoritmo di Metropolis corrisponde alla seguente passeggiata casuale.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  L'algoritmo inizia con un valore iniziale qualsiasi da 1 a \(K=8\) della variabile casuale.
\item
  Per simulare il valore successivo della sequenza, lanciamo una moneta equilibrata. Se esce testa, consideriamo come valore candidato il valore immediatamente precedente al valore corrente nella sequenza \(1, \dots, 8\); se esce croce, il valore candidato sarà il valore immediatamente successivo al valore corrente nella sequenza.
\item
  Calcoliamo il rapporto tra la probabilità del valore candidato e la probabilità del valore corrente:
\end{enumerate}

\[
R = \frac{pd(\text{valore candidato})}{pd(\text{valore corrente})}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Estraiamo un numero a caso \(\in [0, 1]\). Se tale valore è minore di \(R\) accettiamo il valore candidato come valore successivo della catena markoviana; altrimenti il valore successivo della catena rimane il valore corrente.
\end{enumerate}

I passi da 1 a 4 definiscono una catena di Markov irriducibile e aperiodica sui valori di stato \(\{1, 2,\dots, 8\}\), dove il passo 1 fornisce il valore iniziale della catena e i passi da 2 a 4 definiscono la matrice di transizione \(P\). Un modo di campionare da una distribuzione di massa di probabilità \texttt{pd} consiste nell'iniziare da una posizione qualsiasi e eseguire una passeggiata casuale costituita da un grande numero di passi, ripetendo le fasi 2, 3 e 4 dell'algoritmo di Metropolis. Dopo un grande numero di passi, la distribuzione dei valori della catena markoviana approssimerà la distribuzione di probabilità \texttt{pd}.

La funzione \texttt{random\_walk()} implementa l'algoritmo di Metropolis. Tale funzione richiede in input la distribuzione di probabilità \texttt{pd}, la posizione di partenza \texttt{start} e il numero di passi dell'algoritmo \texttt{num\_steps}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random\_walk }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(pd, start, num\_steps)\{}
\NormalTok{  y }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, num\_steps)}
\NormalTok{  current }\OtherTok{\textless{}{-}}\NormalTok{ start}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{num\_steps)\{}
\NormalTok{    candidate }\OtherTok{\textless{}{-}}\NormalTok{ current }\SpecialCharTok{+} \FunctionTok{sample}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DecValTok{1}\NormalTok{)}
\NormalTok{    prob }\OtherTok{\textless{}{-}} \FunctionTok{pd}\NormalTok{(candidate) }\SpecialCharTok{/} \FunctionTok{pd}\NormalTok{(current)}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\textless{}}\NormalTok{ prob)}
\NormalTok{      current }\OtherTok{\textless{}{-}}\NormalTok{ candidate}
\NormalTok{    y[j] }\OtherTok{\textless{}{-}}\NormalTok{ current}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Di seguito, implementiamo l'algoritmo di Metropolis utilizzando, quale valore iniziale, \(X=4\). Ripetiamo la simulazione 10,000 volte.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out }\OtherTok{\textless{}{-}} \FunctionTok{random\_walk}\NormalTok{(pd, }\DecValTok{4}\NormalTok{, }\FloatTok{1e4}\NormalTok{)}

\NormalTok{S }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(out) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(out) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{N =} \FunctionTok{n}\NormalTok{(),}
    \AttributeTok{Prob =}\NormalTok{ N }\SpecialCharTok{/} \DecValTok{10000}
\NormalTok{  )}

\NormalTok{prob\_dist2 }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(}
\NormalTok{  prob\_dist,}
  \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ S}\SpecialCharTok{$}\NormalTok{out,}
    \AttributeTok{prob =}\NormalTok{ S}\SpecialCharTok{$}\NormalTok{Prob}
\NormalTok{  )}
\NormalTok{)}
\NormalTok{prob\_dist2}\SpecialCharTok{$}\NormalTok{Type }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"Prob. corrette"}\NormalTok{, }\StringTok{"Prob. simulate"}\NormalTok{),}
  \AttributeTok{each =} \DecValTok{8}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{8}
\NormalTok{prob\_dist2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x, }\AttributeTok{y =}\NormalTok{ prob, }\AttributeTok{fill =}\NormalTok{ Type)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}
    \AttributeTok{stat =} \StringTok{"identity"}\NormalTok{,}
    \AttributeTok{width =} \FloatTok{0.1}\NormalTok{,}
    \AttributeTok{position =} \FunctionTok{position\_dodge}\NormalTok{(}\FloatTok{0.3}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}
    \StringTok{"x"}\NormalTok{,}
    \AttributeTok{labels =} \FunctionTok{as.character}\NormalTok{(x),}
    \AttributeTok{breaks =}\NormalTok{ x}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_manual}\NormalTok{(}\AttributeTok{values =} \FunctionTok{c}\NormalTok{(}\StringTok{"black"}\NormalTok{, }\StringTok{"gray80"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.title =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \StringTok{"Probabilità"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"X"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/metropolishistogramsim-1} 

}

\caption{L'istogramma confronta i valori prodotti dall'algoritmo di Metropolis con i corretti valori della distribuzione di massa di probabilità.}\label{fig:metropolishistogramsim}
\end{figure}

La figura \ref{fig:metropolishistogramsim} confronta l'istogramma dei valori simulati dalla passeggiata casuale con l'effettiva distribuzione di probabilità \texttt{pd}. Si noti la somiglianza tra le due distribuzioni.

\hypertarget{lalgoritmo-di-metropolis}{%
\subsection{L'algoritmo di Metropolis}\label{lalgoritmo-di-metropolis}}

Vediamo ora come l'algoritmo di Metropolis possa venire usato per generare una catena di Markov irriducibile e aperiodica per la quale la distribuzione stazionaria è uguale alla distribuzione a posteriori di interesse.\footnote{Una illustrazione visiva di come si svolge il processo di ``esplorazione'' dell'algoritmo di Metropolis è fornita in questo \href{https://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/}{post}.} In termini generali, l'algoritmo di Metropolis include due fasi.

\begin{itemize}
\tightlist
\item
  \emph{Fase 1.} La selezione di un valore candidato \(\theta'\) del parametro mediante il campionamento da una distribuzione proposta.
\item
  \emph{Fase 2.} La decisione tra la possibilità di accettare il valore candidato \(\theta^{(m+1)} = \theta'\) o di mantenere il valore corrente \(\theta^{(m+1)} = \theta\) sulla base del seguente criterio:

  \begin{itemize}
  \tightlist
  \item
    se \(\mathcal{L}(\theta' \mid y)p(\theta') > \mathcal{L}(\theta \mid y)p(\theta)\) il valore candidato viene sempre accettato;
  \item
    altrimenti il valore candidato viene accettato solo in una certa proporzione di casi.
  \end{itemize}
\end{itemize}

Esaminiamo ora nei dettagli il funzionamento dell'algoritmo di Metropolis.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\item
  Si inizia con un punto arbitrario \(\theta^{(1)}\), quindi il primo valore della catena di Markov \(\theta^{(1)}\) può corrispondere semplicemente ad un valore a caso tra i valori possibili del parametro.
\item
  Per ogni passo successivo della catena, \(m + 1\), si campiona un valore candidato \(\theta'\) da una distribuzione proposta: \(\theta' \sim \Pi(\theta)\). La distribuzione proposta può essere qualunque distribuzione, anche se, idealmente, è meglio che sia simile alla distribuzione a posteriori. In pratica, però, la distribuzione a posteriori è sconosciuta e quindi il valore \(\theta'\) viene campionato da una qualche distribuzione simmetrica centrata sul valore corrente \(\theta^{(m)}\) del parametro. Nell'esempio qui discusso, useremo la distribuzione gaussiana. Tale distribuzione sarà centrata sul valore corrente della catena e avrà una appropriata deviazione standard: \(\theta' \sim \mathcal{N}(\theta^{(m)}, \sigma)\). In pratica, questo significa che, se \(\sigma\) è piccola, il valore candidato \(\theta'\) sarà simile al valore corrente \(\theta^{(m)}\).
\item
  Una volta generato il valore candidato \(\theta'\) si calcola il rapporto tra la densità della distribuzione a posteriori non normalizzata nel punto \(\theta'\) {[}ovvero, il prodotto tra la verosimiglianza \(\mathcal{L}(y \mid \theta')\) nel punto \(\theta'\) e la distribuzione a priori nel punto \(\theta'\){]} e la densità della distribuzione a posteriori non normalizzata nel punto \(\theta^{(m)}\) {[}ovvero, il prodotto tra la verosimiglianza \(\mathcal{L}(y \mid \theta^{(m)})\) nel punto \(\theta^{(m)}\) e la distribuzione a priori nel punto \(\theta^{(m)}\){]}:
\end{enumerate}

\begin{equation}
\alpha = \frac{p(y \mid \theta') p(\theta')}{p(y \mid \theta^{(m)}) p(\theta^{(m)})}.
\label{eq:ratio-metropolis}
\end{equation}

Si noti che, essendo un rapporto, la \eqref{eq:ratio-metropolis} cancella la costante di normalizzazione.

\begin{enumerate}
\def\labelenumi{(\alph{enumi})}
\setcounter{enumi}{3}
\item
  Il rapporto \(\alpha\) viene utilizzato per decidere se accettare il valore candidato \(\theta'\), oppure se campionare un diverso candidato. Possiamo pensare al rapporto \(\alpha\) come alla risposta alla seguente domanda: alla luce dei dati, è più plausibile il valore candidato del parametro o il valore corrente? Se \(\alpha\) è maggiore di 1 ciò significa che il valore candidato è più plausibile del valore corrente; in tali circostanze il valore candidato viene sempre accettato. Altrimenti, si decide di accettare il valore candidato con una probabilità minore di 1, ovvero non sempre, ma soltanto con una probabilità uguale ad \(\alpha\). Se \(\alpha\) è uguale a 0.10, ad esempio, questo significa che la plausibilità a posteriori del valore candidato è 10 volte più piccola della plausibilità a posteriori del valore corrente. Dunque, il valore candidato verrà accettato solo nel 10\% dei casi. Come conseguenza di questa strategia di scelta, l'algoritmo di Metropolis ottiene un campione casuale dalla distribuzione a posteriori, dato che la probabilità di accettare il valore candidato è proporzionale alla densità del candidato nella distribuzione a posteriori. Dal punto di vista algoritmico, la procedura descritta sopra viene implementata confrontando il rapporto \(\alpha\) con un valore casuale estratto da una distribuzione uniforme \(\mbox{Unif}(0, 1)\). Se \(\alpha > u \sim \mbox{Unif}(0, 1)\) allora il punto candidato \(\theta'\) viene accettato e la catena si muove in quella nuova posizione, ovvero \(\theta^{(m+1)} = \theta'^{(m+1)}\). Altrimenti \(\theta^{(m+1)} = \theta^{(m)}\) e si campiona un nuovo valore candidato \(\theta'\).
\item
  Il passaggio finale dell'algoritmo calcola l'\emph{accettanza} in una specifica esecuzione dell'algoritmo, ovvero la proporzione dei valori candidati \(\theta'\) che sono stati accettati come valori successivi nella sequenza.
\end{enumerate}

L'algoritmo di Metropolis prende come input il numero \(M\) di passi da simulare, la deviazione standard \(\sigma\) della distribuzione proposta e la densità a priori, e ritorna come output la sequenza \(\theta^{(1)}, \theta^{(2)}, \dots, \theta^{(M)}\). La chiave del successo dell'algoritmo di Metropolis è il numero di passi fino a che la catena approssima la stazionarietà. Tipicamente i primi da 1000 a 5000 elementi sono scartati. Dopo un certo periodo \(k\) (detto di \emph{burn-in}), la catena di Markov converge ad una variabile casuale che è distribuita secondo la distribuzione a posteriori. In altre parole, i campioni del vettore \(\left(\theta^{(k+1)}, \theta^{(k+2)}, \dots, \theta^{(M)}\right)\) diventano campioni di \(p(\theta \mid y)\).

\hypertarget{una-applicazione-concreta}{%
\subsection{Una applicazione concreta}\label{una-applicazione-concreta}}

Per fare un esempio concreto, consideriamo nuovamente i 30 pazienti esaminati da \citet{zetschefuture2019}. Di essi, 23 hanno manifestato aspettative distorte negativamente sul loro stato d'animo futuro. Utilizzando l'algoritmo di Metropolis, ci poniamo il problema di ottenere la stima a posteriori di \(\theta\) (probabilità di manifestare un'aspettativa distorta negativamente), dati 23 ``successi'' in 30 prove, imponendo su \(\theta\) la stessa distribuzione a priori usata nel Capitolo \ref{chapter-distr-coniugate}, ovvero \(\mbox{Beta}(2, 10)\).

Per calcolare la funzione di verosimiglianza, avendo fissato i dati di \citet{zetschefuture2019}, definiamo la funzione \texttt{likelihood()}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{likelihood }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param, }\AttributeTok{x =} \DecValTok{23}\NormalTok{, }\AttributeTok{N =} \DecValTok{30}\NormalTok{) \{}
  \FunctionTok{dbinom}\NormalTok{(x, N, param)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

che ritorna l'ordinata della verosimiglianza binomiale per ciascun valore del vettore \texttt{param} in input.

La distribuzione a priori \(\mbox{Beta}(2, 10)\) è implementata nella funzione \texttt{prior()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param, }\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{) \{}
  \FunctionTok{dbeta}\NormalTok{(param, alpha, beta) }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Il prodotto della densità a priori e della verosimiglianza è implementato nella funzione \texttt{posterior()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param) \{}
  \FunctionTok{likelihood}\NormalTok{(param) }\SpecialCharTok{*} \FunctionTok{prior}\NormalTok{(param)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

L'Appendice \ref{es-pratico-zetsche-funzioni} mostra come un'approssimazione della distribuzione a posteriori \(p(\theta \mid y)\) per questi dati possa essere ottenuta mediante il metodo basato su griglia.

\hypertarget{implementazione}{%
\subsection{Implementazione}\label{implementazione}}

Per implementare l'algoritmo di Metropolis utilizzeremo una distribuzione proposta gaussiana. Il valore candidato sarà dunque un valore selezionato a caso da una gaussiana di parametri \(\mu\) uguale al valore corrente nella catena e \(\sigma = 0.9\). In questo esempio, la deviazione standard \(\sigma\) è stata scelta empiricamente in modo tale da ottenere una accettanza adeguata. L'accettanza ottimale è di circa 0.20 e 0.30 --- se l'accettanza è troppo grande, l'algoritmo esplora uno spazio troppo ristretto della distribuzione a posteriori.\footnote{L'accettanza dipende dalla distribuzione proposta: in generale, tanto più la distribuzione proposta è simile alla distribuzione target, tanto più alta diventa l'accettanza.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{proposal\_distribution }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param) \{}
  \ControlFlowTok{while}\NormalTok{(}\DecValTok{1}\NormalTok{) \{}
\NormalTok{    res }\OtherTok{=} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{mean =}\NormalTok{ param, }\AttributeTok{sd =} \FloatTok{0.9}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ (res }\SpecialCharTok{\textgreater{}} \DecValTok{0} \SpecialCharTok{\&}\NormalTok{ res }\SpecialCharTok{\textless{}} \DecValTok{1}\NormalTok{)}
      \ControlFlowTok{break}
\NormalTok{  \}}
\NormalTok{  res}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Nella presente implementazione del campionamento dalla distribuzione proposta è stato inserito un controllo che impone al valore candidato di essere incluso nell'intervallo {[}0, 1{]}.\footnote{Si possono trovare implementazioni dell'algoritmo di Metropolis più eleganti di quella presentata qui. Lo scopo dell'esercizio è quello di illustrare la logica soggiacente all'algoritmo di Metropolis, non quello di proporre un'implementazione efficente dell'algoritmo.}

L'algoritmo di Metropolis viene implementato nella seguente funzione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{run\_metropolis\_MCMC }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(startvalue, iterations) \{}
\NormalTok{  chain }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\AttributeTok{length =}\NormalTok{ iterations }\SpecialCharTok{+} \DecValTok{1}\NormalTok{)}
\NormalTok{  chain[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ startvalue}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{iterations) \{}
\NormalTok{    proposal }\OtherTok{\textless{}{-}} \FunctionTok{proposal\_distribution}\NormalTok{(chain[i])}
\NormalTok{    r }\OtherTok{\textless{}{-}} \FunctionTok{posterior}\NormalTok{(proposal) }\SpecialCharTok{/} \FunctionTok{posterior}\NormalTok{(chain[i])}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\textless{}}\NormalTok{ r) \{}
\NormalTok{      chain[i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ proposal}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      chain[i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ chain[i]}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{  chain}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Avendo definito le funzioni precedenti, generiamo una catena di valori \(\theta\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{startvalue }\OtherTok{\textless{}{-}} \FunctionTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{niter }\OtherTok{\textless{}{-}} \FloatTok{1e4}
\NormalTok{chain }\OtherTok{\textless{}{-}} \FunctionTok{run\_metropolis\_MCMC}\NormalTok{(startvalue, niter)}
\end{Highlighting}
\end{Shaded}

Mediante le istruzioni precedenti otteniamo una catena di Markov costituita da 10,001 valori. Escludiamo i primi 5,000 valori considerati come burn-in. Ci restano dunque con 5,001 valori che verranno considerati come un campione casuale estratto dalla distribuzione a posteriori \(p(\theta \mid y)\).

L'accettanza è pari a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{burnIn }\OtherTok{\textless{}{-}}\NormalTok{ niter }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{acceptance }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(}\FunctionTok{duplicated}\NormalTok{(chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)]))}
\NormalTok{acceptance}
\CommentTok{\#\textgreater{} [1] 0.2511}
\end{Highlighting}
\end{Shaded}

\noindent il che conferma la bontà della deviazione standard (\(\sigma\) = 0.9) scelta per la distribuzione proposta.

A questo punto è facile ottenere una stima a posteriori del parametro \(\theta\). Per esempio, la stima della media a posteriori è:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)])}
\CommentTok{\#\textgreater{} [1] 0.5922}
\end{Highlighting}
\end{Shaded}

Una figura che mostra l'approssimazione di \(p(\theta \mid y)\) ottenuta con l'algoritmo di Metropolis, insieme ad un \emph{trace plot} dei valori della catena di Markov, viene prodotta usando le seguenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)]}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(theta),}
    \AttributeTok{y =} \StringTok{"Frequenza"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"Distribuzione a posteriori"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}
    \AttributeTok{xintercept =} \FunctionTok{mean}\NormalTok{(chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)])}
\NormalTok{  )}
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x =} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)]),}
  \AttributeTok{y =}\NormalTok{ chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)]}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Numero di passi"}\NormalTok{,}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(theta),}
    \AttributeTok{title =} \StringTok{"Valori della catena"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}
    \AttributeTok{yintercept =} \FunctionTok{mean}\NormalTok{(chain[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{burnIn)]),}
    \AttributeTok{colour =} \StringTok{"gray"}
\NormalTok{  )}
\NormalTok{p1 }\SpecialCharTok{+}\NormalTok{ p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/sim-markov-chain-zetsche-1} 

}

\caption{Sinistra. Stima della distribuzione a posteriori della probabilità di una aspettativa futura distorta negativamente per i dati di Zetsche et al. (2019). Destra. Trace plot dei valori della catena di Markov escludendo il periodo di burn-in.}\label{fig:sim-markov-chain-zetsche}
\end{figure}

\hypertarget{input}{%
\subsection{Input}\label{input}}

Negli esempi discussi in questo Capitolo abbiamo illustrato l'esecuzione di una singola catena in cui si parte un unico valore iniziale e si raccolgono i valori simulati da molte iterazioni. È possibile che i valori di una catena siano influenzati dalla scelta del valore iniziale. Quindi una raccomandazione generale è di eseguire l'algoritmo di Metropolis più volte utilizzando diversi valori di partenza. In questo caso, si avranno più catene di Markov. Confrontando le proprietà delle diverse catene si esplora la sensibilità dell'inferenza alla scelta del valore di partenza. I software MCMC consentono sempre all'utente di specificare diversi valori di partenza e di generare molteplici catene di Markov.

\hypertarget{stazionarietuxe0}{%
\section{Stazionarietà}\label{stazionarietuxe0}}

Un punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta ``mixing''.

\hypertarget{approx-post-autocor}{%
\subsection{Autocorrelazione}\label{approx-post-autocor}}

Informazioni sul ``mixing'' della catena di Markov sono fornite dall'autocorrelazione. L'autocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore \(m\)-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità \(k\) (dove \(k\) è l'entità del ritardo) per verificare quanto si correli al variare di \(k\). L'autocorrelazione di ordine 1 (\emph{lag 1}) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra \(\theta^{(m)}\) e \(\theta^{(m-1)}\)); l'autocorrelazione di ordine 2 (\emph{lag 2}) misura la correlazione tra valori della catena di Markow separati da due ``passi'' (cioè, la correlazione tra \(\theta^{(m)}\) e \(\theta^{(m-2)}\)); e così via.

L'autocorrelazione di ordine \(k\) è data da \(\rho_k\) e può essere stimata come:

\begin{align}
\rho_k &= \frac{\Cov(\theta_m, \theta_{m+k})}{\Var(\theta_m)}\notag\\
&= \frac{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})(\theta_{m-k} - \bar{\theta})}{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})^2} \qquad\text{con }\quad \bar{\theta} = \frac{1}{n}\sum_{m=1}^{n}\theta_m.
\label{eq:autocor}
\end{align}

Per fare un esempio pratico, simuliamo dei dati autocorrelati con la funzione R \texttt{colorednoise::colored\_noise()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{suppressPackageStartupMessages}\NormalTok{(}\FunctionTok{library}\NormalTok{(}\StringTok{"colorednoise"}\NormalTok{))}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{34783859}\NormalTok{)}
\NormalTok{rednoise }\OtherTok{\textless{}{-}} \FunctionTok{colored\_noise}\NormalTok{(}
  \AttributeTok{timesteps =} \DecValTok{30}\NormalTok{, }\AttributeTok{mean =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.05}\NormalTok{, }\AttributeTok{phi =} \FloatTok{0.3}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

L'autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza. Nell'esempio, il vettore \texttt{rednoise} è una sequenza temporale di 30 elementi. Il vettore \texttt{rednoise{[}-length(rednoise){]}} include gli elementi con gli indici da 1 a 29 nella sequenza originaria, mentre il vettore \texttt{rednoise{[}-1{]}} include gli elementi 2:30. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici \((1, 2), (2, 3), \dots (29, 30)\) degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori \texttt{rednoise{[}-length(rednoise){]}} e \texttt{rednoise{[}-1{]}} corrisponde dunque all'autocorrelazione di ordine 1 della serie temporale.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(rednoise[}\SpecialCharTok{{-}}\FunctionTok{length}\NormalTok{(rednoise)], rednoise[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 0.3967}
\end{Highlighting}
\end{Shaded}

Il Correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall'autocorrelazione \(\rho_k\) di una catena di Markov in funzione del ritardo (\emph{lag}) \(k\) con cui l'autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell'autocorrelazione (sull'asse delle ordinate) in funzione del ritardo (sull'asse delle ascisse). In \(\R\), il correlogramma può essere prodotto con una chiamata a \texttt{acf()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acf}\NormalTok{(rednoise)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-119-1} \end{center}

Il correlogramma precedente mostra come l'autocorrelazione di ordine 1 sia circa pari a 0.4 e diminuisce per lag maggiori; per lag di 4, l'autocorrelazione diventa negativa e aumenta progressivamente fino ad un lag di 8; eccetera.

In situazioni ottimali l'autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce conferma del ``mixing'' della catena di Markov, ossia di convergenza alla distribuzione stazionaria. Nelle analisi bayesiane, una delle strategie che consentono di ridurre l'autocorrelazione è quella di assottigliare l'output immagazzinando solo ogni \(m\)-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di \emph{thinning}.

\hypertarget{test-di-convergenza}{%
\subsection{Test di convergenza}\label{test-di-convergenza}}

Un test di convergenza può essere svolto in maniera grafica mediante le tracce delle serie temporali (\emph{trace plot}), cioè il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena è in uno stato stazionario le tracce mostrano assenza di periodicità nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota. Un esempio di \emph{trace plot} è fornito nella figura \ref{fig:sim-markov-chain-zetsche} (destra).

Ci sono inoltre alcuni test che permettono di verificare la stazionarietà del campionatore dopo un dato punto. Uno è il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn in, in due parti. Se la catena è in uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test \(z\) per confrontare i due subcampioni ed il risultante test statistico, se ad esempio è più alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi è necessario un periodo di burn-in più lungo.

\hypertarget{commenti-e-considerazioni-finali-11}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-11}}


In generale, la distribuzione a posteriori dei parametri di un modello statistico non può essere determinata per via analitica. Tale problema, invece, viene affrontato facendo ricorso ad una classe di algoritmi per il campionamento da distribuzioni di probabilità che sono estremamente onerosi dal punto di vista computazionale e che possono essere utilizzati nelle applicazioni pratiche solo grazie alla potenza di calcolo dei moderni computer. Lo sviluppo di software che rendono sempre più semplice l'uso dei metodi MCMC, insieme all'incremento della potenza di calcolo dei computer, ha contribuito a rendere sempre più popolare il metodo dell'inferenza bayesiana che, in questo modo, può essere estesa a problemi di qualunque grado di complessità.

Nel 1989 un gruppo di statistici nel Regno Unito si pose il problema di simulare le catene di Markov su un personal computer. Nel 1997 ci riuscirono con il primo rilascio pubblico di un'implementazione Windows dell'inferenza bayesiana basata su Gibbs sampling, detta BUGS. Il materiale presentato in questo capitolo descrive gli sviluppi contemporanei del percorso che è iniziato in quel periodo.

\hypertarget{mod-binom}{%
\chapter{Modello Beta-Binomiale}\label{mod-binom}}

In questo Capitolo vedremo come si possa fare inferenza su una proporzione impiegando nell'analisi il linguaggio Stan.

\hypertarget{una-proporzione}{%
\section{Una proporzione}\label{una-proporzione}}

Si considerino \(n\) variabili casuali Bernoulliane i.i.d.:

\[
y = (y_1, \dots, y_n) \stackrel{iid}{\sim} \mathcal{B}(\theta).
\]

Vogliamo stimare \(\theta\) avendo osservato \(y\). Essendo i.i.d., i dati possono essere riassunti dal numero totale di successi nelle \(n\) prove, denotato da \(y\). Il modello binomiale è

\begin{equation}
p(y \mid \theta) = \Bin(y \mid n, \theta) = \binom{n}{y}\theta^y (1 -\theta)^{n-y},
\end{equation}

dove nel termine di sinistra dell'equazione abbiamo ignorato \(n\) in quanto viene considerato fisso per disegno. L'inferenza sul modello binomiale richiede di assegnare una distribuzione a priori su \(\theta\) che dipende dall'informazione disponibile a priori. Se sceglamo, ad esempio, una \(\mbox{Beta}(2, 2)\) quale distribuzione a priori, il modello diventa:

\begin{align}
y &\sim \Bin(n, \theta) \notag\\
\theta &\sim \mbox{Beta}(2, 2),
\label{eq:beta-binom-trump}
\end{align}

dove la prima riga definisce la funzione di verosimiglianza e la seconda riga definisce la distribuzione a priori. Sulla base di ciò che è stato detto nel Capitolo \ref{chapter-distr-coniugate}, sappiamo che le equazioni \eqref{eq:beta-binom-trump} definiscono il caso Beta-Binomiale.

\hypertarget{il-presidente-trump-e-lidrossiclorochina}{%
\subsection{Il presidente Trump e l'idrossiclorochina}\label{il-presidente-trump-e-lidrossiclorochina}}

Per fare un esempio concreto, consideriamo un set di dati reali. Cito dal \emph{Washington Post} del 7 aprile 2020: \emph{``One of the most bizarre and disturbing aspects of President Trump's nightly press briefings on the coronavirus pandemic is when he turns into a drug salesman. Like a cable TV pitchman hawking `male enhancement' pills, Trump regularly extols the virtues of taking hydroxychloroquine, a drug used to treat malaria and lupus, as a potential `game changer' that just might cure Covid-19.''}

Tralasciamo qui il fatto che il presidente Trump non è un esperto in questo campo. Esaminiamo invece le evidenze iniziali a supporto dell'ipotesi che l'idrossiclorochina possa essere utile per la cura del Covid-19, ovvero le evidenze che erano disponibili nel momento in cui il presidente Trump ha fatto le affermazioni riportate sopra (in seguito, quest'idea è stata screditata). Tali evidenze sono state fornite da uno studio di \citet{Gautret_2020}. Il disegno sperimentale di \citet{Gautret_2020} comprende, tra le altre cose, il confronto tra una condizione sperimentale e una condizione di controllo. Il confronto importante è tra la proporzione di paziente positivi al virus SARS-CoV-2 nel gruppo sperimentale (a cui è stata somministrata l'idrossiclorochina; 6 su 14) e la proporzione di paziente positivi nel gruppo di controllo (a cui non è stata somministrata l'idrossiclorochina; ovvero 14 su 16). Obiettivo di questo Capitolo è mostrare come si possa fare inferenza sul modello \eqref{eq:beta-binom-trump} usando il linguaggio Stan.

\hypertarget{cmdstanr-gautret}{%
\subsection{\texorpdfstring{Interfaccia \texttt{cmdstanr}}{Interfaccia cmdstanr}}\label{cmdstanr-gautret}}

Nella seguente discussione verrà ottenuta una stima bayesiana del parametro \(\theta\) usando l'interfaccia \texttt{cmdstanr} di CmdStan.\footnote{I modelli discussi in questo capitolo sono discussi da \citet{gelman1995bayesian} mentre il codice è stato ricavato dalla seguente \href{http://avehtari.github.io/BDA_R_demos/demos_rstan/rstan_demo.html}{pagina web}.}. Considereremo qui solo il gruppo di controllo. Iniziamo a caricare i pacchetti necessari:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"cmdstanr"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"posterior"}\NormalTok{)}
\FunctionTok{rstan\_options}\NormalTok{(}\AttributeTok{auto\_write =} \ConstantTok{TRUE}\NormalTok{) }\CommentTok{\# avoid recompilation of models}
\CommentTok{\# parallelize across all CPUs}
\FunctionTok{options}\NormalTok{(}\AttributeTok{mc.cores =}\NormalTok{ parallel}\SpecialCharTok{::}\FunctionTok{detectCores}\NormalTok{()) }
\CommentTok{\# improve execution time}
\FunctionTok{Sys.setenv}\NormalTok{(}\AttributeTok{LOCAL\_CPPFLAGS =} \StringTok{\textquotesingle{}{-}march=native\textquotesingle{}}\NormalTok{) }
\NormalTok{SEED }\OtherTok{\textless{}{-}} \DecValTok{374237} \CommentTok{\# set random seed for reproducibility}
\end{Highlighting}
\end{Shaded}

Ci sono due passaggi essenziali per le analisi svolte mediante \texttt{cmdstanr}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  definire la struttura del modello bayesiano nella notazione Stan;
\item
  eseguire il campionamento della distribuzione a posteriori.
\end{enumerate}

Esaminiamo questi due passaggi nel contesto del modello Beta-Binomiale definito dalla \eqref{eq:beta-binom-trump}.

\hypertarget{fase-1}{%
\subsection{Fase 1}\label{fase-1}}

È necessario definire i dati, i parametri e il modello. I \emph{dati} del gruppo di controllo, che verrà qui esaminato, devono essere contenuti in un oggetto di classe \texttt{list}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data1\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \DecValTok{16}\NormalTok{,}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{14}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il modello dipende dal \emph{parametro} \texttt{theta}. In Stan, dobbiamo specificare che \texttt{theta} può essere un qualsiasi numero reale compreso tra 0 e 1.

Il \emph{modello} è \(\Bin(n, \theta)\) e, nel linguaggio Stan, può essere scritto come

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N) \{}
\NormalTok{  y[i] }\SpecialCharTok{\textasciitilde{}} \FunctionTok{bernoulli}\NormalTok{(theta);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

ovvero come

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{bernoulli}\NormalTok{(theta);}
\end{Highlighting}
\end{Shaded}

La struttura del modello Beta-Binomiale viene tradotta nella sintassi Stan\footnote{Si veda l'Appendice \ref{intro-stan}} e viene poi memorizzata come stringa di caratteri del file \texttt{oneprop1.stan}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  int\textless{}lower=0, upper=1\textgreater{} y[N];}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real\textless{}lower=0, upper=1\textgreater{} theta;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  theta \textasciitilde{} beta(2, 2);}
\StringTok{  y \textasciitilde{} bernoulli(theta);}
\StringTok{  // the notation using \textasciitilde{} is syntactic sugar for}
\StringTok{  //  target += beta\_lpdf(theta | 1, 1);   }
\StringTok{  //  target += bernoulli\_lpmf(y | theta); }
\StringTok{  // target is the log density to be sampled}
\StringTok{  //}
\StringTok{  // y is an array of integers and}
\StringTok{  //  y \textasciitilde{} bernoulli(theta);}
\StringTok{  // is equivalent to}
\StringTok{  //  for (i in 1:N) \{}
\StringTok{  //    y[i] \textasciitilde{} bernoulli(theta);}
\StringTok{  //  \}}
\StringTok{  // which is equivalent to}
\StringTok{  //  for (i in 1:N) \{}
\StringTok{  //    target += bernoulli\_lpmf(y[i] | theta); }
\StringTok{  //  \}}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  int y\_rep[N];}
\StringTok{  real log\_lik[N];}
\StringTok{  for (n in 1:N) \{}
\StringTok{    y\_rep[n] = bernoulli\_rng(theta);}
\StringTok{    log\_lik[n] = bernoulli\_lpmf(y[n] | theta);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/oneprop1.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{fase-2}{%
\subsection{Fase 2}\label{fase-2}}

Leggiamo l'indirizzo del file che contiene il codice Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"oneprop1.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Compiliamo il codice:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

Il campionamento MCMC si realizza con la chiamata:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data1\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Avendo assunto una distribuzione a priori per il parametro \(\theta\), l'algoritmo procede in maniera ciclica, correggendo la distribuzione a priori di \(\theta\) condizionandola ai valori già generati. Dopo un certo numero di cicli, necessari per portare l'algoritmo a convergenza, i valori estratti possono essere assunti come campionati dalla distribuzione a posteriori di \(\theta\).

Si noti che \texttt{\$sample()} richiede due tipi di informazioni. Innanzitutto, dobbiamo specificare le informazioni sul modello in base a:

\begin{itemize}
\tightlist
\item
  \texttt{mod} = la stringa di caratteri che definisce il modello (qui \texttt{oneprop1.stan}),
\item
  \texttt{data} = i dati in formato lista (\texttt{data1\_list}).
\end{itemize}

Dobbiamo inoltre specificare le informazioni sul campionamento MCMC utilizzando tre argomenti aggiuntivi:

\begin{itemize}
\tightlist
\item
  L'argomento \texttt{chains} specifica quante catene di Markov parallele eseguire. Eseguiamo qui quattro catene, quindi otteniamo quattro campioni distinti di valori \(\pi\).
\item
  L'argomento \texttt{iter} specifica il numero desiderato di iterazioni o la lunghezza di ciascuna catena di Markov. Per impostazione predefinita, la prima metà di queste iterazioni è costituita da campioni ``burn-in'' o ``warm-up'' che verranno ignorati. La seconda metà è conservata e costituisce un campione della distribuzione a posteriori.
\item
  L'argomento \texttt{seed} per impostare il numero casuale che genera il seme per una simulazione \texttt{cmdstanr}.
\end{itemize}

\hypertarget{burn-in}{%
\subsection{Burn-in}\label{burn-in}}

Al crescere del numero di passi della catena, la distribuzione di target viene sempre meglio approssimata. All'inizio del campionamento, però, la distribuzione può essere significativamente lontana da quella stazionaria, e ci vuole un certo tempo prima di raggiungere la distribuzione stazionaria di equilibrio, detto, appunto, periodo di \emph{burn-in}. I campioni provenienti da tale parte iniziale della catena vanno tipicamente scartati perché possono non rappresentare accuratamente la distribuzione a posteriori

\hypertarget{inferenza}{%
\subsection{Inferenza}\label{inferenza}}

Un sommario della distribuzione a posteriori si ottiene con:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"theta"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 1 x 10}
\CommentTok{\#\textgreater{}   variable  mean median     sd    mad    q5   q95  rhat}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 theta    0.801  0.810 0.0871 0.0863 0.642 0.926  1.00}
\CommentTok{\#\textgreater{} \# ... with 2 more variables: ess\_bulk \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

Creiamo un oggetto di classe \texttt{stanfit}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit1 }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit1}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

di dimensioni

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 16000     1}
\end{Highlighting}
\end{Shaded}

I primi 10 valori sono presentati qui di seguito

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{as.matrix}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}           parameters}
\CommentTok{\#\textgreater{} iterations  theta}
\CommentTok{\#\textgreater{}       [1,] 0.8521}
\CommentTok{\#\textgreater{}       [2,] 0.7239}
\CommentTok{\#\textgreater{}       [3,] 0.7636}
\CommentTok{\#\textgreater{}       [4,] 0.8374}
\CommentTok{\#\textgreater{}       [5,] 0.8481}
\CommentTok{\#\textgreater{}       [6,] 0.7196}
\CommentTok{\#\textgreater{}       [7,] 0.8490}
\CommentTok{\#\textgreater{}       [8,] 0.8490}
\CommentTok{\#\textgreater{}       [9,] 0.8190}
\CommentTok{\#\textgreater{}      [10,] 0.8437}
\end{Highlighting}
\end{Shaded}

La matrice precedente include i valori assunti dalla catena di Markov, ovvero un insieme di valori plausibili \(\theta\) estratti dalla distribuzione a posteriori. Un tracciato della catena di Markov illustra questa esplorazione rappresentando il valore \(\theta\) sulle ordinate e l'indice progressivo di in ogni iterazione sull'ascissa. Usiamo la funzione \texttt{mcmc\_trace()} del pacchetto \texttt{bayesplot} (Gabry et al.~2019) per costruire il grafico che include tutte e quattro le catene di Markov:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit1 }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mcmc\_trace}\NormalTok{(}\AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"theta"}\NormalTok{), }\AttributeTok{size =} \FloatTok{0.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/trace-plot-gautret-1} 

}

\caption{Trace-plot per il parametro $\theta$ nel modello Beta-Binomiale.}\label{fig:trace-plot-gautret}
\end{figure}

La figura \ref{fig:trace-plot-gautret} mostra che le catene esplorano uno spazio compreso approssimativamenre tra 0.7 e 0.9; tale figura descrive il comportamento \emph{longitudinale} delle catene di Markov.

Possiamo anche esaminare la distribuzione degli stati della catena di Markov, ovvero, dei valori che queste catene visitano lungo il loro percorso, ignorando l'ordine di queste visite. L'istogramma della figura \ref{fig:hist-post-gautret} fornisce una rappresentazione grafica di questa distribuzione per i 16000 valori complessivi delle quattro catene, ovvero per 4000 valori provienienti da ciascuna catena.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_hist}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{yaxis\_text}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"count"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/hist-post-gautret-1} 

}

\caption{Istogramma che illustra l'approssimazione della distribuzione a posteriori per il parametro $\theta$ nel modello Beta-Binomiale.}\label{fig:hist-post-gautret}
\end{figure}

Nel modello Beta-Binomiale in cui la verosimiglianza è binomiale con 14 successi su 16 prove e in cui assumiamo una distribuzione a priori di tipo \(\mbox{Beta}(2, 2)\) sul parametro \(\theta\), la distribuzione a posteriori è ancora una distribuzione Beta di parametri \(\alpha\) = 2 + 14 e \(\beta\) = 2 + 16 - 14. La figura \ref{fig:hist-post-gautret-plus-correct} riporta un kernel density plot per i valori delle quattro catene di Markov con sovrapposta in nero la densità \(\mbox{Beta}(16, 4)\). Il punto importante è che la distribuzione dei valori delle catene di Markov produce un'eccellente approssimazione alla distribuzione bersaglio.\footnote{Nel caso presente, il risultato è poco utile dato che è disponibile una soluzione analitica. Tuttavia, questo esercizio mette in evidenza il fatto cruciale che, nei casi in cui possiamo verificarne la soluzione, il campionamento Monte Carlo a catena di Markov è in grado di trovare la risposta corretta. Di conseguenza, possiamo anche essere sicuri che fornirà un'approssimazione alla distribuzione a posteriori anche in quei casi in cui una soluzione analitica non è disponibile.}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_dens}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{yaxis\_text}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"density"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dbeta, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{shape1 =} \DecValTok{16}\NormalTok{, }\AttributeTok{shape2=}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/hist-post-gautret-plus-correct-1} 

}

\caption{Istogramma che illustra l'approssimazione della distribuzione a posteriori per il parametro $\theta$ nel modello Beta-Binomiale. La curva nera rappresenta la corretta distribuzione a posteriori Beta(16, 4).}\label{fig:hist-post-gautret-plus-correct}
\end{figure}

Un intervallo di credibilità al 95\% per \(\theta\) si ottiene con la seguente chiamata:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior1 }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(stanfit1)}
\NormalTok{rstantools}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(stanfit1), }\AttributeTok{prob =} \FloatTok{0.95}\NormalTok{)}
\CommentTok{\#\textgreater{}                 2.5\%     97.5\%}
\CommentTok{\#\textgreater{} theta         0.6048   0.94075}
\CommentTok{\#\textgreater{} y\_rep[1]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[2]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[3]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[4]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[5]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[6]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[7]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[8]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[9]      0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[10]     0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[11]     0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[12]     0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[13]     0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[14]     0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[15]     0.0000   1.00000}
\CommentTok{\#\textgreater{} y\_rep[16]     0.0000   1.00000}
\CommentTok{\#\textgreater{} log\_lik[1]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[2]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[3]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[4]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[5]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[6]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[7]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[8]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[9]   {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[10]  {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[11]  {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[12]  {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[13]  {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[14]  {-}0.5029  {-}0.06107}
\CommentTok{\#\textgreater{} log\_lik[15]  {-}2.8260  {-}0.92834}
\CommentTok{\#\textgreater{} log\_lik[16]  {-}2.8260  {-}0.92834}
\CommentTok{\#\textgreater{} lp\_\_        {-}12.6305 {-}10.00840}
\end{Highlighting}
\end{Shaded}

Svolgendo un'analisi bayesiana simile a questa, \citet{Gautret_2020} hanno trovato che gli intervalli di credibilità del gruppo di controllo e del gruppo sperimentale non si sovrappongono. Questo fatto viene interpretato dicendo che il parametro \(\theta\) è diverso nei due gruppi. Sulla base di queste evidenza, \citet{Gautret_2020} hanno concluso, con un grado di certezza soggettiva del 95\%, che nel gruppo sperimentale vi è una probabilità più bassa di risultare positivi al SARS-CoV-2 rispetto al gruppo di controllo. In altri termini, questa analisi dei dati suggerisce che l'idrossiclorochina sia efficace come terapia per il Covid-19.

\hypertarget{la-critica-di-hulme_2020}{%
\subsection{\texorpdfstring{La critica di \citet{Hulme_2020}}{La critica di @Hulme\_2020}}\label{la-critica-di-hulme_2020}}

Un articolo pubblicato da \citet{Hulme_2020} si è posto il problema di rianalizzare i dati di \citet{Gautret_2020}.\footnote{Si veda \url{https://osf.io/5dgmx/}.} Tra gli autori di questo articolo figura anche Eric-Jan Wagenmakers, uno psicologo molto conosciuto per i suoi contributi metodologici. \citet{Hulme_2020} hanno osservato che, nelle analisi statistiche riportate, \citet{Gautret_2020} hanno escluso alcuni dati. Nel gruppo sperimentale, infatti, vi erano alcuni pazienti i quali, anziché migliorare, sono in realtà peggiorati. L'analisi statistica di \citet{Gautret_2020} ha escluso i dati di questi pazienti. Se consideriamo tutti i pazienti --- non solo quelli selezionati da \citet{Gautret_2020} --- la situazione diventa la seguente:

\begin{itemize}
\tightlist
\item
  gruppo sperimentale: 10 positivi su 18;
\item
  gruppo di controllo: 14 positivi su 16.
\end{itemize}

L'analisi dei dati proposta da \citet{Hulme_2020} richiede l'uso di alcuni strumenti statistici che, in queste dispense, non verranno discussi. Ma possiamo giungere alle stesse conclusioni raggiunte da questi ricercatori anche usando le procedure statistiche descritte nel Paragrafo successivo.

\hypertarget{due-proporzioni}{%
\section{Due proporzioni}\label{due-proporzioni}}

Svolgiamo ora l'analisi considerando tutti i dati, come suggerito da \citet{Hulme_2020}. Per fare questo verrà creato un modello bayesiano per fare inferenza sulla differenza tra due proporzioni. Una volta generate le distribuzioni a posteriori per le proporzioni di ``successi'' nei due gruppi, verrà anche generata la quantità

\[
\omega = \frac{\theta_2 / (1-\theta_2)}{\theta_1 / (1-\theta_1)},
\]

ovvero il rapporto tra gli Odds di positività tra i pazienti del gruppo di controllo e gli Odds di positività tra i pazienti del gruppo sperimentale. Se il valore dell'OR è uguale a 1, significa che l'Odds di positività nel gruppo di controllo è uguale all'odds di positività nel gruppo sperimentale, cioè il fattore in esame (somministrazione dell'idrossiclorochina) è ininfluente sulla comparsa della malattia. L'inferenza statistica sull'efficacia dell'idrossiclorochina come terapia per il Covid-19 può dunque essere effettuata esaminando l'intervallo di credibilità al 95\% per l'OR: se tale intervallo include il valore 1, allora non vi è evidenza che l'idrossiclorochina sia efficace come terapia per il Covid-19.

Nell'implementazione di questo modello, la quantità di interesse è dunque l'odds ratio; tale quantità viene calcolata nel blocco \texttt{generated\ quantities} del programma Stan. In questo esempio useremo delle distribuzioni a priori vagamente informative per i parametri \(\theta_1\) e \(\theta_1\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N1 =} \DecValTok{18}\NormalTok{, }
  \AttributeTok{y1 =} \DecValTok{10}\NormalTok{, }
  \AttributeTok{N2 =} \DecValTok{16}\NormalTok{, }
  \AttributeTok{y2 =} \DecValTok{14}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{//  Comparison of two groups with Binomial}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N1;              // number of experiments in group 1}
\StringTok{  int\textless{}lower=0\textgreater{} y1;              // number of deaths in group 1}
\StringTok{  int\textless{}lower=0\textgreater{} N2;              // number of experiments in group 2}
\StringTok{  int\textless{}lower=0\textgreater{} y2;              // number of deaths in group 2}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real\textless{}lower=0,upper=1\textgreater{} theta1; // probability of death in group 1}
\StringTok{  real\textless{}lower=0,upper=1\textgreater{} theta2; // probability of death in group 2}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  theta1 \textasciitilde{} beta(2, 2);          // prior}
\StringTok{  theta2 \textasciitilde{} beta(2, 2);          // prior}
\StringTok{  y1 \textasciitilde{} binomial(N1, theta1);    // observation model / likelihood}
\StringTok{  y2 \textasciitilde{} binomial(N2, theta2);    // observation model / likelihood}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  // generated quantities are computed after sampling}
\StringTok{  real oddsratio = (theta2/(1{-}theta2))/(theta1/(1{-}theta1));}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/twoprop1.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"twoprop1.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}
\NormalTok{  stanfit,}
  \AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"theta1"}\NormalTok{, }\StringTok{"theta2"}\NormalTok{, }\StringTok{"oddsratio"}\NormalTok{),}
  \AttributeTok{digits\_summary =}\NormalTok{ 3L}
\NormalTok{)}
\CommentTok{\#\textgreater{} Inference for Stan model: twoprop1{-}202201200848{-}1{-}5c9a32.}
\CommentTok{\#\textgreater{} 4 chains, each with iter=6000; warmup=2000; thin=1; }
\CommentTok{\#\textgreater{} post{-}warmup draws per chain=4000, total post{-}warmup draws=16000.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}            mean se\_mean    sd  2.5\%   25\%   50\%   75\%}
\CommentTok{\#\textgreater{} theta1    0.546   0.001 0.103 0.344 0.475 0.546 0.620}
\CommentTok{\#\textgreater{} theta2    0.798   0.001 0.087 0.601 0.744 0.808 0.862}
\CommentTok{\#\textgreater{} oddsratio 4.721   0.043 4.411 0.906 2.166 3.514 5.698}
\CommentTok{\#\textgreater{}            97.5\% n\_eff Rhat}
\CommentTok{\#\textgreater{} theta1     0.740 12795    1}
\CommentTok{\#\textgreater{} theta2     0.937 14193    1}
\CommentTok{\#\textgreater{} oddsratio 15.558 10400    1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Samples were drawn using NUTS(diag\_e) at Gio Gen 20 08:48:10 2022.}
\CommentTok{\#\textgreater{} For each parameter, n\_eff is a crude measure of effective sample size,}
\CommentTok{\#\textgreater{} and Rhat is the potential scale reduction factor on split chains (at }
\CommentTok{\#\textgreater{} convergence, Rhat=1).}
\end{Highlighting}
\end{Shaded}

L'intervallo di credibilità del 95\% per l'OR include il valore di 1.0 (ovvero, il valore che indica che gli odds di positività sono uguali nei due gruppi). In base agli standard correnti, un risultato di questo tipo non viene considerato come evidenza sufficiente per potere concludere che il parametro \(\theta\) assume un valore diverso nei due gruppi. In altri termini, se consideriamo tutti i dati, e non solo quelli selezionati dagli autori della ricerca originaria, non vi è evidenza alcuna che l'idrossiclorochina sia efficace come terapia per il Covid-19.

\hypertarget{commenti-e-considerazioni-finali-12}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-12}}


Concludiamo questa discussione dicendo che ciò che è stato presentato in questo capitolo è un esercizio didattico: la ricerca di \citet{Gautret_2020} include tante altre informazioni che non sono state qui considerate. Tuttavia, notiamo che la semplice analisi statistica che abbiamo qui descritto è stata in grado di replicare le conclusioni a cui sono giunti (per altra via) \citet{Hulme_2020}.

\hypertarget{diagn-markov-chains}{%
\chapter{Diagnostica delle catene markoviane}\label{diagn-markov-chains}}

Come discusso nel Paragrafo \ref{cmdstanr-gautret}, le catene di Markov forniscono un'approssimazione che tende a convergere alla distribuzione a posteriori. ``Approssimazione'' e ``convergenza'' sono le parole chiave qui: il punto è che il campionamento MCMC non è perfetto. Questo solleva le seguenti domande:

\begin{itemize}
\tightlist
\item
  A cosa corrisponde, dal punto di vista grafico, una ``buona'' catena di Markov?
\item
  Come possiamo sapere se il campione prodotto dalla catena di Markov costituisce un'approssimazione adeguata della distribuzione a posteriori?
\item
  Quanto deve essere grande la dimensione del campione casuale prodotto dalla catena Markov?
\end{itemize}

Rispondere a queste ed altre domande di questo tipo fa parte di quell'insieme di pratiche che vano sotto il nome di \emph{diagnostica delle catene Markoviane}.

La diagnostica delle catene Markoviane non è ``una scienza esatta''. Ovvero, non sono disponibili procedure valide in tutti i casi e non sempre siamo in grado di rispondere alle domande precedenti. È piuttosto l'esperienza del ricercatore che consente di riconoscere una ``buona'' catena di Markov e a suggerire cosa si può fare per riparare una ``cattiva'' catena di Markov. In questo Capitolo ci concentreremo su alcuni strumenti diagnostici grafici e numerici che possono essere utilizzati per la diagnostica delle catene markoviane. L'utilizzo di questi strumenti diagnostici deve essere eseguito in modo olistico. Nessuna singola diagnostica visiva o numerica è infatti sufficiente: un quadro completo della qualità della catena di Markov si può solo ottenere considerando tutti gli strumenti descritti di seguito.

\hypertarget{esame-dei-trace-plot}{%
\section{\texorpdfstring{Esame dei \emph{trace plot}}{Esame dei trace plot}}\label{esame-dei-trace-plot}}

La convergenza e il ``mixing'' possono essere controllate mediante il \emph{trace plot} che mostra l'andamento delle simulazioni e ci dice se stiamo effettivamente utilizzando una distribuzione limite. Consideriamo nuovamente il \emph{trace plot} del simulazione Beta-Binomiale della figura \ref{fig:trace-plot-gautret-2}:

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/trace-plot-gautret-2-1} 

}

\caption{Trace plot per il modello Beta-Binomiale dei dati di Gautret et al.(2020).}\label{fig:trace-plot-gautret-2}
\end{figure}

La figura \ref{fig:trace-plot-gautret-2} fornisce un esempio perfetto di come dovrebbero apparire i \emph{trace plot}. Quando le catene markoviane raggiungono uno stato stazionario e sono stabili ciò significa che hanno raggiunto la distribuzione stazionaria e il \emph{trace plot} rivela una assenza di struttura e assomiglia alla rappresentazione del rumore bianco, come nella figura \ref{fig:trace-plot-gautret-2}. Al contrario, la figura \ref{fig:bad-trace-bayesrules} indica mancanza di convergenza\footnote{Figura riprodotta da \citet{Johnson2022bayesrules}}.

\begin{figure}[h]

{\centering \includegraphics[width=7.87in]{images/bad-trace-bayesrules} 

}

\caption{Trace plots (a sinistra) e corrispondenti grafici di densità (a destra) di due ipotetiche catene di Markov. Queste figure forniscono due esempi di come potrebbero apparire delle catene di Markov non stazionarie. Le linee nere sovrapposte alle densità empiriche (a destra) rappresentano una ipotetica distribuzione target Beta(11,3).}\label{fig:bad-trace-bayesrules}
\end{figure}

Consideriamo i trace-plot della figura \ref{fig:bad-trace-bayesrules} (a sinistra). La tendenza verso il basso indica che la catena A non è stazionaria, ovvero non si mantiene costante all'evolversi nel tempo. La tendenza verso il basso suggerisce inoltre la presenza di una forte correlazione tra i valori della catena: il trace-plot non fornisce una rappresentazione di rumore indipendente. Tutto questo significa che la catena A ``si sta mescolando lentamente''. Sebbene le catene di Markov siano intrinsecamente dipendenti, più si comportano come se fossero dei campioni casuali (rumorosi), minore è l'errore dell'approssimazione alla distribuzione a posteriori. La catena B presenta un problema diverso. Come evidenziato dalle due linee completamente piatte nel tracciato, essa tende a bloccarsi quando visita valori bassi di \(\theta\).

Gli istogrammi lisciati della figura \ref{fig:bad-trace-bayesrules} (a destra) confermano che entrambe queste catene sono problematiche: infatti producono approssimazioni scadenti della distribuzione a posteriori che, nell'esempio di \citet{Johnson2022bayesrules}, è una \(\mbox{Beta}(11, 3)\) (curva nera nella figura). Consideriamo la catena A. Dal momento che si sta mescolando lentamente, nelle iterazioni eseguite ha esplorato unicamente i valori \(\theta\) nell'intervallo da 0.6 a 0.9. Di conseguenza, la sua approssimazione della distribuzione a posteriori sopravvaluta la plausibilità dei valori \(\theta\) in questo intervallo e, nel contempo, sottovaluta la plausibilità dei valori \(\theta\) esterni a questo intervallo. Consideriamo ora la catena B. Rimanendo bloccata, la catena B campiona in maniera eccessiva alcuni valori nella coda sinistra della distribuzione a posteriori di \(\theta\). Questo fenomeno produce i picchi che sono presenti nell'approssimazione alla distribuzione a posteriori.

In pratica, al di là dei presenti esempi ``scolastici'' (in cui disponiamo di una formulazione analitica della distribuzione a posteriori), non abbiamo mai il privilegio di poter confrontare i risultati del campionamento MCMC con la corretta distribuzione a posteriori. Ecco perché la diagnostica delle catene di Markov è così importante: se vediamo trace-plots come quelli della figura \ref{fig:bad-trace-bayesrules}, sappiamo che non abbiamo ottenuto una adeguata approssimazione della distribuzione a posteriori.

In tali circostanze possiamo ricorrere ad alcuni rimedi.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Controllare il modello. Siamo sicuri che le distribuzioni a priori e la verosimiglianza siano appropriate per i dati osservati?
\item
  Utilizzare un numero maggiore di iterazioni. Alcune tendenze indesiderate a breve termine della catena possono appianarsi nel lungo termine.
\end{enumerate}

\hypertarget{confronto-delle-catene-parallele}{%
\section{Confronto delle catene parallele}\label{confronto-delle-catene-parallele}}

Nella simulazione \texttt{cmdstanr()} per il modello Beta-Binomiale dei dati di \citet{Gautret_2020} abbiamo utilizzato quattro catene di Markov parallele. Non solo è necessario che ogni singola catena sia stazionaria (come discusso sopra), ma è anche necessario che le quattro catene siano coerenti tra loro. Sebbene le catene esplorino percorsi diversi nello spazio dei parametri, quando convergono ad uno stato di equilibrio dovrebbero presentare caratteristiche simili e dovrebbero produrre approssimazioni simili alla distribuzione a posteriori. Per l'esempio del modello Beta-Binomiale dei dati di \citet{Gautret_2020}, i seguenti istogrammi lisciati indicano che le quattro catene producono approssimazioni quasi indistinguibili della distribuzione a posteriori. Ciò prova che la simulazione è stabile e contiene un nunero sufficiente di valori: l'esecuzione delle catene per un numero maggiore di iterazioni non migliorerebbe l'approssimazione della distribuzione a posteriori.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_dens\_overlay}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"density"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-141-1} \end{center}

Per fare un confronto, consideriamo la simulazione di una catena di Markov più corta per lo stesso modello. La chiamata seguente richiede quattro catene parallele per sole 100 iterazioni ciascuna:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bb\_short }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data1\_list,}
  \AttributeTok{iter\_sampling =} \DecValTok{50}\SpecialCharTok{*}\NormalTok{2L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\ConstantTok{FALSE}\NormalTok{ Running MCMC with }\DecValTok{4}\NormalTok{ parallel chains...}
\ConstantTok{FALSE} 
\ConstantTok{FALSE}\NormalTok{ Chain }\DecValTok{1}\NormalTok{ finished }\ControlFlowTok{in} \FloatTok{0.0}\NormalTok{ seconds.}
\ConstantTok{FALSE}\NormalTok{ Chain }\DecValTok{2}\NormalTok{ finished }\ControlFlowTok{in} \FloatTok{0.0}\NormalTok{ seconds.}
\ConstantTok{FALSE}\NormalTok{ Chain }\DecValTok{3}\NormalTok{ finished }\ControlFlowTok{in} \FloatTok{0.0}\NormalTok{ seconds.}
\ConstantTok{FALSE}\NormalTok{ Chain }\DecValTok{4}\NormalTok{ finished }\ControlFlowTok{in} \FloatTok{0.0}\NormalTok{ seconds.}
\ConstantTok{FALSE} 
\ConstantTok{FALSE}\NormalTok{ All }\DecValTok{4}\NormalTok{ chains finished successfully.}
\ConstantTok{FALSE}\NormalTok{ Mean chain execution time}\SpecialCharTok{:} \FloatTok{0.0}\NormalTok{ seconds.}
\ConstantTok{FALSE}\NormalTok{ Total execution time}\SpecialCharTok{:} \FloatTok{0.3}\NormalTok{ seconds.}

\NormalTok{stanfit\_bb\_short }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(bb\_short}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Di seguito sono riportati i \emph{trace-plot} e i corrispondenti istogrammi lisciati.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_trace}\NormalTok{(stanfit\_bb\_short, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-143-1} \end{center}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_dens\_overlay}\NormalTok{(stanfit\_bb\_short, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-144-1} \end{center}

Anche se i \emph{trace plot} sembrano tutti mostrare un andamento casuale, gli istogrammi lisciati sono piuttosto diversi tra loro e producono approssimazioni diverse della distribuzione a posteriori. Di fronte a tale instabilità è chiaro che sarebbe un errore interrompere la simulazione dopo solo 100 iterazioni.

\hypertarget{numerosita-campionaria-effettiva}{%
\section{Numerosità campionaria effettiva}\label{numerosita-campionaria-effettiva}}

Nella simulazione del modello Beta-Binomiale per i dati di \citet{Gautret_2020} abbiamo utilizzato quattro catene di Markov parallele che producono un totale di \(N\) = 16000 campioni \emph{dipendenti} di \(\theta\). Sapendo che l'errore dell'approssimazione alla distribuzione a posteriori è probabilmente più grande di quello che si otterrebbe usando 16000 campioni \emph{indipendenti}, ci possiamo porre la seguente domanda: quanti campioni indipendenti sarebbero necessari per produrre un'approssimazione della distribuzione a posteriori equivalentemente a quella che abbiamo ottenuto? La numerosità campionaria effettiva (\emph{effective sample size}, \(N_{eff}\)) fornisce una risposta a questa domanda.

Tipicamente, \(N_{eff} < N\), per cui il rapporto campionario effettivo (\emph{effective sample size ratio}) \(\frac{N_{eff}}{N}\) è minore di 1. Come regola euristica, viene considerato problematico un rapporto campionario effettivo minore del 10\% del numero totale di campioni ottenuti nella simulazione (più basso è il rapporto campionario effettivo peggiore è il ``mixing'' della catena). La funzione \texttt{bayesplot::neff\_ratio()} consente di calcolare il rapporto campionario effettivo. Per il modello Beta-Binomiale dei dati di \citet{Gautret_2020}, questo rapporto è di circa 0.34:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesplot}\SpecialCharTok{::}\FunctionTok{neff\_ratio}\NormalTok{(stanfit1, }\AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"theta"}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 0.3629}
\end{Highlighting}
\end{Shaded}

Ciò indica che l'accuratezza dell'approssimazione della distribuzione a posteriori di \(\theta\) ottenuta mediante 16000 campioni dipendenti è approssimativamente simile a quella che si potrebbe ottenere con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesplot}\SpecialCharTok{::}\FunctionTok{neff\_ratio}\NormalTok{(}
\NormalTok{  stanfit1, }\AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"theta"}\NormalTok{)}
\NormalTok{) }\SpecialCharTok{*} \DecValTok{16000}
\CommentTok{\#\textgreater{} [1] 5807}
\end{Highlighting}
\end{Shaded}

campioni \emph{indipendenti}. In questo esempio, il rapporto campionario effettivo è maggiore di 0.1; dunque non ci sono problemi.

\hypertarget{autocorrelazione}{%
\section{Autocorrelazione}\label{autocorrelazione}}

Normalmente un algoritmo MCMC genera catene di Markov di campioni, ognuno dei quali è autocorrelato a quelli generati immediatamente prima e dopo di lui. Conseguentemente campioni successivi non sono indipendenti ma formano una catena di Markov con un certo grado di correlazione. Il valore \(\theta^{(i)}\) tende ad essere più simile al valore \(\theta^{(i-1)}\) che al valore \(\theta^{(i-2)}\), o al valore \(\theta^{(i-3)}\), eccetera. Una misura di ciò è fornita dall'autocorrelazione tra i valori consecutivi della catena.

Il correlogramma per ciascuna delle quattro catene dell'esempio si produce con la seguente chiamata:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesplot}\SpecialCharTok{::}\FunctionTok{mcmc\_acf}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-147-1} \end{center}

Il correlogramma mostra l'autocorrelazione in funzione di ritardi da 0 a 20. L'autocorrelazione di lag 0 è naturalmente 1 -- misura la correlazione tra un valore della catena di Markov e se stesso. L'autocorrelazione di lag 1 è di circa 0.5, indicando una correlazione moderata tra i valori della catena che distano di solo 1 passo l'uno dall'altro. Successivamente, l'autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per un lag di 5. Questo risultato fornisce una conferma del fatto che la catena di Markov costituisce una buona approssimazione di un campione casuale di \(p(\theta \mid y)\).

Al contrario, nella figura \ref{fig:bad-autocorrelation} (a destra) \citep[riprodotta da][]{Johnson2022bayesrules} vediamo un esempio nel quale il trace plot rivela una forte tendenza tra i valori di una catena di Markov e, dunque, una forte autocorrelazione.

\begin{figure}[h]

{\centering \includegraphics[width=7.87in]{images/ch6-acf-2-1} 

}

\caption{Trace plot (a sinistra) e correlogramma (a destra) di una catena di Markow in cui il mixing è lento -- figura riprodotta da @Johnson2022bayesrules.}\label{fig:bad-autocorrelation}
\end{figure}

Questa osservazione è confermata nell'correlogramma (a destra). La lenta diminuzione della curva di autocorrelazione indica che la dipendenza tra i valori della catena non svanisce rapidamente. Con un lag di 20 la correlazione è addirittura pari a 0.9. Poiché i valori della catena sono fortemente associati tra loro, il ``mixing'' è lento: la simulazione richiede un numero molto grande di iterazioni per esplorare adeguatamente l'intera gamma di valori della distribuzione a posteriori.\footnote{Una (famiglia di) catene di Markov è \emph{rapidly mixing} se mostra un comportamento simile a quello di un campione indipendente: i valori delle catene si addensano nell'intervallo dei valori più plausibili della distribuzione a posteriori; l'autocorrelazione tra i valori della catena diminuisce rapidamente; il rapporto campionario effettivo è ragionevolmente grande. Le catene che non sono \emph{rapidly mixing} non godono delle caratteristiche di un campione indipendente: le catene non si addensano nell'intervallo dei valori più plausibili della distribuzione a posteriori; l'autocorrelazione tra i valori della catena diminuisce molto lentamente; il rapporto campionario effettivo è piccolo.}

In presenza di catene di Markov non \emph{rapidly mixing} sono possibili due rimedi.

\begin{itemize}
\tightlist
\item
  Aumentare il numero di iterazioni. Anche una catena non \emph{rapidly mixing} può produrre eventualmente una buona approssimazione della distribuzione a posteriori se il numero di iterazioni è sufficientemente grande.
\item
  \emph{Thinning}. Per esempio, se la catena di Markov è costituita da 16000 valori di \(\theta\), potremmo decidere di conservare solo ogni secondo valore e ignorare gli altri valori: \(\{\theta^{(2)}, \theta^{(4)}, \theta^{(6)}, \dots, \theta^{(16000)}\}\). Oppure, potremmo decidere di conservare ogni decimo valore: \(\{\theta^{(10)}, \theta^{(20)}, \theta^{(30)}, \dots, \theta^{(16000)}\}\). Scartando i campioni intermedi, è possibile rimuovere le forti correlazioni che sono presenti nel caso di lag più piccoli.
\end{itemize}

Vediamo ora come sia possibile estrarre i valodi di una catena dall'oggetto \texttt{stanfit1}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# valori delle 4 catene}
\NormalTok{S }\OtherTok{\textless{}{-}}\NormalTok{ ggmcmc}\SpecialCharTok{::}\FunctionTok{ggs}\NormalTok{(stanfit1)}
\FunctionTok{head}\NormalTok{(S)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 4}
\CommentTok{\#\textgreater{}   Iteration Chain Parameter value}
\CommentTok{\#\textgreater{}       \textless{}dbl\textgreater{} \textless{}int\textgreater{} \textless{}fct\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1         1     1 theta     0.628}
\CommentTok{\#\textgreater{} 2         2     1 theta     0.758}
\CommentTok{\#\textgreater{} 3         3     1 theta     0.719}
\CommentTok{\#\textgreater{} 4         4     1 theta     0.715}
\CommentTok{\#\textgreater{} 5         5     1 theta     0.856}
\CommentTok{\#\textgreater{} 6         6     1 theta     0.870}
\end{Highlighting}
\end{Shaded}

La prima catena può essere isolata nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S1 }\OtherTok{\textless{}{-}}\NormalTok{ S }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{filter}\NormalTok{(}
\NormalTok{    Chain }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
\NormalTok{    Parameter }\SpecialCharTok{==} \StringTok{"theta"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Una serie temporale della catena si ottiene con la funzione \texttt{ggmcmc::ggs\_running}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggmcmc}\SpecialCharTok{::}\FunctionTok{ggs\_running}\NormalTok{(S1)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-150-1} \end{center}

Il grafico precedente mostra che, per il modello bayesiano che stiamo discutendo, una condizione di equilibrio della catena di Markov richiederebbe un numero maggiore di iterazioni di quelle che sono state effettivamente simulate.

L'autocorrelazione di ordine 1 si ottiene nel modo seguente (si veda il Paragrafo \ref{approx-post-autocor}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(S1}\SpecialCharTok{$}\NormalTok{value[}\SpecialCharTok{{-}}\FunctionTok{length}\NormalTok{(S1}\SpecialCharTok{$}\NormalTok{value)], S1}\SpecialCharTok{$}\NormalTok{value[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 0.382}
\end{Highlighting}
\end{Shaded}

Questo valore corrisponde a ciò che è riportato nel correlogramma mostrato sopra.

\hypertarget{statistica-hatr}{%
\section{\texorpdfstring{Statistica \(\hat{R}\)}{Statistica \textbackslash hat\{R\}}}\label{statistica-hatr}}

In precedenza abbiamo detto che non solo è necessario che ogni singola catena sia stazionaria, è anche necessario che le diverse catene siano coerenti tra loro. La statistica \(\hat{R}\) affronta questo problema calcolando il rapporto tra la varianza tra le catene markoviane e la varianza entro le catene. In una situazione ottimale \(\hat{R} = 1\); se \(\hat{R}\) è lontano da 1 questo vuol dire che non è ancora stata raggiunta la convergenza.

È possibile calcolare \(\hat{R}\) mediante la chiamata alla funzione \texttt{bayesplot::rhat()}. Per il modello Beta-Binomiale applicato ai dati di \citet{Gautret_2020} abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesplot}\SpecialCharTok{::}\FunctionTok{rhat}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"theta"}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

il che indica che il valore \(\hat{R}\) ottenuto è molto simile al valore ottimale.

In maniera euristica, si può affermare che se \(\hat{R}\) supera la soglia di 1.05 questo viene interpretato come evidenza che le diverse catene parallele non producono approssimazioni coerenti della distribuzione a posteriori, quindi la simulazione è instabile.

Una rappresentazione grafica dei valori \(\hat{R}\) per tutti i parametri del modello si ottiene con la seguente chiamata:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ggmcmc}\SpecialCharTok{::}\FunctionTok{ggs\_Rhat}\NormalTok{(S) }\SpecialCharTok{+} \FunctionTok{xlab}\NormalTok{(}\StringTok{"R\_hat"}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{xlim}\NormalTok{(}\FloatTok{0.95}\NormalTok{, }\FloatTok{1.05}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-153-1} \end{center}

\hypertarget{diagnostica-di-convergenza-di-geweke}{%
\section{Diagnostica di convergenza di Geweke}\label{diagnostica-di-convergenza-di-geweke}}

La statistica diagnostica di convergenza di Geweke è basata su un test per l'uguaglianza delle medie della prima e dell'ultima parte di una catena di Markov (di default il primo 10\% e l'ultimo 50\% della catena). Se i due campioni sono estratti dalla distribuzione stazionaria della catena, le due medie sono statisticamente uguali e la statistica di Geweke ha una distribuzione asintotica Normale standardizzata.

Utilizzando l'oggetto \texttt{stanfit1}, possiamo recuperare la statistica di Geweke nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit\_mcmc }\OtherTok{\textless{}{-}} \FunctionTok{As.mcmc.list}\NormalTok{(}
\NormalTok{  stanfit1,}
  \AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"theta"}\NormalTok{)}
\NormalTok{)}
\NormalTok{coda}\SpecialCharTok{::}\FunctionTok{geweke.diag}\NormalTok{(fit\_mcmc, }\AttributeTok{frac1 =}\NormalTok{ .}\DecValTok{1}\NormalTok{, }\AttributeTok{frac2 =}\NormalTok{ .}\DecValTok{5}\NormalTok{) }
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fraction in 1st window = 0.1}
\CommentTok{\#\textgreater{} Fraction in 2nd window = 0.5 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}  theta }
\CommentTok{\#\textgreater{} {-}0.017 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[2]]}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fraction in 1st window = 0.1}
\CommentTok{\#\textgreater{} Fraction in 2nd window = 0.5 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}  theta }
\CommentTok{\#\textgreater{} 0.6504 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[3]]}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fraction in 1st window = 0.1}
\CommentTok{\#\textgreater{} Fraction in 2nd window = 0.5 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}    theta }
\CommentTok{\#\textgreater{} {-}0.04024 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[4]]}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Fraction in 1st window = 0.1}
\CommentTok{\#\textgreater{} Fraction in 2nd window = 0.5 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} theta }
\CommentTok{\#\textgreater{} 1.315}
\end{Highlighting}
\end{Shaded}

Per interpretare questi valori ricordiamo che la statistica di Geweke è uguale a zero quando le medie delle due porzioni della catena di Markov sono uguali. Valori maggiori di \(\mid 2 \mid\) suggeriscono che la catena non ha ancora raggiunto una distribuzione stazionaria.

\hypertarget{chapter-sintesi-distr-post}{%
\chapter{Sintesi a posteriori}\label{chapter-sintesi-distr-post}}

La distribuzione a posteriori è un modo per descrivere il nostro grado di incertezza rispetto al parametro incognito (o rispetto ai parametri incogniti) oggetto dell'inferenza. La distribuzione a posteriori contiene tutte le informazioni disponibili sui possibili valori del parametro. Se il parametro esaminato è monodimensionale (o bidimensionale) è possibile fornire un grafico di tutta la distribuzione a posteriori \(p(\theta \mid y)\). Tuttavia, spesso vogliamo anche giungere ad una sintesi numerica della distribuzione a posteriori, soprattutto se il vettore dei parametri ha più di due dimensioni. A a questo proposito è possibile utilizzare le consuete statistiche descrittive, come media, mediana, moda, varianza, deviazione standard e i quantili. In alcuni casi, queste statistiche descrittive sono più facili da presentare e interpretare rispetto alla rappresentazione grafica della distribuzione a posteriori.

La stima puntuale della tendenza centrale della distribuzione a posteriori fornisce informazioni su quello che può essere considerato come il ``valore più plausibile'' del parametro. L'intervallo di credibilità fornisce invece un'indicazione dell'ampiezza dell'intervallo che contiene una determinata quota della massa della distribuzione a posteriori del parametro.

\hypertarget{stima-puntuale}{%
\section{Stima puntuale}\label{stima-puntuale}}

Per sintetizzare la distribuzione a posteriori in modo da giungere ad una stima puntuale di \(\theta\) si è soliti scegliere tra moda, mediana o media a seconda del tipo di distribuzione con cui si ha a che fare e della sua forma. Ogni stima puntuale ha una sua interpretazione.

\begin{itemize}
\tightlist
\item
  La media è il valore atteso a posteriori del parametro.
\item
  La moda può essere interpretata come il singolo valore più credibile (``più plausibile'') del parametro, alla luce dei dati, ovvero il valore per il parametro \(\theta\) che massimizza la distribuzione a posteriori. Per questa ragione la moda viene detta \emph{massimo a posteriori}, MAP. Il limite della moda quale statistica riassuntiva della distribuzione a posteriori è che, talvolta, tale distribuzione è multimodale e il MAP non è necessariamente il valore ``più credibile''.
\item
  La mediana è il valore del parametro tale per cui, su entrambi i lati di essa, giace il 50\% della massa di probabilità a posteriori.
\end{itemize}

La misura di variabilità del parametro è la \emph{varianza a posteriori} la quale, nel caso di una distribuzione a posteriori ottenuta per via numerica, si calcola con la formula della varianza che conosciamo rispetto alla tendenza centrale data dalla media a posteriori. La radice quadrata della varianza a posteriori è la \emph{deviazione standard a posteriori} che descrive l'incertezza a posteriori circa il parametro di interesse nella stessa unità di misura dei dati.

Le procedure bayesiane basate sui metodi MCMC utilizzano un numero finito di campioni dalla distribuzione stazionaria, e una tale caratteristica della simulazione introduce un ulteriore livello di incertezza nella stima del parametro. L'\emph{errore standard della stima} (in inglese \emph{Monte Carlo standard error}, MCSE) misura l'accuratezza della simulazione. La deviazione standard a posteriori e l'errore standard della stima sono due concetti completamente diversi. La deviazione standard a posteriori descrive l'incertezza circa il parametro (l'ampiezza della distribuzione a posteriori) ed è una funzione della dimensione del campione; il MCSE descrive invece l'incertezza nella stima del parametro dovuta alla simulazione MCMC ed è una funzione del numero di iterazioni nella simulazione.

\hypertarget{intervallo-di-credibilituxe0}{%
\section{Intervallo di credibilità}\label{intervallo-di-credibilituxe0}}

Molto spesso la stima puntuale è accompagnata da una stima intervallare. Nella statistica bayesiana, se il parametro \(\theta \in \Theta\) è monodimensionale, si dice \emph{intervallo di credibilità} un intervallo di valori \(I_{\alpha}\) che contiene la proporzione \(1 - \alpha\) della massa di probabilità della funzione a posteriori:

\begin{equation}
p(\Theta \in I_{\alpha} \mid y) = 1 - \alpha.
\label{eq:credibint}
\end{equation}

L'intervallo di credibilità ha lo scopo di esprimere il nostro grado di incertezza riguardo la stima del parametro. Se il parametro \(\theta\) è multidimensionale, si parla invece di ``regione di credibilità''.

La condizione \eqref{eq:credibint} non determina un unico intervallo di credibilità al \((1 - \alpha) \cdot 100\%\). In realtà esiste un numero infinito di tali intervalli. Ciò significa che dobbiamo definire alcune condizioni aggiuntive per la scelta dell'intervallo di credibilità. Esaminiamo due delle condizioni aggiuntive più comuni.

\hypertarget{intervallo-di-credibilituxe0-a-code-uguali}{%
\subsection{Intervallo di credibilità a code uguali}\label{intervallo-di-credibilituxe0-a-code-uguali}}

Un intervallo di credibilità \emph{a code uguali} a livello \(\alpha\) è un intervallo \[I_{\alpha} = [q_{\alpha/2}, 1 - q_{\alpha/2}],\] dove \(q_z\) è un quantile \(z\) della distribuzione a posteriori. Per esempio, l'intervallo di credibilità a code uguali al 95\% è un intervallo

\[
I_{0.05} = [q_{0.025}, q_{0.975}]
\]

che lascia il 2.5\% della massa di densità a posteriori in ciascuna coda.

\hypertarget{intervallo-di-credibilituxe0-a-densituxe0-a-posteriori-piuxf9-alta}{%
\subsection{Intervallo di credibilità a densità a posteriori più alta}\label{intervallo-di-credibilituxe0-a-densituxe0-a-posteriori-piuxf9-alta}}

Nell'intervallo di credibilità a code uguali alcuni valori del parametro che sono inclusi nell'intervallo possono avere una credibilità a posteriori più bassa rispetto a quelli esterni all'intervallo. L'intrevallo di credibilità \emph{a densità a posteriori più alta} (in inglese \emph{High Posterior Density Interval}, HPD) è invece costruito in modo tale da assicurare di includere nell'intervallo tutti i valori \(\theta\) che sono a posteriori maggiormente credibili. Graficamente questo intervallo può essere ricavato tracciando una linea orizzontale sulla rappresentazione della distribuzione a posteriori e regolando l'altezza della linea in modo tale che l'area sottesa alla curva sia pari a \(1 - \alpha\). Questo tipo di intervallo è il più stretto possibile, tra tutti i possibili intervalli di credibilità allo stesso livello di fiducia. Se la distribuzione a posteriori è simmetrica unimodale, l'intervallo di credibilità a densità a posteriori più alta corrisponde all'intervallo di credibilità a code uguali.

\hypertarget{interpretazione-1}{%
\subsection{Interpretazione}\label{interpretazione-1}}

L'interpretazione dell'intervallo di credibilità è molto intuitiva: l'intervallo di credibilità è un intervallo di valori all'interno del quale cade il valore del parametro incognito con un particolare livello di probabilità soggettiva. Possiamo dire che, dopo aver visto i dati crediamo, con un determinato livello di probabilità soggettiva, che il valore del parametro (ad esempio, la dimensione dell'effetto di un trattamento) abbia un valore compreso all'interno dell'intervallo che è stato calcolato, laddove per probabilità soggettiva intendiamo ``il grado di fiducia che lo sperimentatore ripone nel verificarsi di un evento''. Gli intervalli di credibilità si calcolano con un software.

\hypertarget{un-esempio-concreto}{%
\section{Un esempio concreto}\label{un-esempio-concreto}}

Per fare un esempio pratico, consideriamo nuovamente i valori del BDI-II dei 30 soggetti clinici di \citet{zetschefuture2019}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{suppressPackageStartupMessages}\NormalTok{(}\FunctionTok{library}\NormalTok{(}\StringTok{"bayesrules"}\NormalTok{)) }

\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\DecValTok{26}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{44}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{43}\NormalTok{, }
        \DecValTok{24}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{39}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{31}\NormalTok{, }
        \DecValTok{41}\NormalTok{, }\DecValTok{36}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{34}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{22}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Un valore BDI-II \(\geq 30\) indica la presenza di un livello ``grave'' di depressione. Nel campione clinico di \citet{zetschefuture2019},

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{y }\SpecialCharTok{\textgreater{}} \DecValTok{29}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 17}
\end{Highlighting}
\end{Shaded}

17 pazienti su 30 manifestano un livello grave di depressione.

Supponiamo di volere stimare la distribuzione a posteriori della probabilità \(\theta\) di depressione ``grave'' nei pazienti clinici, così come viene misurata dal test BDI-II, imponendo su \(\theta\) una distribuzione a priori \(\mbox{Beta}(8, 2)\).

Sappiamo che il modello Beta-Binomiale può essere espresso nella forma seguente:

\begin{align}
Y | \theta & \sim \mbox{Bin}(30, \theta) \notag\\
\theta & \sim \mbox{Beta}(8, 2) \notag
\end{align}

con una corrispondente distribuzione a posteriori \(\mbox{Beta}(25, 15)\):

\begin{equation}
f(\theta | y = 17) = \frac{\Gamma(25 + 15)}{\Gamma(25)\Gamma(15)}\theta^{25-1} (1-\theta)^{15-1} \;\; \text{ for } \theta \in [0,1] \; .
\label{eq:post-beta-25-15}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_beta\_binomial}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{8}\NormalTok{, }\AttributeTok{beta =} \DecValTok{2}\NormalTok{, }\AttributeTok{y =} \DecValTok{17}\NormalTok{, }\AttributeTok{n =} \DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-157-1} \end{center}

\hypertarget{stime-puntuali-della-distribuzione-a-posteriori}{%
\subsection{Stime puntuali della distribuzione a posteriori}\label{stime-puntuali-della-distribuzione-a-posteriori}}

Una volta trovata l'intera distribuzione a posteriori, quale valore di sintesi è necessario riportare? Questa sembra una domanda innocente, ma in realtà è una domanda a cui è difficile rispondere. La stima bayesiana dei parametri è fornita dall'intera distribuzione a posteriori, che non è un singolo numero, ma una funzione che mappa ciascun valore del parametro ad un valore di plausibilità. Quindi non è necessario scegliere una stima puntuale. In linea di principio, una stima puntuale non è quasi mai necessaria ed è spesso dannosa in quanto comporta una perdita di informazioni.

Tuttavia talvolta una tale sintesi è richiesta. Diverse risposte sono allora possibili. La media della distribuzione a posteriori per \(\theta\) è

\[
\E(\pi \mid y = 17) = \frac{\alpha}{\alpha + \beta} = \frac{25}{25+15} = 0.625.
\] Una stima del massimo della probabilità a posteriori, o brevemente massimo a posteriori, MAP (da \emph{maximum a posteriori probability}), è la moda della distribuzione a posteriori. Nel caso presente, una stima del MAP può essere ottenuta nel modo seguente:

\[
\Mo(\pi \mid y = 17) = \frac{\alpha-1}{\alpha + \beta-2} = \frac{25-1}{25+15-2} = 0.6316.
\]

Gli stessi risultati si ottiengono usando la chiamata a \texttt{bayesrules::summarize\_beta\_binomial()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{8}\NormalTok{, }\AttributeTok{beta =} \DecValTok{2}\NormalTok{, }\AttributeTok{y =} \DecValTok{17}\NormalTok{, }\AttributeTok{n =} \DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta  mean   mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior     8    2 0.800 0.8750 0.014545 0.12060}
\CommentTok{\#\textgreater{} 2 posterior    25   15 0.625 0.6316 0.005716 0.07561}
\end{Highlighting}
\end{Shaded}

La mediana si ottiene con

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbeta}\NormalTok{(.}\DecValTok{5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.6271}
\end{Highlighting}
\end{Shaded}

\hypertarget{intervallo-di-credibilituxe0-1}{%
\subsection{Intervallo di credibilità}\label{intervallo-di-credibilituxe0-1}}

È più comune sintetizzare la distribuzione a posteriori mediante l'intervallo di credibilità. Per esempio, l'intervallo di credibilità a code uguali al 95\%

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot\_beta\_ci}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{25}\NormalTok{, }\AttributeTok{beta =} \DecValTok{15}\NormalTok{, }\AttributeTok{ci\_level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-160-1} \end{center}

è dato dalla chiamata

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbeta}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\DecValTok{25}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.4718 0.7664}
\end{Highlighting}
\end{Shaded}

Il calcolo precedente evidenzia l'interpretazione intuitiva dell'intervallo di credibilità. Tale intervallo, infatti, può essere interpretato come la probabilità che \(\theta\) assuma valori compresi tra 0.472 e 0.766:

\[
P(\theta \in (0.472, 0.766) | Y = 17) = \int_{0.472}^{0.766} f(\theta \mid y=17) d\theta = 0.95,
\]

ovvero

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{postFun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(theta) \{}
  \FunctionTok{gamma}\NormalTok{(}\DecValTok{25} \SpecialCharTok{+} \DecValTok{15}\NormalTok{) }\SpecialCharTok{/} 
\NormalTok{    (}\FunctionTok{gamma}\NormalTok{(}\DecValTok{25}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{gamma}\NormalTok{(}\DecValTok{15}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ theta}\SpecialCharTok{\^{}}\DecValTok{24} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta)}\SpecialCharTok{\^{}}\DecValTok{14}
\NormalTok{\}}
\FunctionTok{integrate}\NormalTok{(}
\NormalTok{  postFun, }
  \AttributeTok{lower =} \FloatTok{0.4717951}\NormalTok{, }
  \AttributeTok{upper =} \FloatTok{0.7663607}
\NormalTok{)}\SpecialCharTok{$}\NormalTok{value}
\CommentTok{\#\textgreater{} [1] 0.95}
\end{Highlighting}
\end{Shaded}

Possiamo costruire diversi intervalli di credibilità a code equivalenti. Ad esempio, l'intervallo di credibilità compreso tra il 25-esimo e il 75-esimo percentile è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qbeta}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.25}\NormalTok{, }\FloatTok{0.75}\NormalTok{), }\DecValTok{25}\NormalTok{, }\DecValTok{15}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.5744 0.6779}
\end{Highlighting}
\end{Shaded}

ovvero, abbiamo una certezza a posteriori del 50\% che la probabilità di depressione grave tra i pazienti clinici sia un valore compreso tra 0.57 e 0.68.

Non esiste un livello credibile ``corretto''. I ricercatori, utilizzano vari livelli, ad esempio 50\%, 80\% o 95\%, a seconda del contesto dell'analisi. Ciascuno di questi intervalli fornisce un'immagine diversa della nostra comprensione della distribuzione a posteriori del parametro di interesse.

Non è inoltre necessario riportare l'intervallo di credibilità a code uguali. Se la distribuzione a posteriori è fortemente asimmetrica è più sensato riportare l'intervallo di credibilità a densità a posteriori più alta. L'intervallo HPD risulta più semplice da determinare quando la distribuzione a posteriori viene approssimata con il metodo MCMC.

\hypertarget{probabilituxe0-della-distribuzione-a-posteriori}{%
\subsection{Probabilità della distribuzione a posteriori}\label{probabilituxe0-della-distribuzione-a-posteriori}}

Il test di ipotesi è un compito comune dell'analisi della distribuzione a posteriori. Supponiamo che si voglia conoscere la probabilità a posteriori che \(\theta\) sia superiore a 0.5. Per sapere quanto credibile sia l'evento \(\theta > 0.5\) possiamo calcolare il seguente integrale:

\[
P(\theta > 0.5 \; \mid \; y = 17) = \int_{0.5}^{1}f(\theta \mid y=17)d\theta \;,
\]

dove \(f(\cdot)\) è la distribuzione \(\mbox{\Beta}(25, 15)\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{15}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0.9459}
\end{Highlighting}
\end{Shaded}

il che è equivalente a:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{postFun }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(theta) \{}
  \FunctionTok{gamma}\NormalTok{(}\DecValTok{25} \SpecialCharTok{+} \DecValTok{15}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{gamma}\NormalTok{(}\DecValTok{25}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{gamma}\NormalTok{(}\DecValTok{15}\NormalTok{)) }\SpecialCharTok{*}\NormalTok{ theta}\SpecialCharTok{\^{}}\DecValTok{24} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ theta)}\SpecialCharTok{\^{}}\DecValTok{14}
\NormalTok{\}}
\FunctionTok{integrate}\NormalTok{(}
\NormalTok{  postFun, }
  \AttributeTok{lower =} \FloatTok{0.5}\NormalTok{, }
  \AttributeTok{upper =} \DecValTok{1}
\NormalTok{)}\SpecialCharTok{$}\NormalTok{value}
\CommentTok{\#\textgreater{} [1] 0.9459}
\end{Highlighting}
\end{Shaded}

È anche possibile formulare un test di ipotesi contrastando due ipotesi contrapposte. Per esempio, \(H_1: \theta \geq 0.5\) e \(H_2: \theta < 0.5\). Ciò consente di calcolare l'\emph{odds a posteriori} di \(\theta > 0.5\):

\begin{equation}
\text{poterior odds} = \frac{H_1 \mid y = 17}{H_2 \mid y = 17}
\end{equation}

ovvero

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior\_odds }\OtherTok{\textless{}{-}} 
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{15}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{/}
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{25}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{15}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{posterior\_odds}
\CommentTok{\#\textgreater{} [1] 17.5}
\end{Highlighting}
\end{Shaded}

L'odds a posteriori rappresenta l'aggiornamento delle nostre credenze dopo avere osservato \(y = 17\) in \(n = 30\). L'odds a priori di \(\theta > 0.5\) era:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_odds }\OtherTok{\textless{}{-}} 
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{8}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{2}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{/}
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{8}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{2}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{prior\_odds}
\CommentTok{\#\textgreater{} [1] 50.2}
\end{Highlighting}
\end{Shaded}

Il \emph{fattore di Bayes} (\emph{Bayes Factor}; BF) confronta gli odds a posteriori con gli odds a priori e quindi fornisce informazioni su quanto sia mutata la nostra comprensione relativa a \(\theta\) dopo avere osservato i nostri dati del campione:

\[
\text{BF} = \frac{\text{odds a posteriori}}{\text{odds a priori}}.
\]

Nel caso presente abbiamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{BF }\OtherTok{\textless{}{-}}\NormalTok{ posterior\_odds }\SpecialCharTok{/}\NormalTok{ prior\_odds}
\NormalTok{BF}
\CommentTok{\#\textgreater{} [1] 0.3485}
\end{Highlighting}
\end{Shaded}

Quindi, dopo avere osservato i dati, gli odds a posteriori della nostra ipotesi a proposito di \(\theta\) sono pari a solo il 34\% degli odds a priori.

Per fare un altro esempio, consideriamo invece il caso in cui le credenze a priori rivelano una credenza diametralmente opposta rispetto a \(\theta\) che nel caso considerato in precedenza, ovvero \(\mbox{Beta}(2, 8)\). In questo secondo caso, la distribuzione a posteriori diventa

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{8}\NormalTok{, }\AttributeTok{y =} \DecValTok{17}\NormalTok{, }\AttributeTok{n =} \DecValTok{30}\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta  mean   mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior     2    8 0.200 0.1250 0.014545 0.12060}
\CommentTok{\#\textgreater{} 2 posterior    19   21 0.475 0.4737 0.006082 0.07799}
\end{Highlighting}
\end{Shaded}

e il BF è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior\_odds }\OtherTok{\textless{}{-}} 
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{19}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{21}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{/}
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{19}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{21}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{prior\_odds }\OtherTok{\textless{}{-}} 
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{2}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{8}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{/}
  \FunctionTok{pbeta}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\AttributeTok{shape1 =} \DecValTok{2}\NormalTok{, }\AttributeTok{shape2 =} \DecValTok{8}\NormalTok{, }\AttributeTok{lower.tail =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{BF }\OtherTok{\textless{}{-}}\NormalTok{ posterior\_odds }\SpecialCharTok{/}\NormalTok{ prior\_odds}
\NormalTok{BF}
\CommentTok{\#\textgreater{} [1] 30.07}
\end{Highlighting}
\end{Shaded}

In alre parole, in questo secondo esempio gli odds a posteriori della nostra ipotesi a proposito di \(\theta\) sono aumentati di 30 volte rispetto agli odds a priori.

In generale, in un test di ipotesi che contrappone un'ipotesi sostantiva \(H_a\) ad un'ipotesi nulla \(H_0\) il BF è un rapporto di odds per l'ipotesi sostantiva:

\[
\text{Bayes Factor}
= \frac{\text{posterior odds}}{\text{prior odds}}
= \frac{P(H_a \mid Y) / P(H_0 \mid Y)}{P(H_a) / P(H_0)}
 \; .
\] Essendo un rapporto, il BF deve esere valutato rispetto al valore di 1. Ci sono tre possibilità:

\begin{itemize}
\tightlist
\item
  BF = 1: La credibilità di \(H_a\) non è cambiata dopo avere osservato i dati.
\item
  BF \textgreater{} 1: La credibilità di \(H_a\) è aumentata dopo avere osservato i dati. Quindi maggiore è BF, più convincente risulta l'evidenza per \(H_a\).
\item
  BF \textless{} 1: La credibilità di \(H_a\) è diminuita dopo avere osservato i dati.
\end{itemize}

Non ci sono delle soglie universalmente riconosciute per interpretare il BF. Per esempio, \citet{lee2014bayesian} propongono il seguente schema:

\begin{longtable}[]{@{}rl@{}}
\toprule
BF & Interpretation \\
\midrule
\endhead
\textgreater{} 100 & Extreme evidence for \(H_a\) \\
30 - 100 & Very strong evidence for \(H_a\) \\
10 - 30 & Strong evidence for \(H_a\) \\
3 - 10 & Moderate evidence for \(H_a\) \\
1 - 3 & Anecdotal evidence for \(H_a\) \\
1 & No evidence \\
1/3 - 1 & Anecdotal evidence for \(H_0\) \\
1/10 - 1/3 & Moderate evidence for \(H_0\) \\
1/30 - 1/10 & Strong evidence for \(H_0\) \\
1/100 - 1/30 & Very strong evidence for \(H_0\) \\
\textless{} 1/100 & Extreme evidence for \(H_0\) \\
\bottomrule
\end{longtable}

Tuttavia, è importante notare che l'opinione maggiormente diffusa nella comunità scientifica sia quella che incoraggia a non trarre conclusioni rigide dai dati utilizzando dei criteri fissati una volta per tutte. Pertanto, non esiste una soglia univoca per il BF che consente di classificare le ipotesi dei ricercatori nelle due categorie ``vero'' o ``falso''. Invece, è più utile adottare una pratica più flessibile capace di tenere in considerazione il contesto e le potenziali implicazioni di ogni singolo test di ipotesi. Inoltre, è stato molte volte ripetuto che la distribuzione a posteriori è molto più informativa di una decisione binaria: la rappresentazione di tutta la distribuzione a posteriori fornisce una misura olistica del nostro livello di incertezza riguardo all'affermazione (il parametro, ovvero l'ipotesi) che viene valutata.

\hypertarget{commenti-e-considerazioni-finali-13}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-13}}


Questo capitolo introduce le procedure di base per la manipolazione della distribuzione a posteriori. Lo strumento fondamentale che è stato utilizzato è quello fornito dai campioni di valori del parametro che vengono estratti dalla distribuzione a posteriori. Lavorare con campioni di valori del parametro estratti dalla distribuzione a posteriori trasforma un problema di calcolo integrale in un problema di riepilogo dei dati. Abbiamo visto le procedure maggiormente usate che consentono di utilizzare i campioni a posteriori per produrre indici di sintesi della distribuzione a posteriori: gli intervalli di credibilità e le stime puntuali.

\hypertarget{chapter-ppc}{%
\chapter{Distribuzione predittiva a posteriori}\label{chapter-ppc}}

Oltre ad una sintesi della distribuzione a posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell'analisi bayesiana è la predizione di nuovi dati futuri. Dopo aver osservato i dati di un campione e ottenuto le distribuzioni a posteriori dei parametri, è infatti possibile ottenere una qualche indicazione su come potrebbero essere i dati futuri. L'uso più immediato della stima della distribuzione dei possibili valori futuri della variabile di esito è la verifica del modello. Infatti, il modo più diretto per testare un modello è quello di utilizzare il modello per fare previsioni sui possibili dati futuri per poi confrontare i dati predetti con i dati effettivi. Questa pratica va sotto il nome di controllo predittivo a posteriori.

\hypertarget{la-distribuzione-dei-possibili-valori-futuri}{%
\section{La distribuzione dei possibili valori futuri}\label{la-distribuzione-dei-possibili-valori-futuri}}

La distribuzione dei possibili valori futuri della variabile di esito può essere predetta da un modello statistico sulla base della distribuzione a posteriori dei parametri, \(p(\theta \mid y)\), avendo già osservato \(n\) manifestazioni del fenomeno \(y\). Una tale distribuzione va sotto il nome di \emph{distribuzione predittiva a posteriori} (\emph{posterior predictive distribution}, PPD).

Quando vengono simulate le osservazioni della distribuzione predittiva a posteriori si usa la notazione \(y^{rep}\) (dove \(rep\) sta per \emph{replica}) quando, nella simulazione, vengono utilizzate le stesse osservazioni di \(X\) che erano state usate per stimare i parametri del modello. Si usa invece la notazione \(\tilde{y}\) per fare riferimento a possibili valori \(X\) che non sono contenuti nel campione osservato, ovvero, ad un campione di dati che potrebbe essere osservato in qualche futura occasione.

La distribuzione predittiva a posteriori viene usata per fare inferenze predittive. L'idea è che, se il modello ben si adatta bene ai dati del campione allora, sulla base dei parametri stimati, dovremmo essere in grado di generare nuovi dati non osservati \(y^{rep}\) che risultano molto simili ai dati osservati \(y\). I dati \(y^{rep}\) vengono concepiti come stime di \(\tilde{y}\). La distribuzione predittiva a posteriorie è data da:

\begin{equation}
p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y}, \theta \mid y) d \theta = \int_{\theta} p(\tilde{y} \mid \theta, y) p(\theta \mid y) d\theta.\notag
\end{equation}

Supponendo che le osservazioni passate e future siano condizionalmente indipendenti dato \(\theta\), ovvero che \(p(\tilde{y} \mid \theta, y) = p(\tilde{y} \mid \theta)\), possiamo scrivere

\begin{equation}
p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y} \mid \theta) p(\theta \mid y) d\theta.
\label{eq:dist-pred-post}
\end{equation}

La \eqref{eq:dist-pred-post} descrive la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di \(\theta\), ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati. Si noti che, nella \eqref{eq:dist-pred-post}, \(\tilde{y}\) è condizionato da \(y\) ma non da ciò che è incognito, ovvero \(\theta\). La distribuzione predittiva a posteriori è invece ottenuta mediante marginalizzazione sopra le variabili da ``scartare'', ovvero sopra i parametri incogniti \(\theta\).

Un esempio formulato mediante il codice Stan può chiarire questo concetto. Consideriamo il codice relativo alla distribuzione predittiva a posteriori nel caso di un modello di regressione lineare classico con un solo predittore \(x\). Il blocco \emph{Model} sarà:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model \{}
\NormalTok{ y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{normal}\NormalTok{(x }\SpecialCharTok{*}\NormalTok{ beta }\SpecialCharTok{+}\NormalTok{ alpha, sigma);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Quello che è di interesse per la discussione presente è il blocco \emph{Generated Quantities}. Tale blocco avrà questa forma:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{generated quantities \{}
\NormalTok{ real y\_rep[N];}
 \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{N) \{}
\NormalTok{   y\_rep[n] }\OtherTok{=} \FunctionTok{normal\_rng}\NormalTok{(x[n] }\SpecialCharTok{*}\NormalTok{ beta }\SpecialCharTok{+}\NormalTok{ alpha, sigma);}
\NormalTok{ \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

La variabile \texttt{y\_rep} è ciò a cui siamo interessati. Nel codice precedente, \texttt{x} è il vettore che contiene i valori della variabile indipendente nel campione di osservazioni esaminato. I parametri del modello di regressione sono \texttt{alpha} e \texttt{beta}; \texttt{sigma} è la stima dell'errore standard della regressione. Supponiamo che questi tre parametri siano degli scalari. Se lo fossero, per il valore \texttt{x} \(n\)-esimo, l'istruzione \texttt{normal\_rng()} ritornerebbe un valore a caso dalla distribuzione normale con media \(\alpha + \beta x_n\) e deviazione standard \(\sigma\). Il ciclo \texttt{for()} ripete questa operazione \(N\) volte, ovvero tante volte quanti sono gli elementi del vettore \texttt{x} del campione. Quello che è stato detto sopra ci dà un'idea di quello che succederebbe se \texttt{alpha}, \texttt{beta} e \texttt{sigma} fossero degli scalari. Ma non lo sono. Per ciascuno dei tre paramatri abbiamo un numero molto alto di stime, ovvero l'approssimazione MCMC della distribuzione a posteriori. Poniamo che l'ampiezza campionaria \(N\) sia 30. Se \texttt{alpha}, \texttt{beta} e \texttt{sigma} fossero degli scalari, la distribuzione predittiva a posteriori sarebbe costituita da 30 valori \(y^{rep}\), ovvero, non sarebbe nient'altro che \(\hat{y} = \hat{\alpha} + \hat{\beta} x\). Ma \texttt{alpha}, \texttt{beta} e \texttt{sigma} non sono degli scalari: per ciascuno di questi parametri abbiamo un grande numero di stime, diciamo 2000. Dunque, quando \texttt{normal\_rng()} estrae un valore a caso dalla distribuzione normale, i parametri della normale non sono fissi: per determinare \(\mu\) prendiamo un valore a caso, chiamiamolo \texttt{beta\textquotesingle{}}, dalla distribuzione dei valori \texttt{beta} e un valore a caso, chiamiamolo \texttt{alpha\textquotesingle{}}, dalla distribuzione dei valori \texttt{alpha}. Avendo questi due valori, calcoliamo il valore \(\mu'_n = \alpha' + \beta' x_n\). Lo stesso si può dire per \(\sigma'\). A questo punto possiamo trovare il valore \texttt{y\_n\textquotesingle{}} estraendo un valore a caso dalla distribuzione gaussiana di parametri \(\mu'\) e \(\sigma'\). Per l'\(n\)-esimo valore \(x\) possiamo ripetere questo processo tante volte. Se lo ripetiamo, ad esempio, 2,000 volte, per tutti e 30 i valori \(x\) del campione otterremo una matrice \(30 \times 2,000\). In questo modo possiamo generare le previsioni del modello, ovvero \(y^{rep}\), che includono due fonti di incertezza:

\begin{itemize}
\tightlist
\item
  la variabilità campionaria, ovvero il fatto che abbiamo osservato uno specifico insieme di valori \((x, y)\); in un altro campione tali valori saranno diversi;
\item
  la variabilità a posteriori della distribuzione dei parametri, ovvero il fatto che di ciascun parametro non conosciamo il ``valore vero'' ma solo una distribuzione (a posteriori) di valori.
\end{itemize}

Nel caso dell'esempio presente, l'integrale della \eqref{eq:dist-pred-post} può essere interpretato dicendo che, nell'esempio della matrice di dimensioni \(30 \times 2,000\), noi marginalizziamo rispetto alle colonne, ovvero, per ciascuna riga facciamo la media dei valori colonna. Otteniamo così un vettore di 30 osservazioni, ovvero \(y^{rep}\).

Quando, con metodi grafici, vengono esaminati i valori della distribuzione predittiva a posteriori, possiamo esaminare un numero arbitrario di previsioni. Per esempio, possiamo rappresentare graficamente 50 rette di regressione predette -- o un qualsiasi altro numero. Questa rappresentazione grafica quantifica la nostra incertezza a posteriori relativamente (in questo esempio) all'orientamento della retta di regressione.

\begin{exercise}
Illustreremo ora il problema di trovare la distribuzione \(p(\tilde{y} \mid y)\) in un caso semplice, ovvero quello dello schema Beta-Binomiale. Nell'esempio, useremo un'altra volta i dati del campione di pazienti clinici depressi di \citet{zetschefuture2019} -- si veda l'Appendice \ref{es-pratico-zetsche}. Supponendo di volere esaminare in futuro altri 30 pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?

Se vogliamo fare predizioni su \(\tilde{y}\) (il numero di ``successi'' previsti futuri) dobbiamo innanzitutto riconoscere che i possibili valori \(\tilde{y} \in \{0, 1, \dots, 30\}\) non sono tutti egualmente plausibili. Sappiamo che \(\tilde{y}\) è una v.c. binomiale con distribuzione

\begin{equation}
p(\tilde{y}\mid \theta) = \binom{30}{\tilde{y}} \theta^{\tilde{y}}(1-\theta)^{30 - \tilde{y}} \; .
\label{eq:post-yprime}
\end{equation}

La v.c. \(\tilde{y}\) dipende da \(\theta\), ma il parametro \(\theta\) è esso stesso una variabile casuale. Avendo osservato \(y = 23\) successi in \(n = 30\) prove nel campione (laddove la presenza di una depressione grave è stata considerata un ``successo''), e avendo assunto come distribuzione a priori per \(\theta\) una \(\mbox{Beta}(2, 10)\) (per continuare con l'esempio precedente), la distribuzione a posteriori di \(\theta\) sarà una \(\mbox{Beta}(25, 17)\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{::}\FunctionTok{summarize\_beta\_binomial}\NormalTok{(}
  \AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{, }\AttributeTok{y =} \DecValTok{23}\NormalTok{, }\AttributeTok{n =} \DecValTok{30}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model alpha beta   mean mode      var      sd}
\CommentTok{\#\textgreater{} 1     prior     2   10 0.1667  0.1 0.010684 0.10336}
\CommentTok{\#\textgreater{} 2 posterior    25   17 0.5952  0.6 0.005603 0.07485}
\end{Highlighting}
\end{Shaded}

Per trovare la distribuzione sui possibili dati previsti futuri \(\tilde{y}\) dobbiamo applicare la \eqref{eq:dist-pred-post}:

\begin{align}
p(\tilde{y} \mid y = 23) = \int_0^1 p(\tilde{y} \mid \theta) p(\theta \mid y = 23) d\theta \; .
\label{eq:post-yprime-y17}
\end{align}

Per il modello Beta-Binomiale è possibile trovare una soluzione analitica alla \eqref{eq:dist-pred-post}.

Poniamo di avere osservato \(y\) successi in \(n\) prove e di utilizzare una distribuzione a priori \(\mbox{Beta}(a, b)\). Possiamo scrivere

\begin{align}
p(\tilde{y} \mid y) &= \int_0^1 p(\tilde{y} \mid \theta)
p(\theta \mid y)\, d\theta \notag\\
 &= \int_0^1 \begin{pmatrix}\tilde{n}\\\tilde{y}\end{pmatrix}
 \theta^{\tilde{y}}
(1-\theta)^{\tilde{n}-\tilde{y}} \mbox{Beta}(a+y,b+n-y) \, d\theta \notag\\
&= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \int_0^1 \theta^{\tilde{y}}
(1-\theta)^{\tilde{n}-\tilde{y}} \frac{1}{B(a+y, b+n-y)}\theta^{a+y-1}(1-\theta)^{b+n-y-1}\notag\\
&= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \frac{1}{B(a+y, b+n-y)}\int_0^1 \theta^{\tilde{y}+a+y-1}(1-\theta)^{\tilde{n}-\tilde{y}+b+n-y-1}\notag\\
&= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \frac{B(\tilde{y}+a+y,b+n-y+\tilde{n}-\tilde{y})}{B(a+y, b+n-y)} \; .
\label{eq:post-yprime-an-sol-betabin}
\end{align}

Svolgendo i calcoli in \(\R\), per i dati dell'esempio otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta\_binom }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(rp) \{}
\NormalTok{  val }\OtherTok{\textless{}{-}} \FunctionTok{choose}\NormalTok{(np, rp) }\SpecialCharTok{*}
    \FunctionTok{beta}\NormalTok{(rp }\SpecialCharTok{+}\NormalTok{ a }\SpecialCharTok{+}\NormalTok{ y, b }\SpecialCharTok{+}\NormalTok{ n }\SpecialCharTok{{-}}\NormalTok{ y }\SpecialCharTok{+}\NormalTok{ np }\SpecialCharTok{{-}}\NormalTok{ rp) }\SpecialCharTok{/}
    \FunctionTok{beta}\NormalTok{(a }\SpecialCharTok{+}\NormalTok{ y, b }\SpecialCharTok{+}\NormalTok{ n }\SpecialCharTok{{-}}\NormalTok{ y)}
\NormalTok{  val}
\NormalTok{\}}

\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{30}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{23}
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{b }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{np }\OtherTok{\textless{}{-}} \DecValTok{30}
\FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{heads =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{np,}
  \AttributeTok{pmf =} \FunctionTok{beta\_binom}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\NormalTok{np)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(heads), }\AttributeTok{y =}\NormalTok{ pmf)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Distribuzione predittiva a posteriori"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"y\textquotesingle{}"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"P(Y = y\textquotesingle{} | Data)"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-174-1} \end{center}

\noindent È facile vedere come, in questo esempio, la distribuzione predittiva a posteriori \(p(\tilde{y} \mid y)\) sia diversa dalla binomiale di parametro \(\theta = 23/30\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{heads =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{np,}
  \AttributeTok{pmf =} \FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =} \DecValTok{0}\SpecialCharTok{:}\NormalTok{np, }\AttributeTok{size =}\NormalTok{ np, }\AttributeTok{prob =} \DecValTok{23} \SpecialCharTok{/} \DecValTok{30}\NormalTok{)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(heads), }\AttributeTok{y =}\NormalTok{ pmf)) }\SpecialCharTok{+}
  \FunctionTok{geom\_col}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"p(y | theta = 0.77)"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"y"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Probabilità"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-175-1} \end{center}

\noindent In particolare, la \(p(\tilde{y} \mid y)\) ha una varianza maggiore di \(\Bin(y \mid \theta = 0.77, n = 30)\). Questa maggiore varianza riflette le due fonti di incertezza che sono presenti nella \eqref{eq:dist-pred-post}: l'incertezza sul valore del parametro (descritta dalla distribuzione a posteriori) e l'incertezza dovuta alla variabilità campionaria (descritta dalla funzione di verosimiglianza). Possiamo concludere la discussione di questo esempio dicendo che, nel caso di 30 nuovi pazienti clinici, alla luce delle nostre credenze precedenti e dei dati osservati nel campione, ci aspettiamo di osservare 18 pazienti con una depressione severa, anche se è ragionevole aspettarci un numero compreso, diciamo, tra 10 e 25.

Una volta trovata la distribuzione predittiva a posteriori \(p(\tilde{y} \mid y)\) diventa possibile rispondere a domande come: qual è la probabilità di depressione grave in almeno 10 dei 30 pazienti futuri? Rispondere a domande di questo tipo è possibile, ma richiede un po' di lavoro. Tuttavia, non è importante imparare scrivere il codice necessario a risolvere problemi di questo tipo perché, in generale, anche per problemi solo leggermente più complessi di quello discusso qui, non sono disponibili espressioni analitiche della distribuzione predittiva a posteriori. Invece, è possibile trovare una approssimazione numerica della \(p(\tilde{y} \mid y)\) mediante simulazioni MCMC. Inoltre, se viene utilizzato un tale metodo, risulta facile rispondere a domande simili a quella che abbiamo presentato sopra.
\end{exercise}

\hypertarget{metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori}{%
\section{Metodi MCMC per la distribuzione predittiva a posteriori}\label{metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori}}

Se svolgiamo l'analisi bayesiana con il metodo MCMC, le repliche \(p(y^{rep} \mid y)\) (ovvero le stime delle possibili osservazioni future \(p(\tilde{y} \mid y)\)) possono essere ottenute nel modo seguente:

\begin{itemize}
\tightlist
\item
  campionare \(\theta_i \sim p(\theta \mid y)\), ovvero campionare un valore del parametro dalla distribuzione a posteriori;
\item
  campionare \(y^{rep} \sim p(y^{rep} \mid \theta_i)\), ovvero campionare il valore di un'osservazione dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente.
\end{itemize}

\noindent Se i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l'istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria (ma non in pratica) potrebbe essere ottenuta per via analitica (si veda il Paragrafo \ref{schema-beta-bin-distr-pred-post}).

\begin{exercise}

Generiamo ora \(p(y^{rep} \mid y)\) nel caso dell'inferenza su una proporzione.

Riportiamo qui sotto il codice Stan --- si veda il Capitolo \ref{mod-binom}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  int\textless{}lower=0, upper=1\textgreater{} y[N];}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real\textless{}lower=0, upper=1\textgreater{} theta;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  theta \textasciitilde{} beta(2, 10);}
\StringTok{  y \textasciitilde{} bernoulli(theta);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  int y\_rep[N];}
\StringTok{  real log\_lik[N];}
\StringTok{  for (n in 1:N) \{}
\StringTok{    y\_rep[n] = bernoulli\_rng(theta);}
\StringTok{    log\_lik[n] = bernoulli\_lpmf(y[n] | theta);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/betabin23{-}30{-}2{-}10.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\noindent Si noti che nel nel blocco \texttt{generated\ quantities} sono state aggiunte le istruzioni necessarie per simulare \(y^{rep}\), ovvero, \texttt{y\_rep{[}n{]}\ =\ bernoulli\_rng(theta)}. I dati dell'esempio sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \DecValTok{30}\NormalTok{,}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{23}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\noindent Compiliamo il codice Stan

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"betabin23{-}30{-}2{-}10.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\noindent ed eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\noindent Per comodità, trasformiamo l'oggetto \texttt{fit} in un oggetto di classe \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\noindent Il contenuto dell'oggetto \texttt{stanfit} può essere esaminato nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list\_of\_draws }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(stanfit)}
\FunctionTok{print}\NormalTok{(}\FunctionTok{names}\NormalTok{(list\_of\_draws))}
\CommentTok{\#\textgreater{} [1] "theta"   "y\_rep"   "log\_lik" "lp\_\_"}
\end{Highlighting}
\end{Shaded}

\noindent Dall'oggetto \texttt{list\_of\_draws} recuperiamo \texttt{y\_rep}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_bern }\OtherTok{\textless{}{-}}\NormalTok{ list\_of\_draws}\SpecialCharTok{$}\NormalTok{y\_rep}
\FunctionTok{dim}\NormalTok{(y\_bern)}
\CommentTok{\#\textgreater{} [1] 16000    30}
\FunctionTok{head}\NormalTok{(y\_bern)}
\CommentTok{\#\textgreater{}           }
\CommentTok{\#\textgreater{} iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8]}
\CommentTok{\#\textgreater{}       [1,]    1    1    0    0    1    0    1    0}
\CommentTok{\#\textgreater{}       [2,]    0    1    0    1    0    1    1    0}
\CommentTok{\#\textgreater{}       [3,]    1    1    0    0    1    1    1    1}
\CommentTok{\#\textgreater{}       [4,]    1    0    1    1    0    1    0    1}
\CommentTok{\#\textgreater{}       [5,]    1    1    0    1    1    1    0    1}
\CommentTok{\#\textgreater{}       [6,]    1    0    1    1    1    0    0    1}
\CommentTok{\#\textgreater{}           }
\CommentTok{\#\textgreater{} iterations [,9] [,10] [,11] [,12] [,13] [,14] [,15]}
\CommentTok{\#\textgreater{}       [1,]    0     0     1     0     1     1     1}
\CommentTok{\#\textgreater{}       [2,]    1     0     1     1     1     1     1}
\CommentTok{\#\textgreater{}       [3,]    1     1     1     0     0     1     1}
\CommentTok{\#\textgreater{}       [4,]    1     1     1     1     1     1     0}
\CommentTok{\#\textgreater{}       [5,]    1     0     1     0     1     1     1}
\CommentTok{\#\textgreater{}       [6,]    1     1     1     1     1     1     1}
\CommentTok{\#\textgreater{}           }
\CommentTok{\#\textgreater{} iterations [,16] [,17] [,18] [,19] [,20] [,21] [,22]}
\CommentTok{\#\textgreater{}       [1,]     1     1     0     0     0     0     1}
\CommentTok{\#\textgreater{}       [2,]     1     1     0     0     0     1     1}
\CommentTok{\#\textgreater{}       [3,]     0     0     1     1     1     1     1}
\CommentTok{\#\textgreater{}       [4,]     1     0     1     0     0     0     0}
\CommentTok{\#\textgreater{}       [5,]     0     1     1     1     1     0     1}
\CommentTok{\#\textgreater{}       [6,]     1     0     1     1     0     0     0}
\CommentTok{\#\textgreater{}           }
\CommentTok{\#\textgreater{} iterations [,23] [,24] [,25] [,26] [,27] [,28] [,29]}
\CommentTok{\#\textgreater{}       [1,]     0     1     1     0     1     0     1}
\CommentTok{\#\textgreater{}       [2,]     1     1     0     1     0     0     1}
\CommentTok{\#\textgreater{}       [3,]     1     1     1     0     1     0     1}
\CommentTok{\#\textgreater{}       [4,]     1     0     1     1     0     1     0}
\CommentTok{\#\textgreater{}       [5,]     0     1     1     1     1     1     1}
\CommentTok{\#\textgreater{}       [6,]     1     0     1     1     1     0     1}
\CommentTok{\#\textgreater{}           }
\CommentTok{\#\textgreater{} iterations [,30]}
\CommentTok{\#\textgreater{}       [1,]     1}
\CommentTok{\#\textgreater{}       [2,]     1}
\CommentTok{\#\textgreater{}       [3,]     1}
\CommentTok{\#\textgreater{}       [4,]     1}
\CommentTok{\#\textgreater{}       [5,]     0}
\CommentTok{\#\textgreater{}       [6,]     1}
\end{Highlighting}
\end{Shaded}

Dato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga di \texttt{y\_bern} include 30 colonne, ciascuna delle quali corrisponde ad un campione (\(n\) = 16000 in questa simulazione) di possibili valori futuri \(y_i \in \{0, 1\}\). Per ottenere una stima della distribuzione predittiva a posteriori \texttt{p(y\_rep)}, ovvero, una stima della probabilità associata a ciascuno dei possibili numeri di ``successi'' in \(N = 30\) nuove prove future, è sufficiente calcolare la proporzione di valori 1 in ciascuna riga:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{y\_rep =} \FunctionTok{rowSums}\NormalTok{(y\_bern)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ y\_rep, }\FunctionTok{after\_stat}\NormalTok{(density))) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-183-1} \end{center}

\end{exercise}

\hypertarget{posterior-predictive-checks}{%
\section{Posterior predictive checks}\label{posterior-predictive-checks}}

La distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti \emph{controlli predittivi a posteriori} (\emph{Posterior Predictive Checks}, PPC). Ricordiamo che la distribuzione predittiva a posteriori corrisponde alla simulazione di un campione di dati generati utilizzando le proprietà del modello adattato. Nei PPC si realizza un confronto grafico tra \(p(y^{rep} \mid y)\) e i dati osservati \(y\). Confrontando visivamente gli aspetti chiave dei dati previsti futuri \(y^{rep}\) e dei dati osservati \(y\) possiamo determinare se il modello è adeguato.

Oltre al confronto tra le distribuzioni \(p(y)\) e \(p(y^{rep})\) è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni \(y^{rep}\), e le corrispondenti statistiche descrittive calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo. Ma confronti di questo tipo sono possibili per qualunque statistica descrittiva. Questi confronti sono chiamati PPC.

\begin{exercise}
Esaminiamo ora un set di dati che non seguono la distribuzione normale \citep{gelman2020regression}. I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. A questi dati verrà (inappropriatamente) adattata una distribuzione normale. L'obiettivo dell'esempio è quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati.

I PPC mostrano che il modo più semplice per verificare l'adattamento del modello è quello di visualizzare \(y^{rep}\) insieme ai dati effettivi. Iniziamo a caricare i dati:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"MASS"}\NormalTok{)}
\FunctionTok{data}\NormalTok{(}\StringTok{"newcomb"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Visualizziamo la distribuzione dei dati con un istogramma:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(newcomb) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ newcomb, }\FunctionTok{after\_stat}\NormalTok{(density))) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-185-1} \end{center}

Creiamo un oggetto di tipo \texttt{list} dove inserire i dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{y =}\NormalTok{ newcomb,}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(newcomb)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il codice Stan per il modello normale è il seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real mu;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  mu \textasciitilde{} normal(25, 10);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 10);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  for (n in 1:N) \{}
\StringTok{    y\_rep[n] = normal\_rng(mu, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/newcomb.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattando il modello ai dati

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"newcomb.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

otteniamo le seguenti stime dei parametri \(\mu\) e \(\sigma\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"mu"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 10}
\CommentTok{\#\textgreater{}   variable  mean median    sd   mad    q5   q95  rhat}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 mu        26.2   26.2 1.33  1.30  24.0   28.4  1.00}
\CommentTok{\#\textgreater{} 2 sigma     10.9   10.8 0.958 0.943  9.40  12.5  1.00}
\CommentTok{\#\textgreater{} \# ... with 2 more variables: ess\_bulk \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

Trasformiamo \texttt{fit} in un oggetto \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

La distribuzione a posteriori di \(\mu\) è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu\_draws }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(stanfit, }\AttributeTok{pars =} \StringTok{"mu"}\NormalTok{)}
\FunctionTok{mcmc\_areas}\NormalTok{(mu\_draws, }\AttributeTok{prob =} \FloatTok{0.95}\NormalTok{) }\CommentTok{\# color 95\% interval}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-191-1} \end{center}

Confrontiamo \(\mu\) con la media di \(y\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(newcomb)}
\CommentTok{\#\textgreater{} [1] 26.21}
\end{Highlighting}
\end{Shaded}

Anche se trova la media giusta, il modello non è comunque adeguato a prevedere le altre proprietà della \(y\). Estraiamo \(y^{rep}\) dall'oggetto \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_rep }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(stanfit, }\AttributeTok{pars =} \StringTok{"y\_rep"}\NormalTok{)}
\FunctionTok{dim}\NormalTok{(y\_rep)}
\CommentTok{\#\textgreater{} [1] 16000    66}
\end{Highlighting}
\end{Shaded}

I valori \texttt{y\_rep} sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori \(X\) dei predittori utilizzati per adattare il modello. Il confronto tra l'istogramma della \(y\) e gli istogrammi di diversi campioni \(y^{rep}\) mostra una scarsa corrispondenza tra i due:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppc\_hist}\NormalTok{(data\_list}\SpecialCharTok{$}\NormalTok{y, y\_rep[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{, ], }\AttributeTok{binwidth =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-194-1} \end{center}

Alla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della \(y\) e quella di diversi campioni \(y^{rep}\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppc\_dens\_overlay}\NormalTok{(data\_list}\SpecialCharTok{$}\NormalTok{y, y\_rep[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{50}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-195-1} \end{center}

Generiamo ora i PPC per la media e il minimo della distribuzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppc\_stat\_2d}\NormalTok{(data\_list}\SpecialCharTok{$}\NormalTok{y, y\_rep, }\AttributeTok{stat =} \FunctionTok{c}\NormalTok{(}\StringTok{"mean"}\NormalTok{, }\StringTok{"min"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-196-1} \end{center}

Mentre la media viene riprodotta accuratamente dal modello (come abbiamo visto sopra), ciò non è vero per il minimo dela distribuzione. L'origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa. Dato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione \(t\) di Student:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real mu;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{  real\textless{}lower=0\textgreater{} nu;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  mu \textasciitilde{} normal(25, 10);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 10);}
\StringTok{  nu \textasciitilde{} cauchy(0, 10);}
\StringTok{  y \textasciitilde{} student\_t(nu, mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  for (n in 1:N) \{}
\StringTok{    y\_rep[n] = student\_t\_rng(nu, mu, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/newcomb2.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo questo secondo modello ai dati.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"newcomb2.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\CommentTok{\#\textgreater{} Running MCMC with 4 parallel chains...}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Chain 1 finished in 0.4 seconds.}
\CommentTok{\#\textgreater{} Chain 2 finished in 0.4 seconds.}
\CommentTok{\#\textgreater{} Chain 3 finished in 0.4 seconds.}
\CommentTok{\#\textgreater{} Chain 4 finished in 0.4 seconds.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All 4 chains finished successfully.}
\CommentTok{\#\textgreater{} Mean chain execution time: 0.4 seconds.}
\CommentTok{\#\textgreater{} Total execution time: 0.6 seconds.}
\end{Highlighting}
\end{Shaded}

Per questo secondo modello il confronto tra la funzione di densità empirica della \(y\) e quella di diversi campioni \(y^{rep}\) risulta adeguato:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\NormalTok{y\_rep }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(stanfit, }\AttributeTok{pars =} \StringTok{"y\_rep"}\NormalTok{)}
\FunctionTok{ppc\_dens\_overlay}\NormalTok{(data\_list}\SpecialCharTok{$}\NormalTok{y, y\_rep[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{50}\NormalTok{, ])}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-199-1} \end{center}

Inoltre, anche la statistica ``minimo della distribuzione'' viene ben predetta dal modello.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ppc\_stat\_2d}\NormalTok{(data\_list}\SpecialCharTok{$}\NormalTok{y, y\_rep, }\AttributeTok{stat =} \FunctionTok{c}\NormalTok{(}\StringTok{"mean"}\NormalTok{, }\StringTok{"min"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-200-1} \end{center}

In conclusione, per le misurazioni della velocità della luce di Newcomb l'accuratezza predittiva del modello basato sulla distribuzione \(t\) di Student è chiaramente migliore di quella del modello normale.
\end{exercise}

\hypertarget{commenti-e-considerazioni-finali-14}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-14}}


Questo capitolo presenta i controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: i controlli predittivi a posteriori, quando suggeriscono un buon adattamento del modello alle caratterische dei dati previsti futuri \(y^{rep}\), non forniscono necessariamente una forte evidenza della capacità del modello di generalizzarsi a nuovi campioni di dati. Una tale evidenza sulla generalizzabilità del modello può solo essere fornita da studi di \emph{holdout validation}, ovvero da studi nei quali viene utilizzato un \emph{nuovo} campione di dati. Se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, però, questo controllo fornisce una forte evidenza di una errata specificazione del modello.

\hypertarget{normal-normal-mod-stan}{%
\chapter{Modello Normale-Normale}\label{normal-normal-mod-stan}}

\hypertarget{distribuzione-normale-normale-con-varianza-nota}{%
\section{Distribuzione Normale-Normale con varianza nota}\label{distribuzione-normale-normale-con-varianza-nota}}

Per \(\sigma^2\) nota, la v.c. gaussiana è distribuzione a priori coniugata della v.c. gaussiana. Siano \(Y_1, \dots, Y_n\) \(n\) variabili casuali i.i.d. che seguono la distribuzione gaussiana:

\[
Y_1, \dots, Y_n  \stackrel{iid}{\sim} \mathcal{N}(\mu, \sigma).
\]

Si vuole stimare \(\mu\) sulla base di \(n\) osservazioni \(y_1, \dots, y_n\). Considereremo qui solamente il caso in cui \(\sigma^2\) sia supposta perfettamente nota.

Ricordiamo che la densità di una gaussiana è

\[
p(y_i \mid \mu, \sigma) = \frac{1}{{\sigma \sqrt {2\pi}}}\exp\left\{{-\frac{(y_i - \mu)^2}{2\sigma^2}}\right\}.
\]

Essendo le variabili i.i.d., possiamo scrivere la densità congiunta come il prodotto delle singole densità e quindi si ottiene

\[
p(y \mid \mu) = \, \prod_{i=1}^n p(y_i \mid \mu).
\]

Una volta osservati i dati \(y\), la verosimiglianza diventa

\begin{align}
\mathcal{L}(\mu \mid y) =& \, \prod_{i=1}^n p(y_i \mid \mu) = \notag\\
& \frac{1}{{\sigma \sqrt {2\pi}}}\exp\left\{{-\frac{(y_1 - \mu)^2}{2\sigma^2}}\right\} \times \notag\\
 & \frac{1}{{\sigma \sqrt {2\pi}}}\exp\left\{{-\frac{(y_2 - \mu)^2}{2\sigma^2}}\right\} \times  \notag\\
& \vdots \notag\\
 & \frac{1}{{\sigma \sqrt {2\pi}}}\exp\left\{{-\frac{(y_n - \mu)^2}{2\sigma^2}}\right\}.
\end{align}

Se viene scelta una densità a priori gaussiana, ciò fa sì che anche la densità a posteriori sia gaussiana. Supponiamo che

\begin{equation}
p(\mu) = \frac{1}{{\tau_0 \sqrt {2\pi}}}\exp\left\{{-\frac{(\mu - \mu_0)^2}{2\tau_0^2}}\right\},
\label{eq:prior-mu-norm-norm}
\end{equation}

ovvero che la distribuzione a priori di \(\mu\) sia gaussiana con media \(\mu_0\) e varianza \(\tau_0^2\). Possiamo dire che \(\mu_0\) rappresenta il valore ritenuto più probabile per \(\mu\) e \(\tau_0^2\) il grado di incertezza che abbiamo rispetto a tale valore.

Svolgendo una serie di passaggi algebrici, si arriva a

\begin{equation}
p(\mu \mid y) = \frac{1}{{\tau_p \sqrt {2\pi}}}\exp\left\{{-\frac{(\mu - \mu_p)^2}{2\tau_p^2}}\right\},
\label{eq:post-norm-norm}
\end{equation}

dove

\begin{equation}
\mu_p = \frac{\frac{1}{\tau_0^2}\mu_0+ \frac{n}{\sigma^2}\bar{y}}{\frac {1}{\tau_0^2} + \frac{n}{\sigma^2}} 
\label{eq:post-norm-mup}
\end{equation}

e

\begin{equation}
\tau_p^2 = \frac{1}{\frac {1}{\tau_0^2}+ \frac{n}{\sigma^2}}.
\label{eq:post-norm-taup2}
\end{equation}

In altri termini, se la distribuzione a priori per \(\mu\) è gaussiana, la distribuzione a posteriori è anch'essa gaussiana con valore atteso (a posteriori) \(\mu_p\) e varianza (a posteriori) \(\tau_p^2\) date dalle espressioni precedenti.

In conclusione, il risultato trovato indica che:

\begin{itemize}
\tightlist
\item
  il valore atteso a posteriori è una media pesata fra il valore atteso a priori \(\mu_0\) e la media campionaria \(\bar{y}\); il peso della media campionaria è tanto maggiore tanto più è grande \(n\) (il numero di osservazioni) e \(\tau_0^2\) (l'incertezza iniziale);
\item
  l'incertezza (varianza) a posteriori \(\tau_p^2\) è sempre più piccola dell'incertezza a priori \(\tau_0^2\) e diminuisce al crescere di \(n\).
\end{itemize}

\hypertarget{il-modello-normale-con-stan}{%
\section{Il modello Normale con Stan}\label{il-modello-normale-con-stan}}

Per esaminare un esempio pratico, consideriamo i 30 valori BDI-II dei soggetti clinici di \citet{zetschefuture2019}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}
    \FloatTok{26.0}\NormalTok{, }\FloatTok{35.0}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{44}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{43}\NormalTok{,}
    \DecValTok{24}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{39}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{41}\NormalTok{,}
    \DecValTok{36}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{34}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{22}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Calcoliamo le statistiche descrittive del campione di dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{sample\_mean =} \FunctionTok{mean}\NormalTok{(y),}
    \AttributeTok{sample\_sd =} \FunctionTok{sd}\NormalTok{(y)}
\NormalTok{  )}
\CommentTok{\#\textgreater{}   sample\_mean sample\_sd}
\CommentTok{\#\textgreater{} 1       30.93     6.607}
\end{Highlighting}
\end{Shaded}

Nella discussione seguente assumeremo che \(\mu\) e \(\sigma\) siano indipendenti. Assegneremo a \(\mu\) una distribuzione a priori \(\mathcal{N}(25, 2)\) e a \(\sigma\) una distribuzione a priori \(Cauchy(0, 3)\).

Il modello statistico diventa:

\begin{align}
Y_i &\sim \mathcal{N}(\mu, \sigma) \notag\\
\mu &\sim \mathcal{N}(\mu_{\mu} = 25, \sigma_{\mu} = 2) \notag\\
\sigma &\sim \Cauchy(0, 3) \notag
\end{align}

In base al modello definito, la variabile casuale \(Y\) segue la distribuzione Normale di parametri \(\mu\) e \(\sigma\). Il parametro \(\mu\) è sconosciuto e abbiamo deciso di descrivere la nostra incertezza relativa ad esso mediante una distribuzione a priori Normale con media uguale a 25 e deviazione standard pari a 2. L'incertezza relativa a \(\sigma\) è quantificata da una distribuzione a priori half-Cauchy(0, 5), come indicato nella figura seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{20}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}
    \AttributeTok{fun =}\NormalTok{ dcauchy,}
    \AttributeTok{n =} \FloatTok{1e3}\NormalTok{,}
    \AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\AttributeTok{location =} \DecValTok{0}\NormalTok{, }\AttributeTok{scale =} \DecValTok{3}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"P(x)"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-203-1} \end{center}

Dato che il modello è Normale-Normale, è possibile una soluzione analitica, come descritto in precedenza per il caso in cui \(\sigma\) è noto. In tali condizioni, la distribuzione a posteriori per \(\mu\) può essere trovata con la funzione \texttt{bayesrules:::summarize\_normal\_normal()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{summarize\_normal\_normal}\NormalTok{(}
  \AttributeTok{mean =} \DecValTok{25}\NormalTok{, }
  \AttributeTok{sd =} \DecValTok{2}\NormalTok{, }
  \AttributeTok{sigma =} \FunctionTok{sd}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{y),}
  \AttributeTok{y\_bar =} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{y), }
  \AttributeTok{n =} \DecValTok{30}
\NormalTok{)}
\CommentTok{\#\textgreater{}       model  mean  mode   var    sd}
\CommentTok{\#\textgreater{} 1     prior 25.00 25.00 4.000 2.000}
\CommentTok{\#\textgreater{} 2 posterior 29.35 29.35 1.067 1.033}
\end{Highlighting}
\end{Shaded}

La rappresentazione grafica della funzione a priori, della verosimiglianza e della distribuzione a posteriori per \(\mu\) è fornita da:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{bayesrules}\SpecialCharTok{:::}\FunctionTok{plot\_normal\_normal}\NormalTok{(}
  \AttributeTok{mean =} \DecValTok{25}\NormalTok{, }
  \AttributeTok{sd =} \DecValTok{2}\NormalTok{, }
  \AttributeTok{sigma =} \FunctionTok{sd}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{y), }
  \AttributeTok{y\_bar =} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{y), }
  \AttributeTok{n =} \DecValTok{30}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-205-1} \end{center}

La procedura MCMC utilizzata da Stan è basata su un campionamento Monte Carlo Hamiltoniano che non richiede l'uso di distribuzioni a priori coniugate. Pertanto per i parametri è possibile scegliere una qualunque distribuzione a priori arbitraria.

Per continuare con l'esempio, poniamoci il problema di trovare le distribuzioni a posteriori dei parametri \(\mu\) e \(\sigma\) usando le funzioni del pacchetto \texttt{cmdstanr}. Il modello statistico descritto sopra si può scrivere in Stan nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real mu;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  mu \textasciitilde{} normal(25, 2);}
\StringTok{  sigma \textasciitilde{} normal(0, 5);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/normalmodel.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si noti che, nel modello, il parametro \(\sigma\) è considerato incognito.

Sistemiamo i dati nel formato appropriato per potere essere letti da Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{y),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Leggiamo il file in cui abbiamo salvato il codice Stan

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"normalmodel.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

compiliamo il modello

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

ed eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Le stime a posteriori dei parametri si ottengono con:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"mu"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 10}
\CommentTok{\#\textgreater{}   variable  mean median    sd   mad    q5   q95  rhat}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 mu       29.3   29.3  1.11  1.10  27.4  31.0   1.00}
\CommentTok{\#\textgreater{} 2 sigma     6.86   6.77 0.911 0.886  5.54  8.47  1.00}
\CommentTok{\#\textgreater{} \# ... with 2 more variables: ess\_bulk \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

oppure, dopo avere trasformato l'oggetto \texttt{fit} nel formato \texttt{stanfit},

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{out }\OtherTok{\textless{}{-}}\NormalTok{ rstantools}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}
  \FunctionTok{as.matrix}\NormalTok{(stanfit), }
  \AttributeTok{prob =} \FloatTok{0.95}
\NormalTok{)}
\NormalTok{out}
\CommentTok{\#\textgreater{}         2.5\%   97.5\%}
\CommentTok{\#\textgreater{} mu     27.00  31.366}
\CommentTok{\#\textgreater{} sigma   5.32   8.853}
\CommentTok{\#\textgreater{} lp\_\_  {-}77.04 {-}73.384}
\end{Highlighting}
\end{Shaded}

Possiamo dunque concludere, con un grado di certezza soggettiva del 95\%, che siamo sicuri che la media della popolazione da cui abbiamo tratto i dati è compresa nell'intervallo {[}27, 31.37{]}.

\hypertarget{commenti-e-considerazioni-finali-15}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-15}}


Questo esempio ci mostra come calcolare l'intervallo di credibilità per la media di una v.c. gaussiana. La domanda più ovvia di analisi dei dati, dopo avere visto come creare l'intervallo di credibilità per la media di un gruppo, riguarda il confronto tra le medie di due gruppi. Questo però è un caso speciale di una tecnica di analisi dei dati più generale, chiamate analisi di regressione lineare. Prima di discutere il problema del confronto tra le medie di due gruppi è dunque necessario esaminare il modello statistico di regressione lineare.

\mainmatter

\hypertarget{part-il-modello-lineare}{%
\part{Il modello lineare}\label{part-il-modello-lineare}}

\hypertarget{regr-models-intro}{%
\chapter{Introduzione}\label{regr-models-intro}}

Lo scopo della ricerca è trovare le associazioni tra le variabili e fare confronti fra le condizioni sperimentali. Nel caso della psicologia, il ricercatore vuole scoprire le leggi generali che descrivono le relazioni tra i costrutti psicologici e le relazioni che intercorrono tra i fenomeni psicologici e quelli non psicologici (sociali, economici, storici, \ldots). Abbiamo già visto come la correlazione di Pearson sia uno strumento adatto a questo scopo. Infatti, essa ci informa sulla direzione e sull'intensità della relazione lineare tra due variabili. Tuttavia, la correlazione non è sufficiente, in quanto il ricercatore ha a disposizione solo i dati di un campione, mentre vorrebbe descrivere la relazione tra le variabili nella popolazione. A causa della variabilità campionaria, le proprietà dei campioni sono necessariamente diverse da quelle della popolazione: ciò che si può osservare nella popolazione potrebbe non emergere nel campione e, al contrario, il campione manifesta caratteristiche che non sono necessariamente presenti nella popolazione. È dunque necessario chiarire, dal punto di vista statistico, il legame che intercorre tra le proprietà del campione e le proprietà della popolazione da cui esso è stato estratto. Il modello lineare utilizza la funzione matematica più semplice per descrivere la relazione fra due variabili, ovvero la funzione lineare. In questo Capitolo vedremo come si possa fare inferenza sulla relazione tra due variabili mediante il modello lineare bayesiano. Inizieremo a descrivere le proprietà geometriche della funzione lineare per poi utilizzare questa semplice funzione per costruire un modello statistico secondo un approccio bayesiano.

\hypertarget{la-funzione-lineare}{%
\section{La funzione lineare}\label{la-funzione-lineare}}

Iniziamo con un ripasso sulla funzione di lineare. Si chiama \emph{funzione lineare} una funzione del tipo

\begin{equation}
f(x) = a + b x,
\end{equation}

dove \(a\) e \(b\) sono delle costanti. Il grafico di tale funzione è una retta di cui il parametro \(b\) è detto \emph{coefficiente angolare} e il parametro \(a\) è detto \emph{intercetta} con l'asse delle \(y\) {[}infatti, la retta interseca l'asse \(y\) nel punto \((0,a)\), se \(b \neq 0\){]}.

Per assegnare un'interpretazione geometrica alle costanti \(a\) e \(b\) si consideri la funzione

\begin{equation}
y = b x.
\end{equation}

Tale funzione rappresenta un caso particolare, ovvero quello della \emph{proporzionalità diretta} tra \(x\) e \(y\). Il caso generale della linearità

\begin{equation}
y = a + b x
\end{equation}

non fa altro che sommare una costante \(a\) a ciascuno dei valori \(y = b x\). Nella funzione lineare \(y = a + b x\), se \(b\) è positivo allora \(y\) aumenta al crescere di \(x\); se \(b\) è negativo allora \(y\) diminuisce al crescere di \(x\); se \(b=0\) la retta è orizzontale, ovvero \(y\) non muta al variare di \(x\).

Consideriamo ora il coefficiente \(b\). Si consideri un punto \(x_0\) e un incremento arbitrario \(\varepsilon\) come indicato nella figura \ref{fig:linearfunction}. Le differenze \(\Delta x = (x_0 + \varepsilon) - x_0\) e \(\Delta y = f(x_0 + \varepsilon) - f(x_0)\) sono detti \emph{incrementi} di \(x\) e \(y\). Il coefficiente angolare \(b\) è uguale al rapporto

\begin{equation}
    b = \frac{\Delta y}{\Delta x} = \frac{f(x_0 + \varepsilon) - f(x_0)}{(x_0 + \varepsilon) - x_0},
\end{equation}

indipendentemente dalla grandezza degli incrementi \(\Delta x\) e \(\Delta y\). Il modo più semplice per assegnare un'interpretazione geometrica al coefficiente angolare (o pendenza) della retta è dunque quello di porre \(\Delta x = 1\). In tali circostanze infatti \(b = \Delta y\).

\begin{figure}[h]

{\centering \includegraphics[width=4.17in]{images/linear_function} 

}

\caption{La funzione lineare $y = a + bx$.}\label{fig:linearfunction}
\end{figure}

\hypertarget{lerrore-di-misurazione}{%
\section{L'errore di misurazione}\label{lerrore-di-misurazione}}

Per descrivere l'associazione tra due variabili, tuttavia, la funzione lineare non è sufficiente. Nel mondo empirico, infatti, la relazione tra variabili non è mai perfettamente lineare. È dunque necessario includere nel modello lineare anche una componente d'errore, ovvero una componente della \(Y\) che non può essere spiegata dal modello lineare. Nel caso di due sole variabili, questo ci conduce alla seguente formulazione del modello lineare:

\begin{equation}
y = \beta_0 + \beta_1 x + \varepsilon,
\label{eq:regbivpop}
\end{equation}

laddove i parametri \(\beta_0\) e \(\beta_1\) descrivono l'associazione tra le variabili casuali \(Y\) e \(X\), e il termine d'errore \(\varepsilon\) specifica quant'è grande la porzione della variabile \(y\) che non può essere predetta nei termini di una relazione lineare con la \(X\).

Si noti che la \eqref{eq:regbivpop} consente di formulare una predizione, nei termini di un modello lineare, del valore atteso della \(Y\) conoscendo \(X\), ovvero

\begin{equation}
\hat{Y} = \mathbb{E}(Y \mid X = x) = \beta_0 + \beta_1 x.
\label{eq:regbivpop2}
\end{equation}

In altri termini, se i parametri del modello (\(\beta_0\) e \(\beta_1\)) sono noti, allora è possibile predire la \(Y\) sulla base della nostra conoscenza della \(X\). Per esempio, se conosciamo la relazione lineare tra quoziente di intelligenza ed aspettativa di vita, allora possiamo prevedere quanto a lungo vivrà una persona sulla base del suo QI. Sì, c'è una relazione lineare tra intelligenza e aspettativa di vita \citep{hambrick2015research}! Ma quando è accurata la previsione? Ciò dipende dal termine d'errore della \eqref{eq:regbivpop}. Il modello lineare fornisce un metodo per rispondere a domande di questo tipo\footnote{Per una discussione sugli aspetti di base del modello lineare, si veda il \href{https://openintro-ims.netlify.app/model-slr.html}{capitolo 7} di \emph{Introduction to Modern Statistics}.}.

\hypertarget{una-media-per-ciascuna-osservazione}{%
\section{Una media per ciascuna osservazione}\label{una-media-per-ciascuna-osservazione}}

In precedenza abbiamo visto come sia possibile stimare i parametri di un modello bayesiano nel quale le osservazioni sono indipendenti e identicamente distribuite secondo una densità gaussiana,

\begin{equation}
Y_i \stackrel{i.i.d.}{\sim} \mathcal{N}(\mu, \sigma), \quad i = 1, \dots, n.
\label{eq:normalsamplingmodel}
\end{equation}

Il modello \eqref{eq:normalsamplingmodel} assume che ogni \(Y_i\) sia una realizzazione di una v.c. descritta da una \(\mathcal{N}(\mu, \sigma^2)\). Da un punto di vista bayesiano\footnote{Per un'introduzione alla trattazione frequentista del modello lineare, si veda l'Appendice \ref{least-squares}.}, si assegnano distribuzioni a priori ai parametri \(\mu\) e \(\sigma\), si genera la verosimiglianza in base ai dati osservati e, con queste informazioni, si generano le distribuzione a posteriori dei parametri \citep{gelman2020regression}:

\begin{align}
Y_i \mid \mu, \sigma & \stackrel{iid}{\sim} \mathcal{N}(\mu, \sigma^2)\notag\\
\mu       & \sim \mathcal{N}(\mu_0, \tau^2) \notag\\
\sigma    & \sim \Cauchy(x_0, \gamma) \notag
\end{align}

È comune però che vengano registrate altre variabili \(x_i\) che possono essere associate alla risposta di interesse \(y_i\). La variabile \(x_i\) viene chiamata \emph{predittore} (o variabile indipendente) in quanto il ricercatore è tipicamente interessato a predire il valore \(y_i\) a partire da \(x_i\). Come si può estende il modello \eqref{eq:normalsamplingmodel} per lo studio della possibile relazione tra \(y_i\) e \(x_i\)?

Il modello \eqref{eq:normalsamplingmodel} assume una media \(\mu\) comune per ciascuna osservazione \(Y_i\). Dal momento che desideriamo introdurre una nuova variabile \(x_i\) che assume un diverso valore per ciascuna osservazione \(y_i\), il modello \eqref{eq:normalsamplingmodel} può essere modificato in modo che la media comune \(\mu\) venga sostituita da una media \(\mu_i\) specifica a ciascuna osservazione \(i\)-esima:

\begin{equation}
Y_i \mid \mu_i, \sigma \stackrel{ind}{\sim} \mathcal{N}(\mu_i, \sigma), \quad i = 1, \dots, n.
\label{eq:normalsamplinglinearmodel}
\end{equation}

Si noti che le osservazioni \(Y_1, \dots, Y_n\) non sono più identicamente distribuite poiché hanno medie diverse, ma sono ancora indipendenti come indicato dalla notazione \texttt{ind} posta sopra il simbolo \(\sim\) nella \eqref{eq:normalsamplinglinearmodel}.

\hypertarget{relazione-lineare-tra-la-media-y-mid-x-e-il-predittore}{%
\subsection{\texorpdfstring{Relazione lineare tra la media \(y \mid x\) e il predittore}{Relazione lineare tra la media y \textbackslash mid x e il predittore}}\label{relazione-lineare-tra-la-media-y-mid-x-e-il-predittore}}

L'approccio che consente di mettere in relazione un predittore \(x_i\) con la risposta \(Y_i\) è quello di assumere che la media di ciascuna \(Y_i\), ovvero \(\mu_i\), sia una funzione lineare del predittore \(x_i\). Una tale relazione lineare è scritta come

\begin{equation}
\mu_i = \beta_0 + \beta_ 1 x_i, \quad i = 1, \dots, n.
\label{eq:regmodel}
\end{equation}

Nella \eqref{eq:regmodel}, ciascuna \(x_i\) è una costante nota (ecco perché viene usata una lettera minuscola per la \(x\)) e \(\beta_0\) e \(\beta_ 1\) sono parametri incogniti. Questi parametri rappresentano l'intercetta e la pendenza della retta di regressione e sono delle variabili casuali.\footnote{Una notazione alternativa per tali parametri è \(\alpha\), \(\beta\), anziché \(\beta_0\), \(\beta_ 1\).} Si assegna una distribuzione a priori a \(\beta_0\) e a \(\beta_ 1\) e si esegue l'inferenza riassumendo la distribuzione a posteriori di questi parametri.

Nel modello \eqref{eq:regmodel}, la funzione lineare \(\beta_0 + \beta_ 1 x_i\) è interpretata come il valore atteso della \(Y_i\) per ciascun valore \(x_i\), mentre l'intercetta \(\beta_0\) rappresenta il valore atteso della \(Y_i\) quando \(x_i = 0\). Il parametro \(\beta_ 1\) (pendenza) rappresenta invece l'aumento medio della \(Y_i\) quando \(x_i\) aumenta di un'unità. È importante notare che la relazione lineare \eqref{eq:normalsamplinglinearmodel} di parametri \(\beta_0\) e \(\beta_ 1\) descrive l'associazione tra \emph{la media} \(\mu_i\) e il predittore \(x_i\). In altri termini, tale relazione lineare ci fornisce una predizione sul valore medio \(\mu_i\), non sul valore \emph{effettivo} \(Y_i\).

\hypertarget{il-modello-lineare}{%
\subsection{Il modello lineare}\label{il-modello-lineare}}

Sostituendo la \eqref{eq:regmodel} nella \eqref{eq:normalsamplinglinearmodel} otteniamo il modello lineare:

\begin{equation}
Y_i \mid \beta_0, \beta_ 1, \sigma \stackrel{ind}{\sim} \mathcal{N}(\beta_0 + \beta_ 1 x_i, \sigma), \quad i = 1, \dots, n.
\label{eq:samplinglinearmodel}
\end{equation}

Questo è un caso speciale del modello di campionamento Normale, dove le \(Y_i\) seguono indipendentemente una densità Normale con una media (\(\beta_0 + \beta_ 1 x_i\)) specifica per ciascuna osservazione e con una deviazione standard (\(\sigma\)) comune a tutte le osservazioni. Poiché include un solo predittore (\(x\)), questo modello è comunemente chiamato \emph{modello di regressione lineare semplice}.

In maniera equivalente, il modello \eqref{eq:samplinglinearmodel} può essere formulato come

\begin{equation}
Y_i = \mu_i + \varepsilon_i, \quad i = 1, \dots, n,
\label{eq:samplinglinearmodel2}
\end{equation}

dove la risposta media è \(\mu_i = \beta_0 + \beta_ 1 x_i\) e i residui \(\varepsilon_1, \dots, \varepsilon_n\) sono i.i.d. da una Normale con media 0 e deviazione standard \(\sigma\).

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-214-1} \end{center}

Nel modello lineare, l'osservazione \(Y_i\) è una variabile casuale, il predittore \(x_i\) è una costante fissa, e \(\beta_0\), \(\beta_1\) e \(\sigma\) sono parametri incogniti. Utilizzando il paradigma bayesiano, viene assegnata una distribuzione a priori congiunta a \((\beta_0, \beta_1, \sigma)\). Dopo avere osservato le risposte \(Y_i, i = 1, \dots, n\), l'inferenza procede stimando la distribuzione a posteriori dei parametri.

\begin{remark}

Nella costruzione di un modello di regressione bayesiano, è importante iniziare dalle basi e procedere un passo alla volta. Sia \(Y\) una variabile di risposta e sia \(x\) un predittore o un insieme di predittori. È possibile costruire un modello di regressione di \(Y\) su \(x\) applicando i seguenti principi generali:

\begin{itemize}
\item
  Stabilire se \(Y\) è discreto o continuo. Di conseguenza, identificare l'appropriata struttura dei dati (per esempio, Normale, di Poisson, o Binomiale).
\item
  Esprimere la media di \(Y\) come funzione dei predittori \(x\) (per esempio, \(\mu = \beta_0 + \beta_1 x\)).
\item
  Identificare tutti i parametri incogniti del modello (per esempio, \(\mu, \beta_1, \beta_2\)).
\item
  Valutare quali valori che ciascuno di questi parametri potrebbe assumere. Di conseguenza, identificare le distribuzioni a priori appropriate per questi parametri.
\end{itemize}

\end{remark}

Nel caso di una variabile \(Y\) continua che segue la legge gaussiana e un solo predittore, ad esempio, il modello diventa:

\begin{align} 
Y_i \mid \beta_0, \beta_1, \sigma  &\stackrel{ind}{\sim} \mathcal{N}\left(\mu_i, \sigma^2\right) \;\; \text{ con } \;\; \mu_i = \beta_0 + \beta_1 x_i \notag\\
\beta_0  &\sim \mathcal{N}\left(\mu_0, \sigma_0^2 \right)  \notag\\
\beta_1  & \sim \mathcal{N}\left(\mu_1, \sigma_1^2 \right) \notag\\
\sigma & \sim \text{Cauchy}(x_0, \gamma) \; .\notag
\end{align}

Un algoritmo MCMC viene usato per simulare i campioni dalle distribuzioni a posteriori e, mediante tali campioni, si fanno inferenze sulla risposta attesa \(\beta_0 + \beta_1 x\) per ciascuno specifico valore del predittore \(x\). Inoltre, è possibile valutare le dimensioni degli errori di previsione mediante un indice sintetico della densità a posteriori della deviazione standard \(\sigma\).

\hypertarget{commenti-e-considerazioni-finali-16}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-16}}


Il modello lineare semplice viene usato per descrivere la relazione tra due variabili e per determinare il segno e l'intensità di tale relazione. Inoltre, il modello lineare ci consente di prevedere il valore della variabile dipendente in base ai valori della variabile indipendente. Il modello lineare semplice è in realtà molto limitato, in quanto descrive soltanto la relazione tra la variabile dipendente \(y\) e una sola variabile esplicativa \(x\). Esso diventa molto più utile quando incorpora più variabili indipendenti. In questo secondo caso, però, i calcoli per la stima dei coefficienti del modello diventano più complicati. Abbiamo deciso di iniziare considerando il modello lineare semplice perché, in questo caso, sia la logica dell'inferenza sia le procedure di calcolo sono facilmente maneggiabili. Nel caso più generale, quello del modello lineare multiplo (ovvero, con più di un predittore), la logica dell'inferenza rimane identica a quella discussa qui, ma le procedure di calcolo richiedono l'uso dell'algebra matriciale. Il modello lineare multiplo può includere sia regressori quantitativi, sia regressori qualitativi, utilizzando un opportuno schema di codifica. È interessante notare come un modello lineare multiplo che include una sola variabile esplicativa qualitativa corrisponde all'analisi della varianza ad una via; un modello lineare multiplo che include più di una variabile esplicativa qualitativa corrisponde all'analisi della varianza più vie. Possiamo qui concludere dicendo che il modello lineare, nelle sue varie forme e varianti, costituisce la tecnica di analisi dei dati maggiormente usata in psicologia.

\hypertarget{regr-ml}{%
\chapter{Adattare il modello lineare ai dati}\label{regr-ml}}

In questo Capitolo verranno esposte alcune nozioni matematiche che stanno alla base dell'inferenza sul modello lineare.

\hypertarget{minimi-quadrati}{%
\section{Minimi quadrati}\label{minimi-quadrati}}

Nel modello lineare classico, \(y_i = \beta_0 + \beta_1 x_i + \varepsilon_i\), i coefficienti \(\beta_0\) e \(\beta_1\) sono stimati in modo tale da minimizzare gli errori \(\varepsilon_i\). Se il numero dei dati \(n\) è maggiore di 2, non è generalmente possibile trovare una retta che passi per tutte le osservazioni (\(x, y\)) (sarebbe \(y_i = \beta_0 + \beta_1 x_i\), senza errori, per tutti i punti \(i = 1, \dots, n\)). L'obiettivo della stima dei minimi quadrati è quello di scegliere i valori (\(\hat{\beta}_0, \hat{\beta}_1\)) che minimizzano la somma dei quadrati dei residui,

\begin{equation}
e_i = y_i − (\hat{\beta}_0 + \hat{\beta}_1 x_i)\,.
\end{equation}

Distinguiamo tra i residui \(e_i = y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i)\) e gli \emph{errori} \(\varepsilon_i = y_i − (\beta_0 + \beta_1 x_i)\). Il modello di regressione è scritto in termini degli errori, ma possiamo solo lavorare con i residui: non possiamo calcolare gli errori perché per farlo sarebbe necessario conoscere i parametri ignoti \(\beta_0\) e \(\beta_1\).

La somma dei residui quadratici (\emph{residual sum of squares}) è

\begin{equation}
\text{RSS} = \sum_{i=1}^n (y_i = (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2\,.
\end{equation}

I coefficienti (\(\hat{\beta}_0, \hat{\beta}_1\)) che minimizzano RSS sono chiamati stime dei minimi quadrati, o minimi quadrati ordinari (\emph{ordinari least squares}), o stime OLS.

\hypertarget{stima-della-deviazione-standard-dei-residui-sigma}{%
\subsection{\texorpdfstring{Stima della deviazione standard dei residui \(\sigma\)}{Stima della deviazione standard dei residui \textbackslash sigma}}\label{stima-della-deviazione-standard-dei-residui-sigma}}

Nel modello lineare, gli errori \(\varepsilon_i\) provengono da una distribuzione con media 0 e deviazione standard \(\sigma\): la media è zero per definizione (qualsiasi media diversa da zero viene assorbita nell'intercetta, \(\beta_0\)), e la deviazione standard degli errori può essere stimata dai dati. Un modo apparentemente naturale per stimare \(\sigma\) potrebbe essere quello di calcolare la deviazione standard dei residui, \(\sqrt{\frac{1}{n} \sum_{i=1}^n e_i^2} = \sqrt{ \frac{1}{n} \sum_{i=1}^n y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2}\), ma questo approccio finisce per sottostimare \(\sigma\). La correzione standard di questa sottostima consiste nel sostituire \(n\) con \(n - 2\) al denominatore (la sottrazione di 2 deriva dal fatto che il valore atteso del modello lineare è stato calcolato utilizzando i due coefficienti nel modello, l'intercetta e la pendenza, i quali sono stati stimati dai dati campionari -- si dice che, in questo modo, abbiamo perso due gradi di libertà). Così facendo otteniamo

\begin{equation}
\hat{\sigma} = \sqrt{\frac{1}{n-2} \sum_{i=1}^n (y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i))^2}\, .
\end{equation}

Quando \(n = 1\) o \(2\) l'equazione precedente è priva di significato, il che ha senso: con solo due osservazioni è possibile adattare esattamente una retta al diagramma di dispersione e quindi non c'è modo di stimare l'errore dai dati.

\hypertarget{calcolare-la-somma-dei-quadrati}{%
\section{Calcolare la somma dei quadrati}\label{calcolare-la-somma-dei-quadrati}}

Seguendo \href{https://github.com/ASKurz/Working-through-Regression-and-other-stories/blob/main/08.Rmd}{Solomon Kurz}, creiamo una funzione per calcolare la somma dei quadrati per diversi valori di \(\beta_0\) e \(\beta_1\) che, per semplicità, qui verranno chiamati \(a\) e \(b\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rss }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, a, b) \{  }
  \CommentTok{\# x and y are vectors, }
  \CommentTok{\# a and b are scalars }
\NormalTok{  resid }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{{-}}\NormalTok{ (a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ x)}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{sum}\NormalTok{(resid}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

Per fare un esempio concreto useremo un famoso dataset chiamato \texttt{kidiq} \citep{gelman2020regression} che riporta i dati di un'indagine del 2007 su un campione di donne americane adulte e sui loro bambini di età compresa tra i 3 e i 4 anni. I dati sono costituiti da 434 osservazioni e 4 variabili:

\begin{itemize}
\tightlist
\item
  \texttt{kid\_score}: QI del bambino; è il punteggio totale del \emph{Peabody Individual Achievement Test} (PIAT) costituito dalla somma dei punteggi di tre sottoscale (Mathematics, Reading comprehension, Reading recognition);
\item
  \texttt{mom\_hs}: variabile dicotomica (0 or 1) che indica se la madre del bambino ha completato le scuole superiori (1) oppure no (0);
\item
  \texttt{mom\_iq}: QI della madre;
\item
  \texttt{mom\_age}: età della madre.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"rio"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\FunctionTok{head}\NormalTok{(df)}
\CommentTok{\#\textgreater{}   kid\_score mom\_hs mom\_iq mom\_work mom\_age}
\CommentTok{\#\textgreater{} 1        65      1 121.12        4      27}
\CommentTok{\#\textgreater{} 2        98      1  89.36        4      25}
\CommentTok{\#\textgreater{} 3        85      1 115.44        4      27}
\CommentTok{\#\textgreater{} 4        83      1  99.45        3      25}
\CommentTok{\#\textgreater{} 5       115      1  92.75        4      27}
\CommentTok{\#\textgreater{} 6        98      0 107.90        1      18}
\end{Highlighting}
\end{Shaded}

Calcoliamo alcune statistiche descrittive:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(df)}
\CommentTok{\#\textgreater{}    kid\_score         mom\_hs          mom\_iq     }
\CommentTok{\#\textgreater{}  Min.   : 20.0   Min.   :0.000   Min.   : 71.0  }
\CommentTok{\#\textgreater{}  1st Qu.: 74.0   1st Qu.:1.000   1st Qu.: 88.7  }
\CommentTok{\#\textgreater{}  Median : 90.0   Median :1.000   Median : 97.9  }
\CommentTok{\#\textgreater{}  Mean   : 86.8   Mean   :0.786   Mean   :100.0  }
\CommentTok{\#\textgreater{}  3rd Qu.:102.0   3rd Qu.:1.000   3rd Qu.:110.3  }
\CommentTok{\#\textgreater{}  Max.   :144.0   Max.   :1.000   Max.   :138.9  }
\CommentTok{\#\textgreater{}     mom\_work      mom\_age    }
\CommentTok{\#\textgreater{}  Min.   :1.0   Min.   :17.0  }
\CommentTok{\#\textgreater{}  1st Qu.:2.0   1st Qu.:21.0  }
\CommentTok{\#\textgreater{}  Median :3.0   Median :23.0  }
\CommentTok{\#\textgreater{}  Mean   :2.9   Mean   :22.8  }
\CommentTok{\#\textgreater{}  3rd Qu.:4.0   3rd Qu.:25.0  }
\CommentTok{\#\textgreater{}  Max.   :4.0   Max.   :29.0}
\end{Highlighting}
\end{Shaded}

Il QI medio dei bambini è di circa 87 mentre quello della madre è di 100. La gamma di età delle madri va da 17 a 29 anni con una media di circa 23 anni. Si noti infine che il 79\% delle mamme ha un diploma di scuola superiore.

Ci poniamo ora il problema di descrivere l'associazione tra il QI dei figli, \texttt{kid\_score}, e il QI delle madri, \texttt{mom\_iq}, mediante un modello lineare. Le stime dei minimi quadrati sono fornite dalla funzione \texttt{lm()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fm }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_iq, }\AttributeTok{data =}\NormalTok{ df)}
\NormalTok{fm }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(term }\SpecialCharTok{==} \FunctionTok{c}\NormalTok{(}\StringTok{"(Intercept)"}\NormalTok{, }\StringTok{"mom\_iq"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pull}\NormalTok{(estimate)}
\CommentTok{\#\textgreater{} [1] 25.80  0.61}
\end{Highlighting}
\end{Shaded}

\noindent Calcoliamo la somma dei residui quadratici in base al modello di regressione \(\hat{y}_i = 25.8 + 0.61 x_i\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rss}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq, df}\SpecialCharTok{$}\NormalTok{kid\_score, }\FloatTok{25.8}\NormalTok{, }\FloatTok{0.61}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 144137}
\end{Highlighting}
\end{Shaded}

Per sviluppare una comprensione intuitiva del metodo dei minimi quadrati, esploriamo i valori assunti da \texttt{rss} per diversi valori di \(a\) e \(b\). Per semplicità, manteniamo costante \texttt{b\ =\ 0.61} e variamo i valori \texttt{a}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{a =} \FunctionTok{seq}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{30}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{rss =}\NormalTok{ purrr}\SpecialCharTok{::}\FunctionTok{map\_dbl}\NormalTok{(}
\NormalTok{      a, }
\NormalTok{      rss, }
      \AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_iq, }
      \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,  }
      \AttributeTok{b =} \FloatTok{0.61}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ a, }\AttributeTok{y =}\NormalTok{ rss)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \StringTok{"Il valore b è tenuto costante (b = 0.61)"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-220-1} \end{center}

Il minimo della funzione che qui abbiamo discretizzato costituisce la stima dei minimi quadrati del parametro \(\beta_0\).

Lo stesso può essere fatto per \(b\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{b =} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.8}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{30}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{rss =}\NormalTok{ purrr}\SpecialCharTok{::}\FunctionTok{map\_dbl}\NormalTok{(}
\NormalTok{      b, }
\NormalTok{      rss, }
      \AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_iq, }
      \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,  }
      \AttributeTok{a =} \FloatTok{25.8}\NormalTok{)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ b, }\AttributeTok{y =}\NormalTok{ rss)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{subtitle =} \StringTok{"Il valore a è tenuto costante (a = 25.8)"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-221-1} \end{center}

Il minimo della funzione rappresentata qui sopra costituisce la stima dei minimi quadrati del parametro \(\beta_1\).

In generale, possiamo dire che il metodo dei minimi quadrati consente di minimizzare la funzione quadratica \(RSS = \sum_{i=1}^n \left(y_i - (\hat{\beta}_0 + \hat{\beta}_1 x_i)\right)^2\) rispetto alle due incognite \(\hat{\beta}_0\) e \(\hat{\beta}_1\). Numericamente, ciò corrisponde a variare sia \texttt{a} che \texttt{b} simultaneamente in un listato simile a quello riportato sopra. Anche se il codice \(\R\) necessario per ottenere questo risultato è più complesso di quello qui esaminato, l'idea di base non cambia.

\begin{remark}
Nelle precedenti istruzioni \(\R\) abbiamo utilizzato la funzione \texttt{purrr::map\_dbl()}. Questo oggetto \(\R\) consente di applicare una funzione (in questo caso, \texttt{rss()}) a ciascun elemento di un vettore in input (nel caso presente, il vettore \texttt{a} oppure il vettore \texttt{b}). La funzione \texttt{purrr::map\_dbl()} ritorna un numero reale.
\end{remark}

\hypertarget{commenti-e-considerazioni-finali-17}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-17}}


Se gli errori del modello lineare sono indipendenti e distribuiti normalmente, in modo che \(y_i \sim \mathcal{N}(\beta_0 + \beta_1 x_i, \sigma^2)\) per ogni \(i\), allora la stima ai minimi quadrati di (\(\hat{\beta}_0\), \(\hat{\beta}_1\)) coincide con la stima di massima verosimiglianza di questi parametri. In un modello lineare, la funzione di verosimiglianza è definita come la densità di probabilità delle osservazioni, dati i parametri e i predittori, ovvero,

\begin{equation}
 p(y \mid \beta_0, \beta_1, \sigma, x) = \prod_{i=1}^n \mathcal{N}(y_i \mid \beta_0 + \beta_1 x_i, \sigma^2),
 \label{eq:ml-lin-mod}
\end{equation}

dove \(\mathcal{N}(\cdot | \cdot, \cdot)\) è la funzione gaussiana.

Un studio della \eqref{eq:ml-lin-mod} mostra che la massimizzazione della verosimiglianza richiede la minimizzazione della somma dei quadrati dei residui. Se gli errori sono indipendenti e distribuiti normalmente, quindi, la stima dei minimi quadrati \(\hat{\beta} = (\hat{\beta}_0, \hat{\beta}_1)\) coincide con la stima di massima verosimiglianza per i parametri del modello lineare.

\hypertarget{reg-lin-stan}{%
\chapter{Modello lineare in Stan}\label{reg-lin-stan}}

Obiettivo di questo Capitolo è illustrare come svolgere l'analisi bayesiana del modello lineare usando il linguaggio Stan.\footnote{Una descrizione dell'approccio frequentista è fornita nell'Appendice \ref{regr-lin-frequentista}.}

\hypertarget{il-modello-lineare-in-linguaggio-stan}{%
\section{Il modello lineare in linguaggio Stan}\label{il-modello-lineare-in-linguaggio-stan}}

Leggiamo in \(\R\) il dataset \texttt{kidiq}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"rio"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\FunctionTok{head}\NormalTok{(df)}
\CommentTok{\#\textgreater{}   kid\_score mom\_hs mom\_iq mom\_work mom\_age}
\CommentTok{\#\textgreater{} 1        65      1 121.12        4      27}
\CommentTok{\#\textgreater{} 2        98      1  89.36        4      25}
\CommentTok{\#\textgreater{} 3        85      1 115.44        4      27}
\CommentTok{\#\textgreater{} 4        83      1  99.45        3      25}
\CommentTok{\#\textgreater{} 5       115      1  92.75        4      27}
\CommentTok{\#\textgreater{} 6        98      0 107.90        1      18}
\end{Highlighting}
\end{Shaded}

Vogliamo descrivere l'associazione tra il QI dei figli e il QI delle madri mediante un modello lineare. Per farci un'idea del valore dei parametri, adattiamo il modello lineare ai dati mediante la procedura di massima verosimiglianza:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(}\FunctionTok{lm}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_iq, }\AttributeTok{data =}\NormalTok{ df))}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Call:}
\CommentTok{\#\textgreater{} lm(formula = kid\_score \textasciitilde{} mom\_iq, data = df)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residuals:}
\CommentTok{\#\textgreater{}    Min     1Q Median     3Q    Max }
\CommentTok{\#\textgreater{} {-}56.75 {-}12.07   2.22  11.71  47.69 }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Coefficients:}
\CommentTok{\#\textgreater{}             Estimate Std. Error t value Pr(\textgreater{}|t|)    }
\CommentTok{\#\textgreater{} (Intercept)  25.7998     5.9174    4.36  1.6e{-}05 ***}
\CommentTok{\#\textgreater{} mom\_iq        0.6100     0.0585   10.42  \textless{} 2e{-}16 ***}
\CommentTok{\#\textgreater{} {-}{-}{-}}
\CommentTok{\#\textgreater{} Signif. codes:  }
\CommentTok{\#\textgreater{} 0 \textquotesingle{}***\textquotesingle{} 0.001 \textquotesingle{}**\textquotesingle{} 0.01 \textquotesingle{}*\textquotesingle{} 0.05 \textquotesingle{}.\textquotesingle{} 0.1 \textquotesingle{} \textquotesingle{} 1}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Residual standard error: 18.3 on 432 degrees of freedom}
\CommentTok{\#\textgreater{} Multiple R{-}squared:  0.201,  Adjusted R{-}squared:  0.199 }
\CommentTok{\#\textgreater{} F{-}statistic:  109 on 1 and 432 DF,  p{-}value: \textless{}2e{-}16}
\end{Highlighting}
\end{Shaded}

La formulazione bayesiana del modello lineare è:

\[
\begin{aligned}
y_i &\sim \mathcal{N}(\mu_i, \sigma) \\
\mu_i &= \beta_0 + \beta_1 x_i \\
\beta_0 &\sim \mathcal{N}(25, 10) \\
\beta_1 &\sim \mathcal{N}(0, 1) \\
\sigma &\sim \text{Cauchy}(18, 5) 
\end{aligned}
\]

La prima riga definisce la funzione di verosimiglianza e le righe successive definiscono le distribuzioni a priori dei parametri. Il segno \(\sim\) (tilde) si può leggere ``si distribuisce come''. La prima riga ci dice che ciascuna osservazione \(y_i\) è una variabile casuale che segue la distribuzione gaussiana di parametri \(\mu_i\) e \(\sigma\). La seconda riga specifica, in maniera deterministica, che ciascun \(\mu_i\) è una funzione lineare di \(x_i\), con parametri \(\beta_0\) e \(\beta_1\). Le due righe successive specificano le distribuzioni a priori per \(\beta_0\) e \(\beta_1\). La distribuzione a priori di \(\beta_0\) è una distribuzione gaussiana di parametri \(\mu_{\alpha} = 25\) e deviazione standard \(\sigma_{\alpha} = 10\); la distribuzione a priori di \(\beta_1\) è una distribuzione gaussiana standardizzata. L'ultima riga definisce la distribuzione a priori di \(\sigma\), ovvero una Cauchy di parametri 18 e 5.

Poniamoci ora il problema di specificare il modello bayesiano descritto sopra in linguaggio Stan\footnote{Nella discussione che segue ripeto pari pari ciò che è riportato nel manuale del linguaggio \href{https://mc-stan.org/docs/2_27/stan-users-guide/standardizing-predictors-and-outputs.html}{Stan}.}. Il codice Stan viene eseguito più velocemente se l'input è standardizzato così da avere una media pari a zero e una varianza unitaria.\footnote{Si noti un punto importante. Il fatto di standardizzare i dati fa in modo che le distribuzioni a priori sui parametri vadano espresse sulla scala delle v.c. normali standardizzate. Se centriamo sullo 0 tali distribuzioni a priori, con una deviazione standard dell'ordine di grandezza dell'unità, i discorsi sull'arbitrarietà delle distribuzioni a priori perdono di significato: nel caso di dati standardizzati le distribuzioni a priori formulate come indicato sopra sono distribuzioni debolmente informative il cui unico scopo è la regolarizzazione dei dati, ovvero di mantenere le inferenze in una gamma ragionevole di valori; ciò contribuisce nel contempo a limitare l'influenza eccessiva delle osservazioni estreme (valori anomali) --- quello che è importante è che tali distribuzioni a priori non introducono alcuna distorsione sistematica nella stima a posteriori.} Ponendo \(y = (y_1, \dots, y_n)\) e \(x = (x_1, \dots, x_n)\), il modello lineare può essere scritto come

\[
y_i = \alpha + \beta x_i + \varepsilon_i,
\]

dove

\[
\varepsilon_i \sim \mathcal{N}(0, \sigma).
\]

Seguendo la notazione del manuale Stan, i parametri del modello lineare sono qui denotati da \(\alpha\) e \(\beta\).

È necessario prima centrare i dati, sottraendo da essi la media campionaria, per poi scalarli dividendo per la deviazione standard campionaria. Una singola osservazione \(u\) viene standardizzata dalla funzione \(z\) definita da

\[
z_y(u) = \frac{u - \bar{y}}{\texttt{sd}(y)}
\]

dove la media \(\bar{y}\) è

\[
\bar{y} = \frac{1}{n} \sum_{i=1}^n y_i,
\] e la deviazione standard è

\[
\texttt{sd} = \left(\frac{1}{n}\sum_{i=1}^n(y_i - \bar{y})^2\right)^{-\frac{1}{2}}.
\]

La trasformata inversa è definita invertendo i due passaggi precedenti: la deviazione standard è usata per scalare i valori \(u\) e la media campionaria è usata per traslare la distribuzione dei valori \(u\) scalati:

\[
z_y^{-1}(u) = \texttt{sd}(y)u + \bar{y}.
\]

Consideriamo il seguente modello iniziale in linguaggio Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] y;}
\StringTok{  vector[N] x;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  // priors}
\StringTok{  alpha \textasciitilde{} normal(25, 10);}
\StringTok{  beta \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(18, 5);}
\StringTok{  // likelihood}
\StringTok{  for (n in 1:N)}
\StringTok{    y[n] \textasciitilde{} normal(alpha + beta * x[n], sigma);}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/simpleregkidiq.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La funzione \texttt{modelString()} registra una stringa di testo mentre \texttt{writeLines()} crea un file nell'indirizzo specificato. Tale file deve avere l'estensione \texttt{.stan}.

Modificando il codice precedente otteniamo il modello Stan per dati standardizzati. Il blocco \texttt{data} è identico a quello del caso precedente. I predittori e la risposta standardizzati sono definiti nel blocco \texttt{transformed\ data}. Per semplificare la notazione (e velocizzare l'esecuzione), nel blocco \texttt{model} l'istruzione di campionamento è espressa in forma vettorializzata: \texttt{y\_std\ \textasciitilde{}\ normal(alpha\_std\ +\ beta\_std\ *\ x\_std,\ sigma\_std);}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N; }
\StringTok{  vector[N] y; }
\StringTok{  vector[N] x; }
\StringTok{\}}
\StringTok{transformed data \{}
\StringTok{  vector[N] x\_std;}
\StringTok{  vector[N] y\_std;}
\StringTok{  x\_std = (x {-} mean(x)) / sd(x);}
\StringTok{  y\_std = (y {-} mean(y)) / sd(y);}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha\_std;}
\StringTok{  real beta\_std;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_std;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu\_std = alpha\_std + beta\_std * x\_std; }
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha\_std \textasciitilde{} normal(0, 1); }
\StringTok{  beta\_std \textasciitilde{} normal(0, 1);  }
\StringTok{  sigma\_std \textasciitilde{} normal(0, 1); }
\StringTok{  y\_std \textasciitilde{} normal(mu\_std, sigma\_std); }
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  // transform to the original data scale}
\StringTok{  real alpha;}
\StringTok{  real beta;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{  alpha = sd(y) * (alpha\_std {-} beta\_std * mean(x) / sd(x)) + mean(y);}
\StringTok{  beta = beta\_std * sd(y) / sd(x);}
\StringTok{  sigma = sd(y) * sigma\_std;}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/simpleregstd.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si noti che i parametri vengono rinominati per indicare che non sono i parametri ``naturali'', ma per il resto il modello è identico. Sono qui utilizzate distribuzioni a priori debolmente informative per i parametri \texttt{alpha} e \texttt{beta}.

I valori dei parametri sulla scala originale dei dati vengono calcolati nel blocco \texttt{generated\ quantities} e possono essere recuperati con un po' di algebra.

\begin{align}
y_n &= \textrm{z}_y^{-1}(\textrm{z}_y(y_n)) \notag\\
    &= \textrm{z}_y^{-1}
\left( \alpha' + \beta' \textrm{z}_x(x_n) + \epsilon_n' \right) \notag\\
    &= \textrm{z}_y^{-1}
\left( \alpha' + \beta' \left( \frac{x_n - \bar{x}}{\texttt{sd}(x)} \right) + \epsilon_n' \right) \notag\\
    &= \texttt{sd}(y)
\left( \alpha' + \beta' \left( \frac{x_n - \bar{x}}{\texttt{sd}(x)} \right) + \epsilon_n' \right) + \bar{y} \notag\\
    &=
\left( \texttt{sd}(y) \left( \alpha' - \beta' \frac{\bar{x}}{\texttt{sd}(x)} \right) + \bar{y} \right)
+ \left( \beta' \frac{\texttt{sd}(y)}{\texttt{sd}(x)} \right) x_n
+ \texttt{sd}(y) \epsilon'_n,
\end{align}

da cui

\[
\alpha
=
\texttt{sd}(y)
      \left(
          \alpha'
          - \beta' \frac{\bar{x}}{\texttt{sd}(x)}
      \right)
  + \bar{y};
\qquad
\beta = \beta' \frac{\texttt{sd}(y)}{\texttt{sd}(x)};
\qquad
\sigma = \texttt{sd}(y) \sigma'.
\]

Per svolgere l'analisi bayesiana sistemiamo i dati nel formato appropriato per Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_iq}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La funzione \texttt{file.path()} ritorna l'indirizzo del file con il codice Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"simpleregstd.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il codice Stan può essere stampato usando il metodo \texttt{\$print()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod}\SpecialCharTok{$}\FunctionTok{print}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Prendendo come input un file contenente un programma Stan, la funzione \texttt{cmdstan\_model()} ritorna un oggetto di classe \texttt{CmdStanModel}. In pratica, \texttt{CmdStan} traduce un programma Stan in C++ e crea un eseguibile compilato.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

L'indirizzo dell'eseguibile compilato viene ritornato da \texttt{\$exe\_file()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod}\SpecialCharTok{$}\FunctionTok{exe\_file}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Applicando il metodo \texttt{\$sample()} ad un oggetto \texttt{CmdStanModel} eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Al metodo \texttt{\$sample()} possono essere passati molti argomenti. La pagina di documentazione è disponibile al seguente \href{https://mc-stan.org/cmdstanr/reference/model-method-sample.html}{link}.

Un sommario della distribuzione a posteriori per i parametri stimati si ottiene con il metodo \texttt{\$summary()}, il quale chiama la funzione \texttt{summarise\_draws()} del pacchetto \texttt{posterior}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 3 x 10}
\CommentTok{\#\textgreater{}   variable   mean median     sd    mad     q5    q95}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    25.9   25.8   6.02   6.02   16.0   35.8  }
\CommentTok{\#\textgreater{} 2 beta      0.609  0.609 0.0596 0.0603  0.511  0.707}
\CommentTok{\#\textgreater{} 3 sigma    18.3   18.3   0.634  0.644  17.3   19.4  }
\CommentTok{\#\textgreater{} \# ... with 3 more variables: rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

Da questo output possiamo valutare rapidamente la convergenza del modello osservando i valori di Rhat per ciascun parametro. Quando questi sono pari o vicini a 1, le catene hanno realizzato la convergenza. Ci sono molti altri test diagnostici, ma questo test è importante per Stan. Oppure è possibile usare:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{cmdstan\_summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Le statistiche diagnostiche sono fornite dal metodo \texttt{\$cmdstan\_diagnose()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{cmdstan\_diagnose}\NormalTok{()}
\CommentTok{\#\textgreater{} Processing csv files: /var/folders/hl/dt523djx7\_q7xjrthzjpdvc40000gn/T/Rtmperbyvp/simpleregstd{-}202201200849{-}1{-}5fb100.csv, /var/folders/hl/dt523djx7\_q7xjrthzjpdvc40000gn/T/Rtmperbyvp/simpleregstd{-}202201200849{-}2{-}5fb100.csv, /var/folders/hl/dt523djx7\_q7xjrthzjpdvc40000gn/T/Rtmperbyvp/simpleregstd{-}202201200849{-}3{-}5fb100.csv, /var/folders/hl/dt523djx7\_q7xjrthzjpdvc40000gn/T/Rtmperbyvp/simpleregstd{-}202201200849{-}4{-}5fb100.csv}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Checking sampler transitions treedepth.}
\CommentTok{\#\textgreater{} Treedepth satisfactory for all transitions.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Checking sampler transitions for divergences.}
\CommentTok{\#\textgreater{} No divergent transitions found.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Checking E{-}BFMI {-} sampler transitions HMC potential energy.}
\CommentTok{\#\textgreater{} E{-}BFMI satisfactory.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Effective sample size satisfactory.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Split R{-}hat values satisfactory all parameters.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Processing complete, no problems detected.}
\end{Highlighting}
\end{Shaded}

È possibile creare un oggetto di classe \texttt{stanfit}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

per poi utilizzare le funzioni del pacchetto \texttt{bayesplot}. Ad esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mcmc\_trace}\NormalTok{(}\AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-236-1} \end{center}

Infine, eseguendo la funzione \texttt{launch\_shinystan(fit)}, è possibile analizzare oggetti di classe \texttt{stanfit} mediante le funzionalità del pacchetto \texttt{ShinyStan}.

\hypertarget{interpretazione-dei-parametri}{%
\section{Interpretazione dei parametri}\label{interpretazione-dei-parametri}}

Assegnamo ai parametri la seguente interpretazione.

\begin{itemize}
\item
  L'intercetta pari a 25.9 indica il QI medio dei bamini la cui madre ha un QI = 0. Ovviamente questo non ha alcun significato. Vedremo nel modello successivo come trasformare il modello in modo da potere assegnare all'intercetta un'interpretazione sensata.
\item
  La pendenza di 0.61 indica che, all'aumentare di un punto del QI delle madri, il QI medio dei loro bambini aumenta di 0.61 unità. Se consideriamo la gamma di variazione del QI delle madri nel campione, il QI medio dei bambini cambia di 41 punti. Questo indica un sostanziale effetto del QI delle madri sul QI dei loro bambini: \((138.89 - 71.04) * 0.61 = 41.39\).
\item
  Il parametro \(\sigma\) = 18.3 fornisce una stima della dispersione delle osservazioni attorno al valore predetto dal modello lineare, ovvero fornisce una stima della deviazione standard dei residui attorno al valore atteso del modello lineare.
\end{itemize}

\hypertarget{centrare-i-predittori}{%
\subsection{Centrare i predittori}\label{centrare-i-predittori}}

Per migliorare l'interpretazione dell'intercetta possiamo ``centrare'' la \(x\), ovvero esprimere la \(x\) nei termini degli scarti dalla media: \(x - \bar{x}\). In tali circostanze, la pendenza della retta specificata dal modello lineare resta immutata, ma l'intercetta corrisponde a \(\E(y \mid x = \bar{x})\). Per ottenere questo risultato, modifichiamo i dati da passare a Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data2\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_iq }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2 }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data2\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Trasformiamo l'oggetto \texttt{fit} in un oggetto di classe \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit2}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Le stime a posteriori dei parametri si ottengono con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 3 x 10}
\CommentTok{\#\textgreater{}   variable   mean median     sd    mad     q5    q95}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    86.8   86.8   0.876  0.871  85.4   88.2  }
\CommentTok{\#\textgreater{} 2 beta      0.609  0.609 0.0591 0.0589  0.513  0.707}
\CommentTok{\#\textgreater{} 3 sigma    18.3   18.3   0.630  0.624  17.3   19.4  }
\CommentTok{\#\textgreater{} \# ... with 3 more variables: rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

Si noti la nuova intercetta, ovvero 86.8. Questo valore indica il QI medio dei bambini le cui madri hanno un QI pari alla media del campione. Centrare i dati consente dunque di assegnare all'intercetta un'interpretazione utile.

\hypertarget{commenti-e-considerazioni-finali-18}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-18}}


La presente discussione suggerisce che è conveniente standardizzare i dati prima di procedere con l'analisi. Ciò può essere fatto all'interno del codice Stan (come negli esempi di questo Capitolo), oppure prima di passare i dati a Stan. Se vengono usati dati standardizzati diventa poi facile utilizzare distribuzioni a priori debolmente informative per i parametri. Tali distribuzioni a priori hanno, come unico scopo, quello di regolarizzare i dati e di facilitare la stima dei parametri mediante MCMC.

\hypertarget{inference-reg-lin-stan}{%
\chapter{Inferenza sul modello lineare}\label{inference-reg-lin-stan}}

\hypertarget{rappresentazione-grafica-dellincertezza-della-stima}{%
\section{Rappresentazione grafica dell'incertezza della stima}\label{rappresentazione-grafica-dellincertezza-della-stima}}

Un primo modo per rappresentare l'incertezza dell'inferenza in un ottica bayesiana è quella di rappresentare graficamente la retta specificata dal modello lineare. Continuando con l'esempio descritto nel Capitolo precedente (ovvero, i dati \texttt{kid\_score} e \texttt{mom\_iq} centrati), usando la funzione \texttt{rstan::read\_stan\_csv} leggiamo i file CSV generati da \texttt{cmdstan} e trasformiamo le stime a posteriori dei parametri in formato \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit2}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\NormalTok{posterior }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(stanfit)}
\end{Highlighting}
\end{Shaded}

Creiamo ora un diagramma a dispersione dei dati con sovrapposto il valore atteso della \(y\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{kid\_score =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{mom\_iq =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_iq }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(mom\_iq, kid\_score)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}
    \AttributeTok{intercept =} \FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{alpha),}
    \AttributeTok{slope =} \FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-243-1} \end{center}

Un modo per visualizzare l'incertezza della stima della retta specifiata dal modello lineare è quello di tracciare molteplici rette, ciascuna delle quali definita da una diversa stima dei parametri \(\alpha\) e \(\beta\); le diverse stime dei parametri \(\alpha\) e \(\beta\) vengono estratta a caso dalle rispettive distribuzioni a posteriori.

Per ottenere questo risultato dobbiamo estrarre le informazioni richieste dall'oggetto \texttt{stanfit} che abbiamo creato. Per fare questo usiamo le funzionalità di \texttt{tidybayes}. Per esempio

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidybayes}\SpecialCharTok{::}\FunctionTok{get\_variables}\NormalTok{(stanfit)}
\CommentTok{\#\textgreater{}  [1] "alpha\_std"     "beta\_std"      "sigma\_std"    }
\CommentTok{\#\textgreater{}  [4] "alpha"         "beta"          "sigma"        }
\CommentTok{\#\textgreater{}  [7] "lp\_\_"          "accept\_stat\_\_" "treedepth\_\_"  }
\CommentTok{\#\textgreater{} [10] "stepsize\_\_"    "divergent\_\_"   "n\_leapfrog\_\_" }
\CommentTok{\#\textgreater{} [13] "energy\_\_"}
\end{Highlighting}
\end{Shaded}

Creiamo un Dataframe in formato tidy che contiene le stime a posteriori di \(\alpha\) e \(\beta\) nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{draws }\OtherTok{\textless{}{-}}\NormalTok{ stanfit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{spread\_draws}\NormalTok{(beta, alpha)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{draws }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 10 x 5}
\CommentTok{\#\textgreater{}   .chain .iteration .draw  beta alpha}
\CommentTok{\#\textgreater{}    \textless{}int\textgreater{}      \textless{}int\textgreater{} \textless{}int\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1      1          1     1 0.632  88.4}
\CommentTok{\#\textgreater{} 2      1          2     2 0.491  87.5}
\CommentTok{\#\textgreater{} 3      1          3     3 0.717  85.9}
\CommentTok{\#\textgreater{} 4      1          4     4 0.478  87.5}
\CommentTok{\#\textgreater{} 5      1          5     5 0.610  86.4}
\CommentTok{\#\textgreater{} 6      1          6     6 0.570  86.7}
\CommentTok{\#\textgreater{} 7      1          7     7 0.623  87.0}
\CommentTok{\#\textgreater{} 8      1          8     8 0.616  87.2}
\CommentTok{\#\textgreater{} \# ... with 2 more rows}
\end{Highlighting}
\end{Shaded}

Possiamo ora generare il diagramma a dispersione con \texttt{ggplot()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{kid\_score =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{mom\_iq =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_iq }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(mom\_iq, kid\_score)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}
    \AttributeTok{data =}\NormalTok{ draws, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{intercept =}\NormalTok{ alpha, }\AttributeTok{slope =}\NormalTok{ beta),}
    \AttributeTok{size =} \FloatTok{0.2}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.01}\NormalTok{, }\AttributeTok{color =} \StringTok{"darkgray"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_abline}\NormalTok{(}
    \AttributeTok{intercept =} \FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{alpha),}
    \AttributeTok{slope =} \FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Quoziente di intelligenza della madre"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Quoziente di intelligenza del bambino"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-247-1} \end{center}

Il grafico indica che le rette di regressione costruite estraendo a caso valori dalla distribuzione a posteriori dei parametri \(\beta_0\) e \(\beta_1\) tendono ad essere molto simili tra loro. Ciò significa che, relativamente alla dipendenza (lineare) del quoziente di intelligenza del bambino da quello della madra, l'incertezza è piccola (ovvero, la certezza è alta).

\hypertarget{intervalli-di-credibilituxe0}{%
\section{Intervalli di credibilità}\label{intervalli-di-credibilituxe0}}

L'incertezza inferenziale sui parametri può anche essere rappresentata mediante gli \emph{intervalli di credibilità}, ovvero gli intervalli che contengono la quota desiderata (es., il 95\%) della distribuzione a posteriori. Per l'esempio che stiamo discutendo, gli intervalli di credibilità al 95\% si ottengono nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rstantools}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}
  \FunctionTok{as.matrix}\NormalTok{(stanfit), }
  \AttributeTok{prob =} \FloatTok{0.95}
\NormalTok{)}
\CommentTok{\#\textgreater{}                 2.5\%      97.5\%}
\CommentTok{\#\textgreater{} alpha\_std   {-}0.08427    0.08442}
\CommentTok{\#\textgreater{} beta\_std     0.36137    0.53165}
\CommentTok{\#\textgreater{} sigma\_std    0.83903    0.96033}
\CommentTok{\#\textgreater{} alpha       85.07713   88.52021}
\CommentTok{\#\textgreater{} beta         0.49172    0.72343}
\CommentTok{\#\textgreater{} sigma       17.12519   19.60111}
\CommentTok{\#\textgreater{} lp\_\_      {-}173.15908 {-}168.54400}
\end{Highlighting}
\end{Shaded}

Un grafico che, nel caso dei dati standardizzati, riporta l'intervallo di credibilità ai livelli di probabilità desiderati per i parametri \(\alpha\), \(\beta\) e \(\sigma\) si ottiene con l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_areas}\NormalTok{(}
\NormalTok{  fit2}\SpecialCharTok{$}\FunctionTok{draws}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha\_std"}\NormalTok{, }\StringTok{"beta\_std"}\NormalTok{, }\StringTok{"sigma\_std"}\NormalTok{)),}
  \AttributeTok{prob =} \FloatTok{0.8}\NormalTok{,}
  \AttributeTok{prob\_outer =} \FloatTok{0.95}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-249-1} \end{center}

oppure nel modo nel modo seguente

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mcmc\_intervals}\NormalTok{(}
    \AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"alpha\_std"}\NormalTok{, }\StringTok{"beta\_std"}\NormalTok{, }\StringTok{"sigma\_std"}\NormalTok{),}
    \AttributeTok{prob =} \FloatTok{0.8}\NormalTok{,}
    \AttributeTok{prob\_outer =} \FloatTok{0.95}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-250-1} \end{center}

\hypertarget{quale-soglia-usare}{%
\subsection{Quale soglia usare?}\label{quale-soglia-usare}}

Non c'è niente di ``magico'' o necessario relativamente al livello di 0.95: il valore 0.95 è arbitrario. Sono possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l'obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza è descritta dall'\emph{intera} distribuzione a posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è semplicemente quello di riportare graficamente \emph{tutta} la distribuzione a posteriori. Una rappresentazione della distribuzione a posteriori dei parametri del modello dell'esempio si ottiene nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rstan}\SpecialCharTok{::}\FunctionTok{stan\_dens}\NormalTok{(}
\NormalTok{  stanfit,}
  \AttributeTok{pars =} \FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{),}
  \AttributeTok{fill =} \StringTok{"lightgray"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-251-1} \end{center}

\hypertarget{test-di-ipotesi}{%
\section{Test di ipotesi}\label{test-di-ipotesi}}

È facile valutare ipotesi direzionali usando Stan. Per esempio, la probabilità \(Pr(\hat{\beta}_1 > 0)\) è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

ovvero, la probabilità \(Pr(\hat{\beta}_1 < 0)\) è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta)}
\CommentTok{\#\textgreater{} [1] 0}
\end{Highlighting}
\end{Shaded}

\hypertarget{modello-lineare-robusto}{%
\section{Modello lineare robusto}\label{modello-lineare-robusto}}

Spesso i ricercatori devono affrontare il problema degli outlier: in presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produrrà delle stime distorte dei parametri, ovvero stime che non si generalizzano ad altri campioni di dati. Il metodo tradizionale per affrontare questo problema è quello di eliminare gli outlier prima di eseguire l'analisi statistica. Il problema di questo approccio, però, è che il criterio utilizzato per eliminare gli outlier, quale esso sia, è arbitrario; dunque, usando criteri diversi per la rimozione di outlier, i ricercatori finiscono per trovare risultati diversi.

Questo problema trova una semplice soluzione nell'approccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero \(\varepsilon \sim \mathcal{N}(0, \sigma_{\varepsilon})\). In un modello formulato in questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri.

Per fare un esempio, introduciamo un singlo valore anomalo e influente nel set dei dati dell'esempio che stiamo discutendo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df2 }\OtherTok{\textless{}{-}}\NormalTok{ df}
\NormalTok{df2}\SpecialCharTok{$}\NormalTok{kid\_score[}\DecValTok{434}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{500}
\NormalTok{df2}\SpecialCharTok{$}\NormalTok{mom\_iq[}\DecValTok{434}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{140}
\end{Highlighting}
\end{Shaded}

Per comodità, calcoliamo le stime di \(\alpha\) e \(\beta\) con il metodo dei minimi quadrati (tali stime sono simili a quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni a priori debolmente informative). Sappiamo che, nel campione originale di dati, \(\hat{\beta} \approx 0.6\). In presenza di un solo outlier troviamo la stima di \(\beta\) viene drammaticamente ridotta:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{lm}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_iq, }\AttributeTok{data =}\NormalTok{ df2) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{coef}\NormalTok{() }
\CommentTok{\#\textgreater{} (Intercept)      mom\_iq }
\CommentTok{\#\textgreater{}     49.1880      0.3626}
\end{Highlighting}
\end{Shaded}

In generale, però, non è necessario assumere \(\varepsilon \sim \mathcal{N}(0, \sigma_{\varepsilon})\). È altrettanto valido un modello che ipotizza una diversa distribuzione di densità per gli errori come, ad esempio, la distribuzione \(t\) di Student con un piccolo numero di gradi di libertà. Una caratteristica della \(t\) di Student è che le code della distribuzione contengono una massa di probabilità maggiore della distribuzione gaussiana. Ciò fornisce alla \(t\) di Student la possibilità di ``rendere conto'' della presenza di osservazioni lontane dalla media della distribuzione. In altri termini, se in modello lineare usiamo la \(t\) di Student quale distribuzione degli errori, la presenza di outlier avrà una minore influenza sulle stime dei parametri di quanto avvenga nel tradizionale modello lineare gaussiano.

Per verificare questa affermazione, modifichiamo il codice Stan usato in precedenza in modo tale da ipotizzare che \(y\) segua una distribuzione \(t\) di Student con un numero \(\nu\) gradi di libertà stimato dal modello: \texttt{student\_t(nu,\ mu,\ sigma)}.\footnote{È equivalente scrivere \(y_i = \mu_i + \varepsilon_i\), dove \(\mu_i = \alpha + \beta x_i, \varepsilon_i \sim \mathcal{N}(0, \sigma_\varepsilon),\) oppure \(y_i \sim \mathcal{N}(\mu_i, \sigma_\varepsilon).\)}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{\textless{}{-}} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] y;}
\StringTok{  vector[N] x;}
\StringTok{\}}
\StringTok{transformed data \{}
\StringTok{  vector[N] x\_std;}
\StringTok{  vector[N] y\_std;}
\StringTok{  x\_std = (x {-} mean(x)) / sd(x);}
\StringTok{  y\_std = (y {-} mean(y)) / sd(y);}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha\_std;}
\StringTok{  real beta\_std;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_std;}
\StringTok{  real\textless{}lower=1\textgreater{} nu;    // degrees of freedom is constrained \textgreater{}1}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha\_std \textasciitilde{} normal(0, 1);}
\StringTok{  beta\_std \textasciitilde{} normal(0, 1);}
\StringTok{  sigma\_std \textasciitilde{} normal(0, 1);}
\StringTok{  nu \textasciitilde{} gamma(2, 0.1);   // Juárez and Steel(2010)}
\StringTok{  y\_std \textasciitilde{} student\_t(nu, alpha\_std + beta\_std * x\_std, sigma\_std);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  real alpha;}
\StringTok{  real beta;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{  alpha = sd(y) * (alpha\_std {-} beta\_std * mean(x) / sd(x))}
\StringTok{           + mean(y);}
\StringTok{  beta = beta\_std * sd(y) / sd(x);}
\StringTok{  sigma = sd(y) * sigma\_std;}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/simpleregstdrobust.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Costruiamo la lista dei dati usando il data.frame \texttt{df2} che include l'outlier:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data3\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df2}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df2}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{x =}\NormalTok{ df2}\SpecialCharTok{$}\NormalTok{mom\_iq }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(df2}\SpecialCharTok{$}\NormalTok{mom\_iq)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello lineare robusto ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"simpleregstdrobust.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}

\NormalTok{fit4 }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data3\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Se esaminiamo le stime dei parametri notiamo che la stima di \(\beta\) non è stata influenzata dalla presenza di un'osservazione anomala e influente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit4}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{, }\StringTok{"nu"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 10}
\CommentTok{\#\textgreater{}   variable   mean median     sd    mad     q5    q95}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    87.8   87.8   0.901  0.898  86.3   89.3  }
\CommentTok{\#\textgreater{} 2 beta      0.602  0.602 0.0589 0.0587  0.505  0.699}
\CommentTok{\#\textgreater{} 3 sigma    15.9   15.9   0.800  0.803  14.6   17.2  }
\CommentTok{\#\textgreater{} 4 nu        5.58   5.46  1.15   1.09    3.93   7.64 }
\CommentTok{\#\textgreater{} \# ... with 3 more variables: rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

Il modello lineare robusto non risente dunque della presenza di outlier.

\hypertarget{commenti-e-considerazioni-finali-19}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-19}}


Nell'approccio bayesiano possiamo rappresentare l'incertezza delle nostre credenze a posteriori in due modi: mediante la rappresentazione grafica dell'intera distribuzione a posteriori dei parametri o mediante l'uso degli intervalli di credibilità. Un bonus della discussione del presente Capitolo è quello di mostrare come il modello lineare tradizionale (che assume \(\varepsilon \sim \mathcal{N}(0, \sigma_{\varepsilon})\)) possa essere facilmente esteso nei termini di un modello robusto che offre una semplice soluzione al problema di ridurre l'effetto della presenza di osservazioni outlier.

\hypertarget{comp-two-means-stan}{%
\chapter{Confronto tra due gruppi indipendenti}\label{comp-two-means-stan}}

Il problema del confronto tra due gruppi indipendenti può essere formulato nei termini di un modello lineare nel quale la variabile \(X\) è dicotomica, ovvero assume solo due valori.

\hypertarget{modello-lineare-con-una-variabile-dicotomica}{%
\section{Modello lineare con una variabile dicotomica}\label{modello-lineare-con-una-variabile-dicotomica}}

Se \(X\) è una variabile dicotomica con valori 0 e 1, allora per il modello lineare \(\mu_i = \alpha + \beta x_i\) abbiamo quanto segue. Quando \(x=0\), il modello diventa

\[
\mu_i = \alpha
\] mentre, quando \(x=1\), il modello diventa

\[
\mu_i = \alpha + \beta.
\]

Ciò significa che il parametro \(\alpha\) è uguale al valore atteso del gruppo codificato con \(X=0\) e il parametro \(\beta\) è uguale alla differenza tra le medie dei due gruppi (essendo la media del secondo gruppo uguale a \(\alpha + \beta\)). Il parametro \(\beta\), dunque, codifica l'effetto di una manipolazione sperimentale o di un trattamento, e l'inferenza su \(\beta\) corrisponde direttamente all'inferenza sull'efficacia di un trattamento o di un effetto sperimentale. L'inferenza su \(\beta\), dunque, viene utilizzata per capire quanto ``credibile'' può essere considerato l'effetto di un trattamento o di una manipolazione sperimentale.

\hypertarget{confronti-non-effetti}{%
\subsection{Confronti, non effetti}\label{confronti-non-effetti}}

Per ``effetto di un trattamento'' si intende la differenza tra le medie di due gruppi (per esempio, il gruppo ``sperimentale'' e il gruppo ``di controllo''). \citet{gelman2020regression} fanno notare come l'uso della terminologia ``effetto'' implica un modello causale: una variazione di \(X\) \emph{produce} una variazione di \(Y\). In generale, il modello lineare descrive una regolarità osservabile nel campione di dati. Ma questa regolarità (ovvero, la presenza di una relazione approssimativamente lineare tra \(X\) e \(Y\)) non ci dice nulla della presenza (o dell'assenza) di una relazione di causa/effetto tra queste variabili. L'associazione osservata tra le variabili \(X\) e \(Y\) potrebbe dipendere dall'effetto di una o più altre variabili non misurate, senza che tra \(X\) e \(Y\) ci sia alcuna relazione causale. In tali circostanze, l'interpretazione più appropriata dei coefficienti del modello lineare è quella che ci porta a pensare ai coefficienti del modello come ai risultati di un confronto. Nel caso presente, il confronto è quello tra il valore atteso del quoziente di intelligenza dei bambini, quando la madre ha oppure non ha completato il ciclo di istruzione secondaria superiore. Dato che l'affermazione precedente è formulata nei termini del valore atteso, questo significa che facciamo riferimento ad un campione di osservazioni. Niente viene detto della relazione \emph{causale} tra il quoziente di intelligenza del bambino e l'ottenimento del diploma di scuola superiore da parte della madre \emph{all'interno del singolo soggetto}. Quindi, quando usiamo il termine ``effetto'' dobbiamo sempre pensare a tale termine come come se fosse contenuto tra virgolette.

\hypertarget{un-esempio-concreto-1}{%
\subsection{Un esempio concreto}\label{un-esempio-concreto-1}}

Esaminiamo nuovamente i dati \texttt{kid\_score} discussi da \citet{gelman2020regression}. La domanda della ricerca è se il QI del figlio (misurato sulla scala PIAT) è associato al livello di istruzione della madre.

Codifichiamo il livello di istruzione della madre (\(x\)) con una \emph{variabile indicatrice} (ovvero, una variabile che assume solo i valori 0 e 1) tale per cui:

\begin{itemize}
\tightlist
\item
  \(x=0\): la madre non ha completato la scuola secondaria di secondo grado (scuola media superiore);
\item
  \(x=1\): la madre ha completato la scuola media superiore.
\end{itemize}

Supponiamo che i dati siano contenuti nel data.frame \texttt{df}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"rio"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Calcoliamo le statistiche descrittive per i due gruppi:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(mom\_hs) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{mean\_kid\_score =} \FunctionTok{mean}\NormalTok{(kid\_score),}
    \AttributeTok{std =} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(kid\_score))}
\NormalTok{  )}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 3}
\CommentTok{\#\textgreater{}   mom\_hs mean\_kid\_score   std}
\CommentTok{\#\textgreater{}    \textless{}dbl\textgreater{}          \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1      0           77.5  22.6}
\CommentTok{\#\textgreater{} 2      1           89.3  19.0}
\end{Highlighting}
\end{Shaded}

Il punteggio medio PIAT è pari a 77.5 per i bambini la cui madre non ha il diploma di scuola media superiore e pari a 89.3 per i bambini la cui madre ha completato la scuola media superiore. Questa differenza suggerisce un'associazione tra le variabili, ma tale differenza potrebbe essere soltanto la conseguenza della variabilità campionaria, senza riflettere una caratteristica generale della popolazione. Come possiamo usare il modello statistico lineare per fare inferenza sulla differenza osservata tra i due gruppi? Non dobbiamo fare nient'altro che usare il modello lineare che abbiamo definito in precedenza.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] y;}
\StringTok{  vector[N] x;}
\StringTok{\}}
\StringTok{transformed data \{}
\StringTok{  vector[N] x\_std;}
\StringTok{  vector[N] y\_std;}
\StringTok{  x\_std = (x {-} mean(x)) / sd(x);}
\StringTok{  y\_std = (y {-} mean(y)) / sd(y);}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha\_std;}
\StringTok{  real beta\_std;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_std;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha\_std \textasciitilde{} normal(0, 2);}
\StringTok{  beta\_std \textasciitilde{} normal(0, 2);}
\StringTok{  sigma\_std \textasciitilde{} cauchy(0, 2);}
\StringTok{  y\_std \textasciitilde{} normal(alpha\_std + beta\_std * x\_std, sigma\_std);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  real alpha;}
\StringTok{  real beta;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{  real cohen\_d;}
\StringTok{  alpha = sd(y) * (alpha\_std {-} beta\_std * mean(x) / sd(x))}
\StringTok{           + mean(y);}
\StringTok{  beta = beta\_std * sd(y) / sd(x);}
\StringTok{  sigma = sd(y) * sigma\_std;}
\StringTok{  cohen\_d = beta / sigma;}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/simpleregstd.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Come in precedenza, salviamo i dati in un oggetto di classe \texttt{list}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{x =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_hs}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Compiliamo il modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"simpleregstd.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

Adattiamo il modello ai dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Creiamo un grafico con i valori predetti dal modello lineare:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\NormalTok{posterior }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(stanfit)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{kid\_score =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{kid\_score,}
  \AttributeTok{mom\_hs =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_hs}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(mom\_hs, kid\_score)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{geom\_abline}\NormalTok{(}\AttributeTok{intercept =} \FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{alpha), }
              \AttributeTok{slope =} \FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta)) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \StringTok{"Quoziente di intelligenza del bambino"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"Diploma di istruzione secondaria di secondo grado della madre}\SpecialCharTok{\textbackslash{}n}\StringTok{(0 = no; 1 = sì)"}
\NormalTok{  ) }\SpecialCharTok{+} 
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-267-1} \end{center}

Le stime a posteriori dei parametri si ottengono con:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{, }\StringTok{"cohen\_d"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 10}
\CommentTok{\#\textgreater{}   variable   mean median    sd   mad     q5    q95}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    77.6   77.5   2.08  2.06  74.1   81.0  }
\CommentTok{\#\textgreater{} 2 beta     11.8   11.7   2.35  2.34   7.88  15.6  }
\CommentTok{\#\textgreater{} 3 sigma    19.9   19.9   0.676 0.671 18.8   21.0  }
\CommentTok{\#\textgreater{} 4 cohen\_d   0.592  0.591 0.120 0.119  0.393  0.788}
\CommentTok{\#\textgreater{} \# ... with 3 more variables: rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

I risultati confermano ciò che ci aspettavamo:

\begin{itemize}
\tightlist
\item
  il coefficiente \(\texttt{alpha} = 77.56\) corrisponde alla media del gruppo codificato con \(x = 0\), ovvero la media dei punteggi PIAT per i bambini la cui madre non ha completato la scuola media superiore;
\item
  il coefficiente \(\texttt{beta} = 11.76\) corrisponde alla differenza tra le medie dei due gruppi, ovvero 89.32 - 77.55 = 11.77 (con piccoli errori di approssimazione).
\end{itemize}

La seguente chiamata ritorna l'intervallo di credibilità al 95\% per tutti i parametri del modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rstantools}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}
  \FunctionTok{as.matrix}\NormalTok{(stanfit), }\AttributeTok{prob =} \FloatTok{0.95}
\NormalTok{)}
\CommentTok{\#\textgreater{}                 2.5\%      97.5\%}
\CommentTok{\#\textgreater{} alpha\_std   {-}0.09402    0.09248}
\CommentTok{\#\textgreater{} beta\_std     0.14361    0.32886}
\CommentTok{\#\textgreater{} sigma\_std    0.91337    1.04372}
\CommentTok{\#\textgreater{} alpha       73.43237   81.62095}
\CommentTok{\#\textgreater{} beta         7.13511   16.33961}
\CommentTok{\#\textgreater{} sigma       18.64259   21.30291}
\CommentTok{\#\textgreater{} cohen\_d      0.35667    0.82770}
\CommentTok{\#\textgreater{} lp\_\_      {-}208.90605 {-}204.32400}
\end{Highlighting}
\end{Shaded}

Possiamo dunque concludere che i bambini la cui madre ha completato la scuola superiore ottengono in media circa 12 punti in più rispetto ai bambini la cui madre non ha completato la scuola superiore. L'intervallo di credibilità al 95\% ci dice che possiamo essere sicuri al 95\% che tale differenza sia di almeno 7 punti e possa arrivare fino a ben 16 punti. Per riassumere, possiamo concludere, con un grado di certezza soggettiva del 95\%, che c'è un'associazione positiva tra il livello di scolarità della madre e l'intelligenza del bambino: le madri che hanno livello di istruzione più alto della media tendo ad avere bambini il cui QI è anch'esso più alto della media.

\hypertarget{la-dimensione-delleffetto}{%
\section{La dimensione dell'effetto}\label{la-dimensione-delleffetto}}

Nel caso di due gruppi indipendenti, la dimensione dell'effetto si può stimare con la statistica \(d\) di Cohen:

\[
d={\frac {{\bar {y}}_{1}-{\bar {y}}_{2}}{s}}.
\]

Nel caso presente, la differenza \({\bar {y}}_{1}-{\bar {y}}_{2}\) corrisponde a al parametro \(\beta\) del modello lineare. Inoltre, una stima della deviazione starndard comune dei due gruppi è fornita dalla deviazione standard della regressione, ovvero dal parametro \(\sigma\). Nel blocco \texttt{generated\ quantities} del modello Stan ho calcolato \texttt{cohen\_d\ =\ beta\ /\ sigma}. Ciò significa che Stan calcolerà la distribuzione a posteriori del parametro \texttt{cohen\_d}. Possiamo dunque riassumere la distribuzione a posteriori di \texttt{cohen\_d} con un qualche indice di tendenza centrale (che sarà la nostra stima della dimensione dell'effetto) e calcolare l'intervallo di credibilità, per esempio al 95\%. Questi risultati si ottengono con l'istruzione riportata di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior}\SpecialCharTok{::}\FunctionTok{summarise\_draws}\NormalTok{(}
\NormalTok{  stanfit,}
  \SpecialCharTok{\textasciitilde{}} \FunctionTok{quantile}\NormalTok{(.x, }\AttributeTok{probs =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.975}\NormalTok{))}
\NormalTok{)}
\CommentTok{\#\textgreater{} \# A tibble: 8 x 4}
\CommentTok{\#\textgreater{}   variable     \textasciigrave{}2.5\%\textasciigrave{}       \textasciigrave{}50\%\textasciigrave{}   \textasciigrave{}97.5\%\textasciigrave{}}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}         \textless{}dbl\textgreater{}       \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha\_std   {-}0.0940   {-}0.000366    0.0925}
\CommentTok{\#\textgreater{} 2 beta\_std     0.144     0.236       0.329 }
\CommentTok{\#\textgreater{} 3 sigma\_std    0.913     0.974       1.04  }
\CommentTok{\#\textgreater{} 4 alpha       73.4      77.5        81.6   }
\CommentTok{\#\textgreater{} 5 beta         7.14     11.7        16.3   }
\CommentTok{\#\textgreater{} 6 sigma       18.6      19.9        21.3   }
\CommentTok{\#\textgreater{} 7 cohen\_d      0.357     0.591       0.828 }
\CommentTok{\#\textgreater{} 8 lp\_\_      {-}209.     {-}205.       {-}204.}
\end{Highlighting}
\end{Shaded}

I risultati dell'analisi bayesiana coincidono con quelli che si ottengono utilizzando la formula del \(d\) di Cohen con le medie dei due gruppi e una stima della varianza \emph{pooled}. Il calcolo della statistica \(d\) di Cohen è fornita, ad esempio, dal pacchetto \texttt{effectsize}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"effectsize"}\NormalTok{)}
\NormalTok{(d }\OtherTok{\textless{}{-}} \FunctionTok{cohens\_d}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_hs, }\AttributeTok{data =}\NormalTok{ df))}
\CommentTok{\#\textgreater{} Cohen\textquotesingle{}s d |         95\% CI}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} {-}0.59     | [{-}0.83, {-}0.36]}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} {-} Estimated using pooled SD.}
\end{Highlighting}
\end{Shaded}

Il fatto che l'output abbia un segno negativo dipende dal fatto che è stata sottratta la media maggiore dalla media minore (in altri termini, dobbiamo guardare il risultato in valore assoluto).

In conclusione, il valore \(d\) di Cohen di entità ``media'' {[}\(d\) \textgreater{} 0.5; \citet{sawilowsky2009new}{]} può essere interpretato dicendo che la scolarità delle madri ha un'influenza non trascurabile sul QI dei bambini.

\hypertarget{commenti-e-considerazioni-finali-20}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-20}}


La dimensione dell'effetto formulata nei termini dell'indice \(d\) di Cohen fornisce un indice che non dipende dall'unità di misura delle variabili, ovvero è una differenza media standardizzata. L'intrepretazione di \(d\) è semplice: la scala di \(d\) è la deviazione standard. Se, per esempio, \(d = 0.5\), allora la media di un primo gruppo è mezza deviazione standard più grande della media del secondo gruppo. In questo Capitolo abbiamo visto come \(d\) possa essere calcolato mediante un modello lineare bayesiano implementato in linguaggio Stan.

\hypertarget{ch-pred-checks}{%
\chapter{Predictive checks}\label{ch-pred-checks}}

Nel Capitolo \ref{chapter-ppc} abbiamo visto come si genera la distribuzione predittiva a posteriori nel caso del modello più semplice: quello di un'unica variabile con una data distribuzione di probabilità. In questo capitolo estenderemo questa discussione al modello lineare. Esamineremo un esempio di \emph{posterior predictive check} in cui simuleremo da \(p(y^{rep} \mid \theta, y)\), usando le stime a posteriori dei parametri \(\theta\) del modello, e un esempio di \emph{prior predictive check} in cui simuleremo da \(p(y^{rep} \mid \mathcal{M})\), ovvero usando il meccanismo generatore dei dati del modello \(\mathcal{M}\) in esame, senza però includere i dati.

\hypertarget{campionamento-dalla-distribuzione-predittiva-a-posteriori}{%
\section{Campionamento dalla distribuzione predittiva a posteriori}\label{campionamento-dalla-distribuzione-predittiva-a-posteriori}}

La distribuzione predittiva a priori equivale alla distribuzione predittiva a posteriori, senza però i dati osservati. Quindi la distribuzione predittiva a priori non è altro che il caso limite della distribuzione predittiva a posteriori, calcolata però senza utilizzare i dati del campione. Il manuale Stan afferma che, se il codice per il il controllo predittivo a posteriori è già stato scritto, ed è possibile impostare il codice in modo che non sia necessario specificare i dati, allora non è necessario fare nient'altro.

Consideriamo qui un esempio nel quale vengono usati i dati \texttt{kidiq} \citep{gelman2020regression}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"rio"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Iniziamo a generare un istogramma dei valori \(y\) stanardizzati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\FunctionTok{scale}\NormalTok{(kid\_score)[, }\DecValTok{1}\NormalTok{])) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-273-1} \end{center}

Per svolgere l'analisi bayesiana sistemiamo i dati (standardizzati) nel formato appropriato per Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{x =} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)[, }\DecValTok{1}\NormalTok{],}
  \AttributeTok{y =} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score)[, }\DecValTok{1}\NormalTok{]}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Il seguente listato specifica il codice Stan necessario per simulare dati dalla distribuzione predittiva a posteriori.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stancode }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;  }
\StringTok{  vector[N] x; }
\StringTok{  vector[N] y; }
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} normal(0, 1);}
\StringTok{  y \textasciitilde{} normal(alpha + beta * x, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  for(i in 1:N)\{}
\StringTok{    y\_rep[i] = normal\_rng(alpha + beta * x[i], sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{\textquotesingle{}}
\FunctionTok{writeLines}\NormalTok{(stancode, }\AttributeTok{con =} \StringTok{"code/post\_pred\_check\_1.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"post\_pred\_check\_1.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit1 }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Un istogramme dei valori \(y^{rep}\) può essere generato nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(stanfit1, }\AttributeTok{pars =} \StringTok{"y\_rep"}\NormalTok{), }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-279-1} \end{center}

\hypertarget{campionamento-dalla-distribuzione-predittiva-a-priori}{%
\section{Campionamento dalla distribuzione predittiva a priori}\label{campionamento-dalla-distribuzione-predittiva-a-priori}}

Per comprendere le assunzioni che abbiamo introdotto nel modello, possiamo generare dati mediante il modello; tali dati, che sono generati interamente dalle distribuzioni a priori, sono chiamati distribuzione predittiva a priori. La generazione della distribuzione predittiva a priori ci aiuta a verificare se le distribuzioni a priori per i parametri del modello hanno senso. Quello che vogliamo sapere qui è: le distribuzioni a priori che abbiamo scelto generano dati che hanno caratteristiche realistiche?

Dal punto di vista della programmazione, l'unico cambiamento necessario rispetto al codice utilizzato per la distribuzione predittiva a posteriori è quello di eliminare la porzione di codice che fa riferimento ai dati \(y\) -- nel caso di un modello lineare, i valori \(x\) devono invece essere mantenuti per potere generare \(y^{sim}\) (nel codice questa variabile è ancora chiamata \texttt{y\_rep}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{x =} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)[, }\DecValTok{1}\NormalTok{]}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stancode }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;  }
\StringTok{  vector[N] x; }
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} normal(0, 1);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  for(i in 1:N)\{}
\StringTok{    y\_rep[i] = normal\_rng(alpha + beta * x[i], sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{\textquotesingle{}}
\FunctionTok{writeLines}\NormalTok{(stancode, }\AttributeTok{con =} \StringTok{"code/prior\_pred\_check\_1.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"prior\_pred\_check\_1.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit2 }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Questo è un istogramma della distribuzione preditiva a priori. Tale distribuzione viene usata per valutare se le distribuzioni a priori dei parametri sono sensate. Concludiamo che sono sensate se la distribuzione preditiva a priori include tutti i valori possibili della distribuzione della \(y\), senza scostarsti troppo da essa.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(}\FunctionTok{as.matrix}\NormalTok{(stanfit2, }\AttributeTok{pars =} \StringTok{"y\_rep"}\NormalTok{), }\AttributeTok{breaks =} \DecValTok{100}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-285-1} \end{center}

\hypertarget{commenti-e-considerazioni-finali-21}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-21}}


I due \emph{predictive checks} che abbiamo esaminato in questo capitolo servono due scopi diversi.

La distribuzione predittiva a priori viene utilizzata per comprendere le assunzioni introdotte nel modello. Per fare questo possiamo generare dei dati dal modello. Tali dati, che vengono prodotti interamente dalle distribuzioni a priori, sono chiamati distribuzione predittiva a priori. La distribuzione predittiva a priori ci aiuta a capire se le distribuzioni a priori per i parametri del modello hanno un senso. Quello che ci chiedimo è: le distribuzioni a priori generano dei dati che hanno caratteristiche realistiche? Una risposta affermativa a tale domanda corrisponde ad una distribuzione predittiva a priori che è più ampia della distribuzione dei dati osservati, in linea con il principio dei prior debolmente informativi. Tale distribuzione dovrebbe avere almeno una qualche massa nell'intorno ai valori estremi, ma plausibili dei dati; non dovrebbe, invece, esserci massa in corrispondenza di valori di dati completamente implausibili.

La distribuzione predittiva a posteriori viene invece utilizzata per esplorare le caratteristiche che potrebbero avere i possibili dati futuri. L'idea alla base del controllo predittivo a posteriori è semplice: se un modello è appropriato, dovremmo essere in grado di usarlo per generare dati che assomigliano ai dati che abbiamo osservato nel campione. La motivazione è simile a quella che ci ha condotto alla distribuzione predittiva a priori, tranne per il fatto che ora abbiamo un modello generativo dei dati basato sui dati osservati.

\hypertarget{ch-anova}{%
\chapter{\texorpdfstring{Confronto di \(k\) gruppi}{Confronto di k gruppi}}\label{ch-anova}}

L'Analisi della Varianza (ANOVA) consente ai ricercatori di valutare gli effetti di predittori categoriali su una variabile di esito continua. L'ANOVA è un'analisi di regressione nella quale tutte le variabili indipendenti sono qualitative.

\hypertarget{le-abilituxe0-sociali-di-un-robot}{%
\section{Le abilità sociali di un robot}\label{le-abilituxe0-sociali-di-un-robot}}

Per illustrare i concetti chiave dell'ANOVA bayesiana considereremo qui una ricerca di \citet{horstmann2018robot}. I ricercatori si sono chiesti se le persone impiegano più tempo a spegnere un robot quando questo mostra abilità sociali. Nell'esperimento di \citet{horstmann2018robot}, 85 partecipanti hanno interagito con un robot per un certo tempo. Ai partecipanti è stato detto che lo scopo della loro interazione con il robot era quella di testare un nuovo algoritmo. Dopo il completamento di due compiti fittizi, ai partecipanti veniva detto che, se volevano, potevano spegnere il robot. La variabile di interesse dell'esperimento era il tempo impiegato dai partecipanti per spegnere il robot. Seguendo \citet{van2020tutorial}, analizzeremo i tempi di spegnimento trasformati su scala logaritmica perché tale variabile mostra una chiara asimmetria positiva.

\citet{horstmann2018robot} hanno manipolato due variabili in un disegno tra i soggetti.

\begin{itemize}
\tightlist
\item
  \emph{Interaction type}. Le risposte verbali dei robot potevano essere o sociali (ad esempio, ``Oh sì, la pizza è ottima. Una volta ho mangiato una pizza grande come me.'') o funzionali (ad esempio, ``Preferisci la pizza. Ha funzionato bene. Continuiamo.'').
\item
  \emph{Robot's objection}. Il robot poteva protestare quando stava per essere spento (ad esempio, ``No! Per favore, non spegnermi! Ho paura di non riuscire ad accendermi di nuovo!'') oppure no.
\end{itemize}

Pertanto, il disegno di questo studio è un'ANOVA tra i soggetti 2 (\emph{Interaction type}) \(\times\) 2 (\emph{Robot's objection}).

Iniziamo a leggere i dati

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(}
  \FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"pone.0201581.s001.sav"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Per comodità creiamo la variabile \texttt{cond} con quattro modalità (\texttt{SO}, \texttt{FO}, \texttt{SN}, \texttt{FN}), dove \texttt{S} significa \emph{social interaction}, \texttt{F} sta per \emph{funcitonal interaction}, \texttt{O} sta per \emph{objection} e \texttt{N} sta per \emph{no objection}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d}\SpecialCharTok{$}\NormalTok{cond }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{Condition)}

\NormalTok{d}\SpecialCharTok{$}\NormalTok{cond }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}
\NormalTok{  d}\SpecialCharTok{$}\NormalTok{cond, }
  \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"SO"}\NormalTok{, }\StringTok{"FO"}\NormalTok{, }\StringTok{"SN"}\NormalTok{, }\StringTok{"FN"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Ci sono alcuni dati mancanti, quindi verranno omesse le righe con \texttt{NA}. Selezionando le colonne di interesse dal data.frame originario otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dd }\OtherTok{\textless{}{-}}\NormalTok{ d }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(cond, SwitchOff\_Time) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{na.omit}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Nelle quattro condizioni si osservano le seguenti medie \citep[si veda la Tabella 3 di][]{horstmann2018robot}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dd }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(cond) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{avg\_sot =} \FunctionTok{mean}\NormalTok{(SwitchOff\_Time, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{),}
    \AttributeTok{sd\_sot =} \FunctionTok{sd}\NormalTok{(SwitchOff\_Time, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  )}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 3}
\CommentTok{\#\textgreater{}   cond  avg\_sot sd\_sot}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{}   \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 SO       6.19   4.61}
\CommentTok{\#\textgreater{} 2 FO      14.4   15.4 }
\CommentTok{\#\textgreater{} 3 SN       5.05   2.18}
\CommentTok{\#\textgreater{} 4 FN       4.28   2.49}
\end{Highlighting}
\end{Shaded}

Visualizziamo i dati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dd\_summary }\OtherTok{\textless{}{-}}\NormalTok{ dd }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(cond) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}
    \AttributeTok{sot\_mean =} \FunctionTok{mean}\NormalTok{(SwitchOff\_Time),}
    \AttributeTok{sot\_sd =} \FunctionTok{sd}\NormalTok{(SwitchOff\_Time),}
    \AttributeTok{sot\_median =} \FunctionTok{median}\NormalTok{(SwitchOff\_Time)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}

\NormalTok{dd }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ cond, }\AttributeTok{y =}\NormalTok{ SwitchOff\_Time, }\AttributeTok{color =}\NormalTok{ cond)}
\NormalTok{  ) }\SpecialCharTok{+}
\NormalTok{  ggforce}\SpecialCharTok{::}\FunctionTok{geom\_sina}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{color =}\NormalTok{ cond, }\AttributeTok{size =} \DecValTok{3}\NormalTok{, }\AttributeTok{alpha =}\NormalTok{ .}\DecValTok{5}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{geom\_errorbar}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}
      \AttributeTok{y =}\NormalTok{ sot\_median, }\AttributeTok{ymin =}\NormalTok{ sot\_median,}
      \AttributeTok{ymax =}\NormalTok{ sot\_median}
\NormalTok{    ),}
    \AttributeTok{data =}\NormalTok{ dd\_summary, }\AttributeTok{width =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{size =} \DecValTok{3}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_grey}\NormalTok{(}\AttributeTok{name =} \StringTok{"cond"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{""}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"SwitchOff Time"}\NormalTok{,}
    \AttributeTok{color =} \StringTok{"Condizione"}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-290-1} \end{center}

Su scala logaritmica, l'asimmetria positiva della variabile \texttt{dd\$SwitchOff\_Time} viene ridotta.

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-291-1} \end{center}

Per i dati trasformati, la mediana in ciascuna condizione è:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dd}\SpecialCharTok{$}\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(dd}\SpecialCharTok{$}\NormalTok{SwitchOff\_Time }\SpecialCharTok{+} \FloatTok{0.01}\NormalTok{)}
\NormalTok{dd }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(cond) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{avg\_y =} \FunctionTok{median}\NormalTok{(y)}
\NormalTok{  )}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 2}
\CommentTok{\#\textgreater{}   cond  avg\_y}
\CommentTok{\#\textgreater{}   \textless{}fct\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 SO     1.61}
\CommentTok{\#\textgreater{} 2 FO     2.01}
\CommentTok{\#\textgreater{} 3 SN     1.39}
\CommentTok{\#\textgreater{} 4 FN     1.39}
\end{Highlighting}
\end{Shaded}

Creiamo ora la variabile \texttt{x} che indicizza le quattro condizioni (la variabile \texttt{x} verrà usata nel modello Stan):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dd}\SpecialCharTok{$}\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(dd}\SpecialCharTok{$}\NormalTok{cond)}
\FunctionTok{head}\NormalTok{(dd)}
\CommentTok{\#\textgreater{}   cond SwitchOff\_Time     y x}
\CommentTok{\#\textgreater{} 3   SN              6 1.793 3}
\CommentTok{\#\textgreater{} 4   FO              7 1.947 2}
\CommentTok{\#\textgreater{} 5   FO              3 1.102 2}
\CommentTok{\#\textgreater{} 6   FN              4 1.389 4}
\CommentTok{\#\textgreater{} 7   FN              4 1.389 4}
\CommentTok{\#\textgreater{} 8   FO             12 2.486 2}
\end{Highlighting}
\end{Shaded}

Il modello bayesiano che usiamo qui per il confronto tra le medie dei quattro gruppi è una semplice estensione del modello per la media di un solo gruppo. Il codice usato è ispirato da quello fornito nella seguente \href{http://avehtari.github.io/BDA_R_demos/demos_rstan/rstan_demo.html\#8_Comparison_of_(k)_groups_with_hierarchical_models}{pagina web}. Per adattare un modello ``robusto'', ipotizzeremo che la \texttt{y} segua una distribuzione \(t\) di Student con un numero di gradi di libertà stimato dal modello.

Il modello classico dell'ANOVA è basato sulle seguenti assunzioni:

\begin{itemize}
\tightlist
\item
  i residui (cioè la differenza tra il valore dell'\(i\)-esima osservazione e la media di tutte le osservazioni nella \(k\)-esima condizione) devono seguire la distribuzione normale (normalità);
\item
  i residui devono avere la stessa deviazione standard nelle \(k\) popolazioni da cui abbiamo estratto i dati (omoschedasticità);
\item
  il disegno sperimentale utilizzato per raccogliere i dati deve garantire l'indipendenza dei residui.
\end{itemize}

Nella presenta formulazione dell'ANOVA bayesiana, l'assunto di normalità non è richiesto, mentre devono essere soddisfatte le condizioni di omoschedasticità e indipendenza. L'ANOVA bayesiana può comunque essere estesa a condizioni che violano sia l'assunto di omoschedasticità sia quello di indipendenza. Ma qui ci limitiamo a discutere il caso più semplice.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{// Comparison of k groups with common variance (ANOVA)}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;            // number of observations}
\StringTok{  int\textless{}lower=0\textgreater{} K;            // number of groups}
\StringTok{  int\textless{}lower=1,upper=K\textgreater{} x[N]; // discrete group indicators}
\StringTok{  vector[N] y;               // real valued observations}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  vector[K] mu;        // group means}
\StringTok{  real\textless{}lower=0\textgreater{} sigma; // common standard deviation }
\StringTok{  real\textless{}lower=1\textgreater{} nu; }
\StringTok{\}}
\StringTok{model \{}
\StringTok{  mu \textasciitilde{} normal(0, 2);      // weakly informative prior}
\StringTok{  sigma \textasciitilde{} normal(0, 1);     // weakly informative prior}
\StringTok{  nu \textasciitilde{} gamma(2, 0.1);   // Juárez and Steel(2010)}
\StringTok{  y \textasciitilde{} student\_t(nu, mu[x], sigma); // observation model / likelihood}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/grp\_aov.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Creiamo un oggetto che contiene i dati nel formato appropriato per Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data\_grp }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{nrow}\NormalTok{(dd),}
  \AttributeTok{K =} \DecValTok{4}\NormalTok{,}
  \AttributeTok{x =}\NormalTok{ dd}\SpecialCharTok{$}\NormalTok{x,}
  \AttributeTok{y =}\NormalTok{ dd}\SpecialCharTok{$}\NormalTok{y}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Compiliamo il modello:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"grp\_aov.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

Eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_grp,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Esaminando i risultati

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{()}
\CommentTok{\#\textgreater{} \# A tibble: 7 x 10}
\CommentTok{\#\textgreater{}   variable    mean  median     sd    mad      q5}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 lp\_\_     {-}41.2   {-}40.9   1.85   1.69   {-}44.7  }
\CommentTok{\#\textgreater{} 2 mu[1]      1.69    1.68  0.175  0.170    1.41 }
\CommentTok{\#\textgreater{} 3 mu[2]      2.05    2.05  0.196  0.196    1.73 }
\CommentTok{\#\textgreater{} 4 mu[3]      1.52    1.52  0.122  0.120    1.32 }
\CommentTok{\#\textgreater{} 5 mu[4]      1.28    1.28  0.125  0.121    1.07 }
\CommentTok{\#\textgreater{} 6 sigma      0.476   0.472 0.0753 0.0736   0.358}
\CommentTok{\#\textgreater{} 7 nu         2.55    2.41  0.821  0.724    1.49 }
\CommentTok{\#\textgreater{} \# ... with 4 more variables: q95 \textless{}dbl\textgreater{}, rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

ci rendiamo conto che cìè una buona corrispondenza tra le medie a posteriori e le medie campionarie. Trasformiamo l'oggetto \texttt{fit} in un oggetto di classe \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

La funzione \texttt{rstan::extract()} estrae i campioni a posteriori da un oggetto di classe \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(stanfit, }\AttributeTok{permuted =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Una rappresentazione grafica della distribuzione a posteriori delle quattro medie si ottiene con le seguenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{temps }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{setNames}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}SO\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}FO\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}SN\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}FN\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mcmc\_areas}\NormalTok{(temps, }\AttributeTok{prob =} \FloatTok{0.95}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{xlab}\NormalTok{(}\StringTok{\textquotesingle{}Gruppi\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-302-1} \end{center}

I quattro intervalli di credibilità al 95\% sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ci95 }\OtherTok{\textless{}{-}}\NormalTok{ rstanarm}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}
  \FunctionTok{as.matrix}\NormalTok{(stanfit), }
  \AttributeTok{prob =} \FloatTok{0.95}
\NormalTok{)}
\FunctionTok{round}\NormalTok{(ci95, }\DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{}         2.5\%  97.5\%}
\CommentTok{\#\textgreater{} mu[1]   1.36   2.05}
\CommentTok{\#\textgreater{} mu[2]   1.67   2.44}
\CommentTok{\#\textgreater{} mu[3]   1.28   1.76}
\CommentTok{\#\textgreater{} mu[4]   1.03   1.53}
\CommentTok{\#\textgreater{} sigma   0.34   0.63}
\CommentTok{\#\textgreater{} nu      1.37   4.56}
\CommentTok{\#\textgreater{} lp\_\_  {-}45.67 {-}38.67}
\end{Highlighting}
\end{Shaded}

\hypertarget{anova-stan}{%
\section{I test statistici dell'Analisi della Varianza}\label{anova-stan}}

L'ANOVA include test statistici di due tipi: i test sull'interazione tra i fattori e i test sugli effetti principali. Per chiarire il significato di ``interazione'' e di ``effetto principale'' è necessario prima definire il significato di ``effetto statistico''.

\begin{definition}
L'effetto di un fattore rappresenta la variazione media della variabile dipendente al variare dei livelli del fattore stesso.
\end{definition}

\begin{definition}
Si parla di interazione quando l'effetto di un fattore sulla variabile dipendente varia a seconda dei livelli di un altro fattore.
\end{definition}

Vengono presentati qui di seguito alcuni esempi. Le figure seguenti mostrano le medie di ciascuna condizione nel caso di un disegno 3 (fattore riga) \(\times\) 2 (fattore colonna). La spiegazione delle figure è presentata nelle didascalie.

\begin{figure}[h]

{\centering \includegraphics{images/anova1} 

}

\caption{Il fattore colonna è indicato dal colore. **Sinistra** La figura mostra un effetto principale del fattore riga e un effetto principale del fattore colonna. Non c'è interazione tra i fattori riga e colonna. **Destra** La figura mostra un effetto principale del fattore riga. L'effetto principale del fattore colonna è zero. Non c'è interazione tra i fattori riga e colonna.}\label{fig:fig-anova1}
\end{figure}

\begin{figure}[h]

{\centering \includegraphics{images/anova2} 

}

\caption{Il fattore colonna è indicato dal colore. **Sinistra** La figura mostra che l'effetto principale del fattore riga è zero, mentre c'è un effetto principale del fattore colonna. Non c'è interazione tra i fattori riga e colonna. **Destra** Non c'è né un effetto principale del fattore riga, né un effetto pricipale del fattore colonna, né un'interazione tra i fattori riga e colonna.}\label{fig:fig-anova2}
\end{figure}

\begin{figure}[h]

{\centering \includegraphics{images/anova3} 

}

\caption{Il fattore colonna è indicato dal colore. Entrambe le figure mostrano un'interazione tra i fattori riga e colonna. Nella figura di sinistra gli effetti principali non sono interpretabili; nella figura di destra gli effetti principali sono interpretabili in quanto l'interazione è di lieve entità.}\label{fig:fig-anova3}
\end{figure}

Dagli esempi precedenti si evince che c'è un'interazione ogni qualvolta i profili delle medie non sono paralleli. Anche se, nella popolazione, non c'è interazione, a causa della variabilità campionaria i profili delle medie non sono mai perfettamente paralleli nel campione. Il problema è quello di stabilire se l'assenza di parallelismo nel campione fornisce sufficiente evidenza di presenza di interazione nella popolazione.

\hypertarget{test-sullinterazione}{%
\subsection{Test sull'interazione}\label{test-sullinterazione}}

Ritorniamo ora ai dati di \citet{horstmann2018robot}. Nel caso di un disegno 2 \(\times\) 2, con i fattori \emph{Interaction type} (social, functional) e \emph{Robot's objection} (objection, no objection), è possibile verificare la presenza dell'interazione \emph{Interaction type} \(\times\) \emph{Robot's objection}.

Nel modello bayesiano, la distribuzione a posteriori fornisce un enorme numero di stime del valore della media in ciascuna delle quattro condizioni. L'effetto di un fattore corrisponde alla differenza tra le stime della media in corrispondenza di ciascuna modalità del fattore.

Nel caso presente abbiamo:

\begin{itemize}
\tightlist
\item
  \texttt{mu{[}1{]}} \(\rightarrow\) SO
\item
  \texttt{mu{[}2{]}} \(\rightarrow\) FO
\item
  \texttt{mu{[}3{]}} \(\rightarrow\) SN
\item
  \texttt{mu{[}4{]}} \(\rightarrow\) FN
\end{itemize}

Quindi, \texttt{mean(posterior\$mu{[},\ 1{]}\ -\ posterior\$mu{[},\ 3{]})} corrisponde alla stima a posteriori dell'effetto di \emph{Objection} nella condizione \emph{Social Interaction}. Invece, \texttt{mean(posterior\$mu{[},\ 2{]}\ -\ posterior\$mu{[},\ 3{]})} corrisponde alla stima a posteriori dell'effetto di \emph{Objection} nella condizione \emph{Functional Interaction}. In assenza di interazione, questi due effetti devono essere (statisticamente) uguali.

Per sottoporre a verifica questa ipotesi, calcoliamo la proporzione di volte in cui questo \emph{non} si verifica nella distribuzione a posteriori:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}
\NormalTok{  (posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{3}\NormalTok{]) }\SpecialCharTok{\textgreater{}} 
\NormalTok{    (posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{{-}}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{4}\NormalTok{])}
\NormalTok{  ) }\SpecialCharTok{/} 
  \FunctionTok{length}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 0.03144}
\end{Highlighting}
\end{Shaded}

La stima di questa probabilità in un test direzionale è molto simile alla probabilità frequentista riportata da \citet{horstmann2018robot}, ovvero \(p = 0.016\). \citet{horstmann2018robot} riportano la presenza di un'interazione tra \emph{Interaction type} e \emph{Robot's objection} (com'è stato anche trovato con la presente ANOVA bayesiana). Per interpretare l'interazione è necessario esaminare le mediane dei quattro gruppi.\footnote{In presenza di outlier la mediana fornisce una misura di tenenza centrale più robusta della media.} L'esame delle mediane indica che l'effetto del fattore \emph{Robot's objection} è più grande quando il fattore \emph{Interaction type} assume la modalità \emph{Functional} piuttosto che \emph{Social}. Ma possiamo anche leggere l'interazione nella direzione opposta: l'effetto del fattore \emph{Interaction type} è più grande quando il fattore \emph{Robot's objection} assume la modalità \emph{Objection} anziché \emph{No objection}.

\hypertarget{test-sugli-effetti-principali}{%
\subsection{Test sugli effetti principali}\label{test-sugli-effetti-principali}}

L'effetto principale descrive l'effetto marginale di un fattore. Nel caso presente, in cui ciascun fattore ha solo due modalità, l'effetto principale corrisponde alla differenze tra le medie delle modalità di ciascun fattore.

L'effetto principale del fattore \emph{Interaction type} è la differenza tra le medie di \emph{Social} e di \emph{Functional}, ignorando \emph{Robot's objection}. \citet{horstmann2018robot} riportano che gli individui che avevano avuto un'interazione funzionale con il robot impiegavano più tempo a spegnere il robot di coloro che avevano avuto un'interazione sociale con il robot (\(p\) = 0.045). Il presente modello bayesiano offre scarse evidenze di ciò:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{((}\FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{4}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 5.766}
\FunctionTok{mean}\NormalTok{((}\FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{3}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{2}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 5.043}
\end{Highlighting}
\end{Shaded}

Infatti, all'evento \emph{complementare} possiamo associare la seguente probabilità:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}
\NormalTok{  (posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{2}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{4}\NormalTok{]) }\SpecialCharTok{\textless{}} 
\NormalTok{    (posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{3}\NormalTok{])}
\NormalTok{  ) }\SpecialCharTok{/} 
  \FunctionTok{length}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 0.3441}
\end{Highlighting}
\end{Shaded}

L'effetto principale del fattore \emph{Robot's objection} è la differenza tra le medie di \emph{Objection} e di \emph{No Objection}, ignorando \emph{Interaction type}. \citet{horstmann2018robot} riportano che i partecipanti avevano aspettato più a lungo prima di spegnere il robot quando il robot aveva avanzato un'obiezione rispetto a quando non si era opposto ad essere spento:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(}
\NormalTok{  (}\FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{2}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 6.701}

\FunctionTok{mean}\NormalTok{(}
\NormalTok{  (}\FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{3}\NormalTok{]) }\SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{4}\NormalTok{])) }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 4.108}
\end{Highlighting}
\end{Shaded}

In base al modello bayesiano, la probabilità direzionale per l'evento complementare è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}
\NormalTok{  (posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{2}\NormalTok{]) }\SpecialCharTok{\textless{}} 
\NormalTok{    (posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{3}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{4}\NormalTok{])}
\NormalTok{  ) }\SpecialCharTok{/} 
  \FunctionTok{length}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{mu[, }\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] 0.001187}
\end{Highlighting}
\end{Shaded}

e corrisponde, in ordine di grandezza, alla probabilità frequentista riportata da \citet{horstmann2018robot}, ovvero \(p\) = 0.004.

\hypertarget{codice-stan-versione-2}{%
\section{Codice Stan (versione 2)}\label{codice-stan-versione-2}}

È possibile modificare il codice Stan precedente così da avere i dati grezzi in input ed eseguire la standardizzazione all'interno del programma.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{// Comparison of k groups with common variance (ANOVA)}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;            // number of observations}
\StringTok{  int\textless{}lower=0\textgreater{} K;            // number of groups}
\StringTok{  int\textless{}lower=1,upper=K\textgreater{} x[N]; // discrete group indicators}
\StringTok{  vector[N] y;               // real valued observations}
\StringTok{\}}
\StringTok{transformed data \{}
\StringTok{  vector[N] y\_std;}
\StringTok{  y\_std = (y {-} mean(y)) / sd(y);}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  vector[K] mu\_std;        // group means}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_std; // common standard deviation }
\StringTok{  real\textless{}lower=1\textgreater{} nu;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  mu\_std \textasciitilde{} normal(0, 2);  }
\StringTok{  sigma\_std \textasciitilde{} normal(0, 2);     }
\StringTok{  nu \textasciitilde{} gamma(2, 0.1);   // Juárez and Steel(2010)}
\StringTok{  y\_std \textasciitilde{} student\_t(nu, mu\_std[x], sigma\_std); }
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[K] mu;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{  for (i in 1:K) \{}
\StringTok{    mu[i] = mu\_std[i] * sd(y) + mean(y);}
\StringTok{  \}}
\StringTok{  sigma = sd(y) * sigma\_std;}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/grp\_aovstd.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"grp\_aovstd.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

Eseguiamo il campionamento MCMC usando gli stessi dati discussi in precedenza:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2 }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data\_grp,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

I risultati sono equivalenti a quelli trovati in precedenza:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"mu"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{, }\StringTok{"nu"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 10}
\CommentTok{\#\textgreater{}   variable  mean median     sd    mad    q5   q95  rhat}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}    \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 mu[1]    1.70   1.70  0.176  0.171  1.42  2.00   1.00}
\CommentTok{\#\textgreater{} 2 mu[2]    2.07   2.06  0.197  0.196  1.75  2.40   1.00}
\CommentTok{\#\textgreater{} 3 mu[3]    1.53   1.52  0.122  0.121  1.32  1.73   1.00}
\CommentTok{\#\textgreater{} 4 mu[4]    1.29   1.28  0.127  0.124  1.08  1.50   1.00}
\CommentTok{\#\textgreater{} 5 sigma    0.480  0.476 0.0759 0.0744 0.362 0.612  1.00}
\CommentTok{\#\textgreater{} 6 nu       2.58   2.44  0.831  0.725  1.51  4.13   1.00}
\CommentTok{\#\textgreater{} \# ... with 2 more variables: ess\_bulk \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

\hypertarget{mod-hier-stan}{%
\chapter{Modello gerarchico}\label{mod-hier-stan}}

\hypertarget{modello-gerarchico}{%
\section{Modello gerarchico}\label{modello-gerarchico}}

I modelli lineari misti, o modelli lineari gerarchici/multilivello, sono diventati uno strumento fondamentale della ricerca sperimentale in psicologia, linguistica e scienze cognitive, dove i progetti di ricerca a misure ripetute sono la norma. Il presente Capitolo fornisce un'introduzione a tali modelli considerando soltanto il caso più semplice, conosciuto anche col nome di \emph{Random Intercept Model}.

Per fare un esempio concreto useremo il set di dati a misure ripetute con due condizioni di \citeauthor{gibson2013processing} \citetext{\citeyear{gibson2013processing}; \citealp[si veda][]{sorensen2015bayesian}}. La variabile dipendente \texttt{rt} dell'esperimento di \citet{gibson2013processing} è il tempo di lettura in millisecondi del soggetto di una proposizione relativa in un testo. I tempi di reazione sono stati registrati in due condizioni (ovvero, in presenza di un sostantivo riferito al soggetto oppure riferito all'oggetto della proposizione). I dati di \citet{gibson2013processing} provengono da un esperimento con 37 soggetti e 15 item. Gli item erano presentati in un disegno a quadrato latino, il che produce 37 \(\times\) 15 = 555 dati. Risultano mancanti otto dati di un soggetto (id 27), il che ci porta ad un totale di 555 − 8 = 547 dati. Le prime righe del data.frame sono mostrate di seguito:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rdat }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"gibsonwu2012data.txt"}\NormalTok{))}
\NormalTok{rdat}\SpecialCharTok{$}\NormalTok{so }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(rdat}\SpecialCharTok{$}\NormalTok{type }\SpecialCharTok{==} \StringTok{"subj{-}ext"}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{, }\FloatTok{0.5}\NormalTok{)}
\FunctionTok{head}\NormalTok{(rdat)}
\CommentTok{\#\textgreater{}    subj item     type pos word correct   rt region}
\CommentTok{\#\textgreater{} 7     1   13  obj{-}ext   6 抓住       {-} 1140    de1}
\CommentTok{\#\textgreater{} 20    1    6 subj{-}ext   6 男孩       {-} 1197    de1}
\CommentTok{\#\textgreater{} 32    1    5  obj{-}ext   6   撞       {-}  756    de1}
\CommentTok{\#\textgreater{} 44    1    9  obj{-}ext   6 監視       {-}  643    de1}
\CommentTok{\#\textgreater{} 60    1   14 subj{-}ext   6 機師       {-}  860    de1}
\CommentTok{\#\textgreater{} 73    1    4 subj{-}ext   6 男孩       {-}  868    de1}
\CommentTok{\#\textgreater{}               type2   so}
\CommentTok{\#\textgreater{} 7   object relative  0.5}
\CommentTok{\#\textgreater{} 20 subject relative {-}0.5}
\CommentTok{\#\textgreater{} 32  object relative  0.5}
\CommentTok{\#\textgreater{} 44  object relative  0.5}
\CommentTok{\#\textgreater{} 60 subject relative {-}0.5}
\CommentTok{\#\textgreater{} 73 subject relative {-}0.5}
\end{Highlighting}
\end{Shaded}

La variabile di interesse che corrisponde alla manipolazione sperimentale è chiamata \texttt{so} ed è stata codificata con -0.5 se il sostantivo era riferito al soggetto e con +0.5 se il sostantivo era riferito all'oggetto della frase.

Calcoliamo la media dei tempi di reazione su scala logaritmica e per poi ritrasformare il risultato sulla scala originale:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rdat }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(type2) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarise}\NormalTok{(}
    \AttributeTok{avg =} \FunctionTok{exp}\NormalTok{(}\FunctionTok{mean}\NormalTok{(}\FunctionTok{log}\NormalTok{(rt), }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{  )}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 2}
\CommentTok{\#\textgreater{}   type2              avg}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}            \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 object relative   551.}
\CommentTok{\#\textgreater{} 2 subject relative  589.}
\end{Highlighting}
\end{Shaded}

Quando il sostantivo si riferisce al soggetto, i tempi di reazione sono più lenti di circa 30 ms. Questa descrizione dei dati, però non tiene conto né delle differenze tra i soggetti né delle differenze tra gli item. Per tenere in considerazioni queste diverse fonti della variabilità dei dati è necessario utilizzare un modello detto gerarchico.

\hypertarget{modello-ad-effetti-fissi}{%
\section{Modello ad effetti fissi}\label{modello-ad-effetti-fissi}}

Iniziamo con il modello ``ad effetti fissi'' che non tiene conto della struttura gerarchica dei dati, ovvero del fatto che c'è una covariazione all'interno dei cluster di dati definiti dalle variabili ``soggetto'' e ``item''.

Assumiamo che la variabile dipendente \texttt{rt} (del tempo di lettura) sia approssimativamente distribuita in modo logaritmico \citep{rouder2005unshifted}. Ciò presuppone che il logaritmo di \texttt{rt} sia distribuito approssimativamente in maniera normale. Il modello per il logaritmo dei tempi di lettura, \(\log\) \texttt{rt}, diventa

\begin{equation}
\log rt_i = \beta_0 + \beta_1 so_i + \varepsilon_i,
\end{equation}

ovvero

\begin{equation}
rt \sim LogNormal(\beta_0 + \beta_1 so,\sigma)
\end{equation}

dove \(\beta_0\) è la media generale di \(\log\) \texttt{rt} e \(\beta_1 so\) codifica la differenza \(\E(\log rt_{o}) - \E(\log rt_{s})\) quando si passa dalla condizione nella quale il sostantivo è riferito all'oggetto alla condizione nella quale il sostantivo è riferito all'soggetto -- valori negativi significano che i tempi di reazioni sono maggiori nella condizione \texttt{s} che nella condizione \texttt{o}.

Nel modello useremo le seguenti distribuzioni a priori:

\begin{equation}
\begin{aligned}
\beta[1] &\sim Normal(6, 1.5) \\
\beta[2] &\sim Normal(0, 1.0) \\
\sigma &\sim Cauchy(0, 1)\\
\end{aligned}
\end{equation}

In Stan, il modello diventa

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=1\textgreater{} N; //number of data points}
\StringTok{  real rt[N]; //reading time}
\StringTok{  real\textless{}lower={-}0.5, upper=0.5\textgreater{} so[N]; //predictor}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  vector[2] beta; //fixed intercept and slope}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_e; //error sd}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  real mu;}
\StringTok{  // likelihood}
\StringTok{  beta[1] \textasciitilde{} normal(6, 1.5);}
\StringTok{  beta[2] \textasciitilde{} normal(0, 1);}
\StringTok{  sigma\_e \textasciitilde{} cauchy(0, 1);}
\StringTok{  for (i in 1:N)\{}
\StringTok{    mu = beta[1] + beta[2] * so[i];}
\StringTok{    rt[i] \textasciitilde{} lognormal(mu, sigma\_e);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/fixeff\_model.stan"}\NormalTok{)}

\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"fixeff\_model.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

I dati sono contenuti nella lista \texttt{stan\_dat}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stan\_dat }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{rt =}\NormalTok{ rdat}\SpecialCharTok{$}\NormalTok{rt,}
  \AttributeTok{so =}\NormalTok{ rdat}\SpecialCharTok{$}\NormalTok{so,}
  \AttributeTok{N =} \FunctionTok{nrow}\NormalTok{(rdat)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit3 }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ stan\_dat,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Otteniamo un oggetto di classe \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit3}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Calcoliamo gli intervalli di credibilità al 95\%:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ci95 }\OtherTok{\textless{}{-}}\NormalTok{ rstanarm}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}
  \FunctionTok{as.matrix}\NormalTok{(stanfit),}
  \AttributeTok{prob =} \FloatTok{0.95}
\NormalTok{)}
\FunctionTok{round}\NormalTok{(ci95, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}              2.5\%     97.5\%}
\CommentTok{\#\textgreater{} beta[1]     6.321     6.368}
\CommentTok{\#\textgreater{} beta[2]    {-}0.112    {-}0.018}
\CommentTok{\#\textgreater{} sigma\_e     0.613     0.646}
\CommentTok{\#\textgreater{} lp\_\_    {-}2617.040 {-}2612.420}
\end{Highlighting}
\end{Shaded}

L'effetto medio, sulla scala in millisecondi, si trova nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior }\OtherTok{\textless{}{-}} \FunctionTok{extract}\NormalTok{(stanfit, }\AttributeTok{permuted =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{exp}\NormalTok{(}\FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta[, }\DecValTok{1}\NormalTok{] }\SpecialCharTok{+}\NormalTok{ posterior}\SpecialCharTok{$}\NormalTok{beta[, }\DecValTok{2}\NormalTok{])) }\SpecialCharTok{{-}} 
  \FunctionTok{exp}\NormalTok{(}\FunctionTok{mean}\NormalTok{(posterior}\SpecialCharTok{$}\NormalTok{beta[, }\DecValTok{1}\NormalTok{]))}
\CommentTok{\#\textgreater{} [1] {-}35.93}
\end{Highlighting}
\end{Shaded}

\hypertarget{modello-gerarchico-1}{%
\section{Modello gerarchico}\label{modello-gerarchico-1}}

Il modello a effetti fissi è inappropriato per i dati di \citet{gibson2013processing} perché non tiene conto del fatto che abbiamo più misure per ogni soggetto e per ogni item. In altre parole, il modello ad effetti fissi viola l'assunzione di indipendenza degli errori. Inoltre, i coefficienti di effetti fissi \(\beta_0\) e \(\beta_1\) rappresentano le medie calcolate su tutti i soggetti e tutti gli item, ignorando il fatto che alcuni soggetti sono più veloci e altri più lenti della media, e il fatto che alcuni item sono stati letti più velocemente della media e altri più lentamente.

Nei modelli lineari misti, teniamo in considerazione la variabilità dovuta alle differenze tra soggetti e tra item aggiungendo al modello i termini \(u_{0j}\) e \(w_{0k}\) che aggiustano \(\beta_0\) stimando una componente specifica al soggetto \(j\) e all'item \(k\). Questa formulazione del modello scompone parzialmente \(\varepsilon_i\) in una somma di termini \(u_{0j}\) e \(w_{0k}\) che, geometricamente, corrispondono a degli aggiustamenti dell'intercetta \(\beta_0\) specifici per il soggetto \(j\) e per l'item \(k\). Se il soggetto \(j\) è più lento della media di tutti i soggetti, \(u_j\) sarà un numero positivo; se l'item \(k\) viene letto più velocemente del tempo di lettura medio di tutti gli item, allora \(w_k\) sarà un numero negativo. Viene stimato un aggiustamento \(u_{0j}\) per ogni soggetto \(j\) e un aggiustamento \(w_{0k}\) per ogni item. Gli aggiustamenti \(u_{0j}\) e \(w_{0k}\) sono chiamati \emph{random intercepts} o \emph{varying intercepts} \citep{gelman2020regression}. La modifica di \(\beta_0\) mediante \(u_{0j}\) e \(w_{0k}\) consente dunque di tenere in considerazione la variabilità dovuta ai soggetti e agli item.

Il random intercept model assume che gli aggiustamenti \(u_{0j}\) e \(w_{0k}\) siano distribuiti normalmente attorno allo zero con una deviazione standard sconosciuta: \(u_0 ∼ \mathcal{N}(0, \sigma_u)\) e \(w_0 ∼ \mathcal{N}(0, \sigma_w)\). Il modello include dunque tre fonti di varianza: la deviazione standard degli errori \(\sigma_e\), la deviazione standard delle \emph{random intercepts} per i soggetti, \(\sigma_u\), e la deviazione standard delle \emph{random intercepts} per gli item, \(\sigma_w\). Queste tre fonti di variabilità sono dette \emph{componenti della varianza}. Possiamo dunque scrivere:

\begin{equation}
\log rt_{ijk} = \beta_0 + \beta_1 so_i + u_{0j} + w_{0k} + \varepsilon_{ijk}.
\end{equation}

Il coefficiente \(\beta_1\) è quello di interesse primario. Come conseguenza della codifica usata, avrà il valore \(-\beta_1\) nella condizione in cui il sostantivo è riferito al soggetto e \(+\beta_1\) nella condizione in cui il sostantivo è riferito all'oggetto della frase.

In Stan il modello diventa:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=1\textgreater{} N; //number of data points}
\StringTok{  real rt[N]; //reading time}
\StringTok{  real\textless{}lower={-}0.5, upper=0.5\textgreater{} so[N]; //predictor}
\StringTok{  int\textless{}lower=1\textgreater{} J; //number of subjects}
\StringTok{  int\textless{}lower=1\textgreater{} K; //number of items}
\StringTok{  int\textless{}lower=1, upper=J\textgreater{} subj[N]; //subject id}
\StringTok{  int\textless{}lower=1, upper=K\textgreater{} item[N]; //item id}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  vector[2] beta; //fixed intercept and slope}
\StringTok{  vector[J] u; //subject intercepts}
\StringTok{  vector[K] w; //item intercepts}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_e; //error sd}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_u; //subj sd}
\StringTok{  real\textless{}lower=0\textgreater{} sigma\_w; //item sd}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  real mu;}
\StringTok{  //priors}
\StringTok{  u \textasciitilde{} normal(0, sigma\_u); //subj random effects}
\StringTok{  w \textasciitilde{} normal(0, sigma\_w); //item random effects}
\StringTok{  // likelihood}
\StringTok{  for (i in 1:N)\{}
\StringTok{    mu = beta[1] + u[subj[i]] + w[item[i]] + beta[2] * so[i];}
\StringTok{    rt[i] \textasciitilde{} lognormal(mu, sigma\_e);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/random\_intercepts\_model.stan"}\NormalTok{)}

\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"random\_intercepts\_model.stan"}\NormalTok{)}
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

I dati sono

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stan\_dat }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{subj =} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(rdat}\SpecialCharTok{$}\NormalTok{subj)),}
  \AttributeTok{item =} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(rdat}\SpecialCharTok{$}\NormalTok{item)),}
  \AttributeTok{rt =}\NormalTok{ rdat}\SpecialCharTok{$}\NormalTok{rt,}
  \AttributeTok{so =}\NormalTok{ rdat}\SpecialCharTok{$}\NormalTok{so,}
  \AttributeTok{N =} \FunctionTok{nrow}\NormalTok{(rdat),}
  \AttributeTok{J =} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(rdat}\SpecialCharTok{$}\NormalTok{subj)),}
  \AttributeTok{K =} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(rdat}\SpecialCharTok{$}\NormalTok{item))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit4 }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ stan\_dat,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Otteniamo un oggetto di classe \texttt{stanfit}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit4}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Le medie a posteriori si ottengono con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit4}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"beta"}\NormalTok{, }\StringTok{"sigma\_e"}\NormalTok{, }\StringTok{"sigma\_w"}\NormalTok{, }\StringTok{"sigma\_u"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 5 x 10}
\CommentTok{\#\textgreater{}   variable    mean  median      sd     mad      q5}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}      \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 beta[1]   6.35    6.35   0.0514  0.0511   6.26  }
\CommentTok{\#\textgreater{} 2 beta[2]  {-}0.0602 {-}0.0603 0.0222  0.0224  {-}0.0966}
\CommentTok{\#\textgreater{} 3 sigma\_e   0.577   0.577  0.00783 0.00786  0.565 }
\CommentTok{\#\textgreater{} 4 sigma\_w   0.120   0.115  0.0289  0.0262   0.0806}
\CommentTok{\#\textgreater{} 5 sigma\_u   0.238   0.235  0.0318  0.0301   0.192 }
\CommentTok{\#\textgreater{} \# ... with 4 more variables: q95 \textless{}dbl\textgreater{}, rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

Gli intervalli di credibilità sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ci95 }\OtherTok{\textless{}{-}}\NormalTok{ rstanarm}\SpecialCharTok{::}\FunctionTok{posterior\_interval}\NormalTok{(}
  \FunctionTok{as.matrix}\NormalTok{(stanfit),}
  \AttributeTok{prob =} \FloatTok{0.95}
\NormalTok{)}
\FunctionTok{round}\NormalTok{(ci95, }\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}              2.5\%     97.5\%}
\CommentTok{\#\textgreater{} beta[1]     6.245     6.448}
\CommentTok{\#\textgreater{} beta[2]    {-}0.104    {-}0.017}
\CommentTok{\#\textgreater{} u[1]       {-}0.207     0.082}
\CommentTok{\#\textgreater{} u[2]       {-}0.307    {-}0.010}
\CommentTok{\#\textgreater{} u[3]       {-}0.127     0.166}
\CommentTok{\#\textgreater{} u[4]       {-}0.211     0.084}
\CommentTok{\#\textgreater{} u[5]       {-}0.077     0.212}
\CommentTok{\#\textgreater{} u[6]       {-}0.049     0.241}
\CommentTok{\#\textgreater{} u[7]       {-}0.158     0.130}
\CommentTok{\#\textgreater{} u[8]       {-}0.122     0.172}
\CommentTok{\#\textgreater{} u[9]       {-}0.095     0.195}
\CommentTok{\#\textgreater{} u[10]      {-}0.007     0.285}
\CommentTok{\#\textgreater{} u[11]       0.448     0.747}
\CommentTok{\#\textgreater{} u[12]       0.149     0.443}
\CommentTok{\#\textgreater{} u[13]      {-}0.165     0.129}
\CommentTok{\#\textgreater{} u[14]      {-}0.151     0.143}
\CommentTok{\#\textgreater{} u[15]       0.033     0.326}
\CommentTok{\#\textgreater{} u[16]      {-}0.198     0.094}
\CommentTok{\#\textgreater{} u[17]      {-}0.717    {-}0.418}
\CommentTok{\#\textgreater{} u[18]      {-}0.417    {-}0.124}
\CommentTok{\#\textgreater{} u[19]      {-}0.289     0.001}
\CommentTok{\#\textgreater{} u[20]       0.161     0.455}
\CommentTok{\#\textgreater{} u[21]       0.053     0.342}
\CommentTok{\#\textgreater{} u[22]       0.126     0.420}
\CommentTok{\#\textgreater{} u[23]      {-}0.197     0.094}
\CommentTok{\#\textgreater{} u[24]      {-}0.083     0.299}
\CommentTok{\#\textgreater{} u[25]       0.000     0.296}
\CommentTok{\#\textgreater{} u[26]      {-}0.494    {-}0.201}
\CommentTok{\#\textgreater{} u[27]      {-}0.232     0.060}
\CommentTok{\#\textgreater{} u[28]      {-}0.329    {-}0.035}
\CommentTok{\#\textgreater{} u[29]      {-}0.420    {-}0.126}
\CommentTok{\#\textgreater{} u[30]      {-}0.404    {-}0.111}
\CommentTok{\#\textgreater{} u[31]      {-}0.103     0.193}
\CommentTok{\#\textgreater{} u[32]      {-}0.177     0.117}
\CommentTok{\#\textgreater{} u[33]      {-}0.237     0.056}
\CommentTok{\#\textgreater{} u[34]       0.259     0.554}
\CommentTok{\#\textgreater{} u[35]      {-}0.395    {-}0.103}
\CommentTok{\#\textgreater{} u[36]      {-}0.142     0.149}
\CommentTok{\#\textgreater{} u[37]      {-}0.173     0.121}
\CommentTok{\#\textgreater{} w[1]       {-}0.135     0.060}
\CommentTok{\#\textgreater{} w[2]       {-}0.121     0.073}
\CommentTok{\#\textgreater{} w[3]       {-}0.102     0.094}
\CommentTok{\#\textgreater{} w[4]       {-}0.215    {-}0.017}
\CommentTok{\#\textgreater{} w[5]       {-}0.009     0.191}
\CommentTok{\#\textgreater{} w[6]       {-}0.145     0.053}
\CommentTok{\#\textgreater{} w[7]       {-}0.283    {-}0.084}
\CommentTok{\#\textgreater{} w[8]        0.114     0.312}
\CommentTok{\#\textgreater{} w[9]       {-}0.188     0.008}
\CommentTok{\#\textgreater{} w[10]      {-}0.044     0.154}
\CommentTok{\#\textgreater{} w[11]      {-}0.143     0.056}
\CommentTok{\#\textgreater{} w[12]      {-}0.034     0.162}
\CommentTok{\#\textgreater{} w[13]      {-}0.180     0.017}
\CommentTok{\#\textgreater{} w[14]       0.035     0.231}
\CommentTok{\#\textgreater{} w[15]      {-}0.042     0.152}
\CommentTok{\#\textgreater{} sigma\_e     0.562     0.593}
\CommentTok{\#\textgreater{} sigma\_u     0.185     0.309}
\CommentTok{\#\textgreater{} sigma\_w     0.076     0.187}
\CommentTok{\#\textgreater{} lp\_\_    {-}2332.570 {-}2311.140}
\end{Highlighting}
\end{Shaded}

\mainmatter

\hypertarget{part-il-confronto-bayesiano-di-modelli}{%
\part{Il confronto bayesiano di modelli}\label{part-il-confronto-bayesiano-di-modelli}}

\hypertarget{ch:entropy}{%
\chapter{Entropia}\label{ch:entropy}}

Il principio base del metodo scientifico è la \emph{replicabilità} delle osservazioni: le osservazioni che non possono essere replicate sono poco interessanti. Parallelamente, una caratteristica fondamentale di un modello scientifico è la \emph{generalizzabilità}: se un modello è capace di descrivere soltanto le proprietà di uno specifico campione di osservazioni, allora è poco utile. Ma come è possibile valutare la generalizzabilità di un modello statistico? Questa è la domanda a cui cercheremo di rispondere in questa parte della dispensa. In questo Capitolo inizieremo questa discussione introducendo il concetto di entropia.

\hypertarget{la-generalizzabilituxe0-dei-modelli}{%
\section{La generalizzabilità dei modelli}\label{la-generalizzabilituxe0-dei-modelli}}

Secondo \citet{Johnson2022bayesrules}, nel valutare un modello, il ricercatore deve porsi tre domande critiche.

\begin{itemize}
\item
  Quali conseguenze più ampie derivano dall'inferenza? Come e chi ha raccolto i dati? Colui che svolge la ricerca otterrebbe di benefici manipolando i dati (escludendo delle osservazioni; selezionando il campione)? Che impatto hanno inferenze che vengono tratte dai dati sugli individui e sulla società? Quali pregiudizi o strutture di potere possono essere coinvolti in questa analisi?
\item
  Che tipo di distorsioni sistematiche potrebbero essere presenti nell'analisi statistica? Ricordiamo la famosa citazione di George Box: ``Tutti i modelli sono sbagliati, ma alcuni sono utili''. È dunque importante sapere quanto è sbagliato il modello. Le assunzioni che stanno alla base del modello sono ragionevoli? Il meccanismo generatore dei dati che è stato ipotizzato è adeguato per il fenomeno in esame?
\item
  Quanto è accurato il modello? Quanto sono lontane dalla realtà le previsioni del modello?
\end{itemize}

Per approfondire questi temi, si rinvia al testo di \citet{Johnson2022bayesrules}. Qui ci concentreremo su uno dei temi critici relativa alla validità di un modello, ovvero sul tema della generalizzabilità del modello.

Nella scienza l'utilità di una teoria viene verificata esaminando la corrispondenza tra predizioni teoriche e osservazioni. Se vi sono discrepanze significative tra predizioni e osservazioni ciò suggerisce che la teoria, o nella nostra visione più ristretta, il modello statistico, è poco utile. Il problema della capacità predittiva del modello non riguarda soltanto l'adeguatezza del modello in riferimento ad uno specifico campione di dati, ma riguarda anche la capacità di un modello statistico sviluppato in un campione di dati di ben adattarsi ad altri campioni della stessa popolazione.

In generale, i modelli statistici tendono a non generalizzarsi bene a un nuovo campione; questo perché sfruttano le caratteristiche specifiche dei dati del campione e tendono a produrre risultati eccessivamente ottimistici (cioè le dimensioni dell'effetto) che sovrastimano la dimensione dell'effetto atteso sia nella popolazione che in nuovi campioni. Benché i problemi della generalizzabilità dei modelli e il metodo chiave per valutarli -- ovvero, la convalida incrociata (\emph{cross-validation}) -- siano stati discussi sin dagli esordi della letteratura psicometrica \citep{lord1950efficiency}, tali temi sono stati sottovalutati nella formazione psicologica contemporanea e nella ricerca. Tuttavia, questi concetti diventeranno sempre più importanti considerata l'enfasi corrente sulla necessità di condurre ricerche replicabili. Un'introduzione a questi temi è fornita, da esempio, da \citet{song2021making}. Nello specifico, \citet{song2021making} mostrano che un modello che viene adattato a un campione (\emph{campione di calibrazione}) non si generalizza bene a un altro campione (\emph{campione di convalida}): la capacità predittiva del modello è minore quando il modello viene applicato al campione di convalida piuttosto che al campione di calibrazione. Questo problema è detto \emph{sovra-adattamento} (\emph{overfitting}). In generale, \citet{song2021making} mostrano come la capacità di generalizzazione del modello diminuisce (a) all'aumentare della complessità del modello, (b) al diminuire dell'ampiezza del campione di calibrazione, e (c) al diminuire della dimensione dell'effetto nella popolazione.

Sebbene i modelli statistici producono comunemente un sovra-adattamento, è anche possibile che essi producano un \emph{sotto-adattamento} (\emph{underfitting}) dei dati. Tale mancanza di adattamento è dovuta dalla variabilità campionaria e dalla complessità del modello. Il sotto-adattamento porta ad un \(R^2\) basso e ad un \emph{MSE} alto, sia nei campioni di calibrazione che in quelli di convalida. Per questo motivo, la scarsa generalizzabilità del modello può essere dovuta sia al sovra-adattamento che al sotto-adattamento del modello.

Per aumentarne la capacità di generalizzazione del modello devono essere soddisfatte tre condizioni: (a) campioni di calibrazione grandi, (b) dimensioni dell'effetto non piccole nella popolazione, e (c) modelli che non siano inutilmente complessi. Tuttavia, nella ricerca psicologica queste tre condizioni sono difficili da soddisfare: l'aumento della dimensione del campione spesso richiede l'utilizzo di maggiori risorse, la dimensione di un dato effetto nella popolazione non è soggetta alla discrezione dei ricercatori e la complessità del modello è spesso guidata da motivazioni teoriche. Pertanto, negli studi psicologici la generalizzabilità dei modelli è spesso problematica. Ciò rende necessario che il ricercatore fornisca informazioni aggiuntive relative alla capacità del modello di generalizzarsi a nuovi campioni. L'obiettivo di questa parte della dispensa è di descrivere come questo possa essere fatto utilizzando l'approccio bayesiano.

\hypertarget{capacituxe0-predittiva}{%
\section{Capacità predittiva}\label{capacituxe0-predittiva}}

Nel framework bayesiano il problema della generalizzabilità di un modello viene affrontato valutando la capacità predittiva del modello, laddove per capacità predittiva si intende la capacità di un modello, i cui parametri sono stati stimati usando le informazioni di un campione, di ben adattarsi ad un campione di osservazioni future. In questo Capitolo cercheremo di rispondere a tre domande.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Quali criteri consentono di valutare la capacità predittiva di un modello?
\item
  Come quantificare la capacità predittiva di un modello usando solo un campione di osservazioni?
\item
  Come confrontare le capacità predittive di modelli diversi?
\end{enumerate}

\hypertarget{il-rasoio-di-ockham}{%
\section{Il rasoio di Ockham}\label{il-rasoio-di-ockham}}

Il problema di scegliere il modello più adatto a spiegare un fenomeno di interesse è uno dei più importanti problemi in campo scientifico. I ricercatori si chiedono: il modello è completo? È necessario aggiungere un nuovo parametro al modello? Come può essere migliorato il modello? Se ci sono modelli diversi, qual'è il modello migliore?

Per rispondere a queste domande è possibile usare il rasoio di Ockham: \emph{frustra fit per plura quod potest fieri per pauciora} (``si fa inutilmente con molte cose ciò che si può fare con poche cose''). Parafrasando la massima si potrebbe dire: se due modelli descrivono i dati egualmente bene, viene sempre preferito il modello più semplice. Questo è il principio che sta alla base della ricerca scientifica.

Il rasoio di Ockham, però, non consente sempre di scegliere tra modelli alternativi. Se due modelli fanno le stesse predizioni ma differiscono in termini di complessità --- per esempio, relativamente al numero di parametri di cui sono costituiti --- allora è facile decidere: viene preferito il modello più semplice, anche perché, pragmaticamente, è il più facile da usare. Tuttavia, in generale, i modelli differiscono sia per complessità (ovvero, per il numero di parametri) che per accuratezza (ovvero, per la grandezza degli errori di predizione). In tali circostanze il rasoio di Ockham non è sufficiente: non consente infatti di trovare un equilibrio tra accuratezza e semplicità.

In questo Capitolo ci chiederemo come sia possibile misurare l'accuratezza predittiva di un modello. Ciò ci consentirà, in seguito, di usare il rasoio di Ockham: a parità di accuratezza, sarà possibile scegliere il modello più semplice. Ma nella pratica scientifica non si sacrifica mai l'accuratezza per la semplicità: il criterio prioritario è sempre l'accuratezza.

Secondo \citet{McElreath_rethinking}, la selezione tra modelli deve evitare due opposti errori: il sovra-adattamento e il sotto-adattamento. Tale problema va sotto il nome di \emph{bias-variance trade-off}: il sotto-adattamento, infatti, porta a distorsioni (\emph{bias}) nella stima dei parametri, mentre il sovra-adattamento porta a previsioni scadenti in campioni futuri. Spesso l'incertezza relativa alla scelta del modello (sotto-adattamento versus sovra-adattamento) passa inosservata ma il suo impatto può essere drammatico. Secondo \citet{hoeting1999bayesian}, \emph{``Standard statistical practice ignores model uncertainty. Data analysts typically select a model from some class of models and then proceed as if the selected model had generated the data. This approach ignores the uncertainty in model selection, leading to over-confident inferences and decisions that are more risky than one thinks they are.}

In questo Capitolo esamineremo alcune tecniche bayesiane che possono essere utilizzate per operare una selezione tra modelli alternativi, tenendo sotto controllo i pericoli del sovra-adattamento e del sotto-adattamento. In particolare, ci chiederemo quale, tra due o più modelli, sia quello da preferire in base al criterio della capacità predittiva.

\hypertarget{stargazing}{%
\subsection{Stargazing}\label{stargazing}}

Nella pratica concreta della ricerca, il metodo più comune per la selezione tra modelli alternativi utilizza i test di ipotesi statistiche di stampo frequentista. Questo metodo viene chiamato \emph{stargazing}, poiché richiede soltanto l'esame degli asterischi (\(**\)) che si trovano nell'output di un software statistico (gli asterischi marcano i coefficienti del modello che sono ``statisticamente significativi''): alcuni ricercatori ritengono che il modello con più stelline sia anche il modello migliore. Questo però non è vero. Al di là dei problemi legati ai test dell'ipotesi nulla, è sicuramente un errore usare i test di significatività per la selezione di modelli: i valori-\emph{p} non consentono di trovare un equilibrio tra \emph{underfitting} e \emph{overfitting}. Infatti, le variabili che migliorano la capacità predittiva di un modello non sono sempre statisticamente significative; d'altra parte, le variabili statisticamente significative non sempre migliorano la capacità predittiva di un modello.

Quando ci chiediamo quale, tra modelli alternativi, è il modello che meglio rappresenta il ``vero'' processo di generazione dei dati, ci troviamo di fronte al problema di quantificare il grado di ``vicinanza'' di un modello al ``vero'' processo di generazione dei dati. Si noti che, in tale confronto, facciamo riferimento sia alla famiglia distributiva così come ai valori dei parametri. Ad esempio, il modello \(y_i \sim \mathcal{N}(5, 3)\) è diverso dal modello \(y_i \sim \mathcal{N}(5, 6)\), ed è anche diverso dal modello \(y_i \sim \Gamma(2, 2)\). I primi due modelli appartengono alla stessa famiglia distributiva ma differiscono nei termini dei valori dei parametri; gli ultimi due modelli appartengono a famiglie distributive diverse (gaussiano vs.~Gamma). Per misurare il grado di ``vicinanza'' tra due modelli, \(\mathcal{M}_1\) e \(\mathcal{M}_2\), la metrica di gran lunga più popolare è la \emph{divergenza di Kullback-Leibler}. Per chiarire questo concetto è però prima necessario introdurre la nozione di entropia.

\hypertarget{la-misura-del-disordine}{%
\section{La misura del disordine}\label{la-misura-del-disordine}}

Se vogliamo ottenere una comprensione intuitiva del concetto di entropia\footnote{La nozione di entropia fu introdotta agli inizi del XIX secolo nel campo della termodinamica classica; il secondo principio della termodinamica è infatti basato sul concetto di entropia che, in generale, è assunto come una misura del disordine di un sistema fisico. Successivamente Boltzmann fornì una definizione statistica di entropia. Nel 1948 Shannon impiegò la nozione di entropia nell'ambito della teoria delle comunicazioni.} possiamo pensare a quant'è informativa una distribuzione. Maggiore è l'entropia di una distribuzione, meno informativa sarà quella distribuzione e più uniformemente verranno assegnate le probabilità agli eventi. In altri termini, ottenere la risposta di ``42'' è più informativo della risposta ``42 \(\pm\) 5'', che a sua volta è più informativo della risposta ``un numero qualsiasi''. L'entropia quantifica questa osservazione qualitativa.

Il concetto di entropia si applica sia alle distribuzioni continue sia a quelle discrete, ma è più facile da capire usando le distribuzioni discrete. Negli esempi successivi vedremo alcuni esempi applicati al caso discreto, ma gli stessi concetti si applicano al caso continuo.

\hypertarget{entropia-di-un-singolo-evento}{%
\subsection{Entropia di un singolo evento}\label{entropia-di-un-singolo-evento}}

Il concetto di entropia può essere usato per descrivere la quantità di informazione fornita da un evento. L'intuizione che sta alla base del concetto di entropia è che l'informazione fornita da un evento descrive la sorpresa suscitata dall'evento: gli eventi rari (a bassa probabilità) sono più sorprendenti -- e quindi forniscono più informazione -- degli eventi comuni (ad alta probabilità). In altre parole,

\begin{itemize}
\tightlist
\item
  un evento a bassa probabilità è sorprendente e fornisce molta informazione;
\item
  un evento ad alta probabilità è poco o per niente sorprendente e fornisce poca (o nessuna) informazione.
\end{itemize}

È possibile quantificare l'informazione fornita dal verificarsi di un evento mediante la probabilità di quell'evento. Una tale quantità di informazione è chiamata ``informazione di Shannon'', ``auto-informazione'' o semplicemente ``informazione'' e, per un evento discreto \(x\), può essere calcolata come:

\[
\text{informazione}(x) = -\log_2 p(x),
\]

dove \(\log_2\) è il logaritmo in base 2 e \(p(x)\) è la probabilità dell'evento \(x\).

La scelta del logaritmo in base 2 significa che l'unità di misura dell'informazione è il bit (cifre binarie). Questo può essere interpretato dicendo che l'informazione misura il numero di bit richiesti per rappresentare un evento.\footnote{È possibile pensare all'entropia nei termini del numero di domande sì/no che devono essere poste per ridurre l'incertezza. Per esempio, se in un certo giorno ci può essere solo sole o pioggia, per ridurre l'incertezza, a fine giornata chiediamo: ``ha piovuto?'' La risposta (sì/no) ad una singola domanda elimina l'incertezza, e quindi l'informazione ottenuta (ovvero, la riduzione dell'incertezza) è uguale ad 1 bit. Se in una certa giornata ci potrebbero essere sole, pioggia o neve, per ridurre l'incertezza sono necessarie due domande: ``c'era sole?''; ``ha piovuto?'' In questo secondo caso, l'informazione ottenuta (ovvero, la riduzione dell'incertezza) è uguale ad 2 bit. Usando un logaritmo in base 2, dunque, l'entropia può essere interpretata come il numero minimo di bit necessari per codificare la quantità di informazione nei dati.} Solitamente, si denota la quantità di informazione con \(h()\):

\[
h(x) = -\log p(x).
\]

Il segno negativo garantisce che il risultato sia sempre positivo o zero. L'informazione è zero quando la probabilità dell'evento è 1.0, ovvero quando l'evento è certo (assenza di sorpresa).

\begin{example}
Consideriamo il lancio di una moneta equilibrata. La probabilità di testa (e croce) è 0.5. La quantità di informazione di ottenere ``testa'' è dunque

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(}\FloatTok{0.5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

Per rappresentare questo evento abbiamo bisogno di 1 bit di informazione. Se la stessa moneta venisse lanciata \(n\) volte, la quantità di informazione necessaria per rappresentare questo evento (ovvero, questa sequenza di lanci) sarebbe pari a \(n\) bit. Se la moneta non è equilibrata e la probabilità di testa è 0.1, allora l'evento ``testa'' è più raro e richiede più di 3 bit di informazione:

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(}\FloatTok{0.1}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 3.322}
\end{Highlighting}
\end{Shaded}

Consideriamo ora il lancio di un dado. Ci possiamo chiedere quanta informazione sia fornita, ad esempio, dall'evento ``esce il valore 6''. Dato che la probabilità di ottenere un 6 è più piccola della probabilità di ottenere ``testa'' nel lancio di una moneta, ci possiamo aspettare, nel lancio del dado, una maggiore sorpresa, ovvero una maggiore quantità di informazione. La quantità di informazione dell'evento ``esce un 6'' nel lancio di un dado

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{6}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 2.585}
\end{Highlighting}
\end{Shaded}

è infatti più del doppio della quantità di informazione dell'evento ``esce testa'' nel lancio di una moneta.
\end{example}

\begin{example}
Nella figura successiva viene esaminata la relazione tra probabilità e informazione, per valori di probabilità nell'intervallo tra 0 e 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{1000}\NormalTok{)}
\NormalTok{h }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FunctionTok{log2}\NormalTok{(p)}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{tibble}\NormalTok{(p, h), }\FunctionTok{aes}\NormalTok{(p, h)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Probabilità"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Informazione"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-331-1} \end{center}

La figura mostra che questa relazione non è lineare, è infatti leggermente sublineare. Questo ha senso dato che abbiamo usato una funzione logaritmica.
\end{example}

\hypertarget{entropia-di-una-variabile-casuale}{%
\subsection{Entropia di una variabile casuale}\label{entropia-di-una-variabile-casuale}}

Possiamo estendere questa discussione pensando ad un insieme di eventi, ovvero ad una distribuzione. Nella teoria della probabilità, per fare riferimento ad un insieme di eventi e alle associate probabilità, usiamo la nozione di variabile casuale. L'entropia quantifica l'informazione che viene fornita da una variabile casuale.

\begin{definition}
Sia \(Y = y_1, \dots, y_n\) una variabile casuale e \(p_t(y)\) una distribuzione di probabilità su \(Y\). Si definisce la sua entropia (detta di Shannon) come:

\begin{equation}
H(Y) = - \sum_{i=1}^n p_t(y_i) \cdot \log_2 p_t(y_i).
\label{eq:entropy}
\end{equation}
\end{definition}

Per interpretare la \eqref{eq:entropy}, consideriamo un esempio discusso da \citet{martin2022bayesian}.

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{images/entropy_example} 

}

\caption{Funzioni di massa di probabilità e associata entropia.}\label{fig:entropy-example}
\end{figure}

Nella figura \ref{fig:entropy-example} sono rappresentate sei distribuzioni. viene anche riportato il valore di entropia di ciascuna distribuzione. La distribuzione con il picco più pronunciato o con la dispersione minore è \texttt{q}, e questa è la distribuzione con il valore di entropia più basso tra le sei distribuzioni considerate. La distribuzione \texttt{q\ \textasciitilde{}\ binom(n\ =\ 10,\ p\ =\ 0.75)}, e quindi ci sono 11 possibili eventi. \texttt{qu} è una distribuzione uniforme con gli stessi 11 possibili eventi. Possiamo vedere che l'entropia di \texttt{qu} è maggiore di quella di \texttt{q}. Infatti, se calcoliamo l'entropia di distribuzioni binomiali con \(n = 10\) e valori diversi di \(p\) ci possiamo rendere conto che nessuno di tali valori ha un'entropia maggiore di \texttt{qu}. Abbiamo bisogno di aumentare \(n ≈ 3\) volte per trovare la prima distribuzione binomiale con entropia maggiore di \texttt{qu}. Passiamo alla riga successiva. Generiamo la distribuzione \texttt{r} prendendo \texttt{q} e spostandolo a destra e quindi normalizzando (per garantire che la somma di tutte le probabilità sia 1). Poiché \texttt{r} ha una dispersione maggiore di \texttt{q}, la sua entropia è maggiore. \texttt{ru} è la distribuzione uniforme con lo stesso numero di possibili eventi di \texttt{r} (22) -- si noti che sono stati inclusi come possibili valori anche quelli nella valle tra i due picchi. Ancora una volta l'entropia della versione uniforme è quella con l'entropia più grande.

Gli esempi discussi finora sembrano suggerire che l'entropia sia proporzionale alla varianza di una distribuzione. Verifichiamo questa intuizione esaminiamo le ultime due distribuzioni della figura \ref{fig:entropy-example}. La distribuzione \texttt{s} è simile a \texttt{r} ma è presente una maggiore separazione tra i due picchi della distribuzione -- dunque, la dispersione aumenta. Ciò nonostante, l'entropia resta invariata. Quindi la relazione tra entropia e varianza non è così semplice come sembrava. Il risultato che abbiamo trovato può essere spiegato dicendo che, nel calcolo dell'entropia, non vengono considerati gli eventi con probabilità nulla (quindi, nell'esempio, è stato possibile aumentare la varianza della distribuzione senza cambiare l'entropia). La distribuzione \texttt{su} è stata costruita sostituendo i due picchi in \texttt{s} con \texttt{qu} (e normalizzando). Possiamo vedere che \texttt{su} ha un'entropia minore di \texttt{ru}, anche se \texttt{su} ha una dispersione maggiore di \texttt{ru}. Questo è dovuto al fatto che \texttt{su} distribuisce la probabilità totale tra un numero minore di eventi (22) di \texttt{ru} (che ne conta 23); quindi è sensato che \texttt{su} abbia un'entropia minore di \texttt{ru}.

Per chi fosse interessato, il codice Python usato per generare la figura \ref{fig:entropy-example} è riportato qui sotto.

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ scipy}
\ImportTok{import}\NormalTok{ numpy }\ImportTok{as}\NormalTok{ np}

\NormalTok{x }\OperatorTok{=} \BuiltInTok{range}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{26}\NormalTok{)}
\NormalTok{q\_pmf }\OperatorTok{=}\NormalTok{ scipy.stats.binom(}\DecValTok{10}\NormalTok{, }\FloatTok{0.75}\NormalTok{).pmf(x)}
\NormalTok{qu\_pmf }\OperatorTok{=}\NormalTok{ scipy.stats.randint(}\DecValTok{0}\NormalTok{, np.}\BuiltInTok{max}\NormalTok{(np.nonzero(q\_pmf))}\OperatorTok{+}\DecValTok{1}\NormalTok{).pmf(x) }
\NormalTok{r\_pmf }\OperatorTok{=}\NormalTok{ (q\_pmf }\OperatorTok{+}\NormalTok{ np.roll(q\_pmf, }\DecValTok{12}\NormalTok{)) }\OperatorTok{/} \DecValTok{2}
\NormalTok{ru\_pmf }\OperatorTok{=}\NormalTok{ scipy.stats.randint(}\DecValTok{0}\NormalTok{, np.}\BuiltInTok{max}\NormalTok{(np.nonzero(r\_pmf))}\OperatorTok{+}\DecValTok{1}\NormalTok{).pmf(x) }
\NormalTok{s\_pmf }\OperatorTok{=}\NormalTok{ (q\_pmf }\OperatorTok{+}\NormalTok{ np.roll(q\_pmf, }\DecValTok{15}\NormalTok{)) }\OperatorTok{/} \DecValTok{2}
\NormalTok{su\_pmf }\OperatorTok{=}\NormalTok{ (qu\_pmf }\OperatorTok{+}\NormalTok{ np.roll(qu\_pmf, }\DecValTok{15}\NormalTok{)) }\OperatorTok{/} \DecValTok{2}

\NormalTok{\_, ax }\OperatorTok{=}\NormalTok{ plt.subplots(}\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, figsize}\OperatorTok{=}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{5}\NormalTok{), sharex}\OperatorTok{=}\VariableTok{True}\NormalTok{, sharey}\OperatorTok{=}\VariableTok{True}\NormalTok{,}
\NormalTok{  constrained\_layout}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{ax }\OperatorTok{=}\NormalTok{ np.ravel(ax)}
\NormalTok{zipped }\OperatorTok{=} \BuiltInTok{zip}\NormalTok{([q\_pmf, qu\_pmf, r\_pmf, ru\_pmf, s\_pmf, su\_pmf], }
\NormalTok{  [}\StringTok{"q"}\NormalTok{, }\StringTok{"qu"}\NormalTok{, }\StringTok{"r"}\NormalTok{, }\StringTok{"ru"}\NormalTok{, }\StringTok{"s"}\NormalTok{, }\StringTok{"su"}\NormalTok{])}
\ControlFlowTok{for}\NormalTok{ idx, (dist, label) }\KeywordTok{in} \BuiltInTok{enumerate}\NormalTok{(zipped):}
\NormalTok{    ax[idx].vlines(x, }\DecValTok{0}\NormalTok{, dist, label}\OperatorTok{=}\SpecialStringTok{f"H = }\SpecialCharTok{\{}\NormalTok{scipy}\SpecialCharTok{.}\NormalTok{stats}\SpecialCharTok{.}\NormalTok{entropy(dist)}\SpecialCharTok{:.2f\}}\SpecialStringTok{"}\NormalTok{) }
\NormalTok{    ax[idx].set\_title(label)}
\NormalTok{    ax[idx].legend(loc}\OperatorTok{=}\DecValTok{1}\NormalTok{, handlelength}\OperatorTok{=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{example}
Consideriamo un esempio riguardante le previsioni del tempo. Supponiamo che le probabilità di pioggia e sole siano, rispettivamente, \(p_1 = 0.3\) e \(p_2 = 0.7\). Quindi

\[
H(p) = − [p(y_1) \log_2 p(y_1) + p(y_2) \log_2 p(y_2)] \approx 0.61.
\]

Svolgendo i calcoli in \(\R\) abbiamo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{ , }\FloatTok{0.7}\NormalTok{)}
\SpecialCharTok{{-}}\FunctionTok{sum}\NormalTok{(p}\SpecialCharTok{*}\FunctionTok{log}\NormalTok{(p))}
\CommentTok{\#\textgreater{} [1] 0.6109}
\end{Highlighting}
\end{Shaded}

Se però viviamo a Las Vegas, allora le probabilità di pioggia e sole saranno qualcosa come \(p(y_1) = 0.01\) e \(p(y_2) = 0.99\). In questo secondo caso, l'entropia è 0.06, ovvero, molto minore di prima. Infatti, a Las Vegas non piove quasi mai, per cui quando abbiamo imparato che, in un certo giorno, non ha piovuto, abbiamo imparato molto poco rispetto a quello che già sapevamo in precedenza.
\end{example}

\begin{example}

Abbiamo visto in precedenza che, se gli esiti possibili sono pioggia o sole con \(p(y_1) = 0.7\), \(p(y_2) = 0.3\), allora l'entropia è

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\NormalTok{(}\FloatTok{0.7} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} \FloatTok{0.3} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.3}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 0.6109}
\end{Highlighting}
\end{Shaded}

Se gli esiti possibili sono pioggia, neve o sole con \(p(y_1) = 0.7\), \(p(y_2) = 0.15\) e \(p(y_3) = 0.15\), rispettivamente, allora l'entropia sarà maggiore, ovvero pari a 0.82.

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{{-}}\NormalTok{(}\FloatTok{0.7} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.7}\NormalTok{) }\SpecialCharTok{+} \FloatTok{0.15} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.15}\NormalTok{) }\SpecialCharTok{+} \FloatTok{0.15} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FloatTok{0.15}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 0.8188}
\end{Highlighting}
\end{Shaded}

\end{example}

\hypertarget{commenti-e-considerazioni-finali-22}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-22}}


In questo Capitolo abbiamo visto come sia possibile quantificare l'incertezza tramite l'entropia. Ma come è possibile usare l'entropia dell'informazione per specificare quanto differisce un modello dal vero meccanismo generatore dei dati? La risposta a questa domanda è fornita dalla divergenza di Kullback-Leibler (Capitolo \ref{ch:kl-div}).

\hypertarget{ch:kl-div}{%
\chapter{La divergenza di Kullback-Leibler}\label{ch:kl-div}}

È comune in statistica utilizzare una distribuzione di probabilità \(q\) per approssimare un'altra distribuzione \(p\) -- generalmente, questo viene fatto se \(p\) non è conosciuta o è troppo complessa. In questi casi possiamo chiederci quanta informazione viene perduta usando \(q\) al posto di \(p\), o equivalentemente quanta ulteriore incertezza stiamo introducendo nell'analisi statistica. La quantificazione di questo incremento di incertezza viene fornita dalla divergenza di Kullback-Leibler.

\hypertarget{la-perdita-di-informazione}{%
\section{La perdita di informazione}\label{la-perdita-di-informazione}}

Intuitivamente, per quantificare la perdita di informazione quando una distribuzione approssimata \(q\) viene usata per rappresentare la vera distribuzione \(p\) è necessaria una quantità che ha valore zero quando \(q\) è uguale a \(p\), e un valore positivo altrimenti. Seguendo la definizione \eqref{eq:entropy} di entropia, possiamo quantificare una tale perdita di informazione calcolando il valore atteso della differenza tra \(\log(p)\) e \(\log(q)\). Questa quantità è chiamata \emph{entropia relativa} o \emph{divergenza di Kullback-Leibler}:

\begin{equation}
\mathbb{KL} (p \mid\mid q) = \E (\log p - \log q)
\label{eq:kldivergence}
\end{equation}

La divergenza \(\mathbb{KL} (p \mid\mid q)\) corrisponde alla differenza media nelle probabilità logaritmiche quando \(q\) viene usato per approssimare \(p\). Poiché gli eventi si manifestano secondo \(p\), è necessario calcolare il valore atteso rispetto a \(p\). Per distribuzioni discrete abbiamo:

\begin{equation}
\mathbb{KL} (p \mid\mid q) = \sum_i^n p_i (\log p_i - \log q_i) = \sum_i^n p_i \log \frac{p_i}{q_i}
\end{equation}

Riarrangiando i termini otteniamo:

\begin{equation}
\mathbb{KL} (p \mid\mid q) = -\sum_i^n p_i (\log q_i - \log p_i),
\end{equation}

ovvero,

\begin{equation}
\mathbb{KL} (p \mid\mid q) = \underbrace{-\sum_i^n p_i \log q_i}_{H(p, q)} - \underbrace{\left(-\sum_i^n p_i \log p_i\right)}_{H(p)},
\end{equation}

laddove \(H(p)\) è l'entropia di \(p\) e \(H(p, q) = −\E [\log q]\) può essere intesa come l'entropia di \(q\), ma valutata secondo i valori di \(p\).

Riarrangiando l'equazione precedente otteniamo:

\begin{equation}
H(p, q) = H(p) + \mathbb{KL} (p \mid\mid q),
\end{equation}

il che mostra come la divergenza KL può essere interpretata come l'incremento di entropia rispetto a \(H(p)\), quando si usa \(q\) per rappresentare \(p\).

\begin{example}
\citep[da][]{McElreath_rethinking} Sia la distribuzione target \(p = \{0.3, 0.7\}\). Supponiamo che la distribuzione approssimata \(q\) possa assumere valori da \(q = \{0.01, 0.99\}\) a \(q = \{0.99, 0.01\}\). Calcoliamo la divergenza KL.

Le istruzioni \(\R\) sono le seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\OtherTok{\textless{}{-}}
  \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{p\_1 =}\NormalTok{ .}\DecValTok{3}\NormalTok{,}
    \AttributeTok{p\_2 =}\NormalTok{ .}\DecValTok{7}\NormalTok{,}
    \AttributeTok{q\_1 =} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =}\NormalTok{ .}\DecValTok{01}\NormalTok{, }\AttributeTok{to =}\NormalTok{ .}\DecValTok{99}\NormalTok{, }\AttributeTok{by =}\NormalTok{ .}\DecValTok{01}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{q\_2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ q\_1}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{d\_kl =}\NormalTok{ (p\_1 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_1 }\SpecialCharTok{/}\NormalTok{ q\_1)) }\SpecialCharTok{+}\NormalTok{ (p\_2 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_2 }\SpecialCharTok{/}\NormalTok{ q\_2))}
\NormalTok{  )}

\FunctionTok{head}\NormalTok{(t)}
\CommentTok{\#\textgreater{} \# A tibble: 6 x 5}
\CommentTok{\#\textgreater{}     p\_1   p\_2   q\_1   q\_2  d\_kl}
\CommentTok{\#\textgreater{}   \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1   0.3   0.7  0.01  0.99 0.778}
\CommentTok{\#\textgreater{} 2   0.3   0.7  0.02  0.98 0.577}
\CommentTok{\#\textgreater{} 3   0.3   0.7  0.03  0.97 0.462}
\CommentTok{\#\textgreater{} 4   0.3   0.7  0.04  0.96 0.383}
\CommentTok{\#\textgreater{} 5   0.3   0.7  0.05  0.95 0.324}
\CommentTok{\#\textgreater{} 6   0.3   0.7  0.06  0.94 0.276}
\end{Highlighting}
\end{Shaded}

\noindent Nella figura seguente sull'asse delle ascisse sono rappresentati i valori \(q\) e sull'asse delle ordinante sono riportati i corrispondenti valori \(\mathbb{KL}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ q\_1, }\AttributeTok{y =}\NormalTok{ d\_kl)) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =}\NormalTok{ .}\DecValTok{3}\NormalTok{, }\AttributeTok{linetype =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\AttributeTok{size =} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\AttributeTok{geom =} \StringTok{"text"}\NormalTok{, }\AttributeTok{x =}\NormalTok{ .}\DecValTok{4}\NormalTok{, }\AttributeTok{y =} \FloatTok{1.5}\NormalTok{, }\AttributeTok{label =} \StringTok{"q = p"}\NormalTok{,}
           \AttributeTok{size =} \FloatTok{3.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"q[1]"}\NormalTok{,}
       \AttributeTok{y =} \StringTok{"Divergenza di q da p"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-338-1} \end{center}

Tanto meglio la distribuzione \(q\) approssima la distribuzione target tanto più piccolo è il valore di divergenza KL.
\end{example}

\begin{example}
Sia \(p\) una distribuzione binomiale di parametri \(\theta = 0.2\) e \(n = 5\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{4}
\NormalTok{p }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{true\_py }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\NormalTok{n, n, }\FloatTok{0.2}\NormalTok{)}
\NormalTok{true\_py}
\CommentTok{\#\textgreater{} [1] 0.4096 0.4096 0.1536 0.0256 0.0016}
\end{Highlighting}
\end{Shaded}

\noindent Sia \(q_1\) una approssimazione a \(p\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.46}\NormalTok{, }\FloatTok{0.42}\NormalTok{, }\FloatTok{0.10}\NormalTok{, }\FloatTok{0.01}\NormalTok{, }\FloatTok{0.01}\NormalTok{)}
\NormalTok{q1}
\CommentTok{\#\textgreater{} [1] 0.46 0.42 0.10 0.01 0.01}
\end{Highlighting}
\end{Shaded}

Sia \(q_2\) una distribuzione uniforme:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{q2 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{q2}
\CommentTok{\#\textgreater{} [1] 0.2 0.2 0.2 0.2 0.2}
\end{Highlighting}
\end{Shaded}

La divergenza KL di \(q_1\) da \(p\) è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(true\_py }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(true\_py }\SpecialCharTok{/}\NormalTok{ q1))}
\CommentTok{\#\textgreater{} [1] 0.02925}
\end{Highlighting}
\end{Shaded}

La divergenza KL di \(q_2\) da \(p\) è:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(true\_py }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(true\_py }\SpecialCharTok{/}\NormalTok{ q2))}
\CommentTok{\#\textgreater{} [1] 0.4864}
\end{Highlighting}
\end{Shaded}

È chiaro che perdiamo una quantità maggiore di informazioni se, per descrivere la distribuzione binomiale \(p\), usiamo la distribuzione uniforme \(q_2\) anziché \(q_1\).
\end{example}

\hypertarget{la-divergenza-dipende-dalla-direzione}{%
\section{La divergenza dipende dalla direzione}\label{la-divergenza-dipende-dalla-direzione}}

La divergenza KL non è una vera e propria metrica: per esempio, non è simmetrica. In generale, \(\mathbb{KL}(p \mid\mid q) \neq \mathbb{KL}(q \mid\mid p)\), ovvero la \(\mathbb{KL}\) da \(p\) a \(q\) è diversa dalla \(\mathbb{KL}\) da \(q\) a \(p\).

\begin{example}

Usando le seguenti istruzioni \(\R\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{direction =} \FunctionTok{c}\NormalTok{(}\StringTok{"Da q a p"}\NormalTok{, }\StringTok{"Da p a q"}\NormalTok{),}
       \AttributeTok{p\_1 =} \FunctionTok{c}\NormalTok{(.}\DecValTok{01}\NormalTok{, .}\DecValTok{7}\NormalTok{),}
       \AttributeTok{q\_1 =} \FunctionTok{c}\NormalTok{(.}\DecValTok{7}\NormalTok{, .}\DecValTok{01}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p\_1,}
         \AttributeTok{q\_2 =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ q\_1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{d\_kl =}\NormalTok{ (p\_1 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_1 }\SpecialCharTok{/}\NormalTok{ q\_1)) }\SpecialCharTok{+}\NormalTok{ (p\_2 }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(p\_2 }\SpecialCharTok{/}\NormalTok{ q\_2)))}
\CommentTok{\#\textgreater{} \# A tibble: 2 x 6}
\CommentTok{\#\textgreater{}   direction   p\_1   q\_1   p\_2   q\_2  d\_kl}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{} \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 Da q a p   0.01  0.7   0.99  0.3   1.14}
\CommentTok{\#\textgreater{} 2 Da p a q   0.7   0.01  0.3   0.99  2.62}
\end{Highlighting}
\end{Shaded}

\end{example}

\hypertarget{confronto-tra-modelli}{%
\section{Confronto tra modelli}\label{confronto-tra-modelli}}

La divergenza KL viene utilizzata nel confronto tra modelli, ovvero ci consente di quantificare l'informazione che viene perduta quando utilizziamo la distribuzione di probabilità ipotizzata da un modello, chiamiamola \(p_{\mathcal{M}}\), per approssimare la distribuzione di probabilità del vero modello generatore dei dati, \(p_t\).

Nel Capitolo \ref{ch:intro-bayes-inference} abbiamo introdotto il concetto di distribuzione predittiva a posteriori:

\[
p(\tilde{y} \mid y) = \int_\Theta p(\tilde{y} \mid \theta) p(\theta \mid y) \,\operatorname {d}\!\theta .
\]

La distribuzione predittiva a posteriori descrive il tipo di dati che ci aspettiamo vengano prodotti dal modello generativo \(\mathcal{M}\), alla luce delle nostre credenze iniziali, \(p(\theta)\) e dei dati osservati \(y\). Quando valutiamo un modello ci chiediamo in che misura \(p_{\mathcal{M}}(\tilde{y} \mid y)\) approssimi \(p_t(\tilde{y})\). Cioè, ci chiediamo quanto siano simili i dati \(p_{\mathcal{M}}(\cdot)\) prodotti dal modello \(\mathcal{M}\) ai dati prodotti dal vero processo generatore dei dati \(p_t(\cdot)\).

Una misura della ``somiglianza'' tra la distribuzione \(q_{\mathcal{M}}\) ipotizzata dal modello \(\mathcal{M}\) e la distribuzione \(p_t\) del vero modello generatore dei dati è fornita dalla divergenza di Kullback-Leibler \(\mathbb{KL}(p_t \mid\mid q_{\mathcal{M}})\). Supponendo di avere \(k\) modelli della distribuzione a posteriori, \(\{q_{\mathcal{M}_1}, q_{\mathcal{M}_2}, \dots, q_{\mathcal{M}_k}\}\), e di conoscere il vero modello generatore dei dati, possiamo scrivere

\begin{align}
\mathbb{KL} (p_t \mid\mid q_{\mathcal{M}_1}) &= \E (\log p_{\mathcal{M}_0}) - \E (\log q_{\mathcal{M}_1})\notag\\
\mathbb{KL} (p_t \mid\mid q_{\mathcal{M}_2}) &= \E (\log p_t) - \E (\log q_{\mathcal{M}_2})\notag\\
&\cdots\notag\\
\mathbb{KL} (p_t \mid\mid q_{\mathcal{M}_k}) &= \E (\log p_{\mathcal{M}_0}) - \E (\log q_{\mathcal{M}_k}).
\label{eq:kl-mod-comp}
\end{align}

La \eqref{eq:kl-mod-comp} può sembrare un esercizio futile poiché nella vita reale non conosciamo il vero modello generatore dei dati. È però facile rendersi conto che, poiché \(p_t\) è la stessa per tutti i confronti, diventa possibile costruire un ordinamento dei modelli basato unicamente sul secondo termine della \eqref{eq:kl-mod-comp}, ovvero senza nessun riferimento al vero modello generatore dei dati. Per un generico modello \(\mathcal{M}\), il secondo termine della \eqref{eq:kl-mod-comp} può essere scritto come:

\begin{equation}
\E \log p_{\mathcal{M}}(y) = \int_{-\infty}^{+\infty}p_{t}(y)\log p_{\mathcal{M}}(y) \,\operatorname {d}\!y .
\label{eq:kl-div-cont-t2}
\end{equation}

\hypertarget{expected-log-predictive-density}{%
\section{Expected log predictive density}\label{expected-log-predictive-density}}

Le previsioni del modello \(\mathcal{M}\) sui nuovi dati futuri sono date dalla distribuzione predittiva a posteriori. Possiamo dunque riscrivere la \eqref{eq:kl-div-cont-t2} come

\begin{equation}
\elpd = \int_{\tilde{y}} p_{t}(\tilde{y}) \log p(\tilde{y} \mid y) \,\operatorname {d}\!\tilde{y}.
\label{eq:elpd}
\end{equation}

La \eqref{eq:elpd} è chiamata \emph{expected log predictive density} (\(\elpd\)) e fornisce la risposta al problema che ci eravamo posti: nel confronto tra modelli, come è possibile scegliere il modello più simile al vero meccanismo generatore dei dati? Possiamo pensare alla \eqref{eq:elpd} dicendo che descrive la distribuzione predittiva a posteriori del modello ponderando la verosimiglianza dei possibili (sconosciuti) dati futuri (\(\tilde{y}\)) con la vera distribuzione \(p_t\). Di conseguenza, valori \(\elpd\) più grandi identificano il modello che risulta più simile al vero meccanismo generatore dei dati.

Non dobbiamo preoccuparci di trovare una formulazione analitica della distribuzione predittiva a posteriori \(p(\tilde{y} \mid y)\) perché, come abbiamo visto nel Capitolo \ref{chapter-ppc}, è possibile approssimare tale distribuzione mediante simulazione. Notiamo però che la \eqref{eq:elpd} include un termine, \(p_t(\tilde{y})\), il quale descrive la distribuzione dei dati futuri \(\tilde{y}\) secondo il vero modello generatore dei dati. Il termine \(p_t\), ovviamente, è ignoto.\footnote{Se il modello sottostante i dati fosse noto non avremmo bisogno di cercare il modello migliore, perché \(p_t\) è il modello migliore.} Di conseguenza, la quantità \(\elpd\) non può mai essere calcolata in maniera esatta, ma può solo essere stimata. Il secondo problema di questo Capitolo è capire come la \eqref{eq:elpd} possa essere stimata utilizzando un campione di osservazioni.

\hypertarget{log-pointwise-predictive-density}{%
\subsection{Log pointwise predictive density}\label{log-pointwise-predictive-density}}

Ingenuamente, potremmo pensare di stimare la \eqref{eq:elpd} ipotizzando che la distribuzione del campione coincida con \(p_t\). Usare la distribuzione del campione come proxy del vero modello generatore dei dati (ovvero, ipotizzare che la distribuzione del campione rappresenti fedelmente \(p_t\)) comporta due conseguenze:

\begin{itemize}
\tightlist
\item
  non è necessario ponderare per \(p_t\), in quanto assumiamo che la distribuzione empirica del campione corrisponda a \(p_t\) (ciò significa assumere che i valori più comunemente osservati nel campione siano anche quelli più verosimili nella vera distribuzione \(p_t\));
\item
  dato che il campione è finito, anziché eseguire un'operazione di integrazione possiamo semplicemente sommare la densità predittiva a posteriori delle osservazioni.
\end{itemize}

Questo conduce alla seguente equazione:\footnote{In riferimento alla notazione, ricordiamo che \citet{gelman2014understanding} distinguono tra \(y^{rep}\) e \(\tilde{y}\). I valori \(y^{rep}\) corrispondono ad un'altra possibile realizzazione del medesimo modello statistico che ha prodotto \(y\) mediante determinati valori dei parametri \(\theta\) (repliche sotto lo stesso modello statistico). I valori \(\tilde{y}\) corrispondono invece ad un campione empirico di dati osservato in qualche futura occasione.}

\begin{equation}
\frac{1}{n} \sum_{i=1}^n \log p(y_i^{rep} \mid y).
\label{eq:1n-lppd}
\end{equation}

La quantità \eqref{eq:1n-lppd}, senza il passaggio finale della divisione per il numero di osservazioni, è chiamata \emph{log pointwise predictive density} (\(\lppd\))

\begin{equation}
\lppd = \sum_{i=1}^n \log p(y_i^{rep} \mid y)
\label{eq:lppd}
\end{equation}

e corrisponde alla somma delle densità predittive logaritmiche delle \(n\) osservazioni. Valori più grandi della \eqref{eq:lppd} sono da preferire perché indicano una maggiore accuratezza media. È anche comune vedere espressa la quantità precedente nei termini della \emph{devianza}, ovvero alla \(\lppd\) moltiplicata per -2. In questo secondo caso sono da preferire valori piccoli.

È importante notare che \(\lppd\) fornisce una \emph{sovrastima} della \eqref{eq:elpd}. Tale sovrastima è dovuta al fatto che, nel calcolo della \eqref{eq:lppd}, abbiamo usato \(p(y^{rep} \mid y)\) al posto di \(p(\tilde{y} \mid y)\): in altri termini, abbiamo considerato le osservazioni del campione come se fossero un nuovo campione di dati. In una serie di simulazioni, \citet{McElreath_rethinking} esamina il significato di questa sovrastima. Nelle simulazioni la devianza viene calcolata come funzione della complessità (ovvero, il numero di parametri) del modello. La simulazione mostra che \(\lppd\) aumenta al crescere del numero di parametri del modello. Ciò significa che \(\lppd\) mostra lo stesso limite del coefficiente di determinazione: aumenta all'aumentare della complessità del modello.

\begin{example}

Esaminiamo un esempio tratto da \href{https://vasishth.github.io/bayescogsci/book/expected-log-predictive-density-of-a-model.html}{Bayesian Data Analysis for Cognitive Science} nel quale la \(\elpd\) viene calcolata in forma esatta oppure mediante approssimazione. Supponiamo di disporre di un campione di \(n\) osservazioni. Supponiamo inoltre di conoscere il vero processo generativo dei dati (qualcosa che in pratica non è mai possibile), ovvero:

\[
p_t(y) = \Beta(1, 3).
\] I dati sono

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{75}\NormalTok{)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{y\_data }\OtherTok{\textless{}{-}} \FunctionTok{rbeta}\NormalTok{(n, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\FunctionTok{head}\NormalTok{(y\_data)}
\CommentTok{\#\textgreater{} [1] 0.55062 0.13346 0.80251 0.21431 0.01913 0.08677}
\end{Highlighting}
\end{Shaded}

Supponiamo inoltre di avere adattato ai dati un modello bayesiano \(\mathcal{M}\) e di avere ottenuto la distribuzione a posteriori per i parametri del modello. Inoltre, supponiamo di avere derivato la forma analitica della distribuzione predittiva a posteriori per il modello:

\[
p(y^{rep} \mid y) \sim \Beta(2, 2).
\]

Questa distribuzione ci dice quanto sono credibili i possibili dati futuri.

Conoscendo la vera distribuzione dei dati \(p_t(y)\) possiamo calcolare in forma esatta la quantità \(\elpd\), ovvero

\[
\elpd = \int_{y^{rep}}p_{t}(y^{rep})\log p(y^{rep} \mid y) \,\operatorname {d}\!y^{rep}.
\]

Svolgiamo i calcoli in \(\R\) otteniamo:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# True distribution}
\NormalTok{p\_t }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) }\FunctionTok{dbeta}\NormalTok{(y, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\CommentTok{\# Predictive distribution}
\NormalTok{p }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) }\FunctionTok{dbeta}\NormalTok{(y, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\CommentTok{\# Integration}
\NormalTok{integrand }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y) }\FunctionTok{p\_t}\NormalTok{(y) }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FunctionTok{p}\NormalTok{(y))}
\FunctionTok{integrate}\NormalTok{(}\AttributeTok{f =}\NormalTok{ integrand, }\AttributeTok{lower =} \DecValTok{0}\NormalTok{, }\AttributeTok{upper =} \DecValTok{1}\NormalTok{)}
\CommentTok{\#\textgreater{} {-}0.3749 with absolute error \textless{} 6.8e{-}07}
\end{Highlighting}
\end{Shaded}

Tuttavia, in pratica non conosciamo mai \(p_t(y)\). Quindi approssimiamo \(\elpd\) usando la \eqref{eq:elpd}:

\[
\frac{1}{n} \sum_{i=1}^n \log p(y_i \mid y).
\]

Così facendo, e svolgendo i calcoli in \(\R\), otteniamo un valore diverso da quello trovato in precedenza:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{/}\NormalTok{n }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(}\FunctionTok{log}\NormalTok{(}\FunctionTok{p}\NormalTok{(y\_data)))}
\CommentTok{\#\textgreater{} [1] {-}0.3639}
\end{Highlighting}
\end{Shaded}

\end{example}

\hypertarget{commenti-e-considerazioni-finali-23}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-23}}


Dato che non conosciamo il vero meccanismo generatore dei dati \(p\), possiamo usare la distribuzione dei dati osservata come proxy per la vera distribuzione \(p\). Quindi, invece di ponderare la distribuzione predittiva in base alla densità reale di tutti i possibili dati futuri, utilizziamo semplicemente le \(n\) osservazioni che abbiamo. Possiamo farlo perché assumiamo che le nostre osservazioni costituiscano un campione dalla vera distribuzione dei dati: in base a questa ipotesi, nel campione ci aspettiamo di osservare più frequentemente quelle osservazioni che hanno una maggiore verosimiglianza nella vera distribuzione \(p\). È così possibile giungere ad una stima numerica della \(\elpd\) chiamata \emph{log pointwise predictive density} (\(\lppd\)).

\hypertarget{ch:info-criterion}{%
\chapter{Criterio di informazione e convalida incrociata}\label{ch:info-criterion}}

Nel Capitolo precedente abbiamo visto che la \eqref{eq:lppd} fornisce una sovrastima della \(\elpd\). Il modo migliore per stimare \(\elpd\) è raccogliere un nuovo campione indipendente di dati, che si ritiene condivida lo stesso processo di generazione dei dati del campione corrente, e stimare \(\elpd\) sul nuovo campione. Questa procedura è chiamata \emph{out-of-sample validation}. Il problema, però, è che solitamente non abbiamo le risorse per raccogliere un nuovo campione di osservazioni. Di conseguenza, gli statistici hanno messo a punto vari metodi per evitare la sovrastima della \(\elpd\) che deriva dal solo utizzo del campione corrente. Ci sono due approcci generali:

\begin{itemize}
\tightlist
\item
  l'introduzione di un fattore di correzione;
\item
  la convalida incrociata cosiddetta K-fold.
\end{itemize}

Lo scopo del presente Capitolo è di fornire una breve introduzione ai criteri dell'informazione e alla procedura della convalida incrociata.

\hypertarget{aic-dic-e-waic}{%
\section{AIC, DIC e WAIC}\label{aic-dic-e-waic}}

Allo scopo di evitare la sovrastima della \eqref{eq:lppd}, le statistiche \emph{Akaike Information Criterion} (AIC), \emph{Deviance Information Criterion} (DIC) e \emph{Widely Applicable Information Criterion} (WAIC) introducono un fattore di correzione. Le statistiche DIC e WAIC sono più complesse di AIC, ma producono un'approssimazione migliore. Tuttavia, i valori AIC, DIC e WAIC sono spesso molto simili tra loro. Per convenienza, dunque, qui ci accontenteremo di esaminare in dettaglio la statistica più semplice, ovvero AIC.

\hypertarget{criterio-dinformazione-di-akaike}{%
\subsection{Criterio d'informazione di Akaike}\label{criterio-dinformazione-di-akaike}}

Il criterio d'informazione di Akaike (in inglese \emph{Akaike information criterion}, indicato come AIC) fornisce un metodo molto semplice per approssimare \(\elpd\).

\begin{definition}
Il criterio d'informazione di Akaike è definito come

\begin{equation}
AIC = -2 \log p(y \mid \hat{\theta}_{MLE}) + 2k,
\end{equation}

dove \(k\) è il numero di parametri stimati nel modello e \(p(y \mid \hat{\theta}_{MLE})\) è il valore massimizzato della funzione di verosimiglianza del modello stimato.
\end{definition}

Dividendo per -2, otteniamo \(\elpd_{AIC}\):

\begin{equation}
\widehat{\elpd}_{AIC} = \log p(y \mid \hat{\theta}_{MLE}) - k,
\end{equation}

dove \(k\) è il fattore di correzione introdotto per evitare la sovrastima discussa in precedenza.

AIC è di interesse principalmente storico e produce una approssimazione attendibile di \(\elpd\) quando:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  le distribuzioni a priori sono non informative;
\item
  la distribuzione a posteriori è approssimativamente gaussiana multivariata;
\item
  la dimensione \(n\) del campione è molto maggiore del numero \(k\) dei parametri.
\end{enumerate}

\begin{example}
Per meglio comprendere la statistica \(\widehat{\elpd}_{AIC}\), esaminiamo un esempio discusso da \citet{gelman2014understanding}. Sia \(y_1, \dots, y_n \sim \mathcal{N}(\mu, 1)\) un campione di osservazioni. Nel caso di una distribuzione a priori non-informativa \(p(\theta) \propto 1\), la stima di massima verosimiglianza è \(\bar{y}\). La verosimiglianza è

\[
f(Y \mid \mu, \sigma) = \prod_{i=1}^n f(y \mid \mu, \sigma)
\]

e la log-verosimiglianza diventa

\[
\ell(Y \mid \mu, \sigma) = \sum_{i=1}^n \log (f(y \mid \mu, \sigma)).
\] Ovvero,

\begin{align}
\ell(Y \mid \mu, \sigma) &= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi\sigma^2 }}}\exp \left(-{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma^{2}}}\right) \right)\notag\\
&= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \sum_{i=1}^n{\frac {1}{2}}{\frac {(y_i-\mu )^{2}}{\sigma ^{2}}} \notag\\
&= \sum_{i=1}^n \log \left( \frac {1}{{\sqrt {2\pi \sigma^2}}} \right) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag \\
&= \sum_{i=1}^n \log (1) - \sum_{i=1}^n\log \sqrt{2\pi \sigma^2} - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&= - \sum_{i=1}^n\frac{1}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2} \notag\\
&= - \frac{n}{2}  \log (2\pi\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i-\mu )^{2}. \notag
\end{align}

Se \(y \sim \mathcal{N}(\mu, 1)\), usando lo stimatore di massima verosimiglianza per \(\mu\), la log-verosimiglianza diventa

\begin{align}
\log p(y \mid \hat{\theta}_{MLE}) &= -\frac{n}{2} \log (2\pi) - \frac{1}{2}\sum_{i=1}^n (y_i - \bar{y})^2 \notag\\
&= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2,
\end{align}

dove \(s_y^2\) è la varianza campionaria.

Nel caso di un modello gaussiano con con varianza nota e una distribuzione a priori uniforme viene stimato un solo parametro, per cui

\begin{align}
\widehat{\elpd}_{AIC} &= \log p(y \mid \hat{\theta}_{MLE}) - k \notag \\
&= -\frac{n}{2} \log (2\pi) - \frac{1}{2} (n-1)s_y^2 - 1.
\end{align}
\end{example}

\hypertarget{convalida-incrociata-k-fold}{%
\section{Convalida incrociata K-fold}\label{convalida-incrociata-k-fold}}

La sovrastima della \eqref{eq:lppd} può anche essere evitata usando una tecnica chiamata \emph{K-fold cross-validation}. Mediante questo metodo vengono stimati i parametri del modello tralasciando una porzione di osservazioni (chiamata \emph{fold}) dal campione per poi valutare il modello sulle osservazioni che sono state escluse. Una stima complessiva dell'accuratezza si ottiene poi calcolando la media del punteggio di accuratezza ottenuto in ogni fold. Il numero minimo di fold è 2; all'altro estremo, è possibile impiegare una singola osservazione in ciascun fold e adattare il modello tante volte (\(n\)) quante sono le singole osservazioni. Questa strategia è chiamata \emph{leave-one-out cross-validation} (LOO-CV).

\hypertarget{importance-sampling}{%
\subsection{Importance sampling}\label{importance-sampling}}

La strategia LOO-CV è computazionalmente onerosa (ovvero, richiede un tempo di esecuzione molto lungo). È però possibile approssimare LOO-CV mediante un metodo chiamato \emph{Pareto-smoothed importance sampling cross-validation} {[}PSIS; \citet{vehtari2017practical}{]}. Tralasciando qui i dettagli matematici, l'intuizione di base è che PSIS fa leva sul punteggio di ``importanza'' posseduto da ciascuna osservazione all'interno della distribuzione a posteriori. Per ``importanza'' si intende il fatto che alcune osservazioni hanno un impatto maggiore sulle proprietà della distribuzione a posteriori di altre: se viene rimossa un'osservazione importante, le proprietà della distribuzione a posteriori cambiano molto; se viene rimossa un'osservazione poco importante, la distribuzione a posteriori cambia poco. L'``importanza'' così intesa viene chiamata ``peso'' (\emph{weight}) e tali pesi vengono utilizzati per stimare l'accuratezza \emph{out-of-sample} del modello. PSIS-LOO-CV richiede che il modello venga adattato una volta soltanto ai dati e fornisce una stima della devianza \emph{out-of-sample} che evita la sovrastima della \eqref{eq:lppd}. Inoltre, PSIS-LOO-CV fornisce un feedback sulla propria affidabilità identificando le osservazioni i cui pesi molto elevati potrebbero rendere imprecisa la predizione.

Valori \(\widehat{\elpd}_{\LOO}\) più grandi indicano una maggiore accuratezza predittiva. In alternativa, anziché considerare \(\widehat{\elpd}\), è possibile usare la quantità \(-2 \cdot \widehat{\elpd}\), la quale è chiamata \emph{LOO Information Criterion} (LOOIC). In questo secondo caso, valori LOOIC più piccoli sono da preferire.

La quantità \(\widehat{\elpd}_{\LOO}\) viene calcolata dai pacchetti \texttt{loo} e \texttt{brms} ed è chiamata \texttt{elpd\_loo} o \texttt{elpd\_kfold}. È anche possibile calcolare la differenza della quantità \texttt{elpd\_loo} per modelli alternativi, insieme alla deviazione standard della distribuzione campionaria di tale differenza.

\hypertarget{confronto-tra-aic-e-loo-cv}{%
\section{Confronto tra AIC e LOO-CV}\label{confronto-tra-aic-e-loo-cv}}

Per fare un esempio, faremo qui un confronto tra \(\widehat{\elpd}_{AIC}\) e \(\widehat{\elpd}_{LOO-CV}\). Esaminiamo nuovamente l'associazione tra il QI dei figli e il QI delle madri nel campione di dati discusso da \citet{gelman2020regression}. Una tale relazione può essere descritta da un modello di regressione nel quale la \(y\) corrisponde al QI dei figli e la \(x\) al QI delle madri.

Leggiamo i dati in \R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"foreign"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.dta}\NormalTok{(}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score)[, }\DecValTok{1}\NormalTok{]}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)[, }\DecValTok{1}\NormalTok{]}
\FunctionTok{head}\NormalTok{(df)}
\CommentTok{\#\textgreater{}   kid\_score mom\_hs mom\_iq mom\_work mom\_age        y}
\CommentTok{\#\textgreater{} 1        65      1 121.12        4      27 {-}1.06793}
\CommentTok{\#\textgreater{} 2        98      1  89.36        4      25  0.54887}
\CommentTok{\#\textgreater{} 3        85      1 115.44        4      27 {-}0.08805}
\CommentTok{\#\textgreater{} 4        83      1  99.45        3      25 {-}0.18604}
\CommentTok{\#\textgreater{} 5       115      1  92.75        4      27  1.38176}
\CommentTok{\#\textgreater{} 6        98      0 107.90        1      18  0.54887}
\CommentTok{\#\textgreater{}         x1}
\CommentTok{\#\textgreater{} 1  1.40784}
\CommentTok{\#\textgreater{} 2 {-}0.70921}
\CommentTok{\#\textgreater{} 3  1.02954}
\CommentTok{\#\textgreater{} 4 {-}0.03669}
\CommentTok{\#\textgreater{} 5 {-}0.48362}
\CommentTok{\#\textgreater{} 6  0.52679}
\end{Highlighting}
\end{Shaded}

Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1\_freq }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{AIC}\NormalTok{(m1\_freq) }\SpecialCharTok{/} \SpecialCharTok{{-}}\DecValTok{2}
\CommentTok{\#\textgreater{} [1] {-}569.6}
\end{Highlighting}
\end{Shaded}

Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] x1;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta1;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    mu[n] = alpha + beta1*x1[n];}
\StringTok{  \}}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta1 \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 1);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  vector[N] log\_lik;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    y\_rep[n] = normal\_rng(mu[n], sigma);}
\StringTok{    log\_lik[n] = normal\_lpdf(y[n] | x1[n] * beta1, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/simplereg.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data1\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file1 }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"simplereg.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1 }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file1)}
\end{Highlighting}
\end{Shaded}

Eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}}\NormalTok{ mod1}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data1\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Calcoliamo infine la quantità \(\widehat{\elpd}_{LOO-CV}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo1\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit1}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\FunctionTok{print}\NormalTok{(loo1\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}568.6 14.5}
\CommentTok{\#\textgreater{} p\_loo         1.9  0.2}
\CommentTok{\#\textgreater{} looic      1137.2 28.9}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is 0.0.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All Pareto k estimates are good (k \textless{} 0.5).}
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Si noti la somiglianza tra \(\widehat{\elpd}_{LOO-CV}\) e \(\widehat{\elpd}_{AIC}\). In conclusione, possiamo dunque dire che \(\widehat{\elpd}_{LOO-CV}\) è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica \(\widehat{\elpd}_{AIC}\).

\hypertarget{confronto-tra-modelli-mediante-loo-cv}{%
\section{Confronto tra modelli mediante LOO-CV}\label{confronto-tra-modelli-mediante-loo-cv}}

Come menzionato in precedenza, l'obiettivo centrale della misurazione dell'accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.\footnote{A questo proposito, è necessario aggiungere una nota di cautela. Come fa notare \citet{McElreath_rethinking}, fare previsioni e inferire i rapporti causali sono due cose molto diverse. Statistiche quali AIC, WAIC e LOO-CV consentono di individuare modelli con buone capacità predittive. Tali modelli, tuttavia, non riflettono necessariamente la struttura causale del fenomeno considerato: la selezione di modelli basata unicamente sull'accuratezza predittiva non garantisce che venga selezionato il modello che riflette la struttura causale del fenomeno \citep[si veda anche][]{navarro2019between}.}

Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all'età della madre. L'aggiunta di tale predittore migliori l'accuratezza predittiva del modello?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] x1;}
\StringTok{  vector[N] x2;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta1;}
\StringTok{  real beta2;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    mu[n] = alpha + beta1*x1[n] + beta2*x2[n];}
\StringTok{  \}}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta1 \textasciitilde{} normal(0, 1);}
\StringTok{  beta2 \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 1);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  vector[N] log\_lik;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    y\_rep[n] = normal\_rng(mu[n], sigma);}
\StringTok{    log\_lik[n] = normal\_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/mreg2.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_age)[, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data2\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x1,}
  \AttributeTok{x2 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file2 }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"mreg2.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compile model}
\NormalTok{mod2 }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file2)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Running MCMC}
\NormalTok{fit2 }\OtherTok{\textless{}{-}}\NormalTok{ mod2}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data2\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta1"}\NormalTok{, }\StringTok{"beta2"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 10}
\CommentTok{\#\textgreater{}   variable      mean    median     sd    mad      q5}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}        \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    {-}0.000255 {-}0.000162 0.0431 0.0427 {-}0.0714}
\CommentTok{\#\textgreater{} 2 beta1     0.442     0.442    0.0427 0.0427  0.372 }
\CommentTok{\#\textgreater{} 3 beta2     0.0515    0.0514   0.0427 0.0428 {-}0.0179}
\CommentTok{\#\textgreater{} 4 sigma     0.896     0.895    0.0305 0.0303  0.848 }
\CommentTok{\#\textgreater{} \# ... with 4 more variables: q95 \textless{}dbl\textgreater{}, rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo2\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit2}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\FunctionTok{print}\NormalTok{(loo2\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}568.9 14.5}
\CommentTok{\#\textgreater{} p\_loo         3.0  0.3}
\CommentTok{\#\textgreater{} looic      1137.8 29.0}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is 0.0.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All Pareto k estimates are good (k \textless{} 0.5).}
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l'aggiunta di tale predittore migliori la capacità predittiva del modello.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] x1;}
\StringTok{  vector[N] x3;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta1;}
\StringTok{  real beta3;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    mu[n] = alpha + beta1*x1[n] + beta3*x3[n];}
\StringTok{  \}}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta1 \textasciitilde{} normal(0, 1);}
\StringTok{  beta3 \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 1);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  vector[N] log\_lik;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    y\_rep[n] = normal\_rng(mu[n], sigma);}
\StringTok{    log\_lik[n] = normal\_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/mreg3.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{x3 }\OtherTok{\textless{}{-}}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_hs}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data3\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x1,}
  \AttributeTok{x3 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x3}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file3 }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"mreg3.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod3 }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file3)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit3 }\OtherTok{\textless{}{-}}\NormalTok{ mod3}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data3\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit3}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta1"}\NormalTok{, }\StringTok{"beta3"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 10}
\CommentTok{\#\textgreater{}   variable   mean median     sd    mad     q5     q95}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    {-}0.225 {-}0.224 0.0947 0.0945 {-}0.382 {-}0.0705}
\CommentTok{\#\textgreater{} 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488 }
\CommentTok{\#\textgreater{} 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465 }
\CommentTok{\#\textgreater{} 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941 }
\CommentTok{\#\textgreater{} \# ... with 3 more variables: rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo3\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit3}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\FunctionTok{print}\NormalTok{(loo3\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}584.2 16.4}
\CommentTok{\#\textgreater{} p\_loo         7.5  0.6}
\CommentTok{\#\textgreater{} looic      1168.3 32.8}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is 0.0.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All Pareto k estimates are good (k \textless{} 0.5).}
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Per eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni \(\R\) producono la quantità \texttt{elpd\_diff}, ovvero la differenza tra stime della \(\elpd\) fornite da due modelli. Il primo argomento della funzione \texttt{loo\_compare()} specifica il modello che viene usato come confronto. Nella prima riga dell'output, il valore \texttt{elpd\_diff} è 0 (cioè, \(x − x = 0\)). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna \texttt{se\_diff} riporta l'errore standard di tali differenze.

L'incertezza della stima dell'accuratezza \emph{out-of-sample} si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell'output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell'incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{loo\_compare}\NormalTok{(loo1\_result, loo2\_result, loo3\_result)}
\FunctionTok{print}\NormalTok{(w)}
\CommentTok{\#\textgreater{}        elpd\_diff se\_diff}
\CommentTok{\#\textgreater{} model1   0.0       0.0  }
\CommentTok{\#\textgreater{} model2  {-}0.3       1.3  }
\CommentTok{\#\textgreater{} model3 {-}15.6       6.0}
\end{Highlighting}
\end{Shaded}

Per interpretare l'output, usiamo il criterio suggerito da \citet{gelman1995bayesian}: consideriamo ``credibile'' una differenza se \texttt{elpd\_diff} è almeno due volte maggiore di \texttt{se\_diff}. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità \texttt{elpd\_diff} è molto piccola rispetto al suo errore standard. Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell'età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità \texttt{elpd\_diff} è maggiore di due volte il valore dell'errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.

È anche possibile calcolare l'intervallo di credibilità per \texttt{elpd\_diff}:

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{15.5} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FloatTok{6.0}
\CommentTok{\#\textgreater{} [1]  5.631 25.369}
\end{Highlighting}
\end{Shaded}

\hypertarget{outlier}{%
\section{Outlier}\label{outlier}}

Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano \emph{outlier}. È dunque necessario identificare gli outlier e limitare la loro influenza sull'inferenza.\footnote{\citet{McElreath_rethinking} nota che, spesso, i ricercatori eliminano i valori anomali prima di adattare un modello ai dati, basandosi solo sulla distanza dal valore medio della variabile dipendente misurata in termini di unità di deviazione standard. Secondo \citet{McElreath_rethinking} questo non dovrebbe mai essere fatto: un'osservazione può essere considerata come un valore anomalo o un valore influente solo alla luce delle predizioni di un modello (mai prima di avere adattato il modello ai dati). Se ci sono solo pochi valori anomali una strategia possibile è quella di riportare i risultati delle analisi statistiche svolte su tutto il campione dei dati oppure dopo avere eliminato le osservazioni anomale e influenti.}

Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto \texttt{loo}, l'output riporta il parametro di forma della distribuzione di Pareto (valore \texttt{k}). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore \texttt{k} valuta, per ciascun punto del campione, l'approssimazione usata da PSIS-LOO-CV. Se \(k < 0.5\), i pesi di importanza vengono stimati in modo accurato; se il valore \(k\) di Pareto di un punto è \(> 0.7\), i pesi di importanza possono essere inaccurati. Le osservazioni con \(k > 0.7\) sono dunque osservazioni outlier.

Per fare un esempio concreto, introduciamo nel campione dell'esempio precedente una singola osservazione outlier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1 }\OtherTok{\textless{}{-}}\NormalTok{ df}
\FunctionTok{dim}\NormalTok{(df1)}
\CommentTok{\#\textgreater{} [1] 434   9}
\NormalTok{df1}\SpecialCharTok{$}\NormalTok{x1[}\DecValTok{434}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{df1}\SpecialCharTok{$}\NormalTok{y[}\DecValTok{434}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

Sistemiamo i dati nel formato appropriato per Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data1a\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df1}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df1}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df1}\SpecialCharTok{$}\NormalTok{x1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1a }\OtherTok{\textless{}{-}}\NormalTok{ mod1}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data1a\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo1a\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit1a}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(loo1a\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}586.2 19.9}
\CommentTok{\#\textgreater{} p\_loo         6.6  5.0}
\CommentTok{\#\textgreater{} looic      1172.5 39.8}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is NA.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Pareto k diagnostic values:}
\CommentTok{\#\textgreater{}                          Count Pct.    Min. n\_eff}
\CommentTok{\#\textgreater{} ({-}Inf, 0.5]   (good)     433   99.8\%   10708     }
\CommentTok{\#\textgreater{}  (0.5, 0.7]   (ok)         0    0.0\%   \textless{}NA\textgreater{}      }
\CommentTok{\#\textgreater{}    (0.7, 1]   (bad)        1    0.2\%   75        }
\CommentTok{\#\textgreater{}    (1, Inf)   (very bad)   0    0.0\%   \textless{}NA\textgreater{}      }
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(loo1a\_result)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-380-1} \end{center}

Il valore \texttt{k} stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L'indice dell'osservazione outlier è identificato con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pareto\_k\_ids}\NormalTok{(loo1a\_result, }\AttributeTok{threshold =} \FloatTok{0.7}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 434}
\end{Highlighting}
\end{Shaded}

\hypertarget{commenti-e-considerazioni-finali-24}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-24}}


In questo Capitolo, abbiamo imparato come usare la convalida incrociata K-fold e la convalida incrociata leave-one-out, utilizzando Stan insieme al pacchetto \texttt{loo}. Abbiamo esaminato alcuni esempi di confronto di modelli in cui la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata sarà utile quando si confrontano modelli piuttosto diversi; quando i modelli sono molto simili, invece, sarà difficile distinguerli. In particolare, per i dati tipici della psicologia, sarà difficile ottenere risultati conclusivi dai confronti di modelli tramite la convalida incrociata se l'effetto è molto piccolo e/o il campione di dati è piccolo. In questi casi, se l'obiettivo è trovare prove a sostengo di un'affermazione teorica, alcuni ricercatori ritengono che altri metodi di confronto dei modelli siano più utili, come ad esempio i fattori di Bayes. L'uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile sarebbe preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.

\hypertarget{ch:varsel}{%
\chapter{Selezione di variabili}\label{ch:varsel}}

I concetti che sono stati introdotti in questa parte della dispensa, tra le altre cose, risultano utili per affrontare un problema importante in psicologia, ovvero quello della semplificazione di un modello di regressione che contiene molti predittori. Il problema è quello di selezionare un insieme di variabili indipendenti così che tale selezione non comporti una apprezzabile perdita nella capacità predittiva del modello ristretto rispetto al modello completo.

\hypertarget{limportanza-delle-variabili}{%
\section{L'importanza delle variabili}\label{limportanza-delle-variabili}}

Un modo per identificare le variabili rilevanti per prevedere una determinata variabile risposta è quello di utilizzare il metodo basato sulla proiezione, come discusso nel seguente \href{https://cran.r-project.org/web/packages/projpred/vignettes/quickstart.html}{link} e in \citet{piironen2017comparison}. Per descrivere questa procedura, adatto qui un esempio discusso da Mark Lai in \href{https://bookdown.org/marklhc/notes_bookdown/model-comparison-and-regularization.html}{Course Handouts for Bayesian Data Analysis Class}. Iniziamo a leggere i dati.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kidiq }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(here}\SpecialCharTok{::}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\NormalTok{kidiq }\OtherTok{\textless{}{-}}\NormalTok{ kidiq }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{mom\_hs =} \FunctionTok{factor}\NormalTok{(mom\_hs, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"no"}\NormalTok{, }\StringTok{"yes"}\NormalTok{))}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Per semplificare l'analisi, standardizzo le variabili numeriche.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scale\_this }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{as.vector}\NormalTok{(}\FunctionTok{scale}\NormalTok{(x))}
\NormalTok{kidiq\_scaled }\OtherTok{\textless{}{-}}\NormalTok{ kidiq }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\FunctionTok{across}\NormalTok{(}\FunctionTok{where}\NormalTok{(is.numeric), scale\_this))}
\NormalTok{kidiq\_scaled }\OtherTok{\textless{}{-}}\NormalTok{ kidiq\_scaled }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{mom\_hs =}\NormalTok{ kidiq}\SpecialCharTok{$}\NormalTok{mom\_hs}
\NormalTok{  )}
\FunctionTok{glimpse}\NormalTok{(kidiq\_scaled)}
\CommentTok{\#\textgreater{} Rows: 434}
\CommentTok{\#\textgreater{} Columns: 5}
\CommentTok{\#\textgreater{} $ kid\_score \textless{}dbl\textgreater{} {-}1.06793, 0.54887, {-}0.08805, {-}0.186\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_hs    \textless{}fct\textgreater{} yes, yes, yes, yes, yes, no, yes, y\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_iq    \textless{}dbl\textgreater{} 1.40784, {-}0.70921, 1.02954, {-}0.0366\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_work  \textless{}dbl\textgreater{} 0.93422, 0.93422, 0.93422, 0.08777,\textasciitilde{}}
\CommentTok{\#\textgreater{} $ mom\_age   \textless{}dbl\textgreater{} 1.56023, 0.81978, 1.56023, 0.81978,\textasciitilde{}}
\end{Highlighting}
\end{Shaded}

Il seguente modello di regressione utilizza \texttt{kid\_score} quale variabile dipendente e, quali predittori, include tutte le altre variabili disponibili e le loro interazioni a due vie.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(}
\NormalTok{  kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ (mom\_iq }\SpecialCharTok{+}\NormalTok{ mom\_hs }\SpecialCharTok{+}\NormalTok{ mom\_work }\SpecialCharTok{+}\NormalTok{ mom\_age)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{,}
  \AttributeTok{data =}\NormalTok{ kidiq\_scaled,}
  \AttributeTok{seed =} \DecValTok{2302}\NormalTok{,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{backend =} \StringTok{"cmdstan"}
\NormalTok{)}
\CommentTok{\#\textgreater{} Running MCMC with 4 parallel chains...}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Chain 1 finished in 0.3 seconds.}
\CommentTok{\#\textgreater{} Chain 2 finished in 0.2 seconds.}
\CommentTok{\#\textgreater{} Chain 3 finished in 0.2 seconds.}
\CommentTok{\#\textgreater{} Chain 4 finished in 0.2 seconds.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All 4 chains finished successfully.}
\CommentTok{\#\textgreater{} Mean chain execution time: 0.2 seconds.}
\CommentTok{\#\textgreater{} Total execution time: 0.4 seconds.}
\end{Highlighting}
\end{Shaded}

Un grafico che riporta un \emph{posterior predictive check} si ottiene con l'istruzione seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pp\_check}\NormalTok{(m1, }\AttributeTok{ndraws =} \DecValTok{50}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlim}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Kid IQ"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-386-1} \end{center}

Identifichiamo ora l'importanza relativa delle variabili indipendenti nei termini della loro importanza per la previsione:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Variable selection}
\NormalTok{vs }\OtherTok{\textless{}{-}}\NormalTok{ projpred}\SpecialCharTok{::}\FunctionTok{varsel}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

Un grafico dell'importanza relativa di ciascuna variable per la previsione di \texttt{kid\_score} si ottiene nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot predictive performance on training data}
\FunctionTok{plot}\NormalTok{(vs, }\AttributeTok{stats =} \FunctionTok{c}\NormalTok{(}\StringTok{"elpd"}\NormalTok{, }\StringTok{"rmse"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-387-1} \end{center}

\hypertarget{il-pacchetto-projpred}{%
\section{\texorpdfstring{Il pacchetto \texttt{projpred}}{Il pacchetto projpred}}\label{il-pacchetto-projpred}}

Troviamo ora il numero di variabili da mantenere, in base al modello completo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{projpred}\SpecialCharTok{::}\FunctionTok{suggest\_size}\NormalTok{(vs)}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

Usiamo quindi il metodo \texttt{cv\_varsel()} per eseguire la convalida incrociata per vedere quante variabili dovrebbero essere incluse nel modello:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# With cross{-}validation}
\NormalTok{cvs }\OtherTok{\textless{}{-}}\NormalTok{ projpred}\SpecialCharTok{::}\FunctionTok{cv\_varsel}\NormalTok{(m1, }\AttributeTok{verbose =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In base al metodo della convalida incrociata, il numero di variabili da mantenere è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{projpred}\SpecialCharTok{::}\FunctionTok{suggest\_size}\NormalTok{(cvs)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

Generiamo il grafico dei risultati della convalida incrociata, questa volta relativi al modello completo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(cvs, }\AttributeTok{stats =} \FunctionTok{c}\NormalTok{(}\StringTok{"elpd"}\NormalTok{, }\StringTok{"rmse"}\NormalTok{), }\AttributeTok{deltas =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-390-1} \end{center}

Stampiamo l'elenco delle variabili ordinate in base alla loro importanza relativa, secondo il metodo della convalida incrociata:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(cvs, }\AttributeTok{stats=}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}mse\textquotesingle{}}\NormalTok{), }\AttributeTok{type =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}se\textquotesingle{}}\NormalTok{))}
\CommentTok{\#\textgreater{}    size   solution\_terms    mse  mse.se}
\CommentTok{\#\textgreater{} 2     0             \textless{}NA\textgreater{} 1.0016 0.06510}
\CommentTok{\#\textgreater{} 3     1           mom\_iq 0.8044 0.05357}
\CommentTok{\#\textgreater{} 4     2    mom\_iq:mom\_hs 0.7815 0.05193}
\CommentTok{\#\textgreater{} 5     3           mom\_hs 0.7912 0.05300}
\CommentTok{\#\textgreater{} 6     4   mom\_hs:mom\_age 0.8236 0.05463}
\CommentTok{\#\textgreater{} 7     5  mom\_hs:mom\_work 0.7980 0.05384}
\CommentTok{\#\textgreater{} 8     6 mom\_work:mom\_age 0.8046 0.05383}
\CommentTok{\#\textgreater{} 9     7  mom\_iq:mom\_work 0.7958 0.05293}
\CommentTok{\#\textgreater{} 10    8   mom\_iq:mom\_age 0.7993 0.05280}
\CommentTok{\#\textgreater{} 11    9         mom\_work 0.7993 0.05280}
\CommentTok{\#\textgreater{} 12   10          mom\_age 0.7993 0.05280}
\end{Highlighting}
\end{Shaded}

Il metodo basato sulla proiezione produce le distribuzioni a posteriori basate su una proiezione dal modello completo sul modello semplificato. In altre parole, si pone la domanda: ``Se vogliamo un modello con solo \texttt{mom\_iq} nel modello, quali coefficienti dovrebbero essere usati per fare in modo che l'accuratezza della previsione risultante sia la più vicina possibile a quella del modello completo?''. I coefficienti ottenuti con il metodo basato sulla proiezione saranno dunque diversi da quelli che si avrebbero se si stimasse direttamente il modello utilizzando il solo predittore \texttt{mom\_iq} (ad es. \texttt{m2}). I risultati ottenuti da studi basati sulla simulazione hanno mostrato che il metodo basato sulla proiezione produce un modello con prestazioni predittive migliori.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{proj1 }\OtherTok{\textless{}{-}}\NormalTok{ projpred}\SpecialCharTok{::}\FunctionTok{project}\NormalTok{(}
\NormalTok{  cvs,}
  \AttributeTok{nv =} \FunctionTok{suggest\_size}\NormalTok{(cvs),}
  \AttributeTok{seed =} \DecValTok{123}\NormalTok{,}
  \AttributeTok{ns =} \DecValTok{1000}
\NormalTok{)}
\FunctionTok{posterior\_summary}\NormalTok{(proj1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}           Estimate Est.Error   Q2.5 Q97.5}
\CommentTok{\#\textgreater{} Intercept    0.001     0.040 {-}0.079 0.075}
\CommentTok{\#\textgreater{} mom\_iq       0.449     0.037  0.378 0.523}
\CommentTok{\#\textgreater{} sigma        0.918     0.015  0.893 0.954}
\end{Highlighting}
\end{Shaded}

Per fare un confronto, stimiamo i coefficienti del modello di regressione che include unicamente la variabile \texttt{mom\_iq}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{brm}\NormalTok{(kid\_score }\SpecialCharTok{\textasciitilde{}}\NormalTok{ mom\_iq,}
  \AttributeTok{data =}\NormalTok{ kidiq\_scaled,}
  \AttributeTok{seed =} \DecValTok{2302}\NormalTok{,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{backend =} \StringTok{"cmdstan"}
\NormalTok{)}
\CommentTok{\#\textgreater{} Running MCMC with 4 parallel chains...}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Chain 1 finished in 0.0 seconds.}
\CommentTok{\#\textgreater{} Chain 2 finished in 0.0 seconds.}
\CommentTok{\#\textgreater{} Chain 3 finished in 0.0 seconds.}
\CommentTok{\#\textgreater{} Chain 4 finished in 0.0 seconds.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All 4 chains finished successfully.}
\CommentTok{\#\textgreater{} Mean chain execution time: 0.0 seconds.}
\CommentTok{\#\textgreater{} Total execution time: 0.3 seconds.}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(m2)}
\CommentTok{\#\textgreater{}  Family: gaussian }
\CommentTok{\#\textgreater{}   Links: mu = identity; sigma = identity }
\CommentTok{\#\textgreater{} Formula: kid\_score \textasciitilde{} mom\_iq }
\CommentTok{\#\textgreater{}    Data: kidiq\_scaled (Number of observations: 434) }
\CommentTok{\#\textgreater{}   Draws: 4 chains, each with iter = 1000; warmup = 0; thin = 1;}
\CommentTok{\#\textgreater{}          total post{-}warmup draws = 4000}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Population{-}Level Effects: }
\CommentTok{\#\textgreater{}           Estimate Est.Error l{-}95\% CI u{-}95\% CI Rhat}
\CommentTok{\#\textgreater{} Intercept    {-}0.00      0.04    {-}0.09     0.08 1.00}
\CommentTok{\#\textgreater{} mom\_iq        0.45      0.04     0.36     0.53 1.00}
\CommentTok{\#\textgreater{}           Bulk\_ESS Tail\_ESS}
\CommentTok{\#\textgreater{} Intercept     4220     2973}
\CommentTok{\#\textgreater{} mom\_iq        4102     2760}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Family Specific Parameters: }
\CommentTok{\#\textgreater{}       Estimate Est.Error l{-}95\% CI u{-}95\% CI Rhat}
\CommentTok{\#\textgreater{} sigma     0.90      0.03     0.84     0.96 1.00}
\CommentTok{\#\textgreater{}       Bulk\_ESS Tail\_ESS}
\CommentTok{\#\textgreater{} sigma     4348     2782}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Draws were sampled using sample(hmc). For each parameter, Bulk\_ESS}
\CommentTok{\#\textgreater{} and Tail\_ESS are effective sample size measures, and Rhat is the potential}
\CommentTok{\#\textgreater{} scale reduction factor on split chains (at convergence, Rhat = 1).}
\end{Highlighting}
\end{Shaded}

Nel caso presente, le differenze sono minime, ma questo non è sempre vero.

\hypertarget{confronto-di-modelli-tramite-elpd}{%
\section{\texorpdfstring{Confronto di modelli tramite \(\elpd\)}{Confronto di modelli tramite \textbackslash elpd}}\label{confronto-di-modelli-tramite-elpd}}

Confrontiamo ora la capacità predittiva a posteriori dei due modelli discussi sopra rispetto alla loro \(\elpd\). Ricordiamo che tanto maggiore è \(\elpd\) rispetto ad un nuovo insieme di dati futuri \(\tilde{y}\), \(\log p(\tilde{y} \mid y)\), tanto maggiore è l'accuratezza predittiva del modello. Iniziamo a calcolare \(\elpd\) per i due modelli:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo1 }\OtherTok{\textless{}{-}}\NormalTok{ loo}\SpecialCharTok{::}\FunctionTok{loo}\NormalTok{(m1)}
\NormalTok{loo2 }\OtherTok{\textless{}{-}}\NormalTok{ loo}\SpecialCharTok{::}\FunctionTok{loo}\NormalTok{(m2)}
\FunctionTok{c}\NormalTok{(loo1}\SpecialCharTok{$}\NormalTok{estimates[}\DecValTok{1}\NormalTok{], loo2}\SpecialCharTok{$}\NormalTok{estimates[}\DecValTok{1}\NormalTok{])}
\CommentTok{\#\textgreater{} [1] {-}567.4 {-}569.6}
\end{Highlighting}
\end{Shaded}

La quantità \(\elpd\) non fornisce una metrica interpretabile per l'accuratezza predittiva di un singolo modello. Risulta invece utile per il confronto tra modelli alternativi. Un confronto tra il modello completo e il modello semplificato si ottiene mediante la funzione \texttt{loo\_compare()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo}\SpecialCharTok{::}\FunctionTok{loo\_compare}\NormalTok{(loo1, loo2)}
\CommentTok{\#\textgreater{}    elpd\_diff se\_diff}
\CommentTok{\#\textgreater{} m1  0.0       0.0   }
\CommentTok{\#\textgreater{} m2 {-}2.2       5.1}
\end{Highlighting}
\end{Shaded}

I risultati di tale confronto indicano che il Modello \texttt{m1} ha il valore \(\elpd\) più basso e, dunque, sarebbe quello da preferire. Tuttavia, se si considera la differenza in \(\elpd\) in riferimento all'errore standard corrispondente (nella colonna \texttt{se\_diff}), ne risulta una differenza relativamente piccola. Per il Modello \texttt{m1} \(\elpd\) è uguale a -567.3 e per \texttt{m2} è -569.5. La differenza è pari a (-567.3 - -569.5) = 2.2, con un errore standard stimato di 5.0. I dati dunque suggeriscono che la vera differenza in \(\elpd\) tra \texttt{m1} e \texttt{m2} sia compresa tra \(\pm\) 2 errori standard (ovvero nel caso presente, 10 unità) dalla differenza stimata di -2.2 unità, ovvero sia inclusa nell'intervallo \(-2.2 \pm 2 \cdot 5 = (-12.2, 7.8)\). Dato il valore \(\elpd = 0\) è compreso nell'intervallo di \(\pm\) due standard error dalla differenza stimata, i dati non forniscono evidenze convincenti che l'accuratezza predittiva a posteriori di \texttt{m1} sia superiore a quella di \texttt{m2}. Inoltre, dato che il Modello \texttt{m2} è più semplice di \texttt{m1}, concludiamo che \texttt{m2} sia il modello migliore tra i due considerati (rasoio di Ockham).

\hypertarget{coefficiente-di-determinazione-bayesiano}{%
\section{Coefficiente di determinazione bayesiano}\label{coefficiente-di-determinazione-bayesiano}}

\citet{gelman2019r} definiscono il \href{https://avehtari.github.io/bayes_R2/bayes_R2.html}{coefficiente di determinazione bayesiano} come

\begin{equation}
R^2 = \frac{\Var_{\mu}}{\Var_{\mu} + \Var_{\text{res}}},
\end{equation}

dove \(\Var_{\mu}\) è la varianza del valore atteso predetto dal modello e \(\Var_{\text{res}}\) è la varianza dei residui. Entrambe queste quantità sono stimate considerando gli indici a posteriori del modello adattato.

Di seguito vengono calcolati i coefficienti di determinazione bayesiani dei due modelli discussi sopra:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{loo\_R2}\NormalTok{(m1, }\AttributeTok{robust =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}    Estimate Est.Error  Q2.5 Q97.5}
\CommentTok{\#\textgreater{} R2      0.2     0.037 0.125 0.268}
\FunctionTok{loo\_R2}\NormalTok{(m2, }\AttributeTok{robust =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{round}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\CommentTok{\#\textgreater{}    Estimate Est.Error  Q2.5 Q97.5}
\CommentTok{\#\textgreater{} R2    0.197     0.033 0.125 0.259}
\end{Highlighting}
\end{Shaded}

Una rappresentazione grafica della distribuzione a posteriori dei due coefficienti di determinazione bayesiani si ottiene com le seguenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"patchwork"}\NormalTok{)}
\FunctionTok{library}\NormalTok{(}\StringTok{"latex2exp"}\NormalTok{)}

\NormalTok{m1\_fit\_r2 }\OtherTok{\textless{}{-}} \FunctionTok{loo\_R2}\NormalTok{(m1, }\AttributeTok{summary =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{foo }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{R2 =} \FunctionTok{as.numeric}\NormalTok{(m1\_fit\_r2))}
\NormalTok{h1 }\OtherTok{\textless{}{-}}\NormalTok{ foo }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ R2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(}\StringTok{"$R\^{}2$"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Density"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Bayesian R squared}\SpecialCharTok{\textbackslash{}n}\StringTok{ posterior for model 1"}\NormalTok{)}

\NormalTok{m2\_fit\_r2 }\OtherTok{\textless{}{-}} \FunctionTok{loo\_R2}\NormalTok{(m2, }\AttributeTok{summary =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{foo2 }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{R2 =} \FunctionTok{as.numeric}\NormalTok{(m2\_fit\_r2))}
\NormalTok{h2 }\OtherTok{\textless{}{-}}\NormalTok{ foo2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ R2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_density}\NormalTok{(}\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\FunctionTok{TeX}\NormalTok{(}\StringTok{"$R\^{}2$"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Density"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ggtitle}\NormalTok{(}\StringTok{"Bayesian R squared}\SpecialCharTok{\textbackslash{}n}\StringTok{ posterior for model 2"}\NormalTok{)}

\NormalTok{h1 }\SpecialCharTok{|}\NormalTok{ h2}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-398-1} \end{center}

Considerato l'intervallo a posteriori del 95\%, anche in questo caso non abbiamo evidenze convincenti che l'uso di un solo predittore faccia diminuire la capacità predittiva del modello.

\hypertarget{commenti-e-considerazioni-finali-25}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-25}}


Dati due modelli computazionali che forniscono resoconti diversi di un set di dati, come possiamo decidere quale modello è maggiormente supportato dai dati? In questa parte della dispensa abbiamo visto come il problema del confronto di modelli possa essere formulato nei termini di un problema di inferenza statistica.

Abbiamo visto come la divergenza KL possa essere usata per confrontare una ``vera'' distribuzione di probabilità con una sua approssimazione. Abbiamo anche visto come che, da un punto di vista bayesiano, il problema del confronto tra modelli viene presentato nei termini della capacità predittiva di un modello per nuove osservazioni future: ``\emph{The central question is then how one should decide among a set of competing models. A short answer is that a model should be selected based on its generalizability, which is defined as a model's ability to fit current data but also to predict future data}'' \citep{myung2003tutorial}.

Se un modello non si generalizza bene a nuovi dati, si può sostenere che il modello è inappropriato o almeno manca di alcune caratteristiche importanti dato che non cattura la natura del vero processo di generazione dei dati sottostante \(p_t(\tilde{y})\). La capacità predittiva di un modello viene comunemente descritta in termini della sua densità predittiva logaritmica attesa (ELPD):

\[
\overline{\text{ELPD}} = \int \log p_{\mathcal{M}} (\tilde{y} \mid y) p_t(\tilde{y}) d \tilde{y}.
\]

L'ELPD per il modello \(\mathcal{M}\) può essere interpretata come la media pesata della densità predittiva logaritmica \(\log p_{\mathcal{M}} (\tilde{y}_i \mid y)\) per una nuova osservazione per il modello \(\mathcal{M}\), dove i pesi derivano dal vero processo di generazione dei dati \(p_t(\tilde{y})\). Grandi valori di \(\overline{\text{ELPD}}(\mathcal{M})\) indicano che il modello prevede bene nuove osservazioni \(\tilde{y}\), mentre piccoli valori \(\overline{\text{ELPD}}(\mathcal{M})\) mostrano che il modello non si generalizza bene a nuovi dati. In pratica, però, la vera densità \(p_t(\tilde{y})\) è incognita. Una \emph{stima} di \(\overline{\text{ELPD}}(\mathcal{M})\) può essere ottenuta con il metodo di validazione incrociata leave-one-out (LOO) in cui il modello tante volte (\(n\)) quante sono le singole osservazioni (\emph{leave-one-out cross-validation}, LOO-CV). La strategia LOO-CV è computazionalmente troppo onerosa per qualunque scopo pratico e viene quindi approssimata mediante un metodo chiamato \emph{Pareto-smoothed importance sampling cross-validation} {[}PSIS; \citet{vehtari2017practical}{]} -- che non richiede di adattare il modello \(n\) volte. Tale stima della densità predittiva logaritmica viene chiamata ELPD-LOO. Maggiore è il punteggio ELPD-LOO di un modello, migliore è l'accuratezza predittiva out-of-sample del modello. L'errore standard di ELPD-LOO fornisce una descrizione dell'incertezza sulle prestazioni predittive per dati futuri sconosciuti. Nel confronto dei modelli, quando la differenza in ELPD-LOO è maggiore di 4, il numero di osservazioni è maggiore di 100, e in assenza di un errore di specificazione del modello, la differenza dei valori ELPD-LOO di due modelli segue la distribuzione normale. Nel confronto di modelli, un valore \(|\text{elpd}_{\text{diff}} / SE_{\text{diff}}|\) maggiore di 2 può dunque essere considerato degno di menzione (``noteworthy'') \citep{gelman2020regression}.

Anche se la procedura descritta sopra viene correntemente usata dai ricercatori, è però necessaria una nota di cautela. \citet{navarro2019between} ci fa notare che il problema statistico del confronto di modelli non risolve il problema scientifico della selezione di teorie. A questo proposito usa una citazione di George Box: \emph{``Since all models are wrong the scientist must be alert to what is importantly wrong. It is inappropriate to be concerned about mice when there are tigers abroad.''}

La metafora delle tigri di George Box fa riferimento evidentemente all'assunzione che sta alla base delle procedure discusse in questo Capitolo, ovvero all'ipotesi che il vero meccanismo generatore dei dati sia noto e che l'unica incognita corrisponda ai parametri. Tuttavia le cose non sono così semplici: nei casi di interesse scientifico è lo stesso meccanismo generatore dei dati ad essere sconosciuto. I ricercatori non comprendono appieno i fenomeni che stanno studiando (altrimenti perché studiarli?) e qualunque descrizione formale di un fenomeno (modello) è sbagliata in un modo sconosciuto e sistematico. Di conseguenza, è ``facile'' fare inferenza sulla capacità predittiva del modello, ma è molto difficile fare inferenza sulla struttura causale dei fenomeni. In altre parole, se le analisi statistiche ci dicono che un modello ha una buona accuratezza predittiva, con ciò non abbiamo imparato nulla sulla struttura causale del fenomeno. Ma è anche vera l'affermazione opposta: un modello che non ha \emph{neppure} una buona accuratezza predittiva è sicuramente inutile --- non è in grado né di fare previsioni accurate né di catturare la struttura causale.

\mainmatter

\hypertarget{appendix-appendix}{%
\appendix \addcontentsline{toc}{chapter}{\appendixname}}


\hypertarget{simbologia-di-base}{%
\chapter{Simbologia di base}\label{simbologia-di-base}}

Per una scrittura più sintetica possono essere utilizzati alcuni simboli matematici.

\begin{itemize}
\tightlist
\item
  \(\log(x)\): il logaritmo naturale di \(x\).
\item
  L'operatore logico booleano \(\land\) significa ``e'' (congiunzione forte) mentre il connettivo di disgiunzione \(\lor\) significa ``o'' (oppure) (congiunzione debole).
\item
  Il quantificatore esistenziale \(\exists\) vuol dire ``esiste almeno un'' e indica l'esistenza di almeno una istanza del concetto/oggetto indicato. Il quantificatore esistenziale di unicità \(\exists!\) (``esiste soltanto un'') indica l'esistenza di esattamente una istanza del concetto/oggetto indicato. Il quantificatore esistenziale \(\nexists\) nega l'esistenza del concetto/oggetto indicato.
\item
  Il quantificatore universale \(\forall\) vuol dire ``per ogni.''
\item
  \(\mathcal{A, S}\): insiemi.
\item
  \(x \in A\): \(x\) è un elemento dell'insieme \(A\).
\item
  L'implicazione logica ``\(\Rightarrow\)'' significa ``implica'' (se \ldots allora). \(P \Rightarrow Q\) vuol dire che \(P\) è condizione sufficiente per la verità di \(Q\) e che \(Q\) è condizione necessaria per la verità di \(P\).
\item
  L'equivalenza matematica ``\(\iff\)'' significa ``se e solo se'' e indica una condizione necessaria e sufficiente, o corrispondenza biunivoca.
\item
  Il simbolo \(\vert\) si legge ``tale che.''
\item
  Il simbolo \(\triangleq\) (o \(:=\)) si legge ``uguale per definizione.''
\item
  Il simbolo \(\Delta\) indica la differenza fra due valori della variabile scritta a destra del simbolo.
\item
  Il simbolo \(\propto\) si legge ``proporzionale a.''
\item
  Il simbolo \(\approx\) si legge ``circa.''
\item
  Il simbolo \(\in\) della teoria degli insiemi vuol dire ``appartiene'' e indica l'appartenenza di un elemento ad un insieme. Il simbolo \(\notin\) vuol dire ``non appartiene.''
\item
  Il simbolo \(\subseteq\) si legge ``è un sottoinsieme di'' (può coincidere con l'insieme stesso). Il simbolo \(\subset\) si legge ``è un sottoinsieme proprio di.''
\item
  Il simbolo \(\#\) indica la cardinalità di un insieme.
\item
  Il simbolo \(\cap\) indica l'intersezione di due insiemi. Il simbolo \(\cup\) indica l'unione di due insiemi.
\item
  Il simbolo \(\emptyset\) indica l'insieme vuoto o evento impossibile.
\item
  In matematica, \(\mbox{argmax}\) identifica l'insieme dei punti per i quali una data funzione raggiunge il suo massimo. In altre parole, \(\mbox{argmax}_x f(x)\) è l'insieme dei valori di \(x\) per i quali \(f(x)\) raggiunge il valore più alto.
\item
  \(a, c, \alpha, \gamma\): scalari.
\item
  \(\boldsymbol{x}, \boldsymbol{y}\): vettori.
\item
  \(\boldsymbol{X}, \boldsymbol{Y}\): matrici.
\item
  \(X \sim p\): la variabile casuale \(X\) si distribuisce come \(p\).
\item
  \(p(\cdot)\): distribuzione di massa o di densità di probabilità.
\item
  \(p(y \mid \boldsymbol{x})\): la probabilità o densità di \(y\) dato \(\boldsymbol{x}\), ovvero \(p(y = \boldsymbol{Y} \mid x = \boldsymbol{X})\).
\item
  \(f(x)\): una funzione arbitraria di \(x\).
\item
  \(f(\boldsymbol{X}; \theta, \gamma)\): \(f\) è una funzione di \(\boldsymbol{X}\) con parametri \(\theta, \gamma\). Questa notazione indica che \(\boldsymbol{X}\) sono i dati che vengono passati ad un modello di parametri \(\theta, \gamma\).
\item
  \(\mathcal{N}(\mu, \sigma^2)\): distribuzione gaussiana di media \(\mu\) e varianza \(sigma^2\).
\item
  \(\mbox{Beta}(\alpha, \beta)\): distribuzione Beta di parametri \(\alpha\) e \(\beta\).
\item
  \(\mathcal{U}(a, b)\): distribuzione uniforme con limite inferiore \(a\) e limite superiore \(b\).
\item
  \(\mbox{Cauchy}(\alpha, \beta)\): distribuzione di Cauchy di parametri \(\alpha\) (posizione: media) e \(\beta\) (scala: radice quadrata della varianza).
\item
  \(\mathcal{B}(p)\): distribuzione di Bernoulli di parametro \(p\) (probabilità di successo).
\item
  \(\mbox{Bin}(n, p)\): distribuzione binomiale di parametri \(n\) (numero di prove) e \(p\) (probabilità di successo).
\item
  \(\mathbb{KL} (p \mid\mid q)\): la divergenza di Kullback-Leibler da \(p\) a \(q\).
\end{itemize}

\hypertarget{numeri-binari-interi-razionali-irrazionali-e-reali}{%
\chapter{Numeri binari, interi, razionali, irrazionali e reali}\label{numeri-binari-interi-razionali-irrazionali-e-reali}}

\hypertarget{numeri-binari}{%
\section{Numeri binari}\label{numeri-binari}}

I numeri più semplici sono quelli binari, cioè zero o uno. Useremo spesso numeri binari per indicare se qualcosa è vero o falso, presente o assente. I numeri binari sono molto utili per ottenere facilmente delle statistiche riassuntive in \(\R\).Supponiamo di chiedere a 10 studenti ``Ti piacciono i mirtilli?'' Poniamo che le risposte siano le seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{opinion }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
  \StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{, }\StringTok{"No"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{,}
  \StringTok{"Yes"}\NormalTok{, }\StringTok{"Yes"}\NormalTok{, }\StringTok{"Yes"}
\NormalTok{)}
\NormalTok{opinion}
\CommentTok{\#\textgreater{}  [1] "Yes" "No"  "Yes" "No"  "Yes" "No"  "Yes" "Yes"}
\CommentTok{\#\textgreater{}  [9] "Yes" "Yes"}
\end{Highlighting}
\end{Shaded}

Tali risposte possono essere ricodificate nei termini di valori di verità, ovvero, vero e falso, generalmente denotati rispettivamente come 1 e 0. In \(\R\) tale ricodifica può essere effettuata mediante l'operatore \texttt{==} che è un test per l'uguaglianza e restituisce il valore logico VERO se i due oggetti valutati sono uguali e FALSO se non lo sono:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{opinion }\OtherTok{\textless{}{-}}\NormalTok{ opinion }\SpecialCharTok{==} \StringTok{"Yes"}
\NormalTok{opinion}
\CommentTok{\#\textgreater{}  [1]  TRUE FALSE  TRUE FALSE  TRUE FALSE  TRUE  TRUE}
\CommentTok{\#\textgreater{}  [9]  TRUE  TRUE}
\end{Highlighting}
\end{Shaded}

R considera i valori di verità e i numeri binari in modo equivalente, con TRUE uguale a 1 e FALSE uguale a zero. Di conseguenza, possiamo effettuare operazioni algebriche sui valori logici VERO e FALSO. Nell'esempio, possiamo sommare i valori di verità e dividere per 10

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(opinion) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(opinion)}
\CommentTok{\#\textgreater{} [1] 0.7}
\end{Highlighting}
\end{Shaded}

in modo tale da calcolare una propozione, il che ci consente di concludere che 7 risposte su 10 sono positive.

\hypertarget{numeri-interi}{%
\section{Numeri interi}\label{numeri-interi}}

Un numero intero è un numero senza decimali. Si dicono \textbf{naturali} i numeri che servono a contare, come 1, 2, \ldots{} L'insieme dei numeri naturali si indica con il simbolo \(\mathbb{N}\). È anche necessario introdurre i numeri con il segno per poter trattare grandezze negative. Si ottengono così l'insieme numerico dei numeri interi relativi: \(\mathbb{Z} = \{0, \pm 1, \pm 2, \dots \}\)

\hypertarget{numeri-razionali}{%
\section{Numeri razionali}\label{numeri-razionali}}

I numeri razionali sono i numeri frazionari \(m/n\), dove \(m, n \in N\), con \(n \neq 0\). Si ottengono così i numeri razionali: \(\mathbb{Q} = \{\frac{m}{n} \,\vert\, m, n \in \mathbb{Z}, n \neq 0\}\). È evidente che \(\mathbb{N} \subseteq \mathbb{Z} \subseteq \mathbb{Q}\). Anche in questo caso è necessario poter trattare grandezze negative. I numeri razionali non negativi sono indicati con \(\mathbb{Q^+} = \{q \in \mathbb{Q} \,\vert\, q \geq 0\}\).

\hypertarget{numeri-irrazionali}{%
\section{Numeri irrazionali}\label{numeri-irrazionali}}

Tuttavia, non tutti i punti di una retta \(r\) possono essere rappresentati mediante i numeri interi e razionali. È dunque necessario introdurre un'altra classe di numeri. Si dicono \emph{irrazionali}, e sono denotati con \(\mathbb{R}\), i numeri che possono essere scritti come una frazione \(a / b\), con \(a\) e \(b\) interi e \(b\) diverso da 0. I numeri irrazionali sono i numeri illimitati e non periodici che quindi non possono essere espressi sotto forma di frazione. Per esempio, \(\sqrt{2}\), \(\sqrt{3}\) e \({\displaystyle \pi =3,141592\ldots}\) sono numeri irrazionali.

\hypertarget{numeri-reali}{%
\section{Numeri reali}\label{numeri-reali}}

I punti della retta \(r\) sono quindi ``di più'' dei numeri razionali. Per poter rappresentare tutti i punti della retta abbiamo dunque bisogno dei numeri \emph{reali}. I numeri reali possono essere positivi, negativi o nulli e comprendono, come casi particolari, i numeri interi, i numeri razionali e i numeri irrazionali. Spesso in statisticac il numero dei decimali indica il grado di precisione della misurazione.

\hypertarget{intervalli}{%
\section{Intervalli}\label{intervalli}}

Un intervallo si dice chiuso se gli estremi sono compresi nell'intervallo, aperto se gli estremi non sono compresi. Le caratteristiche degli intervalli sono riportate nella tabella seguente.

\begin{longtable}[]{@{}cll@{}}
\toprule
Intervallo & & \\
\midrule
\endhead
chiuso & \([a, b]\) & \(a \leq x \leq b\) \\
aperto & \((a, b)\) & \(a < x < b\) \\
chiuso a sinistra e aperto a destra & \([a, b)\) & \(a \leq x < b\) \\
aperto a sinistra e chiuso a destra & \((a, b]\) & \(a < x \leq b\) \\
\bottomrule
\end{longtable}

\hypertarget{insiemistica}{%
\chapter{Insiemi}\label{insiemistica}}

Un insieme (o collezione, classe, gruppo, \ldots) è un concetto primitivo, ovvero è un concetto che già possediamo. Georg Cantor l'ha definito nel modo seguente: \emph{un insieme è una collezione di oggetti, determinati e distinti, della nostra percezione o del nostro pensiero, concepiti come un tutto unico; tali oggetti si dicono elementi dell'insieme.}

Mentre non è rilevante la natura degli oggetti che costituiscono l'insieme, ciò che importa è distinguere se un dato oggetto appartenga o meno ad un insieme. Deve essere vera una delle due possibilità: il dato oggetto è un elemento dell'insieme considerato oppure non è elemento dell'insieme considerato. Due insiemi \(A\) e \(B\) si dicono uguali se sono formati dagli stessi elementi, anche se disposti in ordine diverso: \(A=B\). Due insiemi \(A\) e \(B\) si dicono diversi se non contengono gli stessi elementi: \(A \neq B\). Ad esempio, i seguenti insiemi sono uguali:

\[
\{1, 2, 3\} = \{3, 1, 2\} = \{1, 3, 2\}= \{1, 1, 1, 2, 3, 3, 3\}.
\]

Gli insiemi sono denotati da una lettera maiuscola, mentre le lettere minuscole, di solito, designano gli elementi di un insieme. Per esempio, un generico insieme \(A\) si indica con

\[
A = \{a_1, a_2, \dots, a_n\}, \quad \text{con~} n > 0.
\]

La scrittura \(a \in A\) dice che \(a\) è un elemento di \(A\). Per dire che \(b\) non è un elemento di \(A\) si scrive \(b \notin A.\)

Per quegli insiemi i cui elementi soddisfano una certa proprietà che li caratterizza, tale proprietà può essere usata per descrivere più sinteticamente l'insieme:

\[
A = \{x ~\vert~ \text{proprietà posseduta da~} x\},
\]

che si legge come ``\(A\) è l'insieme degli elementi \(x\) per cui è vera la proprietà indicata.'' Per esempio, per indicare l'insieme \(A\) delle coppie di numeri reali \((x,y)\) che appartengono alla parabola \(y = x^2 + 1\) si può scrivere:

\[
A = \{(x,y) ~\vert~ y = x^2 + 1\}.
\]

Dati due insiemi \(A\) e \(B\), diremo che \(A\) è un \emph{sottoinsieme} di \(B\) se e solo se tutti gli elementi di \(A\) sono anche elementi di \(B\):

\[
A \subseteq B \iff (\forall x \in A \Rightarrow x \in B).
\]

Se esiste almeno un elemento di \(B\) che non appartiene ad \(A\) allora diremo che \(A\) è un \emph{sottoinsieme proprio} di \(B\):

\[
A \subset B \iff (A \subseteq B, \exists~ x \in B ~\vert~ x \notin A).
\]

Un altro insieme, detto \emph{insieme delle parti}, o insieme potenza, che si associa all'insieme \(A\) è l'insieme di tutti i sottoinsiemi di \(A\), inclusi l'insieme vuoto e \(A\) stesso. Per esempio, per l'insieme \(A = \{a, b, c\}\), l'insieme delle parti è:

\[
\mathcal{P}(A) = \{
\emptyset, \{a\}, \{b\}, \{c\},
 \{a, b\}, \{a, c\}, \{c, b\},
 \{a, b, c\}
\}.
\]

\hypertarget{operazioni-tra-insiemi}{%
\section{Operazioni tra insiemi}\label{operazioni-tra-insiemi}}

Si definisce \emph{intersezione} di \(A\) e \(B\) l'insieme \(A \cap B\) di tutti gli elementi \(x\) che appartengono ad \(A\) e contemporaneamente a \(B\):

\[
A \cap B = \{x ~\vert~ x \in A \land x \in B\}.
\]

Si definisce \emph{unione} di \(A\) e \(B\) l'insieme \(A \cup B\) di tutti gli elementi \(x\) che appartengono ad \(A\) o a \(B\), cioè

\[
A \cup B = \{x ~\vert~ x \in A \lor x \in B\}.
\]

\emph{Differenza}. Si indica con \(A \setminus B\) l'insieme degli elementi di \(A\) che non appartengono a \(B\):

\[
A \setminus B = \{x ~\vert~ x \in A \land x \notin B\}.
\]

\emph{Insieme complementare}. Nel caso che sia \(B \subseteq A\), l'insieme differenza \(A \setminus B\) è detto insieme complementare di \(B\) in \(A\) e si indica con \(B^C\).

Dato un insieme \(S\), una \emph{partizione} di \(S\) è una collezione di sottoinsiemi di \(S\), \(S_1, \dots, S_k\), tali che

\[
S = S_1 \cup S_2 \cup \dots S_k
\]

e

\[
S_i \cap S_j, \quad \text{con~} i \neq j.
\]

La relazione tra unione, intersezione e insieme complementare è data dalle leggi di DeMorgan:

\[
(A \cup B)^c = A^c \cap B^c,
\] \[
(A \cap B)^c = A^c \cup B^c.
\]

\hypertarget{diagrammi-di-eulero-venn}{%
\section{Diagrammi di Eulero-Venn}\label{diagrammi-di-eulero-venn}}

In molte situazioni è utile servirsi dei cosiddetti diagrammi di Eulero-Venn per rappresentare gli insiemi e verificare le proprietà delle operazioni tra insiemi (si veda la figura \ref{fig:sets-venn-diagrams}. I diagrammi di Venn sono così nominati in onore del matematico inglese del diciannovesimo secolo John Venn anche se Leibnitz e Eulero avevano già in precedenza utilizzato rappresentazioni simili. In tale rappresentazione, gli insiemi sono individuati da regioni del piano delimitate da una curva chiusa. Nel caso di insiemi finiti, è possibile evidenziare esplicitamente alcuni elementi di un insieme mediante punti, quando si possono anche evidenziare tutti gli elementi degli insiemi considerati.

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{images/sets-venn-diagrams} 

}

\caption{In tutte le figure $S$ è la regione delimitata dal rettangolo, $L$ è la regione all'interno del cerchio di sinistra e $R$ è la regione all'interno del cerchio di destra. La regione evidenziata mostra l'insieme indicato sotto ciascuna figura.}\label{fig:sets-venn-diagrams}
\end{figure}

I diagrammi di Eulero-Venn che forniscono una dimostrazione delle leggi di DeMorgan sono forniti nella figura \ref{fig:demorgan}.

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth]{images/demorgan} 

}

\caption{Dimostrazione delle leggi di DeMorgan.}\label{fig:demorgan}
\end{figure}

\hypertarget{coppie-ordinate-e-prodotto-cartesiano}{%
\section{Coppie ordinate e prodotto cartesiano}\label{coppie-ordinate-e-prodotto-cartesiano}}

Una coppia ordinata \((x,y)\) è l'insieme i cui elementi sono \(x \in A\) e \(y \in B\) e nella quale \(x\) è la prima componente (o prima coordinata), \(y\) la seconda. L'insieme di tutte le coppie ordinate costruite a partire dagli insiemi \(A\) e \(B\) viene detto \textbf{prodotto cartesiano}:

\[
A \times B = \{(x, y) ~\vert~ x \in A \land y \in B\}.
\]

Ad esempio, sia \(A = \{1, 2, 3\}\) e \(B = \{a, b\}\). Allora,

\[
\{1, 2\} \times \{a, b, c\} = \{(1, a), (1, b), (1, c), (2, a), (2, b), (2, c)\}.
\]

\hypertarget{cardinalituxe0}{%
\section{Cardinalità}\label{cardinalituxe0}}

Si definisce \emph{cardinalità} (o potenza) di un insieme finito il numero degli elementi dell'insieme. Viene indicata con \(\vert A\vert, \#(A)\) o \(\text{c}(A)\).

\hypertarget{sommatorie}{%
\chapter{Simbolo di somma (sommatorie)}\label{sommatorie}}

Le somme si incontrano costantemente in svariati contesti matematici e statistici quindi abbiamo bisogno di una notazione adeguata che ci consenta di gestirle. La somma dei primi \(n\) numeri interi può essere scritta come \(1+2+\dots+(n-1)+n\), dove `\(\dots\)' ci dice di completare la sequenza definita dai termini che vengono prima e dopo. Ovviamente, una notazione come \(1+7+\dots+73.6\) non avrebbe alcun senso senza qualche altro tipo di precisazione. In generale, nel seguito incontreremo delle somme nella forma

\begin{equation}
x_1+x_2+\dots+x_n,\notag
\end{equation}

dove \(x_i\) è un numero che è stato definito altrove. La notazione precedente, che fa uso dei tre puntini di sospensione, è utile in alcuni contesti ma in altri risulta ambigua. Pertanto la notazione di uso corrente è del tipo

\begin{equation}
  \sum_{i=1}^n x_i\notag
\end{equation}

e si legge ``sommatoria per \(i\) che va da \(1\) a \(n\) di \(x_i\)''. Il simbolo \(\sum\) (lettera sigma maiuscola dell'alfabeto greco) indica l'operazione di somma, il simbolo \(x_i\) indica il generico addendo della sommatoria, le lettere \(1\) ed \(n\) indicano i cosiddetti \emph{estremi della sommatoria}, ovvero l'intervallo (da \(1\) fino a \(n\) estremi inclusi) in cui deve variare l'indice \(i\) allorché si sommano gli addendi \(x_i\). Solitamente l'estremo inferiore è \(1\) ma potrebbe essere qualsiasi altri numero \(m < n\). Quindi

\[
  \sum_{i=1}^n x_i = x_1 + x_{2} + \dots + x_{n}.
\]

Per esempio, se i valori \(x\) sono \(\{3, 11, 4, 7\}\), si avrà

\[
  \sum_{i=1}^4 x_i = 3+11+4+7 = 25 
\]

laddove \(x_1 = 3\), \(x_2 = 11\), eccetera. La quantità \(x_i\) nella formula precedente si dice l'\emph{argomento} della sommatoria, mentre la variabile \(i\), che prende i valori naturali successivi indicati nel simbolo, si dice \emph{indice} della sommatoria.

La notazione di sommatoria può anche essere fornita nella forma seguente

\begin{equation}
  \sum_{P(i)} x_i\notag
\end{equation}

dove \(P(i)\) è qualsiasi proposizione riguardante \(i\) che può essere vera o falsa. Quando è ovvio che si vogliono sommare tutti i valori di \(n\) osservazioni, la notazione può essere semplificata nel modo seguente: \(\sum_{i} x_i\) oppure \(\sum x_i\). Al posto di \(i\) si possono trovare altre lettere: \(k, j, l, \dots\),.

\hypertarget{manipolazione-di-somme}{%
\section{Manipolazione di somme}\label{manipolazione-di-somme}}

È conveniente utilizzare le seguenti regole per semplificare i calcoli che coinvolgono l'operatore della sommatoria.

\hypertarget{proprietuxe0-1-1}{%
\subsection{Proprietà 1}\label{proprietuxe0-1-1}}

La sommatoria di \(n\) valori tutti pari alla stessa costante \(a\) è pari a \(n\) volte la costante stessa:

\[
  \sum_{i=1}^{n} a =  \underbrace{a + a + \dots + a}_{n~\text{volte}} = n a.
  \]

\hypertarget{proprietuxe0-2-proprietuxe0-distributiva}{%
\subsection{Proprietà 2 (proprietà distributiva)}\label{proprietuxe0-2-proprietuxe0-distributiva}}

Nel caso in cui l'argomento contenga una costante, è possibile riscrivere la sommatoria. Ad esempio con

\[
  \sum_{i=1}^{n} a x_i =  a x_1 + a x_2 + \dots + a x_n
  \]

è possibile raccogliere la costante \(a\) e fare \(a(x_1 +x_2 + \dots + x_n)\). Quindi possiamo scrivere

\[
  \sum_{i=1}^{n} a x_i =  a  \sum_{i=1}^{n} x_i.
  \]

\hypertarget{proprietuxe0-3-proprietuxe0-associativa}{%
\subsection{Proprietà 3 (proprietà associativa)}\label{proprietuxe0-3-proprietuxe0-associativa}}

Nel caso in cui

\[
  \sum_{i=1}^{n} (a + x_i) =  (a + x_1) +  (a + x_1) + \dots  (a + x_n)
  \]

si ha che

\[
  \sum_{i=1}^{n} (a + x_i) =  n a + \sum_{i=1}^{n} x_i.
  \]

È dunque chiaro che in generale possiamo scrivere

\[
  \sum_{i=1}^{n} (x_i + y_i) =  \sum_{i=1}^{n} x_i + \sum_{i=1}^{n} y_i.
  \]

\hypertarget{proprietuxe0-4}{%
\subsection{Proprietà 4}\label{proprietuxe0-4}}

Se deve essere eseguita un'operazione algebrica (innalzamento a potenza, logaritmo, ecc.) sull'argomento della sommatoria, allora tale operazione algebrica deve essere eseguita prima della somma. Per esempio,

\[
\sum_{i=1}^{n} x_i^2 = x_1^2 + x_2^2 + \dots + x_n^2 \neq \left(\sum_{i=1}^{n} x_i \right)^2.
\]

\hypertarget{proprietuxe0-5}{%
\subsection{Proprietà 5}\label{proprietuxe0-5}}

Nel caso si voglia calcolare \(\sum_{i=1}^{n} x_i y_i\), il prodotto tra i punteggi appaiati deve essere eseguito prima e la somma dopo:

\[
\sum_{i=1}^{n} x_i y_i = x_1 y_1 + x_2 y_2 + \dots + x_n y_n,
\]

infatti, \(a_1 b_1 + a_2 b_2 \neq (a_1 + a_2)(b_1 + b_2)\).

\hypertarget{doppia-sommatoria}{%
\section{Doppia sommatoria}\label{doppia-sommatoria}}

È possibile incontrare la seguente espressione in cui figurano una doppia sommatoria e un doppio indice:

\[
\sum_{i=1}^{n}\sum_{j=1}^{m} x_{ij}.
\]

La doppia sommatoria comporta che per ogni valore dell'indice esterno, \(i\) da \(1\) ad \(n\), occorre sviluppare la seconda sommatoria per \(j\) da \(1\) ad \(m\). Quindi,

\[
\sum_{i=1}^{3}\sum_{j=4}^{6} x_{ij} = (x_{1, 4} + x_{1, 5} + x_{1, 6}) + (x_{2, 4} + x_{2, 5} + x_{2, 6}) + (x_{3, 4} + x_{3, 5} + x_{3, 6}).
\]

Un caso particolare interessante di doppia sommatoria è il seguente:

\[
\sum_{i=1}^{n}\sum_{j=1}^{n} x_i y_j
\]

Si può osservare che nella sommatoria interna (quella che dipende dall'indice \(j\)), la quantità \(x_i\) è costante, ovvero non dipende dall'indice (che è \(j\)). Allora possiamo estrarre \(x_i\) dall'operatore di sommatoria interna e scrivere

\[
\sum_{i=1}^{n} \left( x_i \sum_{j=1}^{n} y_j \right).
\]

Allo stesso modo si può osservare che nell'argomento della sommatoria esterna la quantità costituita dalla sommatoria in \(j\) non dipende dall'indice \(i\) e quindi questa quantità può essere estratta dalla sommatoria esterna. Si ottiene quindi

\[
\sum_{i=1}^{n}\sum_{j=1}^{n} x_i y_j = \sum_{i=1}^{n} \left( x_i \sum_{j=1}^{n} y_j \right) = \sum_{i=1}^{n}\ x_i \sum_{j=1}^{n} y_j.
\]

\begin{exercise}
Si verifichi quanto detto sopra nel caso particolare di \(x = \{2, 3, 1\}\) e \(y = \{1, 4, 9\}\), svolgendo prima la doppia sommatoria per poi verificare che quanto così ottenuto sia uguale al prodotto delle due sommatorie.

\begin{align}
\sum_{i=1}^3 \sum_{j=1}^3 x_i y_j &= x_1y_1 + x_1y_2 + x_1y_3 + 
x_2y_1 + x_2y_2 + x_2y_3 + 
x_3y_1 + x_3y_2 + x_3y_3 \notag\\
&= 2 \times (1+4+9) + 3 \times (1+4+9) + 2 \times (1+4+9) = 84,\notag
\end{align}

ovvero

\[
(2 + 3 + 1) \times (1+4+9) = 84.
\]
\end{exercise}

\hypertarget{sommatorie-e-produttorie-e-operazioni-vettoriali-in-r}{%
\section{\texorpdfstring{Sommatorie (e produttorie) e operazioni vettoriali in \texttt{R}}{Sommatorie (e produttorie) e operazioni vettoriali in R}}\label{sommatorie-e-produttorie-e-operazioni-vettoriali-in-r}}

Si noti che la notazione

\[
\sum_{n=0}^4 3n
\]

non è altro che un ciclo \texttt{for}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sum }\OtherTok{\textless{}{-}} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{0}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) \{}
\NormalTok{  sum }\OtherTok{=}\NormalTok{ sum }\SpecialCharTok{+} \DecValTok{3} \SpecialCharTok{*}\NormalTok{ n}
\NormalTok{\}}
\NormalTok{sum}
\CommentTok{\#\textgreater{} [1] 30}
\end{Highlighting}
\end{Shaded}

In maniera equivalente, e più semplice, possiamo scrivere

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}\DecValTok{3} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{0}\SpecialCharTok{:}\DecValTok{4}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 30}
\end{Highlighting}
\end{Shaded}

Allo stesso modo, la notazione

\[
\prod_{n=1}^{4} 2n
\] è anch'essa equivalente al ciclo \texttt{for}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prod }\OtherTok{\textless{}{-}} \DecValTok{1}
\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{) \{}
\NormalTok{  prod }\OtherTok{\textless{}{-}}\NormalTok{ prod }\SpecialCharTok{*} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ n}
\NormalTok{\}}
\NormalTok{prod}
\CommentTok{\#\textgreater{} [1] 384}
\end{Highlighting}
\end{Shaded}

che si può scrivere, più semplicemente, come

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prod}\NormalTok{(}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{))}
\CommentTok{\#\textgreater{} [1] 384}
\end{Highlighting}
\end{Shaded}

In entrambi i casi precedenti, abbiamo sostituito le operazioni aritmetiche eseguite all'interno di un ciclo \texttt{for} con le stesse operazioni aritmetiche eseguite sui vettori elemento per elemento.

\hypertarget{funs-exp-log}{%
\chapter{Esponenziali e logaritmi}\label{funs-exp-log}}

\hypertarget{potenze-ad-esponente-reale}{%
\section*{Potenze ad esponente reale}\label{potenze-ad-esponente-reale}}


Per un qualsiasi numero razionale \(\frac{m}{n}\) (in cui \(n > 0\)) si ha

\[
a^{\frac{m}{n}} = \sqrt[n]{a^m}
\] per numeri \(a\) reali positivi.

\hypertarget{proprietuxe0-3}{%
\subsection*{Proprietà}\label{proprietuxe0-3}}


Se \(a\), \(b\) sono reali positivi ed \(x\), \(y\) reali qualsiasi, si ha

\begin{itemize}
\tightlist
\item
  \(a^0 = 1\) e \(a^{-x} = \frac{1}{a^x}\),
\item
  \(a^x a^y = a^{x+y}\) e \(\frac{a^x}{a^y} = a^{x-y}\),
\item
  \(a^x b^x = (ab)^{x}\) e \(\frac{a^x}{b^x} = \left(\frac{a}{b}\right)^x\),
\item
  \((a^x)^y = a^{xy}\).
\end{itemize}

\hypertarget{funzione-esponenziale}{%
\section{Funzione esponenziale}\label{funzione-esponenziale}}

\begin{definition}
La funzione esponenziale con base \(a\) è \begin{equation}
f(x) = a^x
\end{equation}

dove \(a > 0\), \(a \neq 1\) e \(x\) è qualsiasi numero reale.
\end{definition}

La base \(a = 1\) è esclusa perché produce \(f(x) = 1^x = 1\), la quale è una costante, non una funzione esponenziale.

Per esempio, un grafico della funzione esponenziale di base 2 si trova con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exp\_base2 }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(x)\{}\DecValTok{2}\SpecialCharTok{\^{}}\NormalTok{x\}}
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ exp\_base2)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-407-1} \end{center}

Se usiamo la base 4 troviamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exp\_base4 }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(x)\{}\DecValTok{4}\SpecialCharTok{\^{}}\NormalTok{x\}}
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ exp\_base4)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-408-1} \end{center}

Oppure

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exp\_base4 }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(x)\{}\DecValTok{4}\SpecialCharTok{\^{}{-}}\NormalTok{\{x\}\}}
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ exp\_base4)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-409-1} \end{center}

In molte applicazioni la scelta più conveniente per la base è il numero irrazionale \(e = 2.718281828\dots\). Questo numero è chiamato la \emph{base naturale}. La funzione \(f(x) = e^x\) è chiamata \emph{funzione esponenziale naturale}.

Per esempio, abbiamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{exp\_base\_e}\OtherTok{=} \ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{exp}\NormalTok{(x)\}}
\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\FloatTok{1.5}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ exp\_base\_e)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-410-1} \end{center}

\hypertarget{logaritmi}{%
\section*{Logaritmi}\label{logaritmi}}


Dati due numeri reali \(b > 0\) e \(a > 0\) con \(a \neq 1\), l'equazione esponenziale \(a^x = b\) ammette sempre una ed una sola soluzione. Tale soluzione è detta \emph{logaritmo in base \(a\) di \(b\)} ed è indicata con la scrittura \(\log_a b\), dove \(b\) è detto \emph{argomento} del logaritmo. In altri termini, per definizione si ha

\[
x = \log_a b \Longleftrightarrow a^x = b
\]

\[
\text{dove deve essere } a > 0, \ a \neq 1,\ b > 0.
\]

Quando valutiamo i logaritmi, dobbiamo ricordare che un logaritmo è un esponente: il logaritmo in base \(a\) di \(b\), \(\log_a b\), è l'esponente da attribuire alla base \(a\) per ottenere l'argomento \(b\). Le seguenti equazioni sono dunque equivalenti:

\begin{equation}
y = \log_a x \qquad x = a^y.\notag
\end{equation}

La prima equazione è in forma logaritmica e la seconda è in forma esponenziale. Ad esempio, l'equazione logaritmica \(2 = \log_3 9\) può essere riscritta in forma esponenziale come \(9 = 3^2\).

\begin{example}

Scrivendo l'argomento come potenza della base si ottiene

\begin{itemize}
\tightlist
\item
  \(\log_2 8 = \log_2 2^3 = 3\)
\item
  \(\log_3 \sqrt[7]{3^{20}} = \log_3 3^{\frac{20}{7}} = \frac{20}{7}\)
\item
  \(\log_{0.1} 0.01 = \log_{\frac{1}{10}}\frac{1}{100} = \log_{\frac{1}{10}}\left(\frac{1}{10}\right)^2 = 2\)
\end{itemize}

\end{example}

\hypertarget{proprietuxe0-6}{%
\subsection*{Proprietà}\label{proprietuxe0-6}}


Nell'operare con i logaritmi si procede spesso mediante le loro proprietà, che costituiscono una rilettura in termini di logaritmi delle proprietà delle potenze: se \(a\), \(b\) sono numeri reali positivi diversi da 1 ed \(x\), \(y\) reali positivi qualunque, allora

\begin{itemize}
\tightlist
\item
  \(\log_a (xy) = \log_a x + \log_a y\),
\item
  \(\log_a \left(\frac{x}{y}\right) = \log_a x - \log_a y\),
\item
  \(\log_a \left(x^{\alpha}\right) = \alpha \log_a x, \quad \forall \alpha \ \text{reale}\),
\item
  \(\log_a x = \frac{\log_b x}{\log_b a}\) (cambiamento di base).
\end{itemize}

\begin{example}
\begin{align}
\log_a (x+1) -\log_a x - 2 \log_a 2 &= \log_a (x+1) - (\log_a x+ \log_a 2^2)\notag\\
&= \log_a (x+1) - \log_a 4x\notag\\
&= \log_a \frac{x+1}{4x}.\notag
\end{align}
\end{example}

\hypertarget{funzione-logaritmica}{%
\section{Funzione logaritmica}\label{funzione-logaritmica}}

La funzione logaritmica è la funzione inversa della funzione esponenziale.

\begin{definition}
Siano \(a > 0\), \(a \neq 1\). Per \(x > 0\)

\begin{equation}
y = \log_a x \quad \text{se e solo se } x = a^y.
\end{equation}

La funzione data da

\begin{equation}
f(x) = \log_a x
\end{equation}

è chiamata funzione logaritmica.
\end{definition}

Per esempio, abbiamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_funct }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x)\{}
  \FunctionTok{log}\NormalTok{(x)}
\NormalTok{\}}
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{, }\DecValTok{4}\NormalTok{)), }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x)) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ log\_funct) }\SpecialCharTok{+} 
  \FunctionTok{xlim}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{ylim}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{ x"}\NormalTok{, }\AttributeTok{y =} \StringTok{"y }\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{, }\AttributeTok{x =} \DecValTok{3}\NormalTok{, }\AttributeTok{y =} \DecValTok{3}\NormalTok{, }\AttributeTok{parse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{size =} \DecValTok{5}\NormalTok{, }\AttributeTok{fontface =} \StringTok{"bold"}\NormalTok{,}
           \AttributeTok{label=}\StringTok{"y == log(x)"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{colour =} \StringTok{"gray"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \DecValTok{0}\NormalTok{, }\AttributeTok{colour =} \StringTok{"gray"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-411-1} \end{center}

\hypertarget{gauss-normale}{%
\chapter{La Normale motivata dal metodo dei minimi quadrati}\label{gauss-normale}}

La distribuzione Normale fu scoperta da Gauss nel 1809 e, nella derivazione di Gauss, è intimamente legata al metodo dei minimi quadrati. Vediamo come Gauss arrivò alla definizione della densità Normale.

Tra il 1735 e il 1754 l'Accademia di Francia effettuò quattro misurazioni della lunghezza di un arco di meridiano a latitudini diverse con lo scopo di determinare la figura della Terra.\footnote{L'espressione ``figura della Terra'' è utilizzata in geodesia per indicare la precisione con cui sono definite la dimensione e la forma della Terra.} Papa Benedetto XIV volle contribuire a questo progetto e nel 1750 incaricò Roger Joseph Boscovich (1711---1787) e il gesuita inglese Christopher Maire di misurare un arco di meridiana nei pressi di Roma e contemporaneamente di costruire una nuova mappa dello Stato Pontificio. Il loro rapporto fu pubblicato nel 1755.

La relazione tra lunghezza d'arco e latitudine per archi piccoli è approssimativamente \(y = \alpha + \beta x\), dove \(y\) è la lunghezza dell'arco e \(x = sin^2L\), dove \(L\) è la latitudine del punto medio dell'arco. Il problema di Boscovich era quello di stimare \(\alpha\) e \(\beta\) da cinque osservazioni di \((x, y)\).

Nel 1757 pubblicò una sintesi del rapporto del 1755 in cui proponeva di risolvere il problema di riconciliare le relazioni lineari inconsistenti mediante la minimizzazione della somma dei valori assoluti dei residui, sotto il vincolo che la somma dei residui fosse uguale a zero. In altre parole, Boscovich propose di minimizzare la quantità \(\sum \mid y_i - a - b x_i \mid\) rispetto ad \(a\) e \(b\) sotto il vincolo \((y_i - a - b x_i) = 0\). Boscovich fu il primo a formulare un metodo per adattare una retta ai dati descritti da un diagramma a dispersione, laddove l'orientamento della retta dipende dalla minimizzazione di una funzione dei residui. La formulazione e la soluzione di Boscovich erano puramente verbali ed era accompagnata da un diagramma che spiegava il metodo di minimizzazione.

Nella \emph{Mécanique Céleste}, Laplace (1749, 1827) ritornò sul problema di Boscovich e mostrò in maniera formale come sia possibile minimizzare la quantità \(\sum w_i \mid y_i - a - b x_i \mid\). Il metodo della minimizzazione del valore assoluto degli scarti presentava degli svantaggi rispetto al metodo dei minimi quadrati: (1) la stima della pendenza della retta era complicata da calcolare e (2) il metodo era limitato a una sola variabile indipendente. Il metodo scomparve quindi dalla pratica statistica fino alla seconda metà del XX secolo quando venne riproposto nel contesto della discussione della robustezza delle stime.

In seguito, tale problema venne ripreso da Legendre. Il suo \emph{Nouvelle methods pour la determinazione des orbites des comètes} contiene un'appendice (pp.~72-80) intitolata \emph{Sur la méthode des moindres carrés}, in cui per la prima volta il metodo dei minimi quadrati viene presentato come un metodo algebrico per l'adattamento di un modello lineare ai dati. Legendre scrive \emph{``Tra tutti i princìpi che si possono proporre a questo scopo, credo che non ce ne sia uno più generale, più esatto e più facile da applicare di quello di cui ci siamo serviti nelle precedenti ricerche, e che consiste nel minimizzare la somma dei quadrati degli errori. In questo modo si stabilisce una sorta di equilibrio tra gli errori, che impedisce agli estremi di prevalere e ben si presta a farci conoscere lo stato del sistema più vicino alla verità.''}

La somma dei quadrati degli errori è

\[
\sum_{i=1}^n e_i^2 = (y_i - a - b_1x_{i1} - \dots - b_m x_{im})^2.
\]

Per trovare il minimo di tale funzione, Legendre pone a zero le derivate della funzione rispetto ad \(a, b_1, \dots, b_m\), il che conduce a quelle che in seguito sono state chiamate le ``equazioni normali''. Risolvendo il sistema di equazioni normali rispetto \(a, b_1, \dots, b_m\), si determinano le stime dei minimi quadrati dei parametri del modello di regressione.

Tutto questo è rilevante per la derivazione della Normale perché, in questo contesto, Legendre osservò che la media aritmetica, quale caso speciale dei minimi quadrati, si ottiene minimizzando \(\sum(y_i - b)^2\). In precedenza, Laplace si era posto il problema di mostrare che la media aritmetica è la migliore stima possibile della tendenza centrale di una distribuzione di errori di misurazione, ma non ci era riuscito perché aveva minimizzato il valore assoluto degli scarti, il che portava ad identificare la mediana quale migliore stimatore della tendenza centrale della distribuzione degli errori, non la media.

Nel 1809, Gauss riformulò il problema ponendosi le seguenti domande. Che forma deve avere la densità della distribuzione degli errori? Quale quantità deve essere minimizzata per fare in modo che la media aritmetica risulti la miglior stima possibile della tendenza centrale della distribuzione degli errori? \emph{``Si è soliti considerare come un assioma l'ipotesi che se una qualsiasi grandezza è stata determinata da più osservazioni dirette, fatte nelle stesse circostanze e con uguale cura, la media aritmetica dei valori osservati dà il valore più probabile, se non rigorosamente, eppure con una grade approssimazione, così che è sempre più sicuro utilizzare tale valore.''}

Basandosi sul risultato di Legendre (ovvero, che è necessario minimizzare il quadrato degli scarti dalla tendenza centrale, non il valore assoluto degli scarti), Gauss derivò la formula della densità Normale quale modello teorico della distribuzione degli errori di misurazione. La Normale ha infatti la proprietà desiderata: il valore atteso della distribuzione corrisponde alla media aritmetica.

La scoperta della distribuzione normale segna l'inizio di una nuova era nella statistica. La distribuzione Normale è importante, in primo luogo, perché molti fenomeni naturali hanno approssimativamente le caratteristiche descritte dall'esempio precedente. In secondo luogo, è importante perché molti modelli statistici assumono che il fenomeno aleatorio di interesse abbia una distribuzione Normale.

Nella derivazione della Normale, Gauss fornì una giustificazione probabilistica al metodo dei minimi quadrati basata sull'ipotesi che le osservazioni siano distribuite normalmente e che la distribuzione a priori del parametro di tendenza centrale sia uniforme. Si noti come la discussione sia formulata in termini bayesiani.

La derivazione formale della Normale è troppo complessa per gli scopi presenti. Il Paragrafo \ref{normal-random-walk} illustra invece come si possa giungere alla Normale mediante una simulazione. La motivazione del presente escursus storico è stata quella di mostrare come la Normale sia fortemente legata, in un contesto storico, al modello lineare e al metodo dei minimi quadrati.

\hypertarget{appendix:max-like}{%
\chapter{La stima di massima verosimiglianza}\label{appendix:max-like}}

\hypertarget{derivation-smv-prop}{%
\section{La s.m.v. per una proporzione}\label{derivation-smv-prop}}

La s.m.v. della proporzione di successi \(\theta\) in una sequenza di prove Bernoulliane è uguale data dalla proporzione di successi campionari. Questo risultato può essere dimostrato come segue.

\begin{proof}
Per \(n\) prove Bernoulliane indipendenti, le quali producono \(y\) successi e (\(n-y\)) insuccessi, la funzione nucleo (ovvero, la funzione di verosimiglianza da cui sono state escluse tutte le costanti moltiplicative che non hanno alcun effetto su \(\hat{\theta}\)) è

\[
\mathcal{L}(p \mid y) = \theta^y (1-\theta)^{n - y}.\notag
\] La funzione nucleo di log-verosimiglianza è

\[
\begin{aligned}
\ell(\theta \mid y) &= \log \mathcal{L}(\theta \mid y) \notag\\
          &= \log \left(\theta^y (1-\theta)^{n - y} \right) \notag\\
          &= \log \theta^y + \log \left( (1-\theta)^{n - y} \right) \notag\\
          &= y \log \theta + (n - y) \log (1-\theta).\notag
\end{aligned}
\]

Per calcolare il massimo della funzione di log-verosimiglianza è necessario differenziare \(\ell(\theta \mid y)\) rispetto a \(\theta\), porre la derivata a zero e risolvere. La derivata di \(\ell(\theta \mid y)\) è:

\[
\ell'(\theta \mid y) = \frac{y}{\theta} -\frac{n-y}{1-\theta}.
\]

Ponendo l'equazione uguale a zero e risolvendo otteniamo la s.m.v.:

\begin{equation}
  \hat{\theta} = \frac{y}{n},
  \label{eq:mlprop}
\end{equation}

ovvero la frequenza relativa dei successi nel campione.
\end{proof}

\hypertarget{calcolo-numerico}{%
\subsection*{Calcolo numerico}\label{calcolo-numerico}}


In maniera più semplice, il risultato descritto nel Paragrafo \ref{derivation-smv-prop} può essere ottenuto mediante una simulazione in \R. Iniziamo a definire un insieme di valori possibili per il parametro incognito \(\theta\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \FloatTok{1e3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Sappiamo che la funzione di verosimiglianza è la funzione di massa di probabilità espressa in funzione del parametro sconosciuto \(\theta\) assumendo come noti i dati. Questo si può esprimere in \(\R\) nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{like }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =} \DecValTok{23}\NormalTok{, }\AttributeTok{size =} \DecValTok{30}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ theta)}
\end{Highlighting}
\end{Shaded}

Si noti che, nell'istruzione precedente, abbiamo passato alla funzione \texttt{dbinom()} i dati, ovvero \texttt{x\ =\ 23} successi in \texttt{size\ =\ 30} prove. Inoltre, abbiamo passato alla funzione il vettore \texttt{prob\ =\ theta} che contiene 1000 valori possibili per il parametro \(\theta \in [0, 1]\). Per ciascuno dei valori \(\theta\), la funzione \texttt{dbinom()} ritorna un valore che corrisopnde all'ordinata della funzione di verosimiglianza, tenendo sempre costanti i dati (ovvero, 6 successi in 9 prove). Un grafico della funzione di verosimiglianza è dato da:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(theta, like) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ theta, }\AttributeTok{y =}\NormalTok{ like)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{L}\NormalTok{(theta)),}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(}\StringTok{\textquotesingle{}Valori possibili di\textquotesingle{}} \SpecialCharTok{\textasciitilde{}}\NormalTok{ theta)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-415-1} \end{center}

Nella simulazione, il valore \(\theta\) che massimizza la funzione di verosimiglianza può essere trovato nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta[}\FunctionTok{which.max}\NormalTok{(like)]}
\CommentTok{\#\textgreater{} [1] 0.7668}
\end{Highlighting}
\end{Shaded}

Il valore così trovato è uguale al valore definito dalla \eqref{eq:mlprop}.

\hypertarget{derivation-smv-norm}{%
\section{La s.m.v. del modello Normale}\label{derivation-smv-norm}}

Ora che abbiamo capito come costruire la funzione verosimiglianza di una binomiale è relativamente semplice fare un passo ulteriore e considerare la verosimiglianza del caso di una funzione di densità, ovvero nel caso di una variabile casuale continua. Consideriamo qui il caso della Normale.

\begin{proof}
La densità di una distribuzione Normale di parametri \(\mu\) e \(\sigma\) è

\[
f(y \mid \mu, \sigma) = \frac{1}{\sigma \sqrt{2\pi}} \exp\left\{-\frac{1}{2\sigma^2}(y-\mu)^2\right\}.
\label{eq:gausslike}
\]

Poniamoci il problema di trovare la s.m.v. dei parametri sconosciuti \(\mu\) e \(\sigma\) nel caso in cui le \(n\) osservazioni \(y = (y_1, \dots, y_n)\) sono realizzazioni indipendenti ed identicamente distribuite (di seguito, i.i.d.) della medesima variabile casuale \(Y \sim \mathcal{N}(\mu, \sigma)\). Per semplicità, scriveremo \(\theta = \{\mu, \sigma\}.\)

Il campione osservato è un insieme di eventi, ciascuno dei quali corrisponde alla realizzazione di una variabile casuale --- possiamo pensare ad uno di tali eventi come all'estrazione casuale di un valore dalla ``popolazione'' \(\mathcal{N}(\mu, \sigma)\). Se le variabili casuali sono i.i.d., la loro densità congiunta è data da:

\begin{align}
f(y \mid \theta) &= f(y_1 \mid \theta) \cdot f(y_2 \mid \theta) \cdot \; \dots \; \cdot f(y_n \mid \theta)\notag\\
                 &= \prod_{i=1}^n f(y_i \mid \theta),
\label{eq:gauss-prob-cong}
\end{align}

laddove la funzione \(f(\cdot)\) è la \eqref{eq:gausslike}. Tenendo costanti i dati \(y\), la funzione di verosimiglianza è:

\begin{equation}
\mathcal{L}(\theta \mid y) = \prod_{i=1}^n f(y_i \mid \theta).
\label{eq:gausslike2}
\end{equation}

L'obiettivo è quello di massimizzare la funzione di verosimiglianza per trovare i valori \(\theta\) ottimali. Usando la notazione matematica questo si esprime dicendo che cerchiamo l'argmax della \eqref{eq:gausslike2} rispetto a \(\theta\), ovvero

\[
\hat{\theta} = \text{argmax}_{\theta} \prod_{i=1}^n f(y_i \mid \theta).
\]

Questo problema si risolve calcolando le derivate della funzione rispetto a \(\theta\), ponendo le derivate uguali a zero e risolvendo. Saltando tutti i passaggi algebrici di questo procedimento, per \(\mu\) troviamo

\begin{equation}
\hat{\mu} = \frac{1}{n} \sum_{i=1}^n y_i
\label{eq:maxlikemu}
\end{equation}

e per \(\sigma\) abbiamo

\begin{equation}
\hat{\sigma} = \sqrt{\sum_{i=1}^n\frac{1}{n}(y_i- \mu)^2}.
\label{eq:maxlikesigma}
\end{equation}

In altri termini, la s.m.v. del parametro \(\mu\) è la media del campione e la s.m.v. del parametro \(\sigma\) è la deviazione standard del campione.
\end{proof}

\hypertarget{calcolo-numerico-1}{%
\section*{Calcolo numerico}\label{calcolo-numerico-1}}


Consideriamo ora un esempio che utilizza dei dati reali. I dati corrispondono ai valori BDI-II dei trenta soggetti del campione clinico di \citet{zetschefuture2019}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{y =} \FunctionTok{c}\NormalTok{(}
    \DecValTok{26}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{44}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{43}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{39}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{25}\NormalTok{, }
    \DecValTok{28}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{31}\NormalTok{, }\DecValTok{41}\NormalTok{, }\DecValTok{36}\NormalTok{, }\DecValTok{26}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{33}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{34}\NormalTok{, }\DecValTok{27}\NormalTok{, }\DecValTok{22}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Ci poniamo l'obiettivo di creare la funzione di verosimiglianza per questi dati, supponendo, in base ai risultati di ricerche precedenti, di sapere che i punteggi BDI-II si distribuiscono secondo una legge Normale.

Per semplificare il problema, assumeremo di conoscere \(\sigma\) (lo porremo uguale alla deviazione standard del campione) in modo da avere un solo parametro sconosciuto, cioè \(\mu\). Il problema è dunque quello di trovare la funzione di verosimiglianza per il parametro \(\mu\), date le 30 osservazioni del campione e dato \(\sigma = s = 6.61\).

Per una singola osservazione, la funzione di verosimiglianza è la densità Normale espressa in funzione dei parametri. Per un campione di osservazioni i.i.d., ovvero \(y = (y_1, y_2, \dots, y_n)\), la verosimiglianza è la funzione di densità congiunta \(f(y \mid \mu, \sigma)\) espressa in funzione dei parametri, ovvero \(\mathcal{L}(\mu, \sigma \mid y)\). Dato che le osservazioni sono i.i.d., la densità congiunta è data dal prodotto delle densità delle singole osservazioni. Per semplicità, assumiamo \(\sigma\) noto e uguale alla deviazione standard del campione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{true\_sigma }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y)}
\NormalTok{true\_sigma }
\CommentTok{\#\textgreater{} [1] 6.607}
\end{Highlighting}
\end{Shaded}

Avendo posto \(\sigma = 6.61\), per una singola osservazione \(y_i\) abbiamo

\[
f(y_i \mid \mu, \sigma) = \frac{1}{{6.61 \sqrt {2\pi}}}\exp\left\{{-\frac{(y_i - \mu)^2}{2\cdot 6.61^2}}\right\},\notag
\]

dove il pedice \(i\) specifica l'osservazione \(y_i\) tra le molteplici osservazioni \(y\), e \(\mu\) è il parametro sconosciuto che deve essere determinato (nell'esempio, \(\sigma = s\)). La densità congiunta è dunque

\[
f(y \mid \mu, \sigma) = \, \prod_{i=1}^n f(y_i \mid \mu, \sigma)\notag
\] e, alla luce dei dati osservati, la verosimiglianza diventa

\[
\begin{aligned}
\mathcal{L}(\mu, \sigma \mid y) =& \, \prod_{i=1}^n f(y_i \mid \mu, \sigma) = \notag\\
& \frac{1}{{6.61 \sqrt {2\pi}}}\exp\left\{{-\frac{(26 - \mu)^2}{2\cdot 6.61^2}}\right\} \times \notag\\
 & \frac{1}{{6.61 \sqrt {2\pi}}}\exp\left\{{-\frac{(35 - \mu)^2}{2\cdot 6.61^2}}\right\} \times  \notag\\
& \vdots \notag\\
 & \frac{1}{{6.61 \sqrt {2\pi}}}\exp\left\{{-\frac{(22 - \mu)^2}{2\cdot 6.61^2}}\right\}.
\end{aligned}
\label{eq:lldepression}
\]

Poniamoci ora il problema di rappresentare graficamente la funzione di verosimiglianza per il parametro \(\mu\). Avendo un solo parametro sconosciuto, possiamo rappresentare la verosimiglianza con una curva. In \R, definiamo la funzione di log-verosimiglianza nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{log\_likelihood }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(y, mu, }\AttributeTok{sigma =}\NormalTok{ true\_sigma) \{}
  \FunctionTok{sum}\NormalTok{(}\FunctionTok{dnorm}\NormalTok{(y, mu, sigma, }\AttributeTok{log =} \ConstantTok{TRUE}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Nella funzione \texttt{log\_likelihood()}, \texttt{y} è un vettore che, nel caso presente contiene \(n = 30\) valori. Per ciascuno di questi valori, la funzione \texttt{dnorm()} trova la densità Normale utilizzando il valore \(\mu\) che passato a \texttt{log\_likelihood()} e il valore \(\sigma\) uguale a 6.61 --- nell'esempio, questo parametro viene assunto come noto. L'argomento \texttt{log\ =\ TRUE} specifica che deve essere preso il logaritmo. La funzione \texttt{dnorm()} è un argomento della funzione \texttt{sum()}. Ciò significa che i 30 valori così trovati, espressi su scala logaritmica, verranno sommati --- sommare logaritmi è equivalente a fare il prodotto dei valori sulla scala originaria.

Se applichiamo questa funzione ad un solo valore \(\mu\) otteniamo l'ordinata della funzione di log-verosimiglianza in corrispondenza del valore \(\mu\) (si veda la figura \eqref{eq:lldepression}). Si noti che, per trovare un tale valore, abbiamo utilizzato le seguenti informazioni:

\begin{itemize}
\tightlist
\item
  i 30 dati del campione,
\item
  il valore \(\sigma = s\) fissato a 6.61,
\item
  il singolo valore \(\mu\) passato alla funzione \texttt{log\_likelihood()}.
\end{itemize}

Avendo trovato un singolo punto della funzione di log-verosimiglianza, dobbiamo ripetere i calcoli precedenti per tutti i possibili valori che \(\mu\) può assumere. Nel seguente ciclo \texttt{for()} viene calcolata la log-verosimiglianza di 100,000 valori possibili del parametro \(\mu\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nrep }\OtherTok{\textless{}{-}} \FloatTok{1e5}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}
  \FunctionTok{mean}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y) }\SpecialCharTok{{-}} \FunctionTok{sd}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y), }
  \FunctionTok{mean}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y) }\SpecialCharTok{+} \FunctionTok{sd}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y), }
  \AttributeTok{length.out =}\NormalTok{ nrep}
\NormalTok{)}

\NormalTok{ll }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA}\NormalTok{, nrep)}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nrep) \{}
\NormalTok{  ll[i] }\OtherTok{\textless{}{-}} \FunctionTok{log\_likelihood}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y, mu[i], true\_sigma)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Il vettore \texttt{mu} contiene 100,000 possibili valori del parametro \(\mu\); tali valori sono stati scelti nell'intervallo \(\bar{y} \pm s\). Per ciascuno di questi valori la funzione \texttt{log\_likelihood()} calcola il valore di log-verosimiglianza. I 100,000 risultati vengono salvati nel vettore \texttt{ll}.

I vettori \texttt{mu} e \texttt{ll} possono dunque essere usati per disegnare il grafico della funzione di log-verosimiglianza per il parametro \(\mu\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(mu, ll) }\SpecialCharTok{\%\textgreater{}\%} 
\FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ mu, }\AttributeTok{y =}\NormalTok{ ll)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{vline\_at}\NormalTok{(}\FunctionTok{mean}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{y), }\AttributeTok{color =} \StringTok{"gray"}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{y =} \StringTok{"Log{-}verosimiglianza"}\NormalTok{,}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(}\StringTok{"Parametro"}\SpecialCharTok{\textasciitilde{}}\NormalTok{mu)}
\NormalTok{  ) }
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-421-1} \end{center}

Dalla figura notiamo che, per i dati osservati, il massimo della funzione di log-verosimiglianza calcolata per via numerica, ovvero 30.93, è identico alla media dei dati campionari e corrisponde al risultato teorico della \eqref{eq:maxlikemu}.

\hypertarget{considerazioni-conclusive}{%
\section*{Considerazioni conclusive}\label{considerazioni-conclusive}}


La verosimiglianza viene utilizzata sia nell'inferenza bayesiana che in quella frequentista. In entrambi i paradigmi di inferenza, il suo ruolo è quantificare la forza con la quale i dati osservati supportano i possibili valori dei parametri sconosciuti.

Nella funzione di verosimiglianza i dati (osservati) vengono trattati come fissi, mentre i valori del parametro (o dei parametri) \(\theta\) vengono variati: la verosimiglianza è una funzione di \(\theta\) per il dato fisso \(y\). Pertanto, la funzione di verosimiglianza riassume i seguenti elementi: un modello statistico che genera stocasticamente i dati (in questo capitolo abbiamo esaminato due modelli statistici: quello binomiale e quello Normale), un intervallo di valori possibili per \(\theta\) e i dati osservati \(y\).

Nella statistica frequentista l'inferenza si basa solo sui dati a disposizione e qualunque informazione fornita dalle conoscenze precedenti non viene presa in considerazione. Nello specifico, nella statistica frequentista l'inferenza viene condotta massimizzando la funzione di (log) verosimiglianza, condizionatamente ai valori assunti dalle variabili casuali campionarie. Nella statistica bayesiana, invece, l'inferenza statistica viene condotta combinando la funzione di verosimiglianza con le distribuzioni a priori dei parametri incogniti \(\theta\).

La differenza fondamentale tra inferenza bayesiana e frequentista è dunque che i frequentisti non ritengono utile descrivere in termini probabilistici i parametri: i parametri dei modelli statistici vengono concepiti come fissi ma sconosciuti. Nell'inferenza bayesiana, invece, i parametri sconosciuti sono intesi come delle variabili casuali e ciò consente di quantificare in termini probabilistici il nostro grado di intertezza relativamente al loro valore.

\hypertarget{appendix:future-exp}{%
\chapter{Le aspettative future dei pazienti depressi}\label{appendix:future-exp}}

\hypertarget{app:zet}{%
\section{\texorpdfstring{La ricerca di \citet{zetschefuture2019}}{La ricerca di @zetschefuture2019}}\label{app:zet}}

Per descrivere vari aspetti dell'analisi bayesiana utilizzeremo dei dati reali, nello specifico quelli raccolti da \citet{zetschefuture2019}. Questi ricercatori si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente. Esamineremo qui i 30 partecipanti dello studio di \citet{zetschefuture2019} che hanno riportato la presenza di un episodio di depressione maggiore in atto. All'inizio della settimana di test, a questi pazienti è stato chiesto di valutare l'umore che si aspettavano di esperire nei giorni seguenti della settimana. Mediante una app, i partecipanti dovevano poi valutare il proprio umore in cinque momenti diversi di ciascuno dei cinque giorni successivi. Lo studio considera diverse emozioni, ma qui ci concentriamo solo sulla tristezza.

Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei giudizi relativi al livello di tristezza raccolti da ciascun partecipante tramite la app. Tale media è stata poi sottratta dall'aspettativa del livello di tristezza fornita all'inizio della settimana. La discrepanza tra aspettative e realtà è stata considerata come un evento dicotomico: valori positivi di tale differenza indicano che le aspettative circa il livello di tristezza erano maggiori del livello di tristezza effettivamente esperito --- ciò significa che le aspettative future risultano negativamente distorte (evento codificato con ``1''). Viceversa, si ha che le aspettative risultano positivamente distorte se la differenza descritta in precedenza assume un valore negativo (evento codificato con ``0'').

Nel campione dei 30 partecipanti clinici di \citet{zetschefuture2019}, le aspettative future di 23 partecipanti risultano distorte negativamente e quelle di 7 partecipanti risultano distorte positivamente. Chiameremo \(\theta\) la probabilità dell'evento ``le aspettative del partecipante sono distorte negativamente''. Ci poniamo il problema di ottenere una stima a posteriori di \(\theta\) avendo osservato 23 ``successi'' in 30 prove.

Si noti un punto importante: dire semplicemente che la stima di \(\theta\) è uguale a 23/30 = 0.77 ci porta ad ignorare il livello di incertezza associato a tale stima. Infatti, lo stesso valore (0.77) si può ottenere come 23/30, o 230/300, o 2300/3000, o 23000/30000, ma l'incertezza di una stima pari a 0.77 è molto diversa nei quattro casi. Quando si traggono conclusioni dai dati è invece necessario quantificare il livello della nostra incertezza relativamente alla stima del parametro di interesse (nel caso presente, \(\theta\)). Lo strumento ci consente di quantificare tale incertezza è la distribizione a posteriori \(p(\theta \mid y)\). Ovviamente, \(p(\theta \mid y)\) assume forme molto diverse nei quattro casi descritti sopra.

\hypertarget{appendix:beta-binom}{%
\chapter{Modello Beta-binomiale}\label{appendix:beta-binom}}

\hypertarget{funzione-per-il-modello-beta-binomiale}{%
\section{Funzione per il modello Beta-binomiale}\label{funzione-per-il-modello-beta-binomiale}}

La seguente funzione può essere usata per rappresentare la distribuzione a priori, la distribuzione a posteriori e la versosimiglianza (normalizzata) nel caso del modello Beta-binomiale. I parametri in input sono, nell'ordine, i parametri \(\alpha\) e \(\beta\) della distribuzione a priori Beta, \(y\) (numero di successi) e \(n\) (numero di prove).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_beta\_bin }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, b, y, n) \{}
  \FunctionTok{library}\NormalTok{(}\StringTok{"tidyverse"}\NormalTok{)}
  
\NormalTok{  df1 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{theta =} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.001}\NormalTok{))}
\NormalTok{  prior\_un }\OtherTok{\textless{}{-}} \FunctionTok{dbeta}\NormalTok{(df1}\SpecialCharTok{$}\NormalTok{theta, a, b)}
\NormalTok{  df1}\SpecialCharTok{$}\NormalTok{prior }\OtherTok{\textless{}{-}}\NormalTok{ prior\_un }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(prior\_un)}

  \CommentTok{\# Likelihood}
\NormalTok{  like\_un }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(y, n, }\AttributeTok{prob =} \FunctionTok{seq}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.001}\NormalTok{))}
\NormalTok{  df1}\SpecialCharTok{$}\NormalTok{like }\OtherTok{\textless{}{-}}\NormalTok{ like\_un }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(like\_un)}

  \CommentTok{\# Posterior}
\NormalTok{  post\_un }\OtherTok{\textless{}{-}}\NormalTok{ df1}\SpecialCharTok{$}\NormalTok{prior }\SpecialCharTok{*}\NormalTok{ df1}\SpecialCharTok{$}\NormalTok{like}
\NormalTok{  df1}\SpecialCharTok{$}\NormalTok{post }\OtherTok{\textless{}{-}}\NormalTok{ post\_un }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(post\_un)}

\NormalTok{  df2 }\OtherTok{\textless{}{-}}\NormalTok{ df1 }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pivot\_longer}\NormalTok{(}\SpecialCharTok{!}\NormalTok{theta, }\AttributeTok{names\_to =} \StringTok{"grp"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"val"}\NormalTok{)}

\NormalTok{  df2}\SpecialCharTok{$}\NormalTok{grp }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(df2}\SpecialCharTok{$}\NormalTok{grp)}
  \CommentTok{\# levels(df2$grp)}
\NormalTok{  df2}\SpecialCharTok{$}\NormalTok{grp }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(df2}\SpecialCharTok{$}\NormalTok{grp, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"prior"}\NormalTok{, }\StringTok{"like"}\NormalTok{, }\StringTok{"post"}\NormalTok{))}
  \FunctionTok{levels}\NormalTok{(df2}\SpecialCharTok{$}\NormalTok{grp) }\OtherTok{\textless{}{-}}
    \FunctionTok{c}\NormalTok{(}
      \StringTok{"Distribuzione a priori"}\NormalTok{, }\StringTok{"Verosimiglianza"}\NormalTok{,}
      \StringTok{"Distribuzione a posteriori"}
\NormalTok{    )}

\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df2) }\SpecialCharTok{+}
    \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(theta, val)) }\SpecialCharTok{+}
    \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{grp, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{coord\_cartesian}\NormalTok{(}\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{breaks =} \ConstantTok{NULL}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{""}\NormalTok{, }\AttributeTok{y =} \StringTok{""}\NormalTok{)}

\NormalTok{  p}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{appendix:const-norm-bino23}{%
\chapter{Verosimiglianza marginale}\label{appendix:const-norm-bino23}}

\hypertarget{derivazione-analitica-della-costante-di-normalizzazione}{%
\section{Derivazione analitica della costante di normalizzazione}\label{derivazione-analitica-della-costante-di-normalizzazione}}

Riportiamo di seguito la derivazione analitica per la costante di normalizzazione discussa nella Sezione \ref{sec:const-normaliz-bino23}, ovvero dell'integrale \eqref{eq:likebino23}.

\begin{proof}
Sia la distribuzione a priori \(\theta \sim \mbox{Beta}(a, b)\) e sia \(y = \{y_1, \dots, y_n\} \sim \Bin(\theta, n)\). Scrivendo la \emph{funzione beta} come

\[
\B(a, b) = \frac{\Gamma(a)\Gamma(b)}{\Gamma(a+b)},
\] la verosimiglianza marginale diventa

\begin{align}
p(y) &= \int p(y \mid \theta) p(\theta) \,\operatorname {d}\!\theta \notag\\
&= \int_0^1 \binom{n}{y}\theta^{y} (1 - \theta)^{n- y} \frac{1}{\B(a,b)} \theta^{a-1} (1-\theta)^{b-1} \,\operatorname {d}\!\theta \notag\\
&= \binom{n}{y}\frac{1}{\B(a,b)} \int_0^1 \theta^{y + a - 1} (1-\theta)^{n- y + b-1}  \,\operatorname {d}\!\theta \notag\\
&= \binom{n}{y}\frac{\Beta(y + a, n- y + b)}{\Beta(a,b)},
\label{eq:constant-norm-beta-binom}
\end{align}

in quanto

\begin{align}
\int_0^1 \frac{1}{\Beta(a,b)} \theta^{a-1} (1-\theta)^{b-1} \,\operatorname {d}\! \theta &= 1\notag\\
\frac{1}{\Beta(a,b)} \int_0^1  \theta^{a-1} (1-\theta)^{b-1} \,\operatorname {d}\! \theta &= 1\notag\\
\int_0^1  \theta^{a-1} (1-\theta)^{b-1} \,\operatorname {d}\!\theta &= \Beta(a,b). \notag
\end{align}

In conclusione, nel caso di una verosimiglianza binomiale \(y = \sim \Bin(\theta, n)\) e di una distribuzione a priori \(\theta \sim \mbox{Beta}(a, b)\), la verosimiglianza marginale diventa uguale alla \eqref{eq:constant-norm-beta-binom}.
\end{proof}

\begin{exercise}

Si verifichi la \eqref{eq:constant-norm-beta-binom} mediante di dati di \citet{zetschefuture2019}.

Per replicare mediante la \eqref{eq:constant-norm-beta-binom} il risultato trovato per via numerica nella Sezione \ref{sec:const-normaliz-bino23} assumiamo una distribuzione a priori uniforme, ovvero \(\mbox{Beta}(1, 1)\). I valori del problema dunque diventano i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{b }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{y }\OtherTok{\textless{}{-}} \DecValTok{23}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{30}
\end{Highlighting}
\end{Shaded}

Definiamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(a, b) \{}
\NormalTok{  (}\FunctionTok{gamma}\NormalTok{(a) }\SpecialCharTok{*} \FunctionTok{gamma}\NormalTok{(b)) }\SpecialCharTok{/} \FunctionTok{gamma}\NormalTok{(a }\SpecialCharTok{+}\NormalTok{ b)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Il risultato cercato è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{choose}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{23}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{B}\NormalTok{(y }\SpecialCharTok{+}\NormalTok{ a, n }\SpecialCharTok{{-}}\NormalTok{ y }\SpecialCharTok{+}\NormalTok{ b) }\SpecialCharTok{/} \FunctionTok{B}\NormalTok{(a, b)}
\CommentTok{\#\textgreater{} [1] 0.03226}
\end{Highlighting}
\end{Shaded}

\end{exercise}

\hypertarget{es-pratico-zetsche}{%
\chapter{Aspettative degli individui depressi}\label{es-pratico-zetsche}}

Per fare pratica, applichiamo il metodo basato su griglia ad un campione di dati reali. \citet{zetschefuture2019} si sono chiesti se gli individui depressi manifestino delle aspettative accurate circa il loro umore futuro, oppure se tali aspettative siano distorte negativamente. Esamineremo qui i 30 partecipanti dello studio di \citet{zetschefuture2019} che hanno riportato la presenza di un episodio di depressione maggiore in atto. All'inizio della settimana di test, a questi pazienti è stato chiesto di valutare l'umore che si aspettavano di esperire nei giorni seguenti della settimana. Mediante una app, i partecipanti dovevano poi valutare il proprio umore in cinque momenti diversi di ciascuno dei cinque giorni successivi. Lo studio considera diverse emozioni, ma qui ci concentriamo solo sulla tristezza.

Sulla base dei dati forniti dagli autori, abbiamo calcolato la media dei giudizi relativi al livello di tristezza raccolti da ciascun partecipante tramite la app. Tale media è stata poi sottratta dall'aspettativa del livello di tristezza fornita all'inizio della settimana. La discrepanza tra aspettative e realtà è stata considerata come un evento dicotomico: valori positivi di tale differenza indicano che le aspettative circa il livello di tristezza erano maggiori del livello di tristezza effettivamente esperito --- ciò significa che le aspettative future risultano negativamente distorte (evento codificato con ``1''). Viceversa, si ha che le aspettative risultano positivamente distorte se la differenza descritta in precedenza assume un valore negativo (evento codificato con ``0'').

Nel campione dei 30 partecipanti clinici di \citet{zetschefuture2019}, le aspettative future di 23 partecipanti risultano distorte negativamente e quelle di 7 partecipanti risultano distorte positivamente. Chiameremo \(\theta\) la probabilità dell'evento ``le aspettative del partecipante sono distorte negativamente''. Ci poniamo il problema di ottenere una stima a posteriori di \(\theta\) usando il metodo basato su griglia.

\hypertarget{la-griglia}{%
\section{La griglia}\label{la-griglia}}

Fissiamo una griglia di \(n = 50\) valori equispaziati nell'intervallo {[}0, 1{]} per il parametro \(\theta\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_points }\OtherTok{\textless{}{-}} \DecValTok{50}
\NormalTok{p\_grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ n\_points)}
\NormalTok{p\_grid}
\CommentTok{\#\textgreater{}  [1] 0.00000 0.02041 0.04082 0.06122 0.08163 0.10204}
\CommentTok{\#\textgreater{}  [7] 0.12245 0.14286 0.16327 0.18367 0.20408 0.22449}
\CommentTok{\#\textgreater{} [13] 0.24490 0.26531 0.28571 0.30612 0.32653 0.34694}
\CommentTok{\#\textgreater{} [19] 0.36735 0.38776 0.40816 0.42857 0.44898 0.46939}
\CommentTok{\#\textgreater{} [25] 0.48980 0.51020 0.53061 0.55102 0.57143 0.59184}
\CommentTok{\#\textgreater{} [31] 0.61224 0.63265 0.65306 0.67347 0.69388 0.71429}
\CommentTok{\#\textgreater{} [37] 0.73469 0.75510 0.77551 0.79592 0.81633 0.83673}
\CommentTok{\#\textgreater{} [43] 0.85714 0.87755 0.89796 0.91837 0.93878 0.95918}
\CommentTok{\#\textgreater{} [49] 0.97959 1.00000}
\end{Highlighting}
\end{Shaded}

\hypertarget{distribuzione-a-priori}{%
\section{Distribuzione a priori}\label{distribuzione-a-priori}}

Supponiamo di avere scarse credenze a priori sulla tendenza di un individuo clinicamente depresso a manifestare delle aspettative distorte negativamente circa il suo umore futuro. Imponiamo quindi una distribuzione non informativa sulla distribuzione a priori di \(\theta\) --- ovvero, una distribuzione uniforme nell'intervallo {[}0, 1{]}. Dato che consideriamo soltanto \(n = 50\) valori possibili per il parametro \(\theta\), creiamo un vettore di 50 elementi che conterrà i valori della distribuzione a priori scalando ciascun valore del vettore per \(n\) in modo tale che la somma di tutti i valori sia uguale a 1.0:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior1 }\OtherTok{\textless{}{-}} \FunctionTok{dbeta}\NormalTok{(p\_grid, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{dbeta}\NormalTok{(p\_grid, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{prior1}
\CommentTok{\#\textgreater{}  [1] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02}
\CommentTok{\#\textgreater{} [11] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02}
\CommentTok{\#\textgreater{} [21] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02}
\CommentTok{\#\textgreater{} [31] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02}
\CommentTok{\#\textgreater{} [41] 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02 0.02}
\end{Highlighting}
\end{Shaded}

Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(prior1)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

\noindent La distribuzione a priori così costruita è rappresentata nella figura \ref{fig:gridappr1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(p\_grid, prior1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{p\_grid, }\AttributeTok{xend=}\NormalTok{p\_grid, }\AttributeTok{y=}\DecValTok{0}\NormalTok{, }\AttributeTok{yend=}\NormalTok{prior1)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.17}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Parametro \textbackslash{}U03B8"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Probabilità a priori"}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"50 punti"}
\NormalTok{  )}
\NormalTok{p1}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/gridappr1-1} 

}

\caption{Rappresentazione grafica della distribuzione a priori per il parametro $   heta$, ovvero la probabilità di aspettative future distorte negativamente.}\label{fig:gridappr1}
\end{figure}

\hypertarget{funzione-di-verosimiglianza}{%
\section{Funzione di verosimiglianza}\label{funzione-di-verosimiglianza}}

Calcoliamo ora la funzione di verosimiglianza utilizzando i 50 valori \(\theta\) definiti in precedenza. A ciascuno dei valori della griglia applichiamo la formula binomiale, tendendo costanti i dati (ovvero 23 ``successi'' in 30 prove). Ad esempio, in corrispondenza del valore \(\theta = 0.816\), l'ordinata della funzione di verosimiglianza diventa

\begin{equation}
\binom{30}{23} \cdot 0.816^{23} \cdot (1 - 0.816)^{7} = 0.135.\notag
\end{equation}

Per \(\theta = 0.837\), l'ordinata della funzione di verosimiglianza sarà

\begin{equation}
\binom{30}{23} \cdot 0.837^{23} \cdot (1 - 0.837)^{7} = 0.104.\notag
\end{equation}

Dobbiamo svolgere questo calcolo per tutti gli elementi della griglia. Usando \(\R\), tale risultato si trova nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{likelihood }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x =} \DecValTok{23}\NormalTok{, }\AttributeTok{size =} \DecValTok{30}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ p\_grid)}
\NormalTok{likelihood}
\CommentTok{\#\textgreater{}  [1] 0.000e+00 2.353e{-}33 1.703e{-}26 1.644e{-}22 1.054e{-}19}
\CommentTok{\#\textgreater{}  [6] 1.525e{-}17 8.602e{-}16 2.528e{-}14 4.607e{-}13 5.819e{-}12}
\CommentTok{\#\textgreater{} [11] 5.499e{-}11 4.106e{-}10 2.520e{-}09 1.311e{-}08 5.919e{-}08}
\CommentTok{\#\textgreater{} [16] 2.362e{-}07 8.457e{-}07 2.749e{-}06 8.197e{-}06 2.260e{-}05}
\CommentTok{\#\textgreater{} [21] 5.799e{-}05 1.393e{-}04 3.149e{-}04 6.721e{-}04 1.359e{-}03}
\CommentTok{\#\textgreater{} [26] 2.612e{-}03 4.779e{-}03 8.340e{-}03 1.390e{-}02 2.214e{-}02}
\CommentTok{\#\textgreater{} [31] 3.372e{-}02 4.910e{-}02 6.830e{-}02 9.068e{-}02 1.147e{-}01}
\CommentTok{\#\textgreater{} [36] 1.378e{-}01 1.568e{-}01 1.682e{-}01 1.689e{-}01 1.575e{-}01}
\CommentTok{\#\textgreater{} [41] 1.349e{-}01 1.044e{-}01 7.133e{-}02 4.166e{-}02 1.973e{-}02}
\CommentTok{\#\textgreater{} [46] 6.937e{-}03 1.535e{-}03 1.473e{-}04 1.868e{-}06 0.000e+00}
\end{Highlighting}
\end{Shaded}

La funzione \texttt{dbinom(x,\ size,\ prob)} richiede che vengano specificati tre parametri: il numero di ``successi'', il numero di prove e la probabilità di successo. Nella chiamata precedente, \texttt{x} (numero di successi) e \texttt{size} (numero di prove bernoulliane) sono degli scalari e \texttt{prob} è il vettore \texttt{p\_grid}. In tali circostanze, l'output di \texttt{dbinom()} è il vettore che abbiamo chiamato \texttt{likelihood}. Gli elementi di tale vettore sono stati calcolati applicando la formula della distribuzione binomiale a ciascuno dei 50 elementi della griglia, tenendo sempre costanti i dati {[}ovvero, \texttt{x} (il numero di successi) e \texttt{size} (numero di prove bernoulliane){]}; ciò che varia è il valore \texttt{prob}, che assume valori diversi (\texttt{p\_grid}) in ciascuna cella della griglia.

La chiamata a \texttt{dbinom()} produce dunque un vettore i cui valori corrispondono all'ordinata della funzione di verosimiglianza per per ciascun valore \(\theta\) specificato in \texttt{p\_grid}. La verosimiglianza discretizzata così ottenuta è riportata nella figura \ref{fig:gridappr2}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(p\_grid, likelihood) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{p\_grid, }\AttributeTok{xend=}\NormalTok{p\_grid, }\AttributeTok{y=}\DecValTok{0}\NormalTok{, }\AttributeTok{yend=}\NormalTok{likelihood)) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.17}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Parametro \textbackslash{}U03B8"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Verosimiglianza"}
\NormalTok{  )}
\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/gridappr2-1} 

}

\caption{Rappresentazione della funzione di verosimiglianza per il parametro $\theta$, ovvero la probabilità di aspettative future distorte negativamente.}\label{fig:gridappr2}
\end{figure}

\hypertarget{distribuzione-a-posteriori-1}{%
\section{Distribuzione a posteriori}\label{distribuzione-a-posteriori-1}}

L'approssimazione discretizzata della distribuzione a posteriori \(p(\theta \mid y)\) si ottiene facendo il prodotto della verosimiglianza e della distribuzione a priori per poi scalare tale prodotto per una costante di normalizzazione. Il prodotto \(p(\theta)\mathcal{L}(y \mid \theta)\) produce la distribuzione a posteriori \emph{non standardizzata}.

Nel caso di una distribuzione a priori non informativa (ovvero una distribuzione uniforme), per ottenere la funzione a posteriori non standardizzata è sufficiente moltiplicare ciascun valore della funzione di verosimiglianza per 0.02. Per esempio, per il primo valore della funzione di verosimiglianza usato quale esempio poco sopra, abbiamo \(0.135 \cdot 0.02\); per il secondo valore dell'esempio abbiamo \(0.104 \cdot 0.02\); e così via. Possiamo svolgere tutti i calcoli usando \(\R\) nel modo seguente:\footnote{Ricordiamo il principio dell'aritmetica vettorializzata: i vettori \texttt{likelihood} e \texttt{prior1} sono entrambi costituiti da 50 elementi. Se facciamo il prodotto tra i due vettori otteniamo un vettore di 50 elementi, ciascuno dei quali uguale al prodotto dei corrispondenti elementi dei vettori \texttt{likelihood} e \texttt{prior1}.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{unstd\_posterior }\OtherTok{\textless{}{-}}\NormalTok{ likelihood }\SpecialCharTok{*}\NormalTok{ prior1}
\NormalTok{unstd\_posterior}
\CommentTok{\#\textgreater{}  [1] 0.000e+00 4.705e{-}35 3.406e{-}28 3.288e{-}24 2.107e{-}21}
\CommentTok{\#\textgreater{}  [6] 3.050e{-}19 1.720e{-}17 5.057e{-}16 9.214e{-}15 1.164e{-}13}
\CommentTok{\#\textgreater{} [11] 1.100e{-}12 8.211e{-}12 5.040e{-}11 2.622e{-}10 1.184e{-}09}
\CommentTok{\#\textgreater{} [16] 4.724e{-}09 1.691e{-}08 5.499e{-}08 1.639e{-}07 4.519e{-}07}
\CommentTok{\#\textgreater{} [21] 1.160e{-}06 2.786e{-}06 6.297e{-}06 1.344e{-}05 2.718e{-}05}
\CommentTok{\#\textgreater{} [26] 5.224e{-}05 9.558e{-}05 1.668e{-}04 2.780e{-}04 4.428e{-}04}
\CommentTok{\#\textgreater{} [31] 6.744e{-}04 9.820e{-}04 1.366e{-}03 1.814e{-}03 2.294e{-}03}
\CommentTok{\#\textgreater{} [36] 2.756e{-}03 3.136e{-}03 3.363e{-}03 3.378e{-}03 3.150e{-}03}
\CommentTok{\#\textgreater{} [41] 2.697e{-}03 2.087e{-}03 1.427e{-}03 8.331e{-}04 3.945e{-}04}
\CommentTok{\#\textgreater{} [46] 1.387e{-}04 3.070e{-}05 2.947e{-}06 3.736e{-}08 0.000e+00}
\end{Highlighting}
\end{Shaded}

Avendo calcolato i valori della funzione a posteriori non standardizzata è poi necessario dividere per una costante di normalizzazione. Nel caso discreto, trovare il denominatore del teorema di Bayes è facile: esso è uguale alla somma di tutti i valori della distribuzione a posteriori non normalizzata. Per i dati presenti, tale costante di normalizzazione è uguale a 0.032:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(unstd\_posterior)}
\CommentTok{\#\textgreater{} [1] 0.03161}
\end{Highlighting}
\end{Shaded}

La standardizzazione dei due valori usati come esempio è data da: \(0.135 \cdot 0.02 / 0.032\) e da \(0.104 \cdot 0.02 / 0.032\). Usiamo \(\R\) per svolgere questo calcolo su tutti i 50 valori di \texttt{unstd\_posterior} così che la somma dei 50 i valori di \texttt{posterior} sia uguale a 1.0:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior }\OtherTok{\textless{}{-}}\NormalTok{ unstd\_posterior }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(unstd\_posterior)}
\NormalTok{posterior}
\CommentTok{\#\textgreater{}  [1] 0.000e+00 1.488e{-}33 1.077e{-}26 1.040e{-}22 6.666e{-}20}
\CommentTok{\#\textgreater{}  [6] 9.649e{-}18 5.442e{-}16 1.600e{-}14 2.915e{-}13 3.681e{-}12}
\CommentTok{\#\textgreater{} [11] 3.479e{-}11 2.597e{-}10 1.594e{-}09 8.295e{-}09 3.745e{-}08}
\CommentTok{\#\textgreater{} [16] 1.494e{-}07 5.350e{-}07 1.739e{-}06 5.186e{-}06 1.430e{-}05}
\CommentTok{\#\textgreater{} [21] 3.669e{-}05 8.814e{-}05 1.992e{-}04 4.252e{-}04 8.599e{-}04}
\CommentTok{\#\textgreater{} [26] 1.652e{-}03 3.023e{-}03 5.276e{-}03 8.794e{-}03 1.401e{-}02}
\CommentTok{\#\textgreater{} [31] 2.133e{-}02 3.106e{-}02 4.321e{-}02 5.737e{-}02 7.256e{-}02}
\CommentTok{\#\textgreater{} [36] 8.719e{-}02 9.922e{-}02 1.064e{-}01 1.069e{-}01 9.966e{-}02}
\CommentTok{\#\textgreater{} [41] 8.533e{-}02 6.602e{-}02 4.513e{-}02 2.635e{-}02 1.248e{-}02}
\CommentTok{\#\textgreater{} [46] 4.389e{-}03 9.712e{-}04 9.321e{-}05 1.182e{-}06 0.000e+00}
\end{Highlighting}
\end{Shaded}

Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(posterior)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

La distribuzione a posteriori così trovata non è altro che la versione normalizzata della funzione di verosimiglianza: questo avviene perché la distribuzione a priori uniforme non ha aggiunto altre informazioni oltre a quelle che erano già fornite dalla funzione di verosimiglianza. L'approssimazione discretizzata di \(p(\theta \mid y)\) che abbiamo appena trovato è riportata nella figura \ref{fig:gridappr3}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p3 }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(p\_grid, posterior) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{p\_grid, }\AttributeTok{xend=}\NormalTok{p\_grid, }\AttributeTok{y=}\DecValTok{0}\NormalTok{, }\AttributeTok{yend=}\NormalTok{posterior)) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.17}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Parametro \textbackslash{}U03B8"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Probabilità a posteriori"}
\NormalTok{  )}
\NormalTok{p3}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/gridappr3-1} 

}

\caption{Rappresentazione della distribuzione a posteriori per il parametro $\theta$, ovvero la probabilità di aspettative future distorte negativamente.}\label{fig:gridappr3}
\end{figure}

I grafici delle figure \ref{fig:gridappr1}, \ref{fig:gridappr2} e \ref{fig:gridappr3} sono state calcolati utilizzando una griglia di 50 valori equi-spaziati per il parametro \(\theta\). I segmenti verticali rappresentano l'intensità della funzione in corrispondenza di ciascuna modalità parametro \(\theta\). Nella figura \ref{fig:gridappr1} e nella figura \ref{fig:gridappr3} la somma delle lunghezze dei segmenti verticali è uguale a 1.0; ciò non si verifica, invece, nel caso della figura \ref{fig:gridappr3} (la funzione di verosimiglianza non è mai una funzione di probabilità, né nel caso discreto né in quello continuo).

\hypertarget{es-depression-beta-2-10}{%
\section{La stima della distribuzione a posteriori (versione 2)}\label{es-depression-beta-2-10}}

Continuiamo l'analisi di questi dati esaminiamo l'impatto di una distribuzione a priori informativa sulla distribuzione a posteriori. Una distribuzione a priori informativa riflette un alto grado di certezza a priori sui valori dei parametri del modello. Un ricercatore utilizza una distribuzione a priori informativa per introdurre nel processo di stima informazioni pre-esistenti alla raccolta dei dati, introducendo così delle restrizioni sulla possibile gamma di valori del parametro.

Nel caso presente, supponiamo che la letteratura psicologica fornisca delle informazioni su \(\theta\) (la probabilità che le aspettative future di un individuo clinicamente depresso siano distorte negativamente). Per fare un esempio, supponiamo (irrealisticamente) che tali conoscenze pregresse possano essere rappresentate da una Beta di parametri \(\alpha = 2\) e \(\beta = 10\). Tali ipotetiche conoscenze pregresse ritengono molto plausibili valori \(\theta\) bassi e considerano implausibili valori \(\theta > 0.5\). Questo è equivalente a dire che ci aspettiamo che le aspettative relative all'umore futuro siano distorte negativamente solo per pochissimi individui clinicamente depressi --- ovvero, ci aspettiamo che la maggioranza degli individui clinicamente depressi sia inguaribilmente ottimista. Questa è, ovviamente, una credenza a priori del tutto irrealistica. La esamino qui, non perché abbia alcun senso nel contesto dei dati di \citet{zetschefuture2019}, ma soltanto per fare un esempio nel quale risulta chiaro come la distribuzione a posteriori sia una sorta di ``compromesso'' tra la distribuzione a priori e la verosimiglianza.

Con calcoli del tutto simili a quelli descritti sopra si giunge alla distribuzione a posteriori rappresentata nella figura \ref{fig:gridappr4}. Useremo ora una griglia di 100 valori per il parametro \(\theta\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_points }\OtherTok{\textless{}{-}} \DecValTok{100}
\NormalTok{p\_grid }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{0}\NormalTok{, }\AttributeTok{to =} \DecValTok{1}\NormalTok{, }\AttributeTok{length.out =}\NormalTok{ n\_points)}
\end{Highlighting}
\end{Shaded}

Per la distribuzione a priori scegliamo una Beta(2, 10):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{alpha }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{beta }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{prior2 }\OtherTok{\textless{}{-}} \FunctionTok{dbeta}\NormalTok{(p\_grid, alpha, beta) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{dbeta}\NormalTok{(p\_grid, alpha, beta))}
\FunctionTok{sum}\NormalTok{(prior2)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

Tale distribuzione a priori è rappresentata nella figura \ref{fig:gridappr4}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(p\_grid, prior2)}
\NormalTok{p4 }\OtherTok{\textless{}{-}}\NormalTok{ plot\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{p\_grid, }\AttributeTok{xend=}\NormalTok{p\_grid, }\AttributeTok{y=}\DecValTok{0}\NormalTok{, }\AttributeTok{yend=}\NormalTok{prior2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.17}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{""}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Probabilità a priori"}
\NormalTok{  )}
\NormalTok{p4}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/gridappr4-1} 

}

\caption{Rappresentazione di una funzione a priori informativa per il parametro $\theta$.}\label{fig:gridappr4}
\end{figure}

Calcoliamo il valore di verosimiglianza per ciascun punto della griglia:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{likelihood }\OtherTok{\textless{}{-}} \FunctionTok{dbinom}\NormalTok{(}\DecValTok{23}\NormalTok{, }\AttributeTok{size =} \DecValTok{30}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ p\_grid)}
\end{Highlighting}
\end{Shaded}

\noindent Per ciascun punto della griglia, il prodotto tra la verosimiglianza e distribuzione a priori è dato da:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{unstd\_posterior2 }\OtherTok{\textless{}{-}}\NormalTok{ likelihood }\SpecialCharTok{*}\NormalTok{ prior2}
\end{Highlighting}
\end{Shaded}

\noindent È necessario normalizzare la distribuzione a posteriori discretizzata:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior2 }\OtherTok{\textless{}{-}}\NormalTok{ unstd\_posterior2 }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(unstd\_posterior2)}
\end{Highlighting}
\end{Shaded}

\noindent Verifichiamo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(posterior2)}
\CommentTok{\#\textgreater{} [1] 1}
\end{Highlighting}
\end{Shaded}

\noindent La nuova funzione a posteriori discretizzata è rappresentata nella figura \ref{fig:gridappr5}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plot\_df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(p\_grid, posterior2)}
\NormalTok{p5 }\OtherTok{\textless{}{-}}\NormalTok{ plot\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p\_grid, }\AttributeTok{xend =}\NormalTok{ p\_grid, }\AttributeTok{y =} \DecValTok{0}\NormalTok{, }\AttributeTok{yend =}\NormalTok{ posterior2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_segment}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{0.17}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \StringTok{"Parametro \textbackslash{}U03B8"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"Probabilità a posteriori"}
\NormalTok{  )}
\NormalTok{p5}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/gridappr5-1} 

}

\caption{Rappresentazione della funzione a posteriori per il parametro $\theta$ calcolata utilizzando una distribuzione a priori informativa.}\label{fig:gridappr5}
\end{figure}

Facendo un confronto tra le figure \ref{fig:gridappr4} e \ref{fig:gridappr5} notiamo una notevole differenza tra la distribuzione a priori e la distribuzione a posteriori. In particolare, la distribuzione a posteriori risulta spostata verso destra su posizioni più vicine a quelle della verosimiglianza {[}figura \ref{fig:gridappr2}{]}. Si noti inoltre che, a causa dell'effetto della distribuzione a priori, le distribuzioni a posteriori delle figure \ref{fig:gridappr3} e \ref{fig:gridappr5} sono molto diverse tra loro.

Campioniamo ora 10,000 punti dall'approssimazione discretizzata della distribuzione a posteriori:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Set the seed}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{84735}\NormalTok{)}

\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
\NormalTok{  p\_grid,}
\NormalTok{  posterior2}
\NormalTok{)}
\CommentTok{\# Step 4: sample from the discretized posterior}
\NormalTok{post\_samples }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice\_sample}\NormalTok{(}
  \AttributeTok{n =} \FloatTok{1e5}\NormalTok{,}
  \AttributeTok{weight\_by =}\NormalTok{ posterior2,}
  \AttributeTok{replace =} \ConstantTok{TRUE}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\noindent Una rappresentazione grafica del campione casuale estratto dalla distribuzione a posteriori \(p(\theta \mid y)\) è data da:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{post\_samples }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ p\_grid)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}
    \FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ ..density..), }
    \AttributeTok{color =} \StringTok{"white"}\NormalTok{, }
    \AttributeTok{binwidth =} \FloatTok{0.05}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{stat\_function}\NormalTok{(}\AttributeTok{fun =}\NormalTok{ dbeta, }\AttributeTok{args =} \FunctionTok{list}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{17}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{lims}\NormalTok{(}\AttributeTok{x =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-444-1} \end{center}

\noindent All'istogramma è stata sovrapposta la corretta distribuzione a posteriori, ovvero una Beta di parametri 25 (\(y + \alpha\) = 23 + 2) e 17 (\(n - y + \beta\) = 30 - 23 + 10).

La stima della moda a posteriori si ottiene con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{p\_grid[}\FunctionTok{which.max}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{posterior2)]}
\CommentTok{\#\textgreater{} [1] 0.596}
\end{Highlighting}
\end{Shaded}

e corrisponde a

\[
\Mo = \frac{\alpha -1}{\alpha + \beta - 2} = \frac{25 - 1}{25 + 17 - 2} = 0.6.
\]

La stima della media a posteriori si ottiene con

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(post\_samples}\SpecialCharTok{$}\NormalTok{p\_grid)}
\CommentTok{\#\textgreater{} [1] 0.5953}
\end{Highlighting}
\end{Shaded}

e corrisponde a

\[
\bar{\theta} = \frac{\alpha}{\alpha + \beta} = \frac{25}{25 + 17} \approx 0.5952.
\]

La stima della mediana a posteriori si ottiene con

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{median}\NormalTok{(post\_samples}\SpecialCharTok{$}\NormalTok{p\_grid)}
\CommentTok{\#\textgreater{} [1] 0.596}
\end{Highlighting}
\end{Shaded}

e corrisponde a

\[
\Me = \frac{\alpha - \frac{1}{3}}{\alpha + \beta - \frac{2}{3}} \approx 0.5968.
\]

\hypertarget{es-pratico-zetsche-funzioni}{%
\section{Versione 2}\label{es-pratico-zetsche-funzioni}}

Possiamo semplificare i calcoli precedenti definendo le funzioni \texttt{likelihood()}, \texttt{prior()} e \texttt{posterior()}.

Per calcolare la funzione di verosimiglianza per i 30 valori di \citet{zetschefuture2019} useremo la funzione \texttt{likelihood()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \DecValTok{23}
\NormalTok{N }\OtherTok{\textless{}{-}} \DecValTok{30}
\NormalTok{param }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{100}\NormalTok{)}

\NormalTok{likelihood }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param, }\AttributeTok{x =} \DecValTok{23}\NormalTok{, }\AttributeTok{N =} \DecValTok{30}\NormalTok{) \{}
  \FunctionTok{dbinom}\NormalTok{(x, N, param)}
\NormalTok{\}}

\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ param, }
  \AttributeTok{y =} \FunctionTok{likelihood}\NormalTok{(param)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(theta),}
    \AttributeTok{y =} \StringTok{"Verosimiglianza"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-448-1} \end{center}

La funzione \texttt{likelihood()} ritorna l'ordinata della verosimiglianza binomiale per ciascun valore del vettore \texttt{param} in input.

Quale distribuzione a priori utilizzeremo una \(\mbox{Beta}(2, 10)\) che è implementata nella funzione \texttt{prior()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param, }\AttributeTok{alpha =} \DecValTok{2}\NormalTok{, }\AttributeTok{beta =} \DecValTok{10}\NormalTok{) \{}
\NormalTok{  param\_vals }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{100}\NormalTok{)}
  \FunctionTok{dbeta}\NormalTok{(param, alpha, beta) }\CommentTok{\# / sum(dbeta(param\_vals, alpha, beta))}
\NormalTok{\}}

\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ param, }
  \AttributeTok{y =} \FunctionTok{prior}\NormalTok{(param)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(theta),}
    \AttributeTok{y =} \StringTok{"Densità"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-449-1} \end{center}

La funzione \texttt{posterior()} ritorna il prodotto della densità a priori e della verosimiglianza:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(param) \{}
  \FunctionTok{likelihood}\NormalTok{(param) }\SpecialCharTok{*} \FunctionTok{prior}\NormalTok{(param)}
\NormalTok{\}}

\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x =}\NormalTok{ param, }
  \AttributeTok{y =} \FunctionTok{posterior}\NormalTok{(param)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(x, y)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(theta),}
    \AttributeTok{y =} \StringTok{"Densità"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-450-1} \end{center}

La distribuzione a posteriori non normalizzata mostrata nella figura replica il risultato ottenuto con il codice utilizzato nella prima parte di questo Capitolo. Per l'implementazione dell'algoritmo di Metropolis non è necessaria la normalizzazione della distribuzione a posteriori.

\hypertarget{integration-mc}{%
\chapter{Integrazione di Monte Carlo}\label{integration-mc}}

Il termine Monte Carlo si riferisce al fatto che la computazione fa ricorso ad un ripetuto campionamento casuale attraverso la generazione di sequenze di numeri casuali. Una delle sue applicazioni più potenti è il calcolo degli integrali mediante simulazione numerica. Sia l'integrale da calcolare

\[
\int_a^b h(y) dy.
\] Se decomponiamo \(h(y)\) nel prodotto di una funzione \(f(y)\) e una funzione di densità di probabilità \(p(y)\) definita nell'intervallo \((a, b)\) avremo:

\[
\int_a^b h(y) dy = \int_a^b f(y) p(y) dy = \E[f(y)],
\] così che l'integrale può essere espresso come una funzione di aspettazione \(f(y)\) sulla densità \(p(y)\). Se definiamo un gran numero di variabili casuali \(y_1, y_2, \dots, y_n\) appartenenti alla densità di probabilità \(p(y)\) allora avremo

\[
\int_a^b h(y) dy = \int_a^b f(y) p(y) dy = \E[f(y)] \approx \frac{1}{n}\sum_{i=1}^n f(y)
\] che è l'integrale di Monte Carlo.

L'integrazione con metodo Monte Carlo trova la sua giustificazione nella \emph{Legge forte dei grandi numeri}. Data una successione di variabili casuali \(Y_{1}, Y_{2},\dots, Y_{n},\dots\) indipendenti e identicamente distribuite con media \(\mu\), ne segue che

\[
P\left( \lim_{n \rightarrow \infty} \frac{1}{n} \sum_{i=1}^n Y_i = \mu \right) = 1.
\] Ciò significa che, al crescere di \(n\), la media delle realizzazioni di \(Y_{1}, Y_{2},\dots, Y_{n},\dots\) converge con probabilità 1 al vero valore \(\mu\).

Possiamo fornire un esempio intuitivo della legge forte dei grandi numeri facendo riferimento ad una serie di lanci di una moneta dove \(Y=1\) significa ``testa'' e \(Y=0\) significa ``croce''. Per la legge forte dei grandi numeri, nel caso di una moneta equilibrata la proporzione di eventi ``testa'' converge alla vera probabilità dell'evento ``testa''

\[
  \frac{1}{n} \sum_{i=1}^n Y_i \rightarrow \frac{1}{2}
\] con probabilità di uno.

Quello che è stato detto sopra non è che un modo sofisticato per dire che, se vogliamo calcolare un'approssimazione del valore atteso di una variabile casuale, non dobbiamo fare altro che la media aritmetica di un grande numero di realizzazioni della variabile casuale. Come è facile intuire, l'approssimazione migliora al crescere del numero di dati che abbiamo a disposizione.

L'integrazione di Monte Carlo può essere usata per approssimare la distribuzione a posteriori richiesta da una analisi Bayesiana: una stima di \(p(\theta \mid y)\) può essere ottenuta mediante un grande numero di campioni casuali della distribuzionea a posteriori.

\hypertarget{markov-chains}{%
\chapter{Le catene di Markov}\label{markov-chains}}

Per introdurre il concetto di catena di Markov, supponiamo che una persona esegua una passeggiata casuale sulla retta dei numeri naturali considerando solo i valori 1, 2, 3, 4, 5, 6.\footnote{Seguiamo qui la presentazione fornita da \href{https://github.com/bob-carpenter/prob-stats}{Bob Carpenter}.} Se la persona è collocata su un valore interno dei valori possibili (ovvero, 2, 3, 4 o 5), nel passo successivo è altrettanto probabile che rimanga su quel numero o si sposti su un numero adiacente. Se si muove, è ugualmente probabile che si muova a sinistra o a destra. Se la persona si trova su uno dei valori estremi (ovvero, 1 o 6), nel passo successivo è altrettanto probabile che rimanga rimanga su quel numero o si sposti nella posizione adiacente.

Questo è un esempio di una catena di Markov discreta. Una catena di Markov descrive il movimento probabilistico tra un numero di stati. Nell'esempio ci sono sei possibili stati, da 1 a 6, i quali corrispondono alle possibili posizioni della passeggiata casuale. Data la sua posizione corrente, la persona si sposterà nelle altre posizioni possibili con delle specifiche probabilità. La probabilità che si sposti in un'altra posizione dipende solo dalla sua posizione attuale e non dalle posizioni visitate in precedenza.

È possibile descrivere il movimento tra gli stati nei termini delle cosiddette \emph{probabilità di transizione}, ovvero le probabilità di movimento tra tutti i possibili stati in un unico passaggio di una catena di Markov. Le probabilità di transizione sono riassunte in una \emph{matrice di transizione} \(P\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{P }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(.}\DecValTok{5}\NormalTok{, .}\DecValTok{5}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
\NormalTok{    .}\DecValTok{25}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{25}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
    \DecValTok{0}\NormalTok{, .}\DecValTok{25}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{25}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
    \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, .}\DecValTok{25}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{25}\NormalTok{, }\DecValTok{0}\NormalTok{,}
    \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, .}\DecValTok{25}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{25}\NormalTok{,}
    \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, .}\DecValTok{5}\NormalTok{, .}\DecValTok{5}
\NormalTok{    ),}
  \AttributeTok{nrow =} \DecValTok{6}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{6}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{kableExtra}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(P)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r|r|r|r}
\hline
0.50 & 0.50 & 0.00 & 0.00 & 0.00 & 0.00\\
\hline
0.25 & 0.50 & 0.25 & 0.00 & 0.00 & 0.00\\
\hline
0.00 & 0.25 & 0.50 & 0.25 & 0.00 & 0.00\\
\hline
0.00 & 0.00 & 0.25 & 0.50 & 0.25 & 0.00\\
\hline
0.00 & 0.00 & 0.00 & 0.25 & 0.50 & 0.25\\
\hline
0.00 & 0.00 & 0.00 & 0.00 & 0.50 & 0.50\\
\hline
\end{tabular}

\hfill\break

La prima riga della matrice di transizione \(P\) fornisce le probabilità di passare a ciascuno degli stati da 1 a 6 in un unico passaggio a partire dalla posizione 1; la seconda riga fornisce le probabilità di transizione in un unico passaggio dalla posizione 2 e così via. Per esempio, il valore \(P[1, 1]\) ci dice che, se la persona è nello stato 1, avrà una probabilità di 0.5 di rimanere in quello stato; \(P[1, 2]\) ci dice che c'è una probabilità di 0.5 di passare dallo stato 1 allo stato 2. Gli altri elementi della prima riga sono 0 perché, in un unico passaggio, non è possibile passare dallo stato 1 agli stati 3, 4, 5 e 6. Il valore \(P[2, 1]\) ci dice che, se la persona è nello stato 1 (seconda riga), avrà una probabilità di 0.25 di passare allo stato 1; avra una probabilità di 0.5 di rimanere in quello stato, \(P[2, 2]\); e avrà una probabilità di 0.25 di passare allo stato 3, \(P[2, 3]\); eccetera.

Si notino alcune importanti proprietà di questa particolare catena di Markov.

\begin{itemize}
\tightlist
\item
  È possibile passare da ogni stato a qualunque altro stato in uno o più passaggi: una catena di Markov con questa proprietà si dice \emph{irriducibile}.
\item
  Dato che la persona si trova in un particolare stato, se può tornare a questo stato solo a intervalli regolari, si dice che la catena di Markov è \emph{periodica}. In questo esempio la catena è \emph{aperiodica} poiché la passeggiata casuale non può eitornare allo stato attuale a intervalli regolari.
\end{itemize}

Un'importante proprietà di una catena di Markov irriducibile e aperiodica è che il passaggio ad uno stato del sistema dipende unicamente dallo stato immediatamente precedente e non dal come si è giunti a tale stato (dalla storia). Per questo motivo si dice che un processo markoviano è senza memoria. Tale ``assenza di memoria'' può essere interpretata come la proprietà mediante cui è possibile ottenere un insieme di campioni casuali da una distribuzione di interesse. Nel caso dell'inferenza bayesiana, la distribuzione di interesse è la distribuzione a posteriori, \(p(\theta \mid y)\). Le catene di Markov consentono di stimare i valori di aspettazione di variabili rispetto alla distribuzione a posteriori.

La matrice di transizione che si ottiene dopo un enorme numero di passi di una passeggiata casuale markoviana si chiama \emph{distribuzione stazionaria}. Se una catena di Markov è irriducibile e aperiodica, allora ha un'unica distribuzione stazionaria \(w\). La distribuzione limite di una tale catena di Markov, quando il numero di passi tende all'infinito, è uguale alla distribuzione stazionaria \(w\).

\hypertarget{simulare-una-catena-di-markov}{%
\section{Simulare una catena di Markov}\label{simulare-una-catena-di-markov}}

Un metodo per dimostrare l'esistenza della distribuzione stazionaria di una catena di Markov è quello di eseguire un esperimento di simulazione. Iniziamo una passeggiata casuale partendo da un particolare stato, diciamo la posizione 3, e quindi simuliamo molti passaggi della catena di Markov usando la matrice di transizione \(P\). Al crescere del numero di passi della catena, le frequenze relative che descrivono il passaggio a ciascuno dei sei possibili nodi della catena approssimano sempre meglio la distribuzione stazionaria \(w\).

Senza entrare nei dettagli della simulazione, la figura \ref{fig:markovsim} mostra i risultati ottenuti in 10,000 passi di una passeggiata casuale markoviana. Si noti che, all'aumentare del numero di iterazioni, le frequenze relative approssimano sempre meglio le probabilità nella distribuzione stazionaria \(w = (0.1, 0.2, 0.2, 0.2, 0.2, 0.1)\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{s }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"numeric"}\NormalTok{, }\DecValTok{10000}\NormalTok{)}
\NormalTok{s[}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{3}
\ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{2}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{) \{}
\NormalTok{  s[j] }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\AttributeTok{size =} \DecValTok{1}\NormalTok{, }\AttributeTok{prob =}\NormalTok{ P[s[j }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{], ])}
\NormalTok{\}}
\NormalTok{S }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Iterazione =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10000}\NormalTok{,}
  \AttributeTok{Location =}\NormalTok{ s}
\NormalTok{)}

\NormalTok{S }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{L1 =}\NormalTok{ (Location }\SpecialCharTok{==} \DecValTok{1}\NormalTok{),}
    \AttributeTok{L2 =}\NormalTok{ (Location }\SpecialCharTok{==} \DecValTok{2}\NormalTok{),}
    \AttributeTok{L3 =}\NormalTok{ (Location }\SpecialCharTok{==} \DecValTok{3}\NormalTok{),}
    \AttributeTok{L4 =}\NormalTok{ (Location }\SpecialCharTok{==} \DecValTok{4}\NormalTok{),}
    \AttributeTok{L5 =}\NormalTok{ (Location }\SpecialCharTok{==} \DecValTok{5}\NormalTok{),}
    \AttributeTok{L6 =}\NormalTok{ (Location }\SpecialCharTok{==} \DecValTok{6}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{Proporzione\_1 =} \FunctionTok{cumsum}\NormalTok{(L1) }\SpecialCharTok{/}\NormalTok{ Iterazione,}
    \AttributeTok{Proporzione\_2 =} \FunctionTok{cumsum}\NormalTok{(L2) }\SpecialCharTok{/}\NormalTok{ Iterazione,}
    \AttributeTok{Proporzione\_3 =} \FunctionTok{cumsum}\NormalTok{(L3) }\SpecialCharTok{/}\NormalTok{ Iterazione,}
    \AttributeTok{Proporzione\_4 =} \FunctionTok{cumsum}\NormalTok{(L4) }\SpecialCharTok{/}\NormalTok{ Iterazione,}
    \AttributeTok{Proporzione\_5 =} \FunctionTok{cumsum}\NormalTok{(L5) }\SpecialCharTok{/}\NormalTok{ Iterazione,}
    \AttributeTok{Proporzione\_6 =} \FunctionTok{cumsum}\NormalTok{(L6) }\SpecialCharTok{/}\NormalTok{ Iterazione}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  dplyr}\SpecialCharTok{::}\FunctionTok{select}\NormalTok{(}
\NormalTok{    Iterazione, Proporzione\_1, Proporzione\_2, Proporzione\_3,}
\NormalTok{    Proporzione\_4, Proporzione\_5, Proporzione\_6}
\NormalTok{  ) }\OtherTok{{-}\textgreater{}}\NormalTok{ S1}

\FunctionTok{gather}\NormalTok{(S1, Outcome, Probability, }\SpecialCharTok{{-}}\NormalTok{Iterazione) }\OtherTok{{-}\textgreater{}}\NormalTok{ S2}

\FunctionTok{ggplot}\NormalTok{(S2, }\FunctionTok{aes}\NormalTok{(Iterazione, Probability)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{Outcome, }\AttributeTok{ncol =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylim}\NormalTok{(}\DecValTok{0}\NormalTok{, .}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"Frequenza relativa"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# theme(text=element\_text(size=14))  +}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{3000}\NormalTok{, }\DecValTok{6000}\NormalTok{, }\DecValTok{9000}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[h]

{\centering \includegraphics{ds4psy_files/figure-latex/markovsim-1} 

}

\caption{Frequenze relative degli stati da 1 a 6 in funzione del numero di iterazioni per la simulazione di una catena di Markov.}\label{fig:markovsim}
\end{figure}

Il metodo di campionamento utilizzato dagli algoritmi MCMC consente di creare una catena di Markov irriducibile e aperiodica, la cui distribuzione stazionaria equivale alla distribuzione a posteriori \(p(\theta \mid y)\).

\hypertarget{intro-stan}{%
\chapter{Programmare in Stan}\label{intro-stan}}

\hypertarget{che-cosuxe8-stan}{%
\section{Che cos'è Stan?}\label{che-cosuxe8-stan}}

\href{http://mc-stan.org/}{STAN} è un linguaggio di programmazione probabilistico usato per l'inferenza bayesiana \citep{carpenter2017stan}. Prende il nome da uno dei creatori del metodo Monte Carlo, Stanislaw Ulam \citep{Eckhardt1987stan}. Stan consente di generare campioni da distribuzioni di probabilità basati sulla costruzione di una catena di Markov avente come distribuzione di equilibrio (o stazionaria) la distribuzione desiderata.

È possibile accedere al linguaggio Stan tramite diverse interfacce:

\begin{itemize}
\tightlist
\item
  \texttt{CmdStan}: eseguibile da riga di comando,
\item
  \texttt{RStan} - integrazione con il linguaggio \R;
\item
  \texttt{PyStan} - integrazione con il linguaggio di programmazione Python;
\item
  \texttt{MatlabStan} - integrazione con MATLAB;
\item
  \texttt{Stan.jl} - integrazione con il linguaggio di programmazione Julia;
\item
  \texttt{StataStan} - integrazione con Stata.
\end{itemize}

Inoltre, vengono fornite interfacce di livello superiore con i pacchetti che utilizzano Stan come backend, principalmente in Linguaggio \R:

\begin{itemize}
\tightlist
\item
  \texttt{shinystan}: interfaccia grafica interattiva per l'analisi della distribuzione a posteriori e le diagnostiche MCMC;\\
\item
  \texttt{bayesplot}: insieme di funzioni utilizzabili per creare grafici relativi all'analisi della distribuzione a posteriori, ai test del modello e alle diagnostiche MCMC;\\
\item
  \texttt{brms}: fornisce un'ampia gamma di modelli lineari e non lineari specificando i modelli statistici mediante la sintassi usata in \R;
\item
  \texttt{rstanarm}: fornisce un sostituto per i modelli frequentisti forniti da base \(\R\) e \texttt{lme4} utilizzando la sintassi usata in \(\R\) per la specificazione dei modelli statistici;
\item
  \texttt{edstan}: modelli Stan per la Item Response Theory;
\item
  \texttt{cmdstanr}, un'interfaccia \(\R\) per \texttt{CmdStan}.
\end{itemize}

\hypertarget{interfaccia-cmdstanr}{%
\section{\texorpdfstring{Interfaccia \texttt{cmdstanr}}{Interfaccia cmdstanr}}\label{interfaccia-cmdstanr}}

Negli esempi di questa dispensa verrà usata l'interfaccia \texttt{cmdstanr}. Il pacchetto \texttt{cmdstanr} non è ancora disponibile su CRAN, ma può essere installato come indicato su questo \href{https://mc-stan.org/docs/2_27/cmdstan-guide/cmdstan-installation.html}{link}. Una volta che è stato installato, il pacchetto \texttt{cmdstanr} può essere caricato come un qualsiasi altro pacchetto R.

Si noti che \texttt{cmdstanr} richiede un'installazione funzionante di \texttt{CmdStan}, l'interfaccia shell per Stan. Se \texttt{CmdStan} non è installato, \texttt{cmdstanr} lo installerà automaticamente se il computer dispone di una \emph{Toolchain} adatta. Stan richiede infatti che sul computer su cui viene installato siano presenti alcuni strumenti necessari per gestire i file C++. Tra le altre ragioni, questo è dovuto al fatto che il codice Stan viene tradotto in codice C++ e compilato. Il modo migliore per ottenere il software necessario per un computer Windows o Mac è quello di installare \texttt{RTools}. Per un computer Linux, è necessario installare \texttt{build-essential} e una versione recente dei compilatori g++ o clang++. I requisiti sono descritti nella \href{https://mc-stan.org/docs/cmdstan-guide/cmdstan-installation.html}{Guida di CmdStan}.

Per verificare che la Toolchain sia configurata correttamente è possibile utilizzare la funzione \texttt{check\_cmdstan\_toolchain()}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{check\_cmdstan\_toolchain}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Se la toolchain è configurata correttamente, \texttt{CmdStan} può essere installato mediante la funzione \texttt{install\_cmdstan()}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# do not run!}
\CommentTok{\# install\_cmdstan(cores = 2)}
\end{Highlighting}
\end{Shaded}

La versione installata di \texttt{CmdStan} si ottiene con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cmdstan\_version}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] "2.28.2"}
\end{Highlighting}
\end{Shaded}

\hypertarget{codice-stan}{%
\section{Codice Stan}\label{codice-stan}}

Qualunque sia l'interfaccia che viene usata, i modelli sottostanti sono sempre scritti nel linguaggio Stan, il che significa che lo stesso codice Stan è valido per tutte le interfacce possibili. Il codice Stan è costituito da una serie di blocchi che vengono usati per specificare un modello statistico. In ordine, questi blocchi sono: \texttt{data}, \texttt{transformed\ data}, \texttt{parameters}, \texttt{transformed\ parameters}, \texttt{model}, e \texttt{generated\ quantities}.

\hypertarget{hello-world-stan}{%
\subsection{``Hello, world'' -- Stan}\label{hello-world-stan}}

Quando si studia un nuovo linguaggio di programmazione si utilizza spesso un programma ``Hello, world''. Questo è un modo semplice, spesso minimo, per dimostrare alcune delle sintassi di base del linguaggio. In Python, il programme ``Hello, world'' program è:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(}\StringTok{"Hello, world."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Qui presentiamo Stan e scriviamo un programma ``Hello, world'' per Stan.

Prima di scrivere il nostro primo programma ``Hello, world'' per Stan (che estrarrà campioni dalla distribuzione a posteriori di un modello gaussiano) spendiamo due parole per spiegare cosa fa Stan. Un utente scrive un modello usando il linguaggio Stan. Questo è solitamente memorizzato in un file di testo \texttt{.stan}. Il modello viene compilato in due passaggi. Innanzitutto, Stan traduce il modello nel file \texttt{.stan} in codice C++. Quindi, quel codice C++ viene compilato in codice macchina. Una volta creato il codice macchina, l'utente può, tramite l'interfaccia CmdStan, campionare la distribuzione definita dal modello ed eseguire altri calcoli con il modello. I risultati del campionamento vengono scritti su disco come file CSV e txt. Come mostrato di seguito, l'utente accede a questi file utilizzando varie funzioni \(\R\), senza interagire direttamente con loro.

Per iniziare, possiamo dire che un programma Stan contiene tre ``blocchi'' obbligatori: blocco \texttt{data}, blocco \texttt{parameters}, blocco \texttt{model}.

\hypertarget{blocco-data}{%
\subsection{\texorpdfstring{Blocco \texttt{data}}{Blocco data}}\label{blocco-data}}

Qui vengono dichiarate le variabili che saranno passate a Stan. Devono essere elencati i nomi delle variabili che saranno utilizzate nel programma, il \emph{tipo di dati} da registrare per ciascuna variabile, per esempio:

\begin{itemize}
\tightlist
\item
  \emph{int} = intero,
\item
  \emph{real} = numeri reali (ovvero, numeri con cifre decimali),
\item
  \emph{vector} = sequenze ordinate di numeri reali unidimensionali,
\item
  \emph{matrix} = matrici bidimensionali di numeri reali,
\item
  \emph{array} = sequenze ordinate di dati multidimensionali.
\end{itemize}

Devono anche essere dichiarate le dimensioni delle variabili e le eventuali restrizioni sulle variabili (es. \texttt{upper\ =\ 1} \texttt{lower\ =\ 0}, che fungono da controlli per Stan). Tutti i nomi delle variabili assegnate qui saranno anche usati negli altri blocchi del programma.

Per esempio, l'istruzione seguente dichiaria la variabile \texttt{Y} -- la quale rappresenta, ad esempio, l'altezza di 10 persone -- come una variabile di tipo \texttt{real{[}10{]}}. Ciò significa che specifichiamo un array di lunghezza 10, i cui elementi sono variabili continue definite sull'intervallo dei numeri reali \([-\infty, +\infty]\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data \{}
\NormalTok{  real Y[}\DecValTok{10}\NormalTok{]; }\SpecialCharTok{/}\ErrorTok{/}\NormalTok{ heights }\ControlFlowTok{for} \DecValTok{10}\NormalTok{ people}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Invece, con l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data \{}
\NormalTok{  int Y[}\DecValTok{10}\NormalTok{]; }\SpecialCharTok{/}\ErrorTok{/}\NormalTok{ qi }\ControlFlowTok{for} \DecValTok{10}\NormalTok{ people}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

dichiariamo la variabile \texttt{Y} -- la quale rappresenta, ad esempio, il QI di 10 persone -- come una variabile di tipo \texttt{int{[}10{]}}, ovvero un array di lunghezza 10, i cui elementi sono numeri naturali, cioè numeri interi non negativi \(\{0, +1, +2, +3, +4, \dots\}\).

Un altro esempio è

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data \{}
\NormalTok{  real}\SpecialCharTok{\textless{}}\NormalTok{lower}\OtherTok{=}\DecValTok{0}\NormalTok{, upper}\OtherTok{=}\DecValTok{1}\SpecialCharTok{\textgreater{}}\NormalTok{ Y[}\DecValTok{10}\NormalTok{]; }\SpecialCharTok{/}\ErrorTok{/} \DecValTok{10}\NormalTok{ proportions}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

nel quale viene specificato un array di lunghezza 10, i cui elementi sono delle variabili continue definite sull'intervallo dei numeri reali \([0, 1]\) --- per esempio, delle proporzioni.

Si noti che i tipi \texttt{vector} e \texttt{matrix} contengono solo elementi di tipo \texttt{real}, ovvero variabili continue, mentre gli \texttt{array} possono contenere dati di qualsiasi tipo. I dati passati a Stan devono essere contenuti in un oggetto del tipo \texttt{list}.

\hypertarget{blocco-parameters}{%
\subsection{\texorpdfstring{Blocco \texttt{parameters}}{Blocco parameters}}\label{blocco-parameters}}

I parametri che vengono stimati sono dichiarati nel blocco \texttt{parameters}. Per esempio, l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{parameters \{}
\NormalTok{  real mu; }\SpecialCharTok{/}\ErrorTok{/}\NormalTok{ mean height }\ControlFlowTok{in}\NormalTok{ population}
\NormalTok{  real}\SpecialCharTok{\textless{}}\NormalTok{lower}\OtherTok{=}\DecValTok{0}\SpecialCharTok{\textgreater{}}\NormalTok{ sigma; }\SpecialCharTok{/}\ErrorTok{/}\NormalTok{ sd of height distribution}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

dichiaria la variabile \texttt{mu} che codifica l'altezza media nella popolazione, che è una variabile continua in un intervallo illimitato di valori, e la deviazione standard \texttt{sigma}, che è una variabile continua non negativa. Avremmo anche potuto specificare un limite inferiore di zero su \texttt{mu} perché deve essere non negativo.

Per una regressione lineare semplice, ad esempio, devono essere dichiarate le variabili corrispondenti all'intercetta (\texttt{alpha}), alla pendenza (\texttt{beta}) e alla deviazione standard degli errori attorno alla linea di regressione (\texttt{sigma}). In altri termini, nel blocco \texttt{parameters} devono essere elencati tutti i parametri che dovranno essere stimati dal modello. Si noti che parametri discreti non sono possibili. Infatti, Stan attualmente non supporta i parametri con valori interi, almeno non direttamente.

\hypertarget{blocco-model}{%
\subsection{\texorpdfstring{Blocco \texttt{model}}{Blocco model}}\label{blocco-model}}

Nel blocco \texttt{model} vengono elencate le dichiarazioni relative alla verosimiglianza dei dati e alle distribuzioni a priori dei parametri, come ad esempio, nelle istruzioni seguenti.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model \{}
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
\NormalTok{    Y[i] }\SpecialCharTok{\textasciitilde{}} \FunctionTok{normal}\NormalTok{(mu, sigma);}
\NormalTok{  \}}
\NormalTok{  mu }\SpecialCharTok{\textasciitilde{}} \FunctionTok{normal}\NormalTok{(}\DecValTok{170}\NormalTok{, }\DecValTok{15}\NormalTok{); }\SpecialCharTok{/}\ErrorTok{/}\NormalTok{ prior }\ControlFlowTok{for}\NormalTok{ mu}
\NormalTok{  sigma }\SpecialCharTok{\textasciitilde{}} \FunctionTok{cauchy}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{20}\NormalTok{); }\SpecialCharTok{/}\ErrorTok{/}\NormalTok{ prior }\ControlFlowTok{for}\NormalTok{ sigma}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Mediante l'istruzione all'interno del ciclo \texttt{for}, ciascun valore dell'altezza viene concepito come una variable casuale proveniente da una distribuzione Normale di parametri \(\mu\) e \(\sigma\) (i parametri di interesse nell'inferenza). Il ciclo \texttt{for} viene ripetuto 10 volte perché i dati sono costituiti da un array di 10 elementi (ovvero, il campione è costituito da 10 osservazioni).

Le due righe che seguno il ciclo \texttt{for} specificano le distribuzioni a priori dei parametri su cui vogliamo effettuare l'inferenza. Per \(\mu\) assumiamo una distribuzione a priori Normale di parametri \(\mu = 170\) e \(\sigma = 15\); per \(\sigma\) assumiamo una distribuzione a priori Cauchy(0, 20).

Se non viene definita alcuna distribuzione a priori, Stan utilizzerà la distribuzione a priori predefinita \(Unif(-\infty, +\infty)\). Raccomandazioni sulle distribuzioni a priori sono fornite in questo \href{https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations}{link}.

La precedente notazione di campionamento può anche essere espressa usando la seguente notazione alternativa:

\begin{Shaded}
\begin{Highlighting}[]
  \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
\NormalTok{    target }\SpecialCharTok{+}\ErrorTok{=} \FunctionTok{normal\_lpdf}\NormalTok{(Y[i] }\SpecialCharTok{|}\NormalTok{ mu, sigma);}
\NormalTok{  \}}
\end{Highlighting}
\end{Shaded}

Questa notazione rende trasparente il fatto che, in pratica, Stan esegue un campionamento nello spazio

\[
\log p(\theta \mid y) \propto \log p(y \mid \theta) + \log p(\theta) = \sum_{i=1}^n \log p(y_i \mid \theta) + \log p(\theta).
\]

Per ogni passo MCMC, viene ottenuto un nuovo valore di \(\mu\) e \(\sigma\) eviene valutata la log densità a posteriori non normalizzata. Ad ogni passo MCMC, Stan calcola un nuovo valore della densità a posteriori su scala logaritmica partendo da un valore di 0 e incrementandola ogni volta che incontra un'istruzione \texttt{\textasciitilde{}}. Quindi, le istruzioni precedenti aumentano la log-densità di una quantità pari a \(\log (p(Y[i])) \propto -\frac{1}{2} \log(\sigma^2) - (Y[i]-\mu)^2 / 2\sigma^2\) per le altezze si ciascuno degli \(i=1 \dots, 10\) individui -- laddove la formula esprime, in termini logaritmici, la densità Normale da cui sono stati esclusi i termini costanti.

Oppure, in termini vettorializzati, il modello descritto sopra può essere espresso come

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{model \{}
\NormalTok{  Y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{normal}\NormalTok{(mu, sigma);}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

dove il termine a sinistra di \(\sim\) è un array. Questa notazione più compatta è anche la più efficiente.

\hypertarget{blocchi-opzionali}{%
\subsection{Blocchi opzionali}\label{blocchi-opzionali}}

Ci sono inoltre tre blocchi opzionali:

\begin{itemize}
\tightlist
\item
  Il blocco \texttt{transformed\ data} consente il pre-processing dei dati. È possibile trasformare i parametri del modello; solitamente ciò viene fatto nel caso dei modelli più avanzati per consentire un campionamento MCMC più efficiente.
\item
  Il blocco \texttt{transformed\ parameters} consente la manipolazione dei parametri prima del calcolo della distribuzione a posteriori.
\item
  Il blocco \texttt{generated\ quantities} consente il post-processing riguardante qualsiasi quantità che non fa parte del modello ma può essere calcolata a partire dai parametri del modello, per ogni iterazione dell'algoritmo. Esempi includono la generazione dei campioni a posteriori e le dimensioni degli effetti.
\end{itemize}

\hypertarget{sintassi}{%
\subsection{Sintassi}\label{sintassi}}

Si noti che il codice Stan richiede i punti e virgola (;) alla fine di ogni istruzione di assegnazione. Questo accade per le dichiarazioni dei dati, per le dichiarazioni dei parametri e ovunque si acceda ad un elemento di un tipo \texttt{data} e lo si assegni a qualcos'altro. I punti e virgola non sono invece richiesti all'inizio di un ciclo o di un'istruzione condizionale, dove non viene assegnato nulla.

In STAN, qualsiasi stringa che segue \texttt{//} denota un commento e viene ignorata dal programma.

Stan è un linguaggio estremamente potente e consente di implementare quasi tutti i modelli statistici, ma al prezzo di un certo sforzo di programmazione. Anche l'adattamento di semplici modelli statistici mediante il linguaggio STAN a volte può essere laborioso. Per molti modelli comunemente usati, come i modelli di regressione e multilivello, tale processo può essere semplificato usando le funzioni del pacchetto \texttt{brms}. D'altra parte, per modelli veramente complessi, non ci sono molte alternative all'uso di STAN. Per chi è curioso, il manuale del linguaggio Stan è accessibile al seguente \href{https://mc-stan.org/docs/2_27/stan-users-guide/index.html}{link}.

\hypertarget{workflow}{%
\section{Workflow}\label{workflow}}

Se usiamo \texttt{cmdstanr}, dobbiamo prima scrivere il codice con il modello statistico in un file in formato Stan. È necessario poi ``transpile'' quel file, ovvero tradurre il file in C++ e compilarlo. Ciò viene fatto mediante la funzione \texttt{cmdstan\_model()}. Possiamo poi eseguire il campionamento MCMC con il metodo \texttt{\$sample()}. Infine è possibile creare un sommario dei risultati usando, per esempio, usando il metodo \texttt{\$summary()}.

\hypertarget{ciao-stan}{%
\section{Ciao, Stan}\label{ciao-stan}}

Scriviamo ora il nostro programma Stan ``Hello, world'' per generare campioni da una distribuzione Normale standard (con media zero e varianza unitaria).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{parameters \{}
\StringTok{  real x;}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  x \textasciitilde{} normal(0, 1);}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/hello\_world.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Si noti che ci sono solo due blocchi in questo particolare codice Stan, il blocco parametri e il blocco modello. Questi sono due dei sette blocchi possibili in un codice Stan. Nel blocco parametri, abbiamo i nomi e i tipi di parametri per i quali vogliamo ottenere i campioni. In questo caso, vogliamo ottenere campioni di numeri reale che chiamiamo \texttt{x}. Nel blocco modello, abbiamo il nostro modello statistico. Specifichiamo che x, il parametro di cui vogliamo ottenere i campioni, è normalmente distribuito con media zero e deviazione standard unitaria. Ora che abbiamo il nostro codice (che è stato memorizzato in un file chiamato \texttt{hello\_world.stan}), possiamo usare CmdStan per compilarlo e ottenere \texttt{mod}, che è un oggetto \(\R\) che fornisce l'accesso all'eseguibile Stan compilato.

Leggiamo il file in cui abbiamo salvato il codice Stan

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"hello\_world.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

compiliamo il modello

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file)}
\end{Highlighting}
\end{Shaded}

ed eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}}\NormalTok{ mod}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Tasformiamo l'oggetto \texttt{fit} nel formato \texttt{stanfit} per manipolarlo più facilmente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stanfit }\OtherTok{\textless{}{-}}\NormalTok{ rstan}\SpecialCharTok{::}\FunctionTok{read\_stan\_csv}\NormalTok{(fit}\SpecialCharTok{$}\FunctionTok{output\_files}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Lo esaminiamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(stanfit}\SpecialCharTok{@}\NormalTok{sim}\SpecialCharTok{$}\NormalTok{samples)}
\CommentTok{\#\textgreater{} [1] 4}
\end{Highlighting}
\end{Shaded}

Quello che abbiamo ottenuto sono 4 catene di 4000 osservazioni ciascuna, le quali contengono valori casuali estratti dalla gaussiana standardizzata:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(stanfit}\SpecialCharTok{@}\NormalTok{sim}\SpecialCharTok{$}\NormalTok{samples[[}\DecValTok{1}\NormalTok{]])}
\end{Highlighting}
\end{Shaded}

Verifichiamo

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{hist}\NormalTok{(stanfit}\SpecialCharTok{@}\NormalTok{sim}\SpecialCharTok{$}\NormalTok{samples[[}\DecValTok{1}\NormalTok{]][, }\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-471-1} \end{center}

\hypertarget{least-squares}{%
\chapter{Minimi quadrati}\label{least-squares}}

Nella trattazione classica del modello di regressione, \(y_i = \alpha + \beta x_i + e_i\), i coefficienti \(a = \hat{\alpha}\) e \(b = \hat{\beta}\) vengono stimati in modo tale da minimizzare i residui

\begin{equation}
e_i = y_i - \hat{\alpha} - \hat{\beta} x_i.
\label{eq:residuals}
\end{equation}

In altri termini, il residuo \(i\)-esimo è la differenza fra l'ordinata del punto (\(x_i\), \(y_i\)) e quella del punto di ascissa \(x_i\) sulla retta di regressione campionaria.

Per determinare i coefficienti \(a\) e \(b\) della retta \(y_i = a + b x_i + e_i\) non è sufficiente minimizzare la somma dei residui \(\sum_{i=1}^{n}e_i\), in quanto i residui possono essere sia positivi che negativi e la loro somma può essere molto prossima allo zero anche per differenze molto grandi tra i valori osservati e la retta di regressione. Infatti, ciascuna retta passante per il punto (\(\bar{x}, \bar{y}\)) ha \(\sum_{i=1}^{n}e_i=0\).

Una retta passante per il punto (\(\bar{x}, \bar{y}\)) soddisfa l'equazione \(\bar{y} = a + b \bar{x}\). Sottraendo tale equazione dall'equazione \(y_i = a + b x_i + e_i\) otteniamo

\[
y_i - \bar{y} =  b (x_i - \bar{x}) + e_i. 
\]

Sommando su tutte le osservazioni, si ha che

\begin{equation}
\sum_{i=1}^n e_i = \sum_{i=1}^n (y_i - \bar{y} ) -  b \sum_{i=1}^n (x_i - \bar{x}) = 0 - b(0) = 0. 
\label{eq:res-sum-zero}
\end{equation}

Questo problema viene risolto scegliendo i coefficienti \(a\) e \(b\) che minimizzano, non tanto la somma dei residui, ma bensì l'\emph{errore quadratico}, cioè la somma dei quadrati degli errori:

\begin{equation}
S(a, b) = \sum_{i=1}^{n} e_i^2 = \sum (y_i - a - b x_i)^2.
\end{equation}

Il metodo più diretto per determinare quelli che vengono chiamati i \emph{coefficienti dei minimi quadrati} è quello di trovare le derivate parziali della funzione \(S(a, b)\) rispetto ai coefficienti \(a\) e \(b\):

\begin{align}
\frac{\partial S(a,b)}{\partial a} &= \sum (-1)(2)(y_i - a - b x_i), \notag \\
\frac{\partial S(a,b)}{\partial b} &= \sum (-x_i)(2)(y_i - a - b x_i).
\end{align}

Ponendo le derivate uguali a zero e dividendo entrambi i membri per \(-2\) si ottengono le \emph{equazioni normali}

\begin{align}
 an + b \sum x_i &= \sum y_i, \notag \\
 a \sum x_i + b \sum x_i^2 &= \sum x_i y_i. 
 \label{eq:form-normali}
\end{align}

I coefficienti dei minimi quadrati \(a\) e \(b\) si trovano risolvendo le \eqref{eq:form-normali} e sono uguali a:

\begin{align}
a &= \bar{y} - b \bar{x},\\
b &= \frac{\sum (x_i - \bar{x}) (y_i - \bar{y})}{\sum (x_i - \bar{x})^2}.
\label{eq:minsq-ab}
\end{align}

\hypertarget{massima-verosimiglianza}{%
\section{Massima verosimiglianza}\label{massima-verosimiglianza}}

Se gli errori del modello lineare sono indipendenti e distribuiti secondo una Normale, così che \(y_i \sim \mathcal{N}(\alpha + \beta x, \sigma^2)\) per ciascun \(i\), allora le stime dei minimi quadrati di \(\alpha\) e \(\beta\) corrispondono alla stima di massima verosimiglianza. La funzione di verosimiglianza del modello di regressione è definita come la funzione di densità di probabilità dei dati, dati i parametri e i predittori:

\begin{equation}
p(y \mid \alpha, \beta, \sigma, x) = \prod_{i=1}^n \mathcal{N}(y_i \mid \alpha, \beta x_i, \sigma^2). 
\label{eq:ml-reg}
\end{equation}

Massimizzare la \eqref{eq:ml-reg} conduce alle stime dei minimi quadrati \eqref{eq:minsq-ab}.

\hypertarget{introduzione-al-linguaggio-r}{%
\chapter{Introduzione al linguaggio R}\label{introduzione-al-linguaggio-r}}

In questa sezione della dispensa saranno presentate le caratteristiche di base e la filosofia dell'ambiente \texttt{R}, passando poi a illustrare le strutture dati e le principali strutture di controllo. Verranno introdotte alcune funzioni utili per la gestione dei dati e verranno forniti i rudimenti per realizzare semplici funzioni. Verranno introdotti i tipi di file editabili in RStudio (script, markdown, \ldots). Nello specifico, dopo aver accennato alcune caratteristiche del sistema \texttt{tidyverse}, verranno illustrate le principali funzionalità dell'IDE RStudio e dei pacchetti \texttt{dplyr} e \texttt{ggplot2}. Sul web sono disponibili tantissime introduzioni all'uso di \texttt{R} come, ad esempio, \href{https://rstudio-education.github.io/hopr/}{Hands-On Programming with R}, \href{https://r4ds.had.co.nz}{R for Data Science}, \href{https://bookdown.org/hneth/ds4psy/}{Data Science for Psychologists}, e \href{https://bookdown.org/hneth/i2ds/}{Introduction to Data Science}.

\hypertarget{prerequisiti}{%
\section{Prerequisiti}\label{prerequisiti}}

Al fine di utilizzare \texttt{R} è necessario eseguire le seguenti tre operazioni nell'ordine dato:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Installare \texttt{R};
\item
  Installare RStudio;
\item
  Installare R-Packages (se necessario).
\end{enumerate}

Di seguito viene descritto come installare \texttt{R} e RStudio.

\hypertarget{installare-r-e-rstudio}{%
\subsection{Installare R e RStudio}\label{installare-r-e-rstudio}}

\(\R\) è disponibile gratuitamente ed è scaricabile dal sito \url{http://www.rproject.org/}. Dalla pagina principale del sito \texttt{r-project.org} andiamo sulla sezione \texttt{Download} e scegliamo un server a piacimento per scaricare il software d'installazione. Una volta scaricato l'installer, lo installiamo come un qualsiasi software, cliccando due volte sul file d'istallazione. Esistono versioni di \(\R\) per tutti i più diffusi sistemi operativi (Windows, Mac OS X e Linux).

Il R Core Development Team lavora continuamente per migliorare le prestazioni di \(\R\), per correggere errori e per consentire l'uso di con nuove tecnologie. Di conseguenza, periodicamente vengono rilasciate nuove versioni di \(\R\). Informazioni a questo proposito sono fornite sulla pagina web \url{https://www.r-project.org/}. Per installare una nuova versione di \(\R\) si segue la stessa procedura che è stata seguita per la prima installazione.

Insieme al software si possono scaricare dal sito principale sia manuali d'uso che numerose dispense per approfondire diversi aspetti di \(\R\). In particolare, nel sito \url{http://cran.r-project.org/other-docs.html} si possono trovare anche numerose dispense in italiano (sezione ``Other languages'').

Dopo avere installato \(\R\) è opportuno installare anche RStudio. RStudio si può scaricare da \url{https://www.rstudio.com/}. Anche RStudio è disponibile per tutti i più diffusi sistemi operativi.

\hypertarget{utilizzare-rstudio-per-semplificare-il-lavoro}{%
\subsection{Utilizzare RStudio per semplificare il lavoro}\label{utilizzare-rstudio-per-semplificare-il-lavoro}}

Possiamo pensare ad \(\R\) come al motore di un automobile e a RStudio come al cruscotto di un automobile. Più precisamente, \(\R\) è un linguaggio di programmazione che esegue calcoli mentre RStudio è un ambiente di sviluppo integrato (IDE) che fornisce un'interfaccia grafica aggiungendo una serie di strumenti che facilitano la fase di sviluppo e di esecuzione del codice. Utilizzeremo dunque \(\R\) mediante RStudio. In altre parole,

\textbf{non aprite}

\includegraphics[width=0.15\textwidth,height=\textheight]{images/Rlogo.png}

\textbf{aprite invece}

\includegraphics[width=0.3\textwidth,height=\textheight]{images/RStudio-Logo-Blue-Gradient.png}

L'ambiente di lavoro di RStudio è costituito da quattro finestre: la finestra del codice (scrivere-eseguire script), la finestra della console (riga di comando - output), la finestra degli oggetti (elenco oggetti-cronologia dei comandi) e la finestra dei pacchetti-dei grafici-dell'aiuto in linea.

\begin{figure}
\hypertarget{fig:rstudio_pics}{%
\centering
\includegraphics[width=1\textwidth,height=\textheight]{images/rstudio_pics.png}
\caption{La console di RStudio.}\label{fig:rstudio_pics}
}
\end{figure}

\hypertarget{eseguire-il-codice}{%
\subsection{Eseguire il codice}\label{eseguire-il-codice}}

Mediante il menu a tendina di RStudio, scegliendo il percorso

\begin{verbatim}
File > New File > R Notebook
\end{verbatim}

oppure

\begin{verbatim}
File > New File > R Script
\end{verbatim}

l'utente può aprire nella finestra del codice (in alto a destra) un \(\R\) Notebook o un \(\R\) script dove inserire le istruzioni da eseguire.

In un \(\R\) script, un blocco di codice viene eseguito selezionando un insieme di righe di istruzioni e digitando la sequenza di tasti \texttt{Command} + \texttt{Invio} sul Mac, oppure \texttt{Control} + \texttt{Invio} su Windows. In un R Notebook, un blocco di codice viene eseguito schiacciando il bottone con l'icona \(\color{red}\blacktriangleright\) (``Run current chunk'') posizionata a destra rispetto al codice.

\hypertarget{installare-cmdstan}{%
\section{\texorpdfstring{Installare \texttt{cmdstan}}{Installare cmdstan}}\label{installare-cmdstan}}

È possibile installare \texttt{cmdstan} in almento tre modi. Per informazioni dettagliate, si vedano le istruzioni \href{https://mc-stan.org/docs/2_28/cmdstan-guide/cmdstan-installation.html}{CmdStan Installation}.

Prima di installare \texttt{cmdstan}, tre raccomandazioni generali:

\begin{itemize}
\tightlist
\item
  usare la versione più recente del sistema operativo;
\item
  usare la versione più recente di RStudio;
\item
  usare la versione più recente di \(\R\).
\end{itemize}

Se i tre vincoli precedenti sono soddisfatti, l'installazione di \texttt{cmdstan} dovrebbe procedere senza intoppi. Altrimenti si possono creare dei problemi di non facile soluzione.

Il modo più semplice per installare \texttt{cmdstan} è quello di installare prima \href{https://mc-stan.org/cmdstanr/}{cmdstanr} per poi utilizzare le funzionalità di quel pacchetto per l'installazione di \texttt{cmdstan}.

Un secondo metodo (che è quello che io uso normalmente) è quello di installare dal sorgente, seguendo le istruzioni riportante su \href{https://mc-stan.org/docs/2_28/cmdstan-guide/cmdstan-installation.html}{CmdStan Installation}.

Un terzo metodo (che richiede una minima comprensione delle funzionalità della shell e di Python) richiede, avendo prima installato \href{https://www.anaconda.com/products/individual}{Anaconda}, di digitare sulla console del proprio computer (la shell) le seguenti istruzioni:

\begin{verbatim}
conda create -n stan-env -c conda-forge cmdstan
conda activate stan-env
\end{verbatim}

Su \texttt{macos}, prima di installare \texttt{cmdstan}, è necessario installare la versione più recente di Xcode. Dopo avere installato Xcode, aprire la app. Verrà chiesto all'utente se si vogliono istallare delle componenti aggiuntive. Questo passaggio è cruciale, perché senza queste componenti aggiuntive \texttt{cmdstan} non funzionerà. Dopo avere installato le componenti aggiuntive, aprire Xcode e, in caso, accettare i termini della licenza. A quel punto si può chiudere Xcode. Ogni volta che Xcode viene aggiornato (deve sempre essere aggiornato quando un aggiornamento è disponibile), queste operazioni vanno ripetute.

\hypertarget{chapter-sintassi}{%
\section{Sintassi di base}\label{chapter-sintassi}}

\texttt{R} è un linguaggio di programmazione orientato all'analisi dei dati, il calcolo e la visualizzazione grafica. È disponibile su Internet una vasta gamma di materiali utile per avvicinarsi all'ambiente \texttt{R} e aiutare l'utente nell'apprendimento di questo software statistico. Cercheremo qui di fornire alcune indicazioni e una breve descrizione delle risorse di base di \texttt{R}.

Aggiungo qui sotto alcune considerazioni che ho preso, pari pari, da un testo che tratta di un altro linguaggio di programmazione, ma che si applicano perfettamente anche al caso nostro. \emph{``Come in ogni linguaggio, per parlare in R è necessario seguire un insieme di regole. Come in tutti i linguaggi di programmazione, queste regole sono del tutto inflessibili e inderogabili. In R, un enunciato o è sintatticamente corretto o è incomprensibile all'interprete, che lo segnalerà all'utente. Questo aspetto non è esattamente amichevole per chi non è abituato ai linguaggi di programmazione, e si trova così costretto ad una precisione di scrittura decisamente poco''analogica''. Tuttavia, ci sono due aspetti positivi nello scrivere codice, interrelati tra loro. Il primo è lo sforzo analitico necessario, che allena ad un'analisi precisa del problema che si vuole risolvere in modo da poterlo formalizzare linguisticamente. Il secondo concerne una forma di autoconsapevolezza specifica: salvo ``bachi'' nel linguaggio (rarissimi sebbene possibili), il mantra del programmatore è ``Se qualcosa non ti funziona, è colpa tua''} (testo adattato da Andrea Valle).

A chi preferisce un approccio più ``giocoso'' posso suggerire il seguente \href{https://tinystats.github.io/teacups-giraffes-and-statistics/01_introToR.html}{link}.

\hypertarget{utilizzare-la-console-r-come-calcolatrice}{%
\subsection{\texorpdfstring{Utilizzare la console \texttt{R} come calcolatrice}{Utilizzare la console R come calcolatrice}}\label{utilizzare-la-console-r-come-calcolatrice}}

La console di RStudio contiene un cursore rappresentato dal simbolo ``\textgreater{}'' (linea di comando) dove si possono inserire i comandi e le funzioni -- in realtà è sempre meglio utilizzare un \texttt{R} Notebook anziché la console, ma per ora esaminiamo il funzionamento di quest'ultima.

La console di RStudio può essere utilizzata come semplice calcolatrice. I comandi elementari consistono di espressioni o di assegnazioni. Le operazioni aritmetiche vengono eseguite mediante simboli ``standard:'' +, *, -, /, \texttt{sqrt()}, \texttt{log()}, \texttt{exp()}, \ldots{}

I comandi sono separati da un carattere di nuova linea (si immette un carattere di nuova linea digitando il tasto \texttt{Invio}). Se un comando non è completo alla fine della linea, \texttt{R} darà un prompt differente che per default è il carattere \texttt{+} sulla linea seguente e continuerà a leggere l'input finché il comando non è sintatticamente completo. Ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{4} \SpecialCharTok{{-}}
\SpecialCharTok{+} 
\SpecialCharTok{+} \DecValTok{1}
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

\texttt{R} è un ambiente interattivo, ossia i comandi producono una risposta immediata. Se scriviamo \texttt{2\ +\ 2} e premiamo il tasto di invio, comparirà nella riga successiva il risultato:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{+} \DecValTok{2}
\CommentTok{\#\textgreater{} [1] 4}
\end{Highlighting}
\end{Shaded}

Il risultato è preceduto da \texttt{{[}1{]}}, il che significa che il risultato dell'operazione che abbiamo appena eseguito è il primo valore di questa linea. Alcune funzioni ritornano più di un singolo numero e, in quel caso, l'informazione fornita da \texttt{R} è più utile. Per esempio, l'istruzione \texttt{100:130} ritorna \(31\) valori, ovvero i numeri da \(100\) a \(130\):

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{100}\SpecialCharTok{:}\DecValTok{130}
\CommentTok{\#\textgreater{}  [1] 100 101 102 103 104 105 106 107 108 109 110 111}
\CommentTok{\#\textgreater{} [13] 112 113 114 115 116 117 118 119 120 121 122 123}
\CommentTok{\#\textgreater{} [25] 124 125 126 127 128 129 130}
\end{Highlighting}
\end{Shaded}

In questo caso, sul mio computer, \texttt{{[}24{]}} indica che il valore \(123\) è il ventiquattresimo numero che è stato stampato sulla console -- su un altro computer le cose possono essere diverse in quanto il risultato, credo, dipende dalla grandezza dello schermo.

\hypertarget{espressioni}{%
\subsection{Espressioni}\label{espressioni}}

In questo corso, cercheremo di evitare i numeri nei nomi R, così come le lettere maiuscole e .. Useremo quindi nomi come: my\_data, anova\_results, square\_root, ecc.

Un'espressione in \texttt{R} è un enunciato finito e autonomo del linguaggio: una frase conclusa, si potrebbe dire. Si noti che le espressioni in \texttt{R} non sono delimitate dal \texttt{;} come succede in alcuni linguaggi di programmazione. L'ordine delle espressioni è l'ordine di esecuzione delle stesse.

L'a capo non è rilevante per \texttt{R}. Questo permette di utilizzare l'a capo per migliorare la leggibilità del codice.

\hypertarget{oggetti}{%
\subsection{Oggetti}\label{oggetti}}

\texttt{R} è un linguaggio di programmazione a oggetti, quindi si basa sulla creazione di oggetti e sulla possibilità di salvarli nella memoria del programma. \texttt{R} distingue tra maiuscole e minuscole come la maggior parte dei linguaggi basati su UNIX, quindi \texttt{A} e \texttt{a} sono nomi diversi e fanno riferimento a oggetti diversi.

I comandi elementari di \texttt{R} consistono in espressioni o assegnazioni.

Se un'espressione viene fornita come comando, viene valutata, stampata sullo schermo e il valore viene perso, come succedeva alle operazioni aritmetiche che abbiamo presentato sopra discutendo l'uso della console \texttt{R} come calcolatrice.

Un'assegnazione crea un oggetto oppure valuta un'espressione e passa il valore a un oggetto, ma il risultato non viene stampato automaticamente sullo schermo. Per l'operazione di assegnazione si usa il simbolo \texttt{\textless{}-}. Ad esempio, per creare un oggetto che contiene il risultato dell'operazione \texttt{2\ +\ 2} procediamo nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_sum }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{+} \DecValTok{2}
\NormalTok{res\_sum}
\CommentTok{\#\textgreater{} [1] 4}
\end{Highlighting}
\end{Shaded}

L'operazione di assegnazione (\texttt{\textless{}-}) copia il contenuto dell'operando destro (detto \texttt{r-value}) nell'operando sinistro detto (\texttt{l-value}). Il valore dell'espressione assegnazione è \texttt{r-value}. Nell'esempio precedente, \texttt{res\_sum} (\texttt{l-value}) assume il valore di \(4\).

\hypertarget{variabili}{%
\subsection{Variabili}\label{variabili}}

L'oggetto \texttt{res\_sum} è una \emph{variabile}. Una spiegazione di ciò che questo significa è riportata qui sotto. \emph{``Una variabile è un segnaposto. Tutte le volte che si memorizza un dato lo si assegna ad una variabile. Infatti, se il dato è nella memoria, per potervi accedere, è necessario conoscere il suo indirizzo, la sua ``etichetta'' (come in un grande magazzino in cui si va a cercare un oggetto in base alla sua collocazione). Se il dato è memorizzato ma inaccessibile (come nel caso di un oggetto sperso in un magazzino), allora non si può usare ed è soltanto uno spreco di spazio. La teoria delle variabili è un ambito molto complesso nella scienza della computazione. Ad esempio, una aspetto importante può concernere la tipizzazione delle variabili. Nei linguaggi ``tipizzati'' (ad esempio C), l'utente dichiara che userà quella etichetta (la variabile) per contenere solo ed esclusivamente un certo tipo di oggetto (ad esempio, un numero intero), e la variabile non potrà essere utilizzata per oggetti diversi (ad esempio, una stringa). In questo caso, prima di usare una variabile se ne dichiara l'esistenza e se ne specifica il tipo. I linguaggi non tipizzati non richiedono all'utente di specificare il tipo, che viene inferito in vario modo (ad esempio, in funzione dell'assegnazione del valore alla variabile). Alcuni linguaggi (ad esempio Python) non richiedono neppure la dichiarazione della variabile, che viene semplicemente usata. È l'interprete che inferisce che quella stringa è una variabile. La tipizzazione impone vincoli d'uso sulle variabili e maggiore scrittura del codice, ma assicura una chiara organizzazione dei dati. In assenza di tipizzazione, si lavora in maniera più rapida e snella, ma potenzialmente si può andare incontro a situazioni complicate, come quando si cambia il tipo di una variabile ``in corsa'' senza accorgersene'' (Andrea Valle).}

\texttt{R} è un linguaggio non tipicizzato, come Python. In \texttt{R} non è necessario dichiarare le variabili che si intendono utilizzare, né il loro tipo.

\hypertarget{r-console}{%
\subsection{R console}\label{r-console}}

La console di RStudio fornisce la possibilità di richiamare e rieseguire i comandi. I tasti freccia verticale, \(\uparrow\) e \(\downarrow\), sulla tastiera possono essere utilizzati per scorrere avanti e indietro i comandi già immessi. Appena trovato il comando che interessa, lo si può modificare, ad esempio, con i tasti freccia orizzontali, immettendo nuovi caratteri o cancellandone altri.

Se viene digitato un comando che \texttt{R} non riconosce, sulla console viene visualizzato un messaggio di errore; ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{3}\NormalTok{ \% }\DecValTok{9}
\NormalTok{Errore}\SpecialCharTok{:}\NormalTok{ unexpected input }\ControlFlowTok{in} \StringTok{"3 \% 9"}
\end{Highlighting}
\end{Shaded}

\hypertarget{parentesi}{%
\subsection{Parentesi}\label{parentesi}}

Le parentesi in \texttt{R} (come in generale in ogni linguaggio di programmazione) assegnano un significato diverso alle porzioni di codice che delimitano.

\begin{itemize}
\tightlist
\item
  Le parentesi tonde funzionano come nell'algebra. Per esempio
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{+} \DecValTok{3} \SpecialCharTok{*} \DecValTok{4}
\CommentTok{\#\textgreater{} [1] 14}
\end{Highlighting}
\end{Shaded}

non è equivalente a

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{2} \SpecialCharTok{+} \DecValTok{3}\NormalTok{) }\SpecialCharTok{*} \DecValTok{4}
\CommentTok{\#\textgreater{} [1] 20}
\end{Highlighting}
\end{Shaded}

Le due istruzioni precedenti producono risultati diversi perché, se la sequenza delle operazioni algebriche non viene specificata dalle parentesi, \texttt{R} assegna alle operazioni algebriche il seguente ordine di priorità decrescente: esponenziazione, moltiplicazione / divisione, addizione / sottrazione, confronti logici (\texttt{\textless{},\ \textgreater{},\ \textless{}=,\ \textgreater{}=,\ ==,\ !=}). È sempre una buona idea rendere esplicito l'ordine delle operazioni algebriche che si vuole eseguire mediante l'uso delle parentesi tonde.\\
Le parentesi tonde vengono anche utilizzate per le funzioni, come vedremo nei prossimi paragrafi. Tra le parentesi tonde avremo dunque l'oggetto a cui vogliamo applicare la funzione e gli argomenti passati alla funzione.

\begin{itemize}
\item
  Le parentesi graffe sono destinate alla programmazione. Un blocco tra le parentesi graffe viene letto come un oggetto unico che può contenere una o più istruzioni.
\item
  Le parentesi quadre vengono utilizzate per selezionare degli elementi, per esempio all'interno di un vettore, o di una matrice, o di un data.frame. L'argomento entro le parentesi quadre può essere generato da espressioni logiche.
\end{itemize}

\hypertarget{i-nomi-degli-oggetti}{%
\subsection{I nomi degli oggetti}\label{i-nomi-degli-oggetti}}

Le entità create e manipolate da \texttt{R} si chiamano `oggetti'. Tali oggetti possono essere variabili (come nell'esempio che abbiamo visto sopra), array di numeri, caratteri, stringhe, funzioni, o più in generale strutture costruite a partire da tali componenti. Durante una sessione di R gli oggetti sono creati e memorizzati attraverso opportuni nomi.

I nomi possono contenere un qualunque carattere alfanumerico e come carattere speciale il trattino basso (\texttt{\_}) o il punto. R fornisce i seguenti vincoli per i nomi degli oggetti: i nomi degli oggetti non possono mai iniziare con un carattere numerico e non possono contenere i seguenti simboli: \texttt{\$}, \texttt{@}, \texttt{!}, \texttt{\^{}}, \texttt{+}, \texttt{-}, \texttt{/}, \texttt{*}. È buona pratica usare nomi come \texttt{ratio\_of\_sums}. È fortemente sconsigliato utilizzare nei nomi degli oggetti caratteri accentati o, ancora peggio, apostrofi. Per questa ragione è sensato creare i nomi degli oggetti utilizzando la lingua inglese. È anche bene che i nomi degli oggetti non coincidano con nomi di funzioni. Ricordo nuovamente che \texttt{R} è \emph{case sensitive}, cioè \texttt{A} e \texttt{a} sono due simboli diversi e identificano due oggetti differenti.

In questo corso cercheremo di evitare i numeri nei nomi degli oggetti \texttt{R}, così come le lettere maiuscole e il punto. Useremo quindi nomi come: \texttt{my\_data}, \texttt{regression\_results}, \texttt{square\_root}, ecc.

\hypertarget{permanenza-dei-dati-e-rimozione-di-oggetti}{%
\subsection{Permanenza dei dati e rimozione di oggetti}\label{permanenza-dei-dati-e-rimozione-di-oggetti}}

Gli oggetti vengono salvati nello ``spazio di lavoro'' (\emph{workspace}). Il comando \texttt{ls()} può essere utilizzato per visualizzare i nomi degli oggetti che sono in quel momento memorizzati in \texttt{R}.

Per eliminare oggetti dallo spazio di lavoro è disponibile la funzione \texttt{rm()}; ad esempio

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(x, y, z, ink, junk, temp, foo, bar)}
\end{Highlighting}
\end{Shaded}

cancella tutti gli oggetti indicati entro parentesi. Per eliminare tutti gli oggetti presenti nello spazio di lavoro si può utilizzare la seguente istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{(}\AttributeTok{list =} \FunctionTok{ls}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\hypertarget{chiudere-r}{%
\subsection{Chiudere R}\label{chiudere-r}}

Quando si chiude RStudio il programma ci chiederà se si desidera salvare l'area di lavoro sul computer. Tale operazione è da evitare in quanto gli oggetti così salvati andranno ad interferire con gli oggetti creati in un lavoro futuro. Si consiglia dunque di rispondere negativamente a questa domanda.

\begin{itemize}
\item
  In RStudio, selezionare \texttt{Preferences} dal menu a tendina e, in \texttt{R\ General} \texttt{Workspace}, deselezionare l'opzione \texttt{Restore\ .RData\ into\ workspace\ at\ start-} \texttt{up} e scegliere l'opzione \texttt{Never} nella finestra di dialogo \texttt{Save\ workspace\ to} \texttt{.RData\ on\ exit}.
\item
  In R, selezionare \texttt{Preferences} dal menu a tendina e, in \texttt{Startup}, selezionare l'opzione \texttt{No} in corrispondenza dell'item \texttt{Save\ workspace\ on\ exit\ from\ R}.
\end{itemize}

\hypertarget{creare-ed-eseguire-uno-script-r-con-un-editore}{%
\subsection{Creare ed eseguire uno script R con un editore}\label{creare-ed-eseguire-uno-script-r-con-un-editore}}

È molto più facile interagire con R manipolando uno script con un editore piuttosto che inserendo direttamente le istruzioni nella console. \texttt{R} fornisce il Text Editor dove è possibile inserire il codice (File \(\to\) New Script). Per salvare il file basta utilizzare l'apposito menù a tendina (estensione \texttt{.R}). Tale file potrà poi essere riaperto ed utilizzato in un momento successivo.

L'editore comunica con \texttt{R} nel modo seguente: dopo avere selezionato la porzione di codice che si vuole eseguire, si digita un'apposita sequenza di tasti (\texttt{Command\ +\ Enter} su Mac OS X e \texttt{ctrl\ +\ r} in Windows). \texttt{ctrl\ +\ r} significa premere il tasto \texttt{ctrl} e, tenendolo premuto, premere il tasto \texttt{r} della tastiera. Così facendo, \texttt{R} eseguirà le istruzioni selezionate e l'output verrà stampato sulla console. Il Text Editor fornito da \texttt{R} è piuttosto primitivo: è fortemente consigliato utilizzare RStudio.

\hypertarget{commentare-il-codice}{%
\subsection{Commentare il codice}\label{commentare-il-codice}}

Un ``commento'' è una parte di codice che l'interprete non tiene in considerazione. Quando l'interprete arriva ad un segnalatore di commento salta fino al segnalatore di fine commento e di lì riprende il normale processo esecutivo.

I commenti sono parole in linguaggio naturale (nel nostro caso l'italiano), che permettono agli utilizzatori di capire il flusso logico del codice e a chi lo ha scritto di ricordare il perché di determinate istruzioni.

In \texttt{R}, le parole dopo il simbolo \texttt{\#} sono considerate commenti e sono ignorate; ad esempio:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Questo e\textquotesingle{} un commento}
\end{Highlighting}
\end{Shaded}

\hypertarget{cambiare-la-cartella-di-lavoro}{%
\subsection{Cambiare la cartella di lavoro}\label{cambiare-la-cartella-di-lavoro}}

Quando si inizia una sessione di lavoro, \texttt{R} sceglie una cartella quale ``working directory''. Sarà in tale cartella che andrà a cercare gli script definiti dall'utilizzatore e i file dei dati. È possibile determinare quale sia la corrente ``working directory'' digitando sulla console di RStudio l'istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getwd}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Per cambiare la cartella di lavoro (in maniera tale che corrisponda alla cartella nella quale sono stati salvati i dati e gli script da eseguire) si sceglie la voce \texttt{Set\ Working\ Directory} sul menù a tendina di RStudio e si selezione la voce \texttt{Choose\ Directory…} Nella finestra che compare, si cambia la cartella con quella che si vuole.

\hypertarget{loggetto-base-di-r-il-vettore}{%
\subsection{L'oggetto base di R: il vettore}\label{loggetto-base-di-r-il-vettore}}

\texttt{R} opera su strutture di dati; la più semplice di tali strutture è il vettore numerico, che consiste in un insieme ordinato di numeri; ad esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{7.0}\NormalTok{, }\FloatTok{10.2}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{2.9}\NormalTok{, }\FloatTok{21.4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Nell'istruzione precedente, \texttt{c()} è una funzione. In R gli argomenti sono passati alle funzioni inserendoli all'interno delle parentesi tonde. Si noti che gli argomenti (in questo caso, i numeri \(7.0, 10.2, -2.9, 21.4\)) sono separati a virgole. La funzione \texttt{c()} può prendere un numero arbitrario di argomenti e genera un vettore concatenando i suoi argomenti. L'operatore \texttt{\textless{}-} assegna un nome al vettore che è stato creato. Nel caso presente, digitando \texttt{x} possiamo visualizzare il vettore che abbiamo creato:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x}
\CommentTok{\#\textgreater{} [1]  7.0 10.2 {-}2.9 21.4}
\end{Highlighting}
\end{Shaded}

Se invece eseguiamo l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{c}\NormalTok{(}\FloatTok{7.0}\NormalTok{, }\FloatTok{10.2}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{2.9}\NormalTok{, }\FloatTok{21.4}\NormalTok{)}
\CommentTok{\#\textgreater{} [1]  7.0 10.2 {-}2.9 21.4}
\end{Highlighting}
\end{Shaded}

senza assegnazione, il valore dell'espressione sarà visualizzato nella console, ma il vettore non potrà essere utilizzato in nessun altro modo.

\hypertarget{operazioni-vettorializzate}{%
\subsection{Operazioni vettorializzate}\label{operazioni-vettorializzate}}

Molte operazioni in \texttt{R} sono vettorializzate, il che significa che esse sono eseguite in parallelo in determinati oggetti. Ciò consente di scrivere codice che sia efficiente, conciso e più facile da leggere rispetto al codice che contiene istruzioni non vettorializzate.

\hypertarget{vettori-aritmetici}{%
\subsection{Vettori aritmetici}\label{vettori-aritmetici}}

L'esempio più semplice che illustra come si svolgono le operazioni vettorializzate riguarda le operazioni algebriche applicate ai vettori. I vettori, infatti, possono essere utilizzati in espressioni numeriche nelle quali le operazioni algebriche vengono eseguite ``elemento per elemento''.

Per illustrare questo concetto, definiamo il vettore \texttt{die} che contiene i possibili risultati del lancio di un dado:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{die }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{die}
\CommentTok{\#\textgreater{} [1] 1 2 3 4 5 6}
\end{Highlighting}
\end{Shaded}

Supponiamo di volere sommare \(10\) a ciascun elemento del vettore \texttt{die}. Dato che le operazioni sui vettori sono eseguite elemento per elemento, per ottenere questo risultato è sufficiente eseguire l'istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{die }\SpecialCharTok{+} \DecValTok{10}
\CommentTok{\#\textgreater{} [1] 11 12 13 14 15 16}
\end{Highlighting}
\end{Shaded}

Si noti come la costante \(10\) sia stata sommata a ciascun elemento del vettore. In maniera corrispondente, l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{die }\SpecialCharTok{{-}} \DecValTok{1}
\CommentTok{\#\textgreater{} [1] 0 1 2 3 4 5}
\end{Highlighting}
\end{Shaded}

sottrarrà un'unità da ciascuno degli elementi del vettore \texttt{die}.

Se l'operazione aritmetica coinvolge due o più vettori, R allinea i vettori ed esegue una sequenza di operazioni elemento per elemento. Per esempio, l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{die }\SpecialCharTok{*}\NormalTok{ die}
\CommentTok{\#\textgreater{} [1]  1  4  9 16 25 36}
\end{Highlighting}
\end{Shaded}

fa sì che i due vettori vengano disposti l'uno di fianco all'altro per poi moltiplicare gli elementi corrispondenti: il primo elemento del primo vettore per il primo elemento del secondo vettore e così via. Il vettore risultante avrà la stessa dimensione dei due vettori che sono stati moltiplicati, come indicato qui sotto:

\[
\begin{array}{ccccc}
1 & \times & 1 & \to & 1 \\
2 & \times & 2 & \to & 4 \\
3 & \times & 3 & \to & 9 \\
4 & \times & 4 & \to & 16 \\
5 & \times & 5 & \to & 25 \\
6 & \times & 6 & \to & 36 \\
\hline
\verb+die+ & * & \verb+die+ & = & 
\end{array}
\]

Oltre agli operatori aritmetici elementari \texttt{+}, \texttt{-}, \texttt{*}, \texttt{/}, e \texttt{\^{}} per l'elevamento a potenza, sono disponibili le più comuni funzioni matematiche: \texttt{log()}, \texttt{exp()}, \texttt{sin()}, \texttt{cos()}, \texttt{tan()}, \texttt{sqrt()}, \texttt{max()}, \texttt{min()} e così via. Altre funzioni di uso comune sono: \texttt{range()} che restituisce un vettore \texttt{c(min(x),\ max(x))}; \texttt{sort()} che restituisce un vettore ordinato; \texttt{length(x)} che restituisce il numero di elementi di \texttt{x}; \texttt{sum(x)} che dà la somma degli elementi di \texttt{x}, mentre \texttt{prod(x)} dà il loro prodotto. Due funzioni statistiche di uso comune sono \texttt{mean(x)}, la media aritmetica, e \texttt{var(x)}, la varianza.

\hypertarget{generazione-di-sequenze-regolari}{%
\subsection{Generazione di sequenze regolari}\label{generazione-di-sequenze-regolari}}

\texttt{R} possiede un ampio numero di funzioni per generare sequenze di numeri. Ad esempio, \texttt{c(1:10)} è il vettore \texttt{c(1,\ 2,\ 3,\ 4,\ 5,\ 6,\ 7,\ 8,\ 9,\ 10)}. L'espressione \texttt{c(30:1)} può essere utilizzata per generare una sequenza all'indietro.

La funzione \texttt{seq()} genera un vettore che contiene una sequenza regolare di numeri, generata in base a determinate regole. Può avere 5 argomenti: i primi due rappresentano l'inizio (\texttt{from}) e la fine (\texttt{to}) della sequenza, il terzo specifica l'ampiezza del passo (\texttt{by}), il quarto la lunghezza della sequenza (\texttt{length.out}) e infine il quinto (\texttt{along.with}), che se utilizzato deve essere l'unico parametro presente, è il nome di un vettore, ad esempio \texttt{x}, creando in tal modo la sequenza 1, 2, \ldots, \texttt{length(x)}. Esempi di utilizzo della funzione \texttt{seq()} sono i seguenti:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{to =} \DecValTok{10}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1]  1  2  3  4  5  6  7  8  9 10}
\FunctionTok{seq}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{5}\NormalTok{, }\AttributeTok{by =} \FloatTok{2.5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] {-}5.0 {-}2.5  0.0  2.5  5.0}
\FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \DecValTok{1}\NormalTok{, }\AttributeTok{to =} \DecValTok{7}\NormalTok{, }\AttributeTok{length.out =} \DecValTok{4}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 1 3 5 7}
\FunctionTok{seq}\NormalTok{(}\AttributeTok{along.with =}\NormalTok{ die)}
\CommentTok{\#\textgreater{} [1] 1 2 3 4 5 6}
\end{Highlighting}
\end{Shaded}

Altra funzione utilizzata per generare sequenze è \texttt{rep()} che può essere utilizzata per replicare un oggetto in vari modi. Ad esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{die3 }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(die, }\AttributeTok{times =} \DecValTok{3}\NormalTok{)}
\NormalTok{die3}
\CommentTok{\#\textgreater{}  [1] 1 2 3 4 5 6 1 2 3 4 5 6 1 2 3 4 5 6}
\end{Highlighting}
\end{Shaded}

metterà tre copie di \texttt{die} nell'oggetto \texttt{die3}.

\hypertarget{generazione-di-numeri-casuali}{%
\subsection{Generazione di numeri casuali}\label{generazione-di-numeri-casuali}}

La funzione \texttt{sample()} è una delle tante funzioni che possono essere usate per generare numeri casuali. Per esempio, la seguente istruzione simula dieci lanci di un dado a sei facce:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roll }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{roll}
\CommentTok{\#\textgreater{}  [1] 1 3 3 6 3 1 2 2 6 6}
\end{Highlighting}
\end{Shaded}

Il primo argomento di \texttt{sample()} è il vettore da cui la funzione estrarrà degli elementi a caso; il secondo argomento specifica che dovranno essere effettuate 10 estrazioni casuali; il terzo argomento specifica che le estrazioni sono con rimessa (cioè, lo stesso elemento può essere estratto più di una volta).

Scegliere un elemento a caso dal vettore \(\{1, 2, 3, 4, 5, 6\}\) è equivalente a lanciare un dado e osservare la faccia che si presenta. L'istruzione precedente corrisponde dunque alla simulazione di dieci lanci di un dado a sei facce.

\hypertarget{vettori-logici}{%
\subsection{Vettori logici}\label{vettori-logici}}

Quando si manipolano i vettori, talvolta si vogliono trovare gli elementi che soddisfano determinate condizioni logiche. Per esempio, in dieci lanci di un dado, quante volte è uscito \(5\)? Per rispondere a questa domanda si possono usare gli operatori logici \texttt{\textless{}}, \texttt{\textgreater{}} e \texttt{==} per le operazioni di ``minore di,'' ``maggiore di'' e ``uguale a''. Se scriviamo

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roll }\SpecialCharTok{==} \DecValTok{5}
\CommentTok{\#\textgreater{}  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE}
\CommentTok{\#\textgreater{}  [9] FALSE FALSE}
\end{Highlighting}
\end{Shaded}

creiamo un vettore costituito da elementi \texttt{TRUE/FALSE} i quali identificano gli elementi del vettore che soddisfano la condizione logica specificata.

Possiamo trattare tale vettore come se fosse costituito da elementi di valore \(0\) e \(1\). Sommando gli elementi di tale vettore, infatti, possiamo contare il numero di ``5'':

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(roll }\SpecialCharTok{==} \DecValTok{5}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 0}
\end{Highlighting}
\end{Shaded}

\hypertarget{dati-mancanti}{%
\subsection{Dati mancanti}\label{dati-mancanti}}

Quando si è in presenza di un dato mancante, R assegna il valore speciale \texttt{NA}, che sta per \emph{Not Available}. In generale, un'operazione su un \texttt{NA} dà come risultato un \texttt{NA}. Nell'uso delle funzioni che operano sui dati sarà dunque necessario specificare che, qualunque operazione venga effettuata, gli \texttt{NA} devono essere esclusi.

\hypertarget{vettori-di-caratteri-e-fattori}{%
\subsection{Vettori di caratteri e fattori}\label{vettori-di-caratteri-e-fattori}}

I vettori di caratteri si creano formando una sequenza di caratteri delimitati da doppie virgolette e possono essere concatenati in un vettore attraverso la funzione \texttt{c()}. Successivamente, si può applicare la funzione \texttt{factor()}, che definisce automaticamente le modalità della variabile categoriale. Ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{soc\_status }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"low"}\NormalTok{, }\StringTok{"high"}\NormalTok{, }\StringTok{"medium"}\NormalTok{, }\StringTok{"high"}\NormalTok{, }\StringTok{"low"}\NormalTok{, }\StringTok{"medium"}\NormalTok{, }\StringTok{"high"}\NormalTok{)}
\NormalTok{)}
\FunctionTok{levels}\NormalTok{(soc\_status)}
\CommentTok{\#\textgreater{} [1] "high"   "low"    "medium"}
\end{Highlighting}
\end{Shaded}

Talvolta l'ordine dei livelli del fattore non importa, mentre altre volte l'ordine è importante, per esempio, quando una variable categoriale viene rappresentata in un grafico. Per specificare l'ordine dei livelli del fattore si usa la seguente sintassi:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{soc\_status }\OtherTok{\textless{}{-}} 
  \FunctionTok{factor}\NormalTok{(soc\_status, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"low"}\NormalTok{, }\StringTok{"medium"}\NormalTok{, }\StringTok{"high"}\NormalTok{))}
\FunctionTok{levels}\NormalTok{(soc\_status)}
\CommentTok{\#\textgreater{} [1] "low"    "medium" "high"}
\end{Highlighting}
\end{Shaded}

\hypertarget{funzioni}{%
\subsection{Funzioni}\label{funzioni}}

\texttt{R} offre la possibilità di utilizzare un'enorme libreria di funzioni che permettono di svolgere operazioni complicate, quali ad esempio, il campionamento casuale. Esaminiamo ora con più attenzione le proprietà delle funzioni di \texttt{R} utilizzando ancora l'esempio del lancio di un dado. Abbiamo visto in precedenza come il lancio di un dado possa essere simulato da R con la funzione \texttt{sample()}. La funzione \texttt{sample()} prende tre argomenti: il nome di un vettore, un numero chiamato \texttt{size} e un argomento chiamato \texttt{replace}. La funzione \texttt{sample()} ritorna un numero di elementi del vettore pari a \texttt{size}. Ad esempio

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(die, }\DecValTok{2}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 3 4}
\end{Highlighting}
\end{Shaded}

Assegnando \texttt{TRUE} all'argomento \texttt{replace} specifichiamo che vogliamo un campionamento con rimessa.

Se volgiamo eseguire una serie di lanci indipendenti di un dado, eseguiamo ripetutamente la funzione \texttt{sample()} ponendo \texttt{size} uguale a 1:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(die, }\DecValTok{1}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 3}
\FunctionTok{sample}\NormalTok{(die, }\DecValTok{1}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 2}
\FunctionTok{sample}\NormalTok{(die, }\DecValTok{1}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

Come si fa a sapere quanti e quali argomenti sono richiesti da una funzione? Tale informazione viene fornita dalla funzione \texttt{args()}. Nel nostro caso

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{args}\NormalTok{(sample)}
\CommentTok{\#\textgreater{} function (x, size, replace = FALSE, prob = NULL) }
\CommentTok{\#\textgreater{} NULL}
\end{Highlighting}
\end{Shaded}

ci informa che il primo argomento è un vettore chiamato \texttt{x}, il secondo argomento è chiamato \texttt{size} ed ha il significato descritto sopra, il terzo argomento, \texttt{replace}, specifica se il campionamento è eseguito con o senza reimmissione, e il quarto argomento, \texttt{prob}, assegna delle probabilità agli elementi del vettore. Il significato degli argomenti viene spiegato nel file di help della funzione. Si noti che agli ultimi due argomenti sono stati assegnati dei valori, detti di default. Ciò significa che, se l'utilizzatore non li cambia, verranno usati da . La specificazione \texttt{replace\ =\ FALSE} significa che il campionamento viene eseguito senza reimmissione. Se desideriamo un campionamento con reimmissione, basta specificare \texttt{replace\ =\ TRUE} (nel caso di una singola estrazione è ovviamente irrilevante). Ad esempio, l'istruzione seguente simula i risultati di 10 lanci indipendenti di un dado:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(die, }\DecValTok{10}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\#\textgreater{}  [1] 3 6 1 3 3 4 3 6 3 4}
\end{Highlighting}
\end{Shaded}

Infine, \texttt{prob\ =\ NULL} specifica che non viene alterata la probabilità di estrazione degli elementi del vettore. In generale, gli argomenti di una funzione possono essere oggetti come vettori, matrici, altre funzioni, parametri o operatori logici.

\texttt{R} ha un sistema di help interno in formato HTML che si richiama con \texttt{help.start()}. Per avere informazioni su qualche funzione specifica, per esempio la funzione \texttt{sample()}, il comando da utilizzare è \texttt{help(sample)} oppure \texttt{?sample}.

\hypertarget{scrivere-proprie-funzioni}{%
\subsection{Scrivere proprie funzioni}\label{scrivere-proprie-funzioni}}

Abbiamo visto in precedenza come sia possibile simulare i risultati prodotti da dieci lanci di un dado o, in maniera equivalente, dal singolo lancio di dieci dadi. Possiamo replicare questo processo digitando ripetutamente le stesse istruzioni nella console. Otterremo ogni volta risultati diversi perché, ad ogni ripetizione, il generatore di numeri pseudo-casuali di R dipende dal valore ottenuto dal clock interno della macchina. La funzione \texttt{set.seed()} ci permette di replicare esattamente i risultati della generazione di numeri casuali. Per ottenere questo risultato, basta assegnare al seed un numero arbitrario, es. \texttt{set.seed(12345)}. Tuttavia, questa procedura è praticamente difficile da perseguire se il numero di ripetizioni è alto. In tal caso è vantaggioso scrivere una funzione contenente il codice che specifica il numero di ripetizioni. In questo modo, per trovare il risultato cercato basterà chiamare la funzione una sola volta.

Le funzioni utilizzate da \texttt{R} sono costituite da tre elementi: il nome, il blocco del codice e una serie di argomenti. Per creare una funzione è necessario immagazzinare in R questi tre elementi e \texttt{function()} consente di ottenere tale risultato usando la sintassi seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nome\_funzione }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(arg1, arg2, ...) \{}
\NormalTok{  espressione1}
\NormalTok{  espressione2}
  \FunctionTok{return}\NormalTok{(risultato)}
\NormalTok{\} }
\end{Highlighting}
\end{Shaded}

Una chiamata di funzione è poi eseguita nel seguente modo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nome\_funzione}\NormalTok{(arg1, arg2, ...)}
\end{Highlighting}
\end{Shaded}

Per potere essere utilizzata, una funzione deve essere presente nella memoria di lavoro di \texttt{R}. Le funzioni salvate in un file possono essere richiamate utilizzando la funzione \texttt{source()}, ad esempio, \texttt{source("file\_funzioni.R")}.

Consideriamo ora la funzione \texttt{two\_rolls()} che ritorna la somma dei punti prodotti dal lancio di due dadi non truccati:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{two\_rolls }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{() \{}
\NormalTok{  die }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{6}
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(die, }\AttributeTok{size =} \DecValTok{2}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  sum\_res }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(res)}
  \FunctionTok{return}\NormalTok{(sum\_res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

La funzione \texttt{two\_rolls()} inizia con il creare il vettore \texttt{die} che contiene sei elementi: i numeri da \(1\) a \(6\). Viene poi utilizzata la funzione \texttt{sample()} con gli gli argomenti, \texttt{die}, \texttt{size\ =\ 2} e \texttt{replace\ =\ TRUE}. Tale funzione restituisce il risultato del lancio di due dadi. Il risultato fornito da \texttt{sample(die,\ size\ =\ 2,\ replace\ =\ TRUE)} viene assegnato all'oggetto \texttt{res}. L'oggetto \texttt{res} corrisponde dunque ad un vettore di due elementi. L'istruzione \texttt{sum(res)} somma gli elementi del vettore \texttt{res} e attribuisce il risultato di questa operazione a \texttt{sum\_res}. Infine, la funzione \texttt{return()} ritorna il contenuto dell'oggetto \texttt{sum\_res}. Invocando la funzione \texttt{two\_rolls()} si ottiene dunque la somma del lancio di due dadi. In generale, la funzione \texttt{two\_rolls()} produrrà un risultato diverso ogni volta che viene usata:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{two\_rolls}\NormalTok{()   }
\CommentTok{\#\textgreater{} [1] 9}
\FunctionTok{two\_rolls}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] 4}
\FunctionTok{two\_rolls}\NormalTok{()}
\CommentTok{\#\textgreater{} [1] 7}
\end{Highlighting}
\end{Shaded}

La formattazione del codice mediante l'uso di spazi e rientri non è necessaria ma è altamente raccomandata per minimizzare la probabilità di compiere errori.

\hypertarget{pacchetti}{%
\subsection{Pacchetti}\label{pacchetti}}

Le funzioni di \texttt{R} sono organizzate in pacchetti, i più importanti dei quali sono già disponibili quando si accede al programma.

\hypertarget{istallazione-e-upgrade-dei-pacchetti}{%
\subsection{Istallazione e upgrade dei pacchetti}\label{istallazione-e-upgrade-dei-pacchetti}}

Alcuni pacchetti non sono presenti nella release di base di \texttt{R}. Per installare un pacchetto non presente è sufficiente scrivere nella console:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"nome\_pacchetto"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

La prima volta che si usa questa funzione durante una sessione di lavoro si dovrà anche selezionare da una lista il sito \emph{mirror} da cui scaricare il pacchetto.

Gli autori dei pacchetti periodicamente rilasciano nuove versioni dei loro pacchetti che contengono miglioramenti di varia natura. Per eseguire l'upgrade dei pacchetti \texttt{ggplot2} e \texttt{dplyr}, ad esempio, si usa la seguente istruzione:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{update.packages}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{, }\StringTok{"dplyr"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Per eseguire l'upgrade di tutti i pacchetti l'istruzione è

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{update.packages}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{caricare-un-pacchetto-in-r}{%
\subsection{Caricare un pacchetto in R}\label{caricare-un-pacchetto-in-r}}

L'istallazione dei pacchetti non rende immediatamente disponibili le funzioni in essi contenute. L'istallazione di un pacchetto semplicemente copia il codice sul disco rigido della macchina in uso. Per potere usare le funzioni contenute in un pacchetto installato è necessario caricare il pacchetto in . Ciò si ottiene con il comando:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"ggplot2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

se si vuole caricare il pacchetto \texttt{ggplot2}. A questo punto diventa possibile usare le funzioni contenute in \texttt{ggplot2}. Queste operazioni si possono anche eseguire usando dal menu a tendina di RStudio.

Per sapere quali sono i pacchetti già presenti nella release di \texttt{R} con cui si sta lavorando, basta scrivere:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{chapter-strutture-dati}{%
\section{Strutture di dati}\label{chapter-strutture-dati}}

Solitamente gli psicologi raccolgono grandi quantità di dati. Tali dati vengono codificati in \texttt{R} all'interno di oggetti aventi proprietà diverse. Intuitivamente, in \texttt{R} un oggetto è qualsiasi cosa a cui è possibile assegnare un valore. I dati possono essere di tipo numerico o alfanumerico. Di conseguenza, \texttt{R}distingue tra oggetti aventi \emph{modi} diversi. Inoltre, i dati possono essere organizzati in righe e colonne in base a diversi tipi di strutture che \texttt{R} chiama \emph{classi}.

\hypertarget{classi-e-modi-degli-oggetti}{%
\subsection{Classi e modi degli oggetti}\label{classi-e-modi-degli-oggetti}}

Gli oggetti \texttt{R} si distinguono a seconda della loro classe (\emph{class}) e del loro modo (\emph{mode}). La classe definisce il tipo di oggetto. In \texttt{R}, vengono utilizzate cinque strutture di dati che corrispondono a cinque classi differenti: \texttt{vector}, \texttt{matrix}, \texttt{array}, \texttt{list} e \texttt{data.frame}. Un'altra classe di oggetti \texttt{R} è \texttt{function} (ad essa appartengono le funzioni).

La classe di appartenenza di un oggetto si stabilisce usando le funzioni \texttt{class()}, oppure \texttt{is.list()}, \texttt{is.function()}, \texttt{is.logical()}, e così via. Queste funzioni restituisco \texttt{TRUE} e \texttt{FALSE} in base all'appartenenza o meno dell'argomento a quella determinata classe.

Gli oggetti \texttt{R} possono anche essere classificati in base al loro `modo'. I modi `atomici' degli oggetti sono: \texttt{numeric}, \texttt{complex}, \texttt{character} e \texttt{logical}. Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\FunctionTok{mode}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] "numeric"}
\NormalTok{cards }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"9 of clubs"}\NormalTok{, }\StringTok{"10 of hearts"}\NormalTok{, }\StringTok{"jack of hearts"}\NormalTok{) }
\FunctionTok{mode}\NormalTok{(cards)}
\CommentTok{\#\textgreater{} [1] "character"}
\end{Highlighting}
\end{Shaded}

Nel seguito verranno esaminate le cinque strutture di dati utilizzate da \texttt{R}.

\hypertarget{vettori}{%
\subsection{Vettori}\label{vettori}}

I vettori sono la classe di oggetto più importante in \texttt{R}. Un vettore può essere creato usando la funzione \texttt{c()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{y}
\CommentTok{\#\textgreater{} [1]  2  1  6 {-}3  9}
\end{Highlighting}
\end{Shaded}

Le dimensioni di un vettore presente nella memoria di lavoro possono essere trovare con la funzione \texttt{length()}; ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{length}\NormalTok{(y)}
\CommentTok{\#\textgreater{} [1] 5}
\end{Highlighting}
\end{Shaded}

ci dice che \texttt{y} è un vettore costituito da cinque elementi. La somma, il minimo e il massimo degli elementi contenuti in un vettore si trovano con le seguenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(y)}
\CommentTok{\#\textgreater{} [1] 15}
\FunctionTok{min}\NormalTok{(y)}
\CommentTok{\#\textgreater{} [1] {-}3}
\FunctionTok{max}\NormalTok{(y)}
\CommentTok{\#\textgreater{} [1] 9}
\end{Highlighting}
\end{Shaded}

Mentre ci sono sei `tipi' di vettori `atomici' in \texttt{R}, noi ci focalizzeremo sui tipi seguenti: `numeric' (`integer': \emph{e.g.}, 5; `double': \emph{e.g.}, 5.5), `character' (\emph{e.g.}, `pippo') e `logical' (\emph{e.g.}, \texttt{TRUE}, \texttt{FALSE}). Usiamo la funzione \texttt{typeof()} per determinare il `tipo' di un vettore atomico. Tutti gli elementi di un vettore atomico devono essere dello stesso tipo. La funzione \texttt{str()} rende visibile in maniera compatta la struttura interna di un oggetto.

\hypertarget{matrici}{%
\subsection{Matrici}\label{matrici}}

Una matrice è una collezione di vettori. Il comando per generare una matrice è \texttt{matrix()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{20}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{X}
\CommentTok{\#\textgreater{}      [,1] [,2] [,3] [,4] [,5]}
\CommentTok{\#\textgreater{} [1,]    1    5    9   13   17}
\CommentTok{\#\textgreater{} [2,]    2    6   10   14   18}
\CommentTok{\#\textgreater{} [3,]    3    7   11   15   19}
\CommentTok{\#\textgreater{} [4,]    4    8   12   16   20}
\end{Highlighting}
\end{Shaded}

Il primo argomento è il vettore i cui elementi andranno a disporsi all'interno della matrice. È poi necessario specificare le dimensioni della matrice e il modo in cui \texttt{R} dovrà riempire la matrice. Date le dimensioni del vettore, la specificazione del numero di righe (secondo argomento) è sufficiente per determinare le dimensioni della matrice. L'argomento \texttt{byrow\ =\ FALSE} è il default. In tal caso, \texttt{R} riempie la matrice per colonne. Se vogliamo che \texttt{R} riempia la matrice per righe, usiamo \texttt{byrow\ =\ TRUE}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{20}\NormalTok{, }\AttributeTok{nrow =} \DecValTok{4}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{Y}
\CommentTok{\#\textgreater{}      [,1] [,2] [,3] [,4] [,5]}
\CommentTok{\#\textgreater{} [1,]    1    2    3    4    5}
\CommentTok{\#\textgreater{} [2,]    6    7    8    9   10}
\CommentTok{\#\textgreater{} [3,]   11   12   13   14   15}
\CommentTok{\#\textgreater{} [4,]   16   17   18   19   20}
\end{Highlighting}
\end{Shaded}

Le dimensioni di una matrice presente nella memoria di lavoro possono essere trovare con la funzione \texttt{dim()}; ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(Y)}
\CommentTok{\#\textgreater{} [1] 4 5}
\end{Highlighting}
\end{Shaded}

ci dice che \texttt{Y} è una matrice con quattro righe e cinque colonne.

\hypertarget{array}{%
\subsection{Array}\label{array}}

Un array è una collezione di matrici (si veda la Figura \protect\hyperlink{fig:R_data_structures}{1.1}). Per costruire un array con la funzione \texttt{array()} è necessario specificare un vettore come primo argomento e un vettore di dimensioni, chiamato \texttt{dim}, quale secondo argomento:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ar }\OtherTok{\textless{}{-}} \FunctionTok{array}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\DecValTok{11}\SpecialCharTok{:}\DecValTok{14}\NormalTok{, }\DecValTok{21}\SpecialCharTok{:}\DecValTok{24}\NormalTok{, }\DecValTok{31}\SpecialCharTok{:}\DecValTok{34}\NormalTok{), }
  \AttributeTok{dim =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Un sottoinsieme di questi dati può essere selezionato, per esempio, nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ar[, , }\DecValTok{3}\NormalTok{]}
\CommentTok{\#\textgreater{}      [,1] [,2]}
\CommentTok{\#\textgreater{} [1,]   31   33}
\CommentTok{\#\textgreater{} [2,]   32   34}
\end{Highlighting}
\end{Shaded}

\hypertarget{operazioni-aritmetiche-su-vettori-matrici-e-array}{%
\subsection{Operazioni aritmetiche su vettori, matrici e array}\label{operazioni-aritmetiche-su-vettori-matrici-e-array}}

\hypertarget{operazioni-aritmetiche-su-vettori}{%
\subsubsection{Operazioni aritmetiche su vettori}\label{operazioni-aritmetiche-su-vettori}}

I vettori e le matrici (o gli array) possono essere utilizzati in espressioni aritmetiche. Il risultato è un vettore o una matrice (o un array) formato dalle operazioni fatte elemento per elemento sui vettori o sulle matrici. Ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\SpecialCharTok{+} \DecValTok{3}
\CommentTok{\#\textgreater{} [1]  5  4  9  0 12}
\end{Highlighting}
\end{Shaded}

restituisce un vettore di dimensioni uguali alle dimensioni di \texttt{y}, i cui elementi sono dati dalla somma tra ciascuno degli elementi originari di \texttt{y} e la costante ``3''.

Ovviamente, ad un vettore possono essere applicate tutte le altre operazioni algebriche, sempre elemento per elemento. Ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{3} \SpecialCharTok{*}\NormalTok{ y}
\CommentTok{\#\textgreater{} [1]  6  3 18 {-}9 27}
\end{Highlighting}
\end{Shaded}

restituisce un vettore i cui elementi sono uguali agli elementi di \texttt{y} moltiplicati per 3.

Se sono costituiti dallo stesso numero di elementi, due vettori possono essere sommati, sottratti, moltiplicati e divisi, laddove queste operazioni algebriche vengono eseguite elemento per elemento. Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{x }\SpecialCharTok{+}\NormalTok{ y}
\CommentTok{\#\textgreater{} [1]  3  2  8  4 12}
\NormalTok{x }\SpecialCharTok{{-}}\NormalTok{ y}
\CommentTok{\#\textgreater{} [1] {-}1  0 {-}4 {-}2 {-}6}
\NormalTok{x }\SpecialCharTok{*}\NormalTok{ y}
\CommentTok{\#\textgreater{} [1]  2  1 12  3 27}
\NormalTok{x }\SpecialCharTok{/}\NormalTok{ y}
\CommentTok{\#\textgreater{} [1] 0.5000 1.0000 0.3333 0.3333 0.3333}
\end{Highlighting}
\end{Shaded}

\hypertarget{operazioni-aritmetiche-su-matrici}{%
\subsubsection{Operazioni aritmetiche su matrici}\label{operazioni-aritmetiche-su-matrici}}

Le operazioni algebriche elemento per elemento si possono estendere al caso delle matrici. Per esempio, se \texttt{X}, \texttt{Y} sono entrambe matrici di dimensioni \(4 \times 5\), allora la seguente operazione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ (X }\SpecialCharTok{+}\NormalTok{ Y) }\SpecialCharTok{{-}} \DecValTok{3} 
\end{Highlighting}
\end{Shaded}

crea una matrice \texttt{D} anch'essa di dimensioni \(4 \times 5\) i cui elementi sono ottenuti dalle operazioni fatte elemento per elemento sulle matrici e sugli scalari:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M}
\CommentTok{\#\textgreater{}      [,1] [,2] [,3] [,4] [,5]}
\CommentTok{\#\textgreater{} [1,]    1   11   21   31   41}
\CommentTok{\#\textgreater{} [2,]   13   23   33   43   53}
\CommentTok{\#\textgreater{} [3,]   25   35   45   55   65}
\CommentTok{\#\textgreater{} [4,]   37   47   57   67   77}
\end{Highlighting}
\end{Shaded}

\hypertarget{operazioni-aritmetiche-su-array}{%
\subsubsection{Operazioni aritmetiche su array}\label{operazioni-aritmetiche-su-array}}

Le stesse considerazioni si estendono al caso degli array.

\hypertarget{liste}{%
\subsection{Liste}\label{liste}}

Le liste assomigliano ai vettori perché raggruppano i dati in un insieme unidimensionale. Tuttavia, le liste non raggruppano elementi individuali ma bensì oggetti di \texttt{R}, quali vettori e altre liste. Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list1 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\StringTok{"R"}\NormalTok{, }\FunctionTok{list}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{), }\DecValTok{20}\SpecialCharTok{:}\DecValTok{24}\NormalTok{)}
\NormalTok{list1}
\CommentTok{\#\textgreater{} [[1]]}
\CommentTok{\#\textgreater{} [1] "R"}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[2]]}
\CommentTok{\#\textgreater{} [[2]][[1]]}
\CommentTok{\#\textgreater{} [1] TRUE}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[2]][[2]]}
\CommentTok{\#\textgreater{} [1] FALSE}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} [[3]]}
\CommentTok{\#\textgreater{} [1] 20 21 22 23 24}
\end{Highlighting}
\end{Shaded}

Le doppie parentesi quadre identificano l'elemento della lista a cui vogliamo fare riferimento. Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list1[[}\DecValTok{3}\NormalTok{]]}
\CommentTok{\#\textgreater{} [1] 20 21 22 23 24}
\NormalTok{list1[[}\DecValTok{3}\NormalTok{]][}\DecValTok{2}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] 21}
\end{Highlighting}
\end{Shaded}

\hypertarget{data-frame}{%
\subsection{Data frame}\label{data-frame}}

I data.frame sono strutture tipo matrice, in cui le colonne possono essere vettori di tipi differenti. La funzione usata per generare un data frame è \texttt{data.frame()}, che permette di unire più vettori di uguale lunghezza come colonne del data frame, ognuno dei quali si riferisce ad una diversa variabile. Ad esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{face =} \FunctionTok{c}\NormalTok{(}\StringTok{"ace"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"six"}\NormalTok{),}
  \AttributeTok{suit =} \FunctionTok{c}\NormalTok{(}\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{), }
  \AttributeTok{value =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{)}
\NormalTok{df}
\CommentTok{\#\textgreater{}   face  suit value}
\CommentTok{\#\textgreater{} 1  ace clubs     1}
\CommentTok{\#\textgreater{} 2  two clubs     2}
\CommentTok{\#\textgreater{} 3  six clubs     3}
\end{Highlighting}
\end{Shaded}

L'estrazione di dati da un data.frame può essere effettuata in maniera simile a quanto avviene per i vettori. Ad esempio, per estrarre la variabile \texttt{value} dal data.frame \texttt{df} si può indicare l'indice della terza colonna:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[, }\DecValTok{3}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] 1 2 3}
\end{Highlighting}
\end{Shaded}

Dal momento che le colonne sono delle variabili, è possibile estrarle anche indicando nome della variabile, scrivendo \texttt{nome\_data\_frame\$nome\_variabile}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{value}
\CommentTok{\#\textgreater{} [1] 1 2 3}
\end{Highlighting}
\end{Shaded}

Per fare un esempio, creiamo un data.frame che contenga tutte le informazioni di un mazzo di carte da poker \citep{grolemund2014hands}. In tale data.frame, ciascuna riga corrisponde ad una carta -- in un mazzo da poker ci sono 52 carte, perciò il data.frame avrà 52 righe. Il vettore \texttt{face} indica con una stringa di caratteri il valore di ciascuna carta, il vettore \texttt{suit} indica il seme e il vettore \texttt{value} indica con un numero intero il valore di ciascuna carta. Quindi, il data.frame avrà 3 colonne.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{face =} \FunctionTok{c}\NormalTok{(}\StringTok{"king"}\NormalTok{, }\StringTok{"queen"}\NormalTok{, }\StringTok{"jack"}\NormalTok{, }\StringTok{"ten"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"eight"}\NormalTok{,}
  \StringTok{"seven"}\NormalTok{, }\StringTok{"six"}\NormalTok{, }\StringTok{"five"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"ace"}\NormalTok{, }
  \StringTok{"king"}\NormalTok{, }\StringTok{"queen"}\NormalTok{, }\StringTok{"jack"}\NormalTok{, }\StringTok{"ten"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }
  \StringTok{"six"}\NormalTok{, }\StringTok{"five"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"ace"}\NormalTok{, }\StringTok{"king"}\NormalTok{, }
  \StringTok{"queen"}\NormalTok{, }\StringTok{"jack"}\NormalTok{, }\StringTok{"ten"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }\StringTok{"six"}\NormalTok{, }
  \StringTok{"five"}\NormalTok{, }\StringTok{"four"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"ace"}\NormalTok{, }\StringTok{"king"}\NormalTok{, }\StringTok{"queen"}\NormalTok{, }
  \StringTok{"jack"}\NormalTok{, }\StringTok{"ten"}\NormalTok{, }\StringTok{"nine"}\NormalTok{, }\StringTok{"eight"}\NormalTok{, }\StringTok{"seven"}\NormalTok{, }\StringTok{"six"}\NormalTok{, }\StringTok{"five"}\NormalTok{, }
  \StringTok{"four"}\NormalTok{, }\StringTok{"three"}\NormalTok{, }\StringTok{"two"}\NormalTok{, }\StringTok{"ace"}\NormalTok{), }
  \AttributeTok{suit =} \FunctionTok{c}\NormalTok{(}\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }
  \StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }
  \StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"spades"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }
  \StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }
  \StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"clubs"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }
  \StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }
  \StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }
  \StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"diamonds"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }
  \StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }
  \StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{, }
  \StringTok{"hearts"}\NormalTok{, }\StringTok{"hearts"}\NormalTok{), }
  \AttributeTok{value =} \FunctionTok{c}\NormalTok{(}\DecValTok{13}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Avendo salvato tutte queste informazioni nell'oggetto \texttt{deck}, possiamo stamparle sullo schermo semplicemente digitando il nome dell'oggetto che le contiene:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck}
\CommentTok{\#\textgreater{}     face     suit value}
\CommentTok{\#\textgreater{} 1   king   spades    13}
\CommentTok{\#\textgreater{} 2  queen   spades    12}
\CommentTok{\#\textgreater{} 3   jack   spades    11}
\CommentTok{\#\textgreater{} 4    ten   spades    10}
\CommentTok{\#\textgreater{} 5   nine   spades     9}
\CommentTok{\#\textgreater{} 6  eight   spades     8}
\CommentTok{\#\textgreater{} 7  seven   spades     7}
\CommentTok{\#\textgreater{} 8    six   spades     6}
\CommentTok{\#\textgreater{} 9   five   spades     5}
\CommentTok{\#\textgreater{} 10  four   spades     4}
\CommentTok{\#\textgreater{} 11 three   spades     3}
\CommentTok{\#\textgreater{} 12   two   spades     2}
\CommentTok{\#\textgreater{} 13   ace   spades     1}
\CommentTok{\#\textgreater{} 14  king    clubs    13}
\CommentTok{\#\textgreater{} 15 queen    clubs    12}
\CommentTok{\#\textgreater{} 16  jack    clubs    11}
\CommentTok{\#\textgreater{} 17   ten    clubs    10}
\CommentTok{\#\textgreater{} 18  nine    clubs     9}
\CommentTok{\#\textgreater{} 19 eight    clubs     8}
\CommentTok{\#\textgreater{} 20 seven    clubs     7}
\CommentTok{\#\textgreater{} 21   six    clubs     6}
\CommentTok{\#\textgreater{} 22  five    clubs     5}
\CommentTok{\#\textgreater{} 23  four    clubs     4}
\CommentTok{\#\textgreater{} 24 three    clubs     3}
\CommentTok{\#\textgreater{} 25   two    clubs     2}
\CommentTok{\#\textgreater{} 26   ace    clubs     1}
\CommentTok{\#\textgreater{} 27  king diamonds    13}
\CommentTok{\#\textgreater{} 28 queen diamonds    12}
\CommentTok{\#\textgreater{} 29  jack diamonds    11}
\CommentTok{\#\textgreater{} 30   ten diamonds    10}
\CommentTok{\#\textgreater{} 31  nine diamonds     9}
\CommentTok{\#\textgreater{} 32 eight diamonds     8}
\CommentTok{\#\textgreater{} 33 seven diamonds     7}
\CommentTok{\#\textgreater{} 34   six diamonds     6}
\CommentTok{\#\textgreater{} 35  five diamonds     5}
\CommentTok{\#\textgreater{} 36  four diamonds     4}
\CommentTok{\#\textgreater{} 37 three diamonds     3}
\CommentTok{\#\textgreater{} 38   two diamonds     2}
\CommentTok{\#\textgreater{} 39   ace diamonds     1}
\CommentTok{\#\textgreater{} 40  king   hearts    13}
\CommentTok{\#\textgreater{} 41 queen   hearts    12}
\CommentTok{\#\textgreater{} 42  jack   hearts    11}
\CommentTok{\#\textgreater{} 43   ten   hearts    10}
\CommentTok{\#\textgreater{} 44  nine   hearts     9}
\CommentTok{\#\textgreater{} 45 eight   hearts     8}
\CommentTok{\#\textgreater{} 46 seven   hearts     7}
\CommentTok{\#\textgreater{} 47   six   hearts     6}
\CommentTok{\#\textgreater{} 48  five   hearts     5}
\CommentTok{\#\textgreater{} 49  four   hearts     4}
\CommentTok{\#\textgreater{} 50 three   hearts     3}
\CommentTok{\#\textgreater{} 51   two   hearts     2}
\CommentTok{\#\textgreater{} 52   ace   hearts     1}
\end{Highlighting}
\end{Shaded}

Si noti che, a schermo, \texttt{R} stampa un numero progressivo che corrisponde al numero della riga.

\hypertarget{selezione-di-elementi}{%
\subsubsection{Selezione di elementi}\label{selezione-di-elementi}}

Una volta creato un data.frame, ad esempio quello che contiene un mazzo virtuale di carte (si veda l'esempio~\protect\hyperlink{exmp:deck_of_cards}{\[exmp:deck_of_cards\]}), è necessario sapere come manipolarlo. La funzione \texttt{head()} mostra le prime sei righe del data.frame:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(deck)}
\CommentTok{\#\textgreater{}    face   suit value}
\CommentTok{\#\textgreater{} 1  king spades    13}
\CommentTok{\#\textgreater{} 2 queen spades    12}
\CommentTok{\#\textgreater{} 3  jack spades    11}
\CommentTok{\#\textgreater{} 4   ten spades    10}
\CommentTok{\#\textgreater{} 5  nine spades     9}
\CommentTok{\#\textgreater{} 6 eight spades     8}
\end{Highlighting}
\end{Shaded}

Poniamoci ora il problema di mescolare il mazzo di carte e di estrarre alcune carte dal mazzo. Queste operazioni possono essere eseguite usando il sistema notazionale di \texttt{R}.

Il sistema di notazione di \texttt{R} consente di estrarre singoli elementi dagli oggetti definiti da \texttt{R}. Per estrarre un valore da un data.frame, per esempio, dobbiamo scrivere il nome del data.frame seguito da una coppia di parentesi quadre:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[, ]}
\end{Highlighting}
\end{Shaded}

All'interno delle parentesi quadre ci sono due indici separati da una virgola. \texttt{R} usa il primo indice per selezionare un sottoinsieme di righe del data.frame e il secondo indice per selezionare un sottoinsieme di colonne. L'indice è il numero d'ordine che etichetta progressivamente ognuno dei valori del vettore. Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{9}\NormalTok{, }\DecValTok{2}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] "spades"}
\end{Highlighting}
\end{Shaded}

restituisce l'elemento che si trova nella nella nona riga della seconda colonna di \texttt{deck}.

In \texttt{R} ci sono sei modi diversi per specificare gli indici di un oggetto: interi positivi, interi negativi, zero, spazi vuoti, valori logici e nomi. Esaminiamoli qui di seguito.

\hypertarget{interi-positivi}{%
\subsubsection{Interi positivi}\label{interi-positivi}}

Gli indici \(i, j\) possono essere degli interi positivi che identificano l'elemento nella \(i\)-esima riga e nella \(j\)-esima colonna del data.frame. Per l'esempio relativo al mazzo di carte, l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{]}
\CommentTok{\#\textgreater{} [1] "king"}
\end{Highlighting}
\end{Shaded}

ritorna il valore nella prima riga e nella prima colonna. Per estrarre più di un valore, usiamo un vettore di interi positivi. Per esempio, la prima riga di \texttt{deck} si trova con

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)]}
\CommentTok{\#\textgreater{}   face   suit value}
\CommentTok{\#\textgreater{} 1 king spades    13}
\end{Highlighting}
\end{Shaded}

Tale sistema notazionale non si applica solo ai data.frame ma può essere usato anche per gli altri oggetti di \texttt{R}.

L'indice usato da \texttt{R} inizia da 1. In altri linguaggi di programmazione, per esempio \texttt{C}, inizia da 0.

\hypertarget{interi-negativi}{%
\subsubsection{Interi negativi}\label{interi-negativi}}

Gli interi negativi fanno l'esatto contrario degli interi positivi: R ritornerà tutti gli elementi tranne quelli specificati dagli interi negativi. Per esempio, la prima riga del data.frame può essere specificata nel modo seguente

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\SpecialCharTok{{-}}\NormalTok{(}\DecValTok{2}\SpecialCharTok{:}\DecValTok{52}\NormalTok{), }\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]}
\CommentTok{\#\textgreater{}   face   suit value}
\CommentTok{\#\textgreater{} 1 king spades    13}
\end{Highlighting}
\end{Shaded}

ovvero, escludendo tutte le righe seguenti.

\hypertarget{zero}{%
\subsubsection{Zero}\label{zero}}

Quando lo zero viene usato come indice, \texttt{R} non ritorna nulla dalla dimensione a cui lo zero si riferisce. L'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{]}
\CommentTok{\#\textgreater{} data frame con 0 colonne e 0 righe}
\end{Highlighting}
\end{Shaded}

ritorna un data.frame vuoto. Non molto utile.

\hypertarget{spazio}{%
\subsubsection{\texorpdfstring{Spazio \texttt{’\ ’}}{Spazio ' '}}\label{spazio}}

Uno spazio viene usato quale indice per comunicare a \texttt{R} di estrarre tutti i valori in quella dimensione. Questo è utile per estrarre intere colonne o intere righe da un data.frame. Per esempio, l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{3}\NormalTok{, ]}
\CommentTok{\#\textgreater{}   face   suit value}
\CommentTok{\#\textgreater{} 3 jack spades    11}
\end{Highlighting}
\end{Shaded}

ritorna la terza riga del data.frame \texttt{deck}.

\hypertarget{valori-booleani}{%
\subsubsection{Valori booleani}\label{valori-booleani}}

Se viene fornito un vettore di stringhe \texttt{TRUE}, \texttt{FALSE}, \texttt{R} selezionerà gli elementi riga o colonna corrispondenti ai valori booleani \texttt{TRUE} usati quali indici. Per esempio, l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{3}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{, }\ConstantTok{FALSE}\NormalTok{)]}
\CommentTok{\#\textgreater{}   face   suit}
\CommentTok{\#\textgreater{} 3 jack spades}
\end{Highlighting}
\end{Shaded}

ritorna i valori delle prime due colonne della terza riga di \texttt{deck}.

\hypertarget{nomi}{%
\subsubsection{Nomi}\label{nomi}}

È possibile selezionare gli elementi del data.frame usando i loro nomi. Per esempio,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"face"}\NormalTok{, }\StringTok{"suit"}\NormalTok{, }\StringTok{"value"}\NormalTok{)]}
\CommentTok{\#\textgreater{}   face   suit value}
\CommentTok{\#\textgreater{} 1 king spades    13}
\NormalTok{deck[, }\StringTok{"value"}\NormalTok{]}
\CommentTok{\#\textgreater{}  [1] 13 12 11 10  9  8  7  6  5  4  3  2  1 13 12 11 10}
\CommentTok{\#\textgreater{} [18]  9  8  7  6  5  4  3  2  1 13 12 11 10  9  8  7  6}
\CommentTok{\#\textgreater{} [35]  5  4  3  2  1 13 12 11 10  9  8  7  6  5  4  3  2}
\CommentTok{\#\textgreater{} [52]  1}
\end{Highlighting}
\end{Shaded}

\hypertarget{giochi-di-carte}{%
\subsection{Giochi di carte}\label{giochi-di-carte}}

Avendo presentato le nozioni base del sistema di notazione di \texttt{R}, utilizziamo tali conoscenze per manipolare il data.frame. L'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{52}\NormalTok{, ]}
\end{Highlighting}
\end{Shaded}

ritorna tutte le righe e tutte e le colonne del data.frame \texttt{deck}. Le righe sono identificate dal primo indice, che va da 1 a 52. Permutare in modo casuale l'indice delle righe equivale a mescolare il mazzo di carte. Per fare questo, utilizziamo la funzione \texttt{sample()} ponendo \texttt{replace=FALSE} e \texttt{size} uguale alla dimensione del vettore che contiene gli indici da 1 a 52:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{52}\NormalTok{, }\AttributeTok{size =} \DecValTok{52}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{random}
\CommentTok{\#\textgreater{}  [1] 41 35 51 22  3 10  2 15 11 16 46 21  7 19 43 17 27}
\CommentTok{\#\textgreater{} [18] 50 39 44 14 18 40 47 31 30 52 37 20 33  6  9  5 49}
\CommentTok{\#\textgreater{} [35] 13  4  8 28 32 45 42 26 36  1 48 23 24 29 34 25 38}
\CommentTok{\#\textgreater{} [52] 12}
\end{Highlighting}
\end{Shaded}

Utilizzando il vettore \texttt{random} di indici permutati otteniamo il risultato cercato:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck\_shuffled }\OtherTok{\textless{}{-}}\NormalTok{ deck[random, ]}
\FunctionTok{head}\NormalTok{(deck\_shuffled)}
\CommentTok{\#\textgreater{}     face     suit value}
\CommentTok{\#\textgreater{} 41 queen   hearts    12}
\CommentTok{\#\textgreater{} 35  five diamonds     5}
\CommentTok{\#\textgreater{} 51   two   hearts     2}
\CommentTok{\#\textgreater{} 22  five    clubs     5}
\CommentTok{\#\textgreater{} 3   jack   spades    11}
\CommentTok{\#\textgreater{} 10  four   spades     4}
\end{Highlighting}
\end{Shaded}

Possiamo ora scrivere una funzione che include le precedenti istruzioni:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shuffle }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cards) \{}
\NormalTok{  random }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{52}\NormalTok{, }\AttributeTok{size =} \DecValTok{52}\NormalTok{, }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{) }
  \FunctionTok{return}\NormalTok{(cards[random, ])}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Invocando la funzione \texttt{shuffle()} possiamo generare un data.frame che rappresenta un mazzo di carte mescolato:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck\_shuffled }\OtherTok{\textless{}{-}} \FunctionTok{shuffle}\NormalTok{(deck)}
\end{Highlighting}
\end{Shaded}

Se immaginiamo di distribuire le carte di questo mazzo a due giocatori di poker, per il primo giocatore avremo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck\_shuffled[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{), ]}
\CommentTok{\#\textgreater{}    face     suit value}
\CommentTok{\#\textgreater{} 26  ace    clubs     1}
\CommentTok{\#\textgreater{} 44 nine   hearts     9}
\CommentTok{\#\textgreater{} 29 jack diamonds    11}
\CommentTok{\#\textgreater{} 42 jack   hearts    11}
\CommentTok{\#\textgreater{} 22 five    clubs     5}
\end{Highlighting}
\end{Shaded}

e per il secondo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{deck\_shuffled[}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{10}\NormalTok{), ]}
\CommentTok{\#\textgreater{}     face     suit value}
\CommentTok{\#\textgreater{} 24 three    clubs     3}
\CommentTok{\#\textgreater{} 47   six   hearts     6}
\CommentTok{\#\textgreater{} 34   six diamonds     6}
\CommentTok{\#\textgreater{} 51   two   hearts     2}
\CommentTok{\#\textgreater{} 17   ten    clubs    10}
\end{Highlighting}
\end{Shaded}

\hypertarget{variabili-locali}{%
\subsection{Variabili locali}\label{variabili-locali}}

Si noti che, nell'esempio precedente, abbiamo passato l'argomento \texttt{deck} alla funzione \texttt{shuffle()}, perché questo è il nome del data.frame che volevamo manipolare. Nella definizione della funzione \texttt{shuffle()}, però, l'argomento della funzione era chiamato \texttt{cards}. Il nome degli argomenti è diverso nei due casi. Allora perché l'istruzione \texttt{shuffle(deck)} non dà un messaggio d'errore?

La risposta a questa domanda è che nelle funzioni le variabili nascono quando la funzione entra in esecuzione e muoiono al termine dell'esecuzione della funzione. Per questa ragione, sono dette `locali'. La variabile \texttt{cards}, in questo esempio, esiste soltanto all'interno della funzione. Dunque non deve (necessariamente) avere lo stesso nome di un altro oggetto che esiste al di fuori della funzione, nello spazio di lavoro di R (anzi, è meglio se il nome degli oggetti usati all'interno delle funzioni è diverso da quello degli oggetti che esistono fuori dalle funzioni). R sa che l'oggetto \texttt{deck} passato a \texttt{shuffle()} corrisponde a \texttt{cards} all'interno della funzione perché assegna il nome \texttt{cards} a qualunque oggetto venga passato alla funzione \texttt{shuffle()} come primo (e, in questo caso, unico) argomento.

\hypertarget{chapter-strut-contr}{%
\section{Strutture di controllo}\label{chapter-strut-contr}}

In \texttt{R} il flusso della computazione segue l'ordine di lettura delle espressioni. I controlli di flusso sono quei costrutti sintattici che possono modificare quest'ordine di computazione. Ad esempio, un ciclo \texttt{for} ripete le istruzioni annidate al suo interno per un certo numero di volte, e quindi procede sequenzialmente da lì in avanti, mentre un condizionale \texttt{if} valuta una condizione rispetto alla quale il flusso di informazioni si biforca (se è vero / se è falso). Ci limitiamo qui ad introdurre il ciclo \texttt{for}.

\hypertarget{il-ciclo-for}{%
\subsection{\texorpdfstring{Il ciclo \texttt{for}}{Il ciclo for}}\label{il-ciclo-for}}

Il ciclo \texttt{for} è una struttura di controllo iterativa che determina l'esecuzione di una porzione di codice ripetuta per un certo numero noto di volte. Il linguaggio \texttt{R} usa la seguente sintassi per il ciclo \texttt{for}:

\texttt{for} (\texttt{indice} in \texttt{valori\_indice}) \{ \emph{operazioni} \}

il che significa ``esegui le operazioni \emph{operazioni} per i diversi valori di \texttt{indice} compresi nel vettore \texttt{valori\_indice}''. Per esempio, il seguente ciclo \texttt{for} non fa altro che stampare il valore della variabile contatore in ciascuna esecuzione del ciclo:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{) \{}
  \FunctionTok{print}\NormalTok{(i)}
\NormalTok{\}}
\CommentTok{\#\textgreater{} [1] 1}
\CommentTok{\#\textgreater{} [1] 2}
\CommentTok{\#\textgreater{} [1] 3}
\end{Highlighting}
\end{Shaded}

Un esempio (leggermente) più complicato è il seguente:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x\_list }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{9}\NormalTok{, }\AttributeTok{by =} \DecValTok{2}\NormalTok{)}
\NormalTok{x\_list}
\CommentTok{\#\textgreater{} [1] 1 3 5 7 9}
\NormalTok{sum\_x }\OtherTok{\textless{}{-}} \DecValTok{0}
\ControlFlowTok{for}\NormalTok{ (x }\ControlFlowTok{in}\NormalTok{ x\_list) \{}
\NormalTok{  sum\_x }\OtherTok{\textless{}{-}}\NormalTok{ sum\_x }\SpecialCharTok{+}\NormalTok{ x}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"L\textquotesingle{}indice corrente e\textquotesingle{}"}\NormalTok{, x, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"La frequenza cumulata e\textquotesingle{}"}\NormalTok{, sum\_x, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{) }
\NormalTok{\}}
\CommentTok{\#\textgreater{} L\textquotesingle{}indice corrente e\textquotesingle{} 1 }
\CommentTok{\#\textgreater{} La frequenza cumulata e\textquotesingle{} 1 }
\CommentTok{\#\textgreater{} L\textquotesingle{}indice corrente e\textquotesingle{} 3 }
\CommentTok{\#\textgreater{} La frequenza cumulata e\textquotesingle{} 4 }
\CommentTok{\#\textgreater{} L\textquotesingle{}indice corrente e\textquotesingle{} 5 }
\CommentTok{\#\textgreater{} La frequenza cumulata e\textquotesingle{} 9 }
\CommentTok{\#\textgreater{} L\textquotesingle{}indice corrente e\textquotesingle{} 7 }
\CommentTok{\#\textgreater{} La frequenza cumulata e\textquotesingle{} 16 }
\CommentTok{\#\textgreater{} L\textquotesingle{}indice corrente e\textquotesingle{} 9 }
\CommentTok{\#\textgreater{} La frequenza cumulata e\textquotesingle{} 25}
\end{Highlighting}
\end{Shaded}

Per esempio, quanti numeri pari sono contenuti in un vettore? La risposta a questa domanda viene fornita dalla funzione \texttt{countEvenNumbers()} che possiamo definire come indicato qui sotto:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{countEvenNumbers }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{  count }\OtherTok{\textless{}{-}} \DecValTok{0}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(x)) \{}
    \ControlFlowTok{if}\NormalTok{ (x[i] }\SpecialCharTok{\%\%} \DecValTok{2} \SpecialCharTok{==} \DecValTok{0}\NormalTok{)  }
\NormalTok{      count }\OtherTok{=}\NormalTok{ count }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  \}}
\NormalTok{  count}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Nella funzione \texttt{countEvenNumbers()} abbiamo inizializzato la variabile \texttt{count} a zero. Prima dell'esecuzione del ciclo \texttt{for}, dunque, \texttt{count} vale zero. Il ciclo \texttt{for} viene eseguito tante volte quanti sono gli elementi che costituiscono il vettore \texttt{x}. L'indice \texttt{i} dunque assume valori compresi tra 1 e il valore che corrisponde al numero di elementi di \texttt{x}. L'operazione modulo, indicato con \texttt{\%\%} dà come risultato il resto della divisione euclidea del primo numero per il secondo. Per esempio, \texttt{9\ \%\%\ 2} dà come risultato \(1\) perché questo è il resto della divisione \(9/2\). L'operazione modulo dà come risultato \(0\) per tutti i numeri pari. In ciascuna esecuzione del ciclo \texttt{for} l'operazione modulo viene eseguita, successivamente, su uno degli elementi di \texttt{x}. Se l'operazione modulo dà \(0\) come risultato, ovvero se il valore considerato è un numero pari, allora la variabile \texttt{count} viene incrementata di un'unità. L'istruzione \texttt{return()} ritorna il numero di valori pari contenuti nel vettore di input alla funzione. Si noti che è necessario usare \texttt{return()}: la funzione ritornerà qualunque cosa sia stampato nell'ultima riga della funzione stessa.

Facciamo un esempio:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\FunctionTok{countEvenNumbers}\NormalTok{(x)}
\CommentTok{\#\textgreater{} [1] 4}
\end{Highlighting}
\end{Shaded}

\hypertarget{chapter-input-output}{%
\section{Input/Output}\label{chapter-input-output}}

I dati raccolti dallo psicologo sono contenuti in file aventi formati diversi: solo testo, CSV, Excel, eccetera. \texttt{R} prevede diverse funzioni di importazione dei dati. Esamineremo qui la funzione \texttt{read.table()} per l'importazione di dati in formato solo testo, ma funzioni analoghe possono essere usate per molti altri formati possibili.

\hypertarget{la-funzione-read.table}{%
\subsection{\texorpdfstring{La funzione \texttt{read.table()}}{La funzione read.table()}}\label{la-funzione-read.table}}

Ci sono tanti modi per importare un file dal nostro computer. \texttt{R} permette di utilizzare delle funzioni che sono già nella libreria di base, oppure possiamo utilizzare delle funzioni specifiche, a seconda del tipo di file da importare, che sono contenute in pacchetti aggiuntivi. Per leggere i dati da file in \texttt{R} è conveniente preliminarmente generare un file di dati in formato ASCII, disponendoli come si farebbe in una matrice di dati, e mettere questo file nella cartella di lavoro corrente. Fatto questo, si può utilizzare la funzione \texttt{read.table()} presente nella libreria di base per leggere l'intero dataset. Se la prima riga del file contiene l'intestazione delle variabili, allora \texttt{read.table("my\_file.txt",\ header\ =\ TRUE)} interpreterà la prima riga del file come una riga dove sono contenuti i nomi delle variabili, assegnando ciascun nome alle variabili del data frame:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"my\_file.txt"}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

In alternativa, si può impiegare la funzione \texttt{read.csv()}, che è adatta a leggere dati salvati in \texttt{.csv}. Utilizzando altre funzioni, si possono leggere in \texttt{R} i dati contenuti in file aventi formati diversi da quelli considerati qui, quali Excel, SPSS, ecc.

\hypertarget{file-di-dati-forniti-da-r}{%
\subsection{File di dati forniti da R}\label{file-di-dati-forniti-da-r}}

In \texttt{R} esistono comunque oltre 50 insiemi di dati contenuti nel package \texttt{base} e altri sono disponibili in altri packages. Per vedere l'elenco degli insiemi di dati disponibili nel package \texttt{base} basta usare l'istruzione \texttt{data()}; per caricare un particolare insieme di dati, ad esempio \texttt{cars}, basta utilizzare l'istruzione

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(cars)}
\end{Highlighting}
\end{Shaded}

Nella maggior parte dei casi questo corrisponde a caricare un oggetto, solitamente un data.frame dello stesso nome: per l'esempio considerato si avrebbe un data frame di nome \texttt{cars}.

\hypertarget{esportazione-di-un-file}{%
\subsection{Esportazione di un file}\label{esportazione-di-un-file}}

Per esportare un data.frame in formato \texttt{.csv} possiamo scrivere il seguente codice

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{write.csv}\NormalTok{(df\_esempio, }\AttributeTok{file =} \StringTok{"esempio.csv"}\NormalTok{, }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

dove \texttt{df\_esempio} è il data.frame da salvare e \texttt{esempio.csv} è il file che verrà salvato all'interno della nostra cartellla di lavoro.

\hypertarget{pacchetto-rio}{%
\subsection{\texorpdfstring{Pacchetto \texttt{rio}}{Pacchetto rio}}\label{pacchetto-rio}}

Un'alternativa più semplice è fornita dalle funzioni fornite dal pacchetto \texttt{rio}. Per importare i dati da un file in qualsiasi formato si usa

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my\_data\_frame }\OtherTok{\textless{}{-}}\NormalTok{ rio}\SpecialCharTok{::}\FunctionTok{import}\NormalTok{(}\StringTok{"my\_file.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Per esportare i dati in un file avente qualsiasi formato si usa invece

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rio}\SpecialCharTok{::}\FunctionTok{export}\NormalTok{(my\_data\_frame, }\StringTok{"my\_file.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{dove-sono-i-miei-file}{%
\subsection{Dove sono i miei file?}\label{dove-sono-i-miei-file}}

Quello che abbiamo detto finora, a proposito dell'importazione ed esportazione dei file, si riferisce a file che si trovano nella cartella di lavoro (\emph{working directory}). Ma non sempre ci troviamo in questa situazione, il che è una buona cosa, perché se dobbiamo gestire un progetto anche leggermente complesso è sempre una buona idea salvare i file che usiamo in cartelle diverse. Per esempio, possiamo usare una cartella chiamata \texttt{psicometria} dove salviamo tutto il materiale di questo insegnamento. Nella cartella \texttt{psicometria} ci potrà essere una cartella chiamata \texttt{scripts} dove salveremo gli script con il codice R utilizzato per i vari esercizi, e una cartella chiamata \texttt{data} dove possiamo salvare i dati. Questa organizzazione minimale ci pone, però, difronte ad un problema: i dati che vogliamo caricare in R non si trovano nella cartella dove sono contenuti gli script. Quando importiamo un file di dati dobbiamo dunque specificare il percorso che identifica la posizione del file sul nostro computer.

Questo problema può essere risolto in due modi: speficicando l'indirizzo assoluto del file, o l'indirizzo relativo. Specificare l'indirizzo assoluto di un file comporta una serie di svantaggi. Il più grande è che non sarà possibile utilizzare quell'istruzione su una macchina diversa. Dunque, è molto più conveniente specificare l'indirizzo dei file in modo relativo. Ma relativo rispetto a cosa? Rispetto alla \emph{working directory} che definirà l'origine del nostro percorso.

È ovvio che la \emph{working directory} cambia da progetto a progetto. Infatti, per ciascun progetto dobbiamo specificare una diversa \emph{working directory}. Per esempio, potremmo avere un progetto relativo all'insegnamento di Psicometria e un progetto relativo alla prova finale.

Per organizzaere il lavoro in questo modo, si procede come segue. Supponiamo di creare una cartella chiamata \texttt{psicometria} che contiene, al suo interno, le cartelle \texttt{scripts} e \texttt{data}:
>>>>>>> main

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(}\StringTok{"foreign"}\NormalTok{)}
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{read.dta}\NormalTok{(}\FunctionTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"kidiq.dta"}\NormalTok{))}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score)[, }\DecValTok{1}\NormalTok{]}
\NormalTok{df}\SpecialCharTok{$}\NormalTok{x1 }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_iq)[, }\DecValTok{1}\NormalTok{]}
\FunctionTok{head}\NormalTok{(df)}
\CommentTok{\#\textgreater{}   kid\_score mom\_hs mom\_iq mom\_work mom\_age        y}
\CommentTok{\#\textgreater{} 1        65      1 121.12        4      27 {-}1.06793}
\CommentTok{\#\textgreater{} 2        98      1  89.36        4      25  0.54887}
\CommentTok{\#\textgreater{} 3        85      1 115.44        4      27 {-}0.08805}
\CommentTok{\#\textgreater{} 4        83      1  99.45        3      25 {-}0.18604}
\CommentTok{\#\textgreater{} 5       115      1  92.75        4      27  1.38176}
\CommentTok{\#\textgreater{} 6        98      0 107.90        1      18  0.54887}
\CommentTok{\#\textgreater{}         x1}
\CommentTok{\#\textgreater{} 1  1.40784}
\CommentTok{\#\textgreater{} 2 {-}0.70921}
\CommentTok{\#\textgreater{} 3  1.02954}
\CommentTok{\#\textgreater{} 4 {-}0.03669}
\CommentTok{\#\textgreater{} 5 {-}0.48362}
\CommentTok{\#\textgreater{} 6  0.52679}
\end{Highlighting}
\end{Shaded}

Dato che AIC non è una statistica bayesiana, può essere calcolata mediante strumenti frequentisti:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1\_freq }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{data =}\NormalTok{ df)}
\FunctionTok{AIC}\NormalTok{(m1\_freq) }\SpecialCharTok{/} \SpecialCharTok{{-}}\DecValTok{2}
\CommentTok{\#\textgreater{} [1] {-}569.6}
\end{Highlighting}
\end{Shaded}

Per ottenere LOO-CV adattiamo ai dati un modello di regressione bayesiano:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] x1;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta1;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    mu[n] = alpha + beta1*x1[n];}
\StringTok{  \}}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta1 \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 1);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  vector[N] log\_lik;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    y\_rep[n] = normal\_rng(mu[n], sigma);}
\StringTok{    log\_lik[n] = normal\_lpdf(y[n] | x1[n] * beta1, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/simplereg.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data1\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file1 }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"simplereg.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod1 }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file1)}
\end{Highlighting}
\end{Shaded}

Eseguiamo il campionamento MCMC:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}}\NormalTok{ mod1}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data1\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Calcoliamo infine la quantità \(\widehat{\elpd}_{LOO-CV}\):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo1\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit1}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\FunctionTok{print}\NormalTok{(loo1\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}568.6 14.5}
\CommentTok{\#\textgreater{} p\_loo         1.9  0.2}
\CommentTok{\#\textgreater{} looic      1137.2 28.9}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is 0.0.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All Pareto k estimates are good (k \textless{} 0.5).}
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Si noti la somiglianza tra \(\widehat{\elpd}_{LOO-CV}\) e \(\widehat{\elpd}_{AIC}\). In conclusione, possiamo dunque dire che \(\widehat{\elpd}_{LOO-CV}\) è la risposta bayesiana allo stesso problema che trova una soluzione frequentista nella statistica \(\widehat{\elpd}_{AIC}\).

\hypertarget{confronto-tra-modelli-mediante-loo-cv}{%
\section{Confronto tra modelli mediante LOO-CV}\label{confronto-tra-modelli-mediante-loo-cv}}

Come menzionato in precedenza, l'obiettivo centrale della misurazione dell'accuratezza predittiva è il confronto di modelli. Una volta capito come calcolare LOO-CV con un condice scritto in linguaggio Stan, svolgeremo ora un confronto di modelli.\footnote{A questo proposito, è necessario aggiungere una nota di cautela. Come fa notare \citet{McElreath_rethinking}, fare previsioni e inferire i rapporti causali sono due cose molto diverse. Statistiche quali AIC, WAIC e LOO-CV consentono di individuare modelli con buone capacità predittive. Tali modelli, tuttavia, non riflettono necessariamente la struttura causale del fenomeno considerato: la selezione di modelli basata unicamente sull'accuratezza predittiva non garantisce che venga selezionato il modello che riflette la struttura causale del fenomeno \citep[si veda anche][]{navarro2019between}.}

Considereremo qui un confronto di modelli di regressione. Il modello di regressione discusso nel Paragrafo precedente prevede il QI dei bambini dal QI delle madri. Aggiungiamo a tale modello un secondo predittore che corrisponde all'età della madre. L'aggiunta di tale predittore migliori l'accuratezza predittiva del modello?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] x1;}
\StringTok{  vector[N] x2;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta1;}
\StringTok{  real beta2;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    mu[n] = alpha + beta1*x1[n] + beta2*x2[n];}
\StringTok{  \}}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta1 \textasciitilde{} normal(0, 1);}
\StringTok{  beta2 \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 1);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  vector[N] log\_lik;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    y\_rep[n] = normal\_rng(mu[n], sigma);}
\StringTok{    log\_lik[n] = normal\_lpdf(y[n] | x1[n] * beta1 + x2[n] * beta2, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/mreg2.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{x2 }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{mom\_age)[, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data2\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x1,}
  \AttributeTok{x2 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file2 }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"mreg2.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# compile model}
\NormalTok{mod2 }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file2)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Running MCMC}
\NormalTok{fit2 }\OtherTok{\textless{}{-}}\NormalTok{ mod2}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data2\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit2}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta1"}\NormalTok{, }\StringTok{"beta2"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 10}
\CommentTok{\#\textgreater{}   variable      mean    median     sd    mad      q5}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}        \textless{}dbl\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    {-}0.000255 {-}0.000162 0.0431 0.0427 {-}0.0714}
\CommentTok{\#\textgreater{} 2 beta1     0.442     0.442    0.0427 0.0427  0.372 }
\CommentTok{\#\textgreater{} 3 beta2     0.0515    0.0514   0.0427 0.0428 {-}0.0179}
\CommentTok{\#\textgreater{} 4 sigma     0.896     0.895    0.0305 0.0303  0.848 }
\CommentTok{\#\textgreater{} \# ... with 4 more variables: q95 \textless{}dbl\textgreater{}, rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo2\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit2}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\FunctionTok{print}\NormalTok{(loo2\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}568.9 14.5}
\CommentTok{\#\textgreater{} p\_loo         3.0  0.3}
\CommentTok{\#\textgreater{} looic      1137.8 29.0}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is 0.0.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All Pareto k estimates are good (k \textless{} 0.5).}
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Consideriamo infine un terzo modello che utilizza come predittori, oltre al QI della madre, una variabile dicotomica (codificata 0 o 1) che distingue madri che hanno completato le scuole superiori da quelle che non le hanno completate. Nuovamente, la domanda è se l'aggiunta di tale predittore migliori la capacità predittiva del modello.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{modelString }\OtherTok{=} \StringTok{"}
\StringTok{data \{}
\StringTok{  int\textless{}lower=0\textgreater{} N;}
\StringTok{  vector[N] x1;}
\StringTok{  vector[N] x3;}
\StringTok{  vector[N] y;}
\StringTok{\}}
\StringTok{parameters \{}
\StringTok{  real alpha;}
\StringTok{  real beta1;}
\StringTok{  real beta3;}
\StringTok{  real\textless{}lower=0\textgreater{} sigma;}
\StringTok{\}}
\StringTok{transformed parameters \{}
\StringTok{  vector[N] mu;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    mu[n] = alpha + beta1*x1[n] + beta3*x3[n];}
\StringTok{  \}}
\StringTok{\}}
\StringTok{model \{}
\StringTok{  alpha \textasciitilde{} normal(0, 1);}
\StringTok{  beta1 \textasciitilde{} normal(0, 1);}
\StringTok{  beta3 \textasciitilde{} normal(0, 1);}
\StringTok{  sigma \textasciitilde{} cauchy(0, 1);}
\StringTok{  y \textasciitilde{} normal(mu, sigma);}
\StringTok{\}}
\StringTok{generated quantities \{}
\StringTok{  vector[N] y\_rep;}
\StringTok{  vector[N] log\_lik;}
\StringTok{  for (n in 1:N)\{}
\StringTok{    y\_rep[n] = normal\_rng(mu[n], sigma);}
\StringTok{    log\_lik[n] = normal\_lpdf(y[n] | x1[n] * beta1 + x3[n] * beta3, sigma);}
\StringTok{  \}}
\StringTok{\}}
\StringTok{"}
\FunctionTok{writeLines}\NormalTok{(modelString, }\AttributeTok{con =} \StringTok{"code/mreg3.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df}\SpecialCharTok{$}\NormalTok{x3 }\OtherTok{\textless{}{-}}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{mom\_hs}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data3\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x1,}
  \AttributeTok{x3 =}\NormalTok{ df}\SpecialCharTok{$}\NormalTok{x3}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{file3 }\OtherTok{\textless{}{-}} \FunctionTok{file.path}\NormalTok{(}\StringTok{"code"}\NormalTok{, }\StringTok{"mreg3.stan"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod3 }\OtherTok{\textless{}{-}} \FunctionTok{cmdstan\_model}\NormalTok{(file3)}
\end{Highlighting}
\end{Shaded}

<<<<<<< HEAD
=======
\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-584-1} \end{center}

Coloriamo ora in maniera diversa i punti che rappresentano animali carnivori, erbivori, ecc.

>>>>>>> main
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit3 }\OtherTok{\textless{}{-}}\NormalTok{ mod3}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data3\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

<<<<<<< HEAD
=======
\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-585-1} \end{center}

È chiaro, senza fare alcuna analisi statistica, che la relazione tra le due variabili non è lineare. Trasformando in maniera logaritmica i valori dell'asse \(x\) la relazione si linearizza.

>>>>>>> main
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit3}\SpecialCharTok{$}\FunctionTok{summary}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"alpha"}\NormalTok{, }\StringTok{"beta1"}\NormalTok{, }\StringTok{"beta3"}\NormalTok{, }\StringTok{"sigma"}\NormalTok{))}
\CommentTok{\#\textgreater{} \# A tibble: 4 x 10}
\CommentTok{\#\textgreater{}   variable   mean median     sd    mad     q5     q95}
\CommentTok{\#\textgreater{}   \textless{}chr\textgreater{}     \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}  \textless{}dbl\textgreater{}   \textless{}dbl\textgreater{}}
\CommentTok{\#\textgreater{} 1 alpha    {-}0.225 {-}0.224 0.0947 0.0945 {-}0.382 {-}0.0705}
\CommentTok{\#\textgreater{} 2 beta1     0.415  0.414 0.0449 0.0450  0.341  0.488 }
\CommentTok{\#\textgreater{} 3 beta3     0.286  0.285 0.108  0.108   0.111  0.465 }
\CommentTok{\#\textgreater{} 4 sigma     0.890  0.889 0.0302 0.0302  0.842  0.941 }
\CommentTok{\#\textgreater{} \# ... with 3 more variables: rhat \textless{}dbl\textgreater{},}
\CommentTok{\#\textgreater{} \#   ess\_bulk \textless{}dbl\textgreater{}, ess\_tail \textless{}dbl\textgreater{}}
\end{Highlighting}
\end{Shaded}

<<<<<<< HEAD
=======
\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-586-1} \end{center}

Infine, aggiustiamo il ``tema'' del grafico (si noti l'utilizzo di una tavolozza di colori adatta ai daltonici mediante il pacchetto \texttt{viridis}), aggiungiamo le etichette sugli assi e il titolo.

>>>>>>> main
\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo3\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit3}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\FunctionTok{print}\NormalTok{(loo3\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}584.2 16.4}
\CommentTok{\#\textgreater{} p\_loo         7.5  0.6}
\CommentTok{\#\textgreater{} looic      1168.3 32.8}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is 0.0.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} All Pareto k estimates are good (k \textless{} 0.5).}
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

<<<<<<< HEAD
Per eseguire un confronto tra modelli in termini della loro capacità predittiva esaminiamo la differenza di LOO-CV tra coppie di modelli. Le seguenti istruzioni \(\R\) producono la quantità \texttt{elpd\_diff}, ovvero la differenza tra stime della \(\elpd\) fornite da due modelli. Il primo argomento della funzione \texttt{loo\_compare()} specifica il modello che viene usato come confronto. Nella prima riga dell'output, il valore \texttt{elpd\_diff} è 0 (cioè, \(x − x = 0\)). Nelle righe successive sono riportate le differenze rispetto al modello di confronto (in questo caso, il modello 1). La colonna \texttt{se\_diff} riporta l'errore standard di tali differenze.
=======
\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-587-1} \end{center}

La visualizzazione può essere migliorata cambiando le etichette della legenda del grafico. Per fare questo è necessario intervenire sui dati prima di usare \texttt{ggplot()} -- per esempio, come abbiamo fatto in precedenza con la funzione \texttt{forcats::fct\_recode()}.

\hypertarget{istogramma-1}{%
\subsubsection{Istogramma}\label{istogramma-1}}
>>>>>>> main

L'incertezza della stima dell'accuratezza \emph{out-of-sample} si distribuisce in maniera approssimativamente normale con media uguale al valore riportato dal software e deviazione standard uguale a ciò che è indicato nell'output come errore standard. Quando il campione è piccolo, questa approssimazione produce una forte sottostima dell'incertezza, ma fornisce comunque una stima migliore di AIC, DIC e WAIC.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{loo\_compare}\NormalTok{(loo1\_result, loo2\_result, loo3\_result)}
\FunctionTok{print}\NormalTok{(w)}
\CommentTok{\#\textgreater{}        elpd\_diff se\_diff}
\CommentTok{\#\textgreater{} model1   0.0       0.0  }
\CommentTok{\#\textgreater{} model2  {-}0.3       1.3  }
\CommentTok{\#\textgreater{} model3 {-}15.6       6.0}
\end{Highlighting}
\end{Shaded}

<<<<<<< HEAD
Per interpretare l'output, usiamo il criterio suggerito da \citet{gelman1995bayesian}: consideriamo ``credibile'' una differenza se \texttt{elpd\_diff} è almeno due volte maggiore di \texttt{se\_diff}. Nel caso presente, dunque, il confronto tra il modello 2 e il modello 1 indica che la quantità \texttt{elpd\_diff} è molto piccola rispetto al suo errore standard. Questo accade se un predittore è associato in modo trascurabile con la variabile dipendente. I dati presenti, dunque, non offrono alcuna evidenza che aggiungere dell'età della madre come predittore migliori la capacità predittiva del modello. Nel confronto tra modello 3 e modello 1, invece, la quantità \texttt{elpd\_diff} è maggiore di due volte il valore dell'errore standard. Questo suggerisce un incremento della capacità predittiva del modello quiando il livello di istruzione della madre viene incluso tra i predittori.
=======
\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-588-1} \end{center}

\hypertarget{scrivere-il-codice-r-con-stile}{%
\subsection{\texorpdfstring{Scrivere il codice \texttt{R} con stile}{Scrivere il codice R con stile}}\label{scrivere-il-codice-r-con-stile}}

Uno stile di programmazione è un insieme di regole per la gestione dell'indentazione dei blocchi di codice, per la creazione dei nomi dei file e delle variabili e per le convenzioni tipografiche che vengono usate. Scrivere il codice in \texttt{R} con stile consente di creare listati più leggibili e semplici da modificare, minimizza la possibilità di errore, e consente correzioni e modifiche più rapide. Vi sono molteplici stili di programmazione che possono essere utilizzati dall'utente, anche se è bene attenersi a quelle che sono le convenzioni maggiormente diffuse, allo scopo di favorire la comunicazione. In ogni caso, l'importante è di essere coerenti, ovvero di adottare le stesse convenzioni in tutte le parti del codice che si scrive. Ad esempio, se si sceglie di usare lo stile \texttt{snake\_case} per il nome composto di una variabile (es., \texttt{personality\_trait}), non è appropriato usare lo stile \emph{lower Camel case} per un'altra variabile (es., \texttt{socialStatus}). Dato che questo argomento è stato trattato ampiamente in varie sedi, mi limito qui a rimandare ad uno \href{http://style.tidyverse.org/}{stile di programmazione} molto popolare, quello proposto da Hadley Wickham, il creatore di \texttt{tidyverse}. La soluzione più semplice è quella installare \texttt{stiler}, che è uno RStudio Addin, e formattare il codice in maniera automatica utilizzando lo stile proposto da Hadley Wickham. Si possono ottenere informazioni su \texttt{stiler} seguendo questo \href{https://github.com/r-lib/styler}{link}.

\hypertarget{ottenere-informazioni-sulle-funzioni-r}{%
\section{\texorpdfstring{Ottenere informazioni sulle funzioni \(\R\)}{Ottenere informazioni sulle funzioni \textbackslash R}}\label{ottenere-informazioni-sulle-funzioni-r}}
>>>>>>> main

È anche possibile calcolare l'intervallo di credibilità per \texttt{elpd\_diff}:

\begin{Shaded}
\begin{Highlighting}[]
\FloatTok{15.5} \SpecialCharTok{+} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FunctionTok{qnorm}\NormalTok{(.}\DecValTok{95}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{*} \FloatTok{6.0}
\CommentTok{\#\textgreater{} [1]  5.631 25.369}
\end{Highlighting}
\end{Shaded}

\hypertarget{outlier}{%
\section{Outlier}\label{outlier}}

Si è soliti pensare che la maggior parte delle osservazioni del campione sia prodotta da un unico meccanismo generatore dei dati, mentre le rimanenti osservazioni sono la realizzazione di un diverso processo stocastico. Le osservazioni che appartengono a questo secondo gruppo si chiamano \emph{outlier}. È dunque necessario identificare gli outlier e limitare la loro influenza sull'inferenza.\footnote{\citet{McElreath_rethinking} nota che, spesso, i ricercatori eliminano i valori anomali prima di adattare un modello ai dati, basandosi solo sulla distanza dal valore medio della variabile dipendente misurata in termini di unità di deviazione standard. Secondo \citet{McElreath_rethinking} questo non dovrebbe mai essere fatto: un'osservazione può essere considerata come un valore anomalo o un valore influente solo alla luce delle predizioni di un modello (mai prima di avere adattato il modello ai dati). Se ci sono solo pochi valori anomali una strategia possibile è quella di riportare i risultati delle analisi statistiche svolte su tutto il campione dei dati oppure dopo avere eliminato le osservazioni anomale e influenti.}

Poniamoci ora il problema di identificare gli outlier con la tecnica PSIS-LOO-CV. Quando PSIS-LOO-CV viene calcolato con il pacchetto \texttt{loo}, l'output riporta il parametro di forma della distribuzione di Pareto (valore \texttt{k}). Tale valore può essere utilizzato per identificare gli outlier. Infatti, il valore \texttt{k} valuta, per ciascun punto del campione, l'approssimazione usata da PSIS-LOO-CV. Se \(k < 0.5\), i pesi di importanza vengono stimati in modo accurato; se il valore \(k\) di Pareto di un punto è \(> 0.7\), i pesi di importanza possono essere inaccurati. Le osservazioni con \(k > 0.7\) sono dunque osservazioni outlier.

Per fare un esempio concreto, introduciamo nel campione dell'esempio precedente una singola osservazione outlier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df1 }\OtherTok{\textless{}{-}}\NormalTok{ df}
\FunctionTok{dim}\NormalTok{(df1)}
\CommentTok{\#\textgreater{} [1] 434   9}
\NormalTok{df1}\SpecialCharTok{$}\NormalTok{x1[}\DecValTok{434}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{10}
\NormalTok{df1}\SpecialCharTok{$}\NormalTok{y[}\DecValTok{434}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{10}
\end{Highlighting}
\end{Shaded}

Sistemiamo i dati nel formato appropriato per Stan:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data1a\_list }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{N =} \FunctionTok{length}\NormalTok{(df1}\SpecialCharTok{$}\NormalTok{kid\_score),}
  \AttributeTok{y =}\NormalTok{ df1}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{x1 =}\NormalTok{ df1}\SpecialCharTok{$}\NormalTok{x1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Adattiamo nuovamente il modello 1 ad un campione di dati che contiene un outlier.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1a }\OtherTok{\textless{}{-}}\NormalTok{ mod1}\SpecialCharTok{$}\FunctionTok{sample}\NormalTok{(}
  \AttributeTok{data =}\NormalTok{ data1a\_list,}
  \AttributeTok{iter\_sampling =}\NormalTok{ 4000L,}
  \AttributeTok{iter\_warmup =}\NormalTok{ 2000L,}
  \AttributeTok{seed =}\NormalTok{ SEED,}
  \AttributeTok{chains =}\NormalTok{ 4L,}
  \AttributeTok{parallel\_chains =}\NormalTok{ 2L,}
  \AttributeTok{cores =}\NormalTok{ 4L,}
  \AttributeTok{refresh =} \DecValTok{0}\NormalTok{,}
  \AttributeTok{thin =} \DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo1a\_result }\OtherTok{\textless{}{-}}\NormalTok{ fit1a}\SpecialCharTok{$}\FunctionTok{loo}\NormalTok{(}\AttributeTok{cores =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Una tabella diagnostica che riassume le stime dei parametri di forma della distribuzione di Pareto si ottiene nel modo seguente:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(loo1a\_result)}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Computed from 16000 by 434 log{-}likelihood matrix}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{}          Estimate   SE}
\CommentTok{\#\textgreater{} elpd\_loo   {-}586.2 19.9}
\CommentTok{\#\textgreater{} p\_loo         6.6  5.0}
\CommentTok{\#\textgreater{} looic      1172.5 39.8}
\CommentTok{\#\textgreater{} {-}{-}{-}{-}{-}{-}}
\CommentTok{\#\textgreater{} Monte Carlo SE of elpd\_loo is NA.}
\CommentTok{\#\textgreater{} }
\CommentTok{\#\textgreater{} Pareto k diagnostic values:}
\CommentTok{\#\textgreater{}                          Count Pct.    Min. n\_eff}
\CommentTok{\#\textgreater{} ({-}Inf, 0.5]   (good)     433   99.8\%   10708     }
\CommentTok{\#\textgreater{}  (0.5, 0.7]   (ok)         0    0.0\%   \textless{}NA\textgreater{}      }
\CommentTok{\#\textgreater{}    (0.7, 1]   (bad)        1    0.2\%   75        }
\CommentTok{\#\textgreater{}    (1, Inf)   (very bad)   0    0.0\%   \textless{}NA\textgreater{}      }
\CommentTok{\#\textgreater{} See help(\textquotesingle{}pareto{-}k{-}diagnostic\textquotesingle{}) for details.}
\end{Highlighting}
\end{Shaded}

Un grafico che riporta le stime dei parametri di forma della distribuzione di Pareto per ciascuna osservazione è dato da:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(loo1a\_result)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics{ds4psy_files/figure-latex/unnamed-chunk-55-1} \end{center}

Il valore \texttt{k} stimato da PSIS-LOO-CV mette chiaramente in luce il fatto che il valore introdotto nel campione è un outlier. L'indice dell'osservazione outlier è identificato con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pareto\_k\_ids}\NormalTok{(loo1a\_result, }\AttributeTok{threshold =} \FloatTok{0.7}\NormalTok{)}
\CommentTok{\#\textgreater{} [1] 434}
\end{Highlighting}
\end{Shaded}

\hypertarget{regolarizzazione}{%
\section{Regolarizzazione}\label{regolarizzazione}}

Abbiamo motivato la presente discussione affermando che uno dei problemi più grandi che i ricercatori devono afforntare è quello della generalizzabilità dei loro risultati. \citet{McElreath_rethinking} fa notare che un modo per favorire la capacità del modello di generalizzarsi a nuovi campioni è quello di fare in modo che produca un adattamento \emph{peggiore} ai dati del campione presente. Il problema del sovra-adattamento (e quindi di una bassa generalizzabilità) dipende dal fatto che tutte le regolarità presenti nei dati del campione ``vengono egualmente prese sul serio'' da un modello che utilizza prior uniformi per i parametri. In tali circostanze, \emph{qualsiasi} valore dei parametri viene considerato plausibile. Un modo per evitare un tale modo di pensare, che sicuramente è inadeguato, è quello di utilizzare dei prior che \citet{McElreath_rethinking} chiama ``scettici''. I priori ``scettici'' più comuni sono quelli che hanno una funzione di regolarizzazione. Tali prior, se calibrati correttamente, riducono il sovra-adattamento pur consentendo al modello di rappresentare le regolarità che sono osservate nel campione. Se il prio è ``troppo scettico'', tuttavia, le regolarità presenti nei dati dal campione non emergeranno, producendo, di conseguenza, un sotto-adattamento. Il problema è dunque quello di trovare l'equilibrio giusto tra queste due opposte tendenze. La buona notizia è che anche un prior ``moderatamente scettico'' fornisce un grande aiuto al modello, e questo è tutto quello che possiamo ottenere dato che, se vogliamo rendere conto delle proprietà del mondo empirico, non ci sono né modelli né distribuzioni a priori ottimali (ovvero, che non possono essere migliorati).

Consideriao un modello lineare, ad esempio. Se standardizziamo i dati, un prior \(\beta ~ Normal(0, 1)\) per la pendenza della retta di regressione ci dice che, prima di osservare i dati, il modello si dimostra molto scettico rispetto ai valori possibili di \(\beta\) esterni all'intervallo \([-2, 2]\) deviazioni standard. In altri termini, ritiene che sia molto improbabile che un cambiamento di di 1 deviazione standard nella \(x\) sia associato ad un cambiamento medio nella \(y\) superiore a 2 unità di deviazione standard.

Ma potremmo anche usare una distribuzione a priori gaussiana con parametro \(\sigma\) uguale a 0.5 oppure a 0.2. Quale prior usare dipende dal modello e dai dati -- non c'è una raccomandazione sempre valida. I prior ``molto scettici'' hanno l'effetto maggiore sui modelli complessi e nel caso di piccole numerosità campionarie -- ovvero, proprio nei casi in cui il rischio del sovra-adattamento è più grande. Se il campione è sufficientemente grande e il modello non è eccessivamente complesso, i prior, quali essi siano, avranno invece un effetto trascurabile sulla stima della distribuzione a posteriori.

\hypertarget{commenti-e-considerazioni-finali-2}{%
\section*{Commenti e considerazioni finali}\label{commenti-e-considerazioni-finali-2}}


In questo Capitolo, abbiamo imparato come usare la convalida incrociata K-fold e la convalida incrociata leave-one-out, utilizzando Stan insieme al pacchetto \texttt{loo}. Abbiamo esaminato alcuni esempi di confronto di modelli in cui la convalida incrociata ci consente di distinguere tra due modelli. In generale, la convalida incrociata sarà utile quando si confrontano modelli piuttosto diversi; quando i modelli sono molto simili, invece, sarà difficile distinguerli. In particolare, per i dati tipici della psicologia, sarà difficile ottenere risultati conclusivi dai confronti di modelli tramite la convalida incrociata se l'effetto è molto piccolo e/o il campione di dati è piccolo. In questi casi, se l'obiettivo è trovare prove a sostengo di un'affermazione teorica, alcuni ricercatori ritengono che altri metodi di confronto dei modelli siano più utili, come ad esempio i fattori di Bayes. L'uso dei fattori di Bayes, tuttavia, è controverso, dato che essi dipendono fortemente dalla scelta delle distribuzioni a priori. Se possibile sarebbe preferibile utilizzare le procedure descritte in questa parte della dispensa, con campioni di ampiezza adeguata.

  \bibliography{refs.bib,book.bib,packages.bib}

\printindex

\end{document}
