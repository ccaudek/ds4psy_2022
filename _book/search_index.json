[["ch-prediction.html", "Capitolo 2 La predizione bayesiana", " Capitolo 2 La predizione bayesiana Oltre ad una sintesi della distribuzione a posteriori attraverso il computo di indici caratteristici e alla verifica di ipotesi, un altro compito dell’analisi bayesiana è la predizione di nuovi dati futuri. Dopo aver osservato i dati di un campione e ottenuto le distribuzioni a posteriori dei parametri, è infatti possibile ottenere una qualche indicazione su come potrebbero essere i dati futuri. L’uso più immediato della stima della distribuzione dei possibili valori futuri della variabile di esito è la verifica del modello. Infatti, il modo più diretto per testare un modello è quello di utilizzare il modello per fare previsioni sui possibili dati futuri per poi confrontare i dati predetti con i dati effettivi. Questa pratica va sotto il nome di controllo predittivo a posteriori. Inizieremo a discutere questo argomento considerando il problema della predizione bayesiana nel caso più semplice, ovvero nel caso dello schema beta-binomiale. Estenderemo poi la discussione al caso generale nel capitolo successivo. "],["la-distribuzione-predittiva.html", "2.1 La distribuzione predittiva", " 2.1 La distribuzione predittiva Una volta costruita la distribuzione a posteriori del parametro \\(\\theta\\), potremmo essere interessati a utilizzare il nostro modello statistico allo scopo di prevedere la probabilità di risultati futuri basandosi sui dati storici. L’obiettivo è andare oltre la comprensione di cosa è successo per arrivare a una migliore valutazione di quello che accadrà in futuro. Questo tipo di analisi inferenziale va sotto il nome di analisi predittiva. L’analisi predittiva utilizza dunque i dati che sono già disponibili per sviluppare un modello che può essere utilizzato per prevedere valori di dati diversi o nuovi. Consideriamo qui il caso beta-binomiale nel quale la distribuzione a priori per il parametro \\(\\theta\\) (probabilità di successo) è una distribuzione Beta, la verosimiglianza è binomiale e i dati sono costituiti dal numero \\(y\\) di successi che è osservato in \\(n\\) prove Bernoulliane indipendenti. Nell’esempio, useremo un’altra volta i dati del campione di pazienti clinici depressi di Zetsche, Bürkner, and Renneberg (2019) – si veda l’Appendice ??. Supponendo di volere esaminare in futuro altri \\(m\\) pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave? Siamo interessati a predire i risultati che si potrebbero osservare in nuovi campioni di \\(m\\) osservazioni. Denotiamo con \\(\\tilde{y}\\) la manifestazione della variabile casuale \\(\\tilde{Y}\\). In un nuovo campione di \\(m\\) osservazioni, \\(\\tilde{y}\\) può assumere il valore di \\(\\tilde{y}_1\\), in un altro campione il valore di \\(\\tilde{y}_2\\), e così via. Siamo interessati a descrivere la distribuzione predittiva a posteriori \\(p(\\tilde{Y} = \\tilde{y} \\mid Y = y)\\). Nel caso dell’esempio in discussione, la distribuzione di \\(\\tilde{Y}\\) dipende da \\(\\theta\\) e la nostra conoscenza corrente di \\(\\theta\\) è fornita dalla distribuzione a posteriori. Usando la regola della catena, possiamo scrivere la distribuzione congiunta di \\(\\tilde{Y}\\) e \\(\\theta\\) nel modo seguente \\[\\begin{equation} p(\\tilde{Y} = \\tilde{y}, \\theta \\mid Y = y) = p(\\tilde{Y} = \\tilde{y} \\mid \\theta) p(\\theta \\mid Y = y). \\end{equation}\\] Integrando su \\(\\theta\\) otteniamo la distribuzione predittiva a posteriori: \\[\\begin{equation} p(\\tilde{y} \\mid y) = \\int_{\\theta} p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y) \\,\\operatorname {d}\\!\\theta. \\end{equation}\\] Nel caso dello schema beta-binomiale, la funzione \\(p(\\tilde{y} \\mid \\theta)\\) è binomiale di parametri \\(m\\) e \\(\\theta\\), e la distribuzione a posteriori \\(p(\\theta \\mid y)\\) è \\(\\mbox{Beta}(\\alpha + y, \\beta + n - y)\\). Risolvendo l’integrale otteniamo: \\[\\begin{align} p(\\tilde{y} \\mid y) &amp;= \\int_0^1 p(\\tilde{y} \\mid \\theta) p(\\theta \\mid y)\\,\\operatorname {d}\\!\\theta \\notag\\\\ &amp;= \\int_0^1 \\begin{pmatrix}m\\\\\\tilde{y}\\end{pmatrix} \\theta^{\\tilde{y}} (1-\\theta)^{m-\\tilde{y}} \\mbox{Beta}(a+y,b+n-y) \\, d\\theta \\notag\\\\ &amp;= \\begin{pmatrix}{m}\\\\\\tilde{y}\\end{pmatrix} \\int_0^1 \\theta^{\\tilde{y}} (1-\\theta)^{m-\\tilde{y}} \\frac{1}{B(a+y, b+n-y)}\\theta^{a+y-1}(1-\\theta)^{b+n-y-1}\\notag\\\\ &amp;= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{1}{B(a+y, b+n-y)}\\int_0^1 \\theta^{\\tilde{y}+a+y-1}(1-\\theta)^{m-\\tilde{y}+b+n-y-1}\\notag\\\\ &amp;= \\begin{pmatrix}{ m }\\\\\\tilde{y}\\end{pmatrix} \\frac{B(\\tilde{y}+a+y,b+n-y+m-\\tilde{y})}{B(a+y, b+n-y)} \\; . \\tag{2.1} \\end{align}\\] In conclusione, per lo schema beta-binomiale, la distribuzione predittiva a posteriori è \\[\\begin{equation} f(\\tilde{y} \\mid y) = \\binom{m}{\\tilde{y}} \\frac{B(a+ y + \\tilde{y}, b + n - y + m - \\tilde{y})}{B(a+y, b+n-y)}, \\end{equation}\\] ovvero, corrisponde ad una distribuzione di probabilità discreta chiamata distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\). La distribuzione beta-binomiale di parametri \\(N\\), \\(\\alpha\\) e \\(\\beta\\) è una distribuzione discreta con una funzione di massa di probabilità uguale a \\[ BetaBinomial(y \\mid N, \\alpha, \\beta) = \\binom{N}{y} \\frac{B(y + \\alpha, N-y+\\beta)}{B(\\alpha, \\beta)}, \\] dove la funzione beta è \\(B(u, v) = \\frac{\\Gamma(u)\\Gamma(v)}{\\Gamma(u+v)}\\). La distribuzione beta-binomiale è una distribuzione che non abbiamo discusso in precedenza e che useremo solo in questo contesto. Senza entrare nei dettagli, ci accontentiamo di sapere che tale distribuzione è implementata nella funzione dbbinom() del pacchetto extraDistr. Il significato dei parametri è chiarito nell’esempio discusso di seguito. Nell’esempio che stiamo discutendo, relativo allo studio di Zetsche, Bürkner, and Renneberg (2019), la verosimiglianza è binomiale, i dati sono costituiti da 23 successi su 30 prove e la distribuzione a priori su \\(\\theta\\) è \\(\\mbox{Beta}(2, 10)\\); di conseguenza la distribuzione a posteriori è \\(\\mbox{Beta}(25, 17)\\). Vogliamo calcolare la distribuzione predittiva a posteriori per un nuovo campione di \\(m = 20\\) osservazioni. Utilizzando il risultato precedente, la distribuzione predittiva sarà una beta-binomiale di parametri \\(m\\), \\(\\alpha+y\\) e \\(\\beta+n-y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le quantità della verosimiglianza. Nel caso dell’esempio, dunque, \\(m = 20\\), \\(\\alpha = 2 + 23 = 25\\), \\(\\beta = 10 + 30 - 23 = 17\\). Svolgendo i calcoli con la funzione dbbinom() possiamo ottenere un grafico della distribuzione predittiva a posteriori nel modo seguente: prob &lt;- extraDistr::dbbinom(0:20, 20, 25, 17) tibble(Y = 0:20, Probability = prob) %&gt;% ProbBayes::prob_plot(Color = &quot;black&quot;) La distribuzione predittiva a posteriori illustrata nella figura ci dice qual è la plausibilità di osservare \\(0, 1, \\dots, 20\\) successi su \\(m = 20\\) prove in un futuro campione di osservazioni, alla luce dei dati che abbiamo osservato nel campione corrente (23 successi in 30 prove), e considerate le nostre opinioni a priori sul valore \\(\\theta\\) (ovvero, \\(\\mbox{Beta}(2, 10)\\)). Esaminando la distribuzione predittiva notiamo che, in campioni futuri di 20 osservazioni, il valore più plausibile per \\(\\tilde{y}\\) è 12. Tuttavia, \\(\\tilde{y}\\) può assumere anche altri valori e la distribuzione predittiva ci informa sulla plausibilità relativa di ciascuno di tali possibili valori futuri \\(\\tilde{y}\\). È desiderabile costruire un intervallo che contiene \\(\\tilde{Y}\\) ad un livello specificato di probabilità. Supponiamo che il livello di probabilità sia 0.89. L’intervallo si costruisce aggiungendo valori \\(\\tilde{y}\\) all’intervallo fino a che il contenuto di probabilità dell’insieme eccede la soglia di 0.89. La procedura è implementata nella funzione discint() del pacchetto LearnBayes. Per i dati dell’esempio otteniamo LearnBayes::discint(cbind(0:20, prob), 0.89) #&gt; $prob #&gt; [1] 0.9144721 #&gt; #&gt; $set #&gt; [1] 8 9 10 11 12 13 14 15 16 da cui \\[ P(8 \\leq \\tilde{Y} \\leq 16) = 0.9145. \\] References "],["simulazione-della-distribuzione-predittiva-a-posteriori.html", "2.2 Simulazione della distribuzione predittiva a posteriori", " 2.2 Simulazione della distribuzione predittiva a posteriori In situazioni dove è difficile derivare l’esatta distribuzione predittiva a posteriori è possibile simulare valori estratti da tale distribuzione. Consideriamo un esempio riferito all’esempio che stiamo discutendo. È possibile implementare una simulazione predittiva estraendo prima i valori del parametro (in questo caso, \\(\\theta\\)) dalla distribuzione a posteriori. Con i valori del parametro così determinati, poi, si possono generare i valori delle possibili osservazioni future (nel caso presente, usando la distribuzione binomiale). Per l’esempio che stiamo discutendo, la distribuzione a posteriori è una Beta(25, 17). Estaiamo 100,000 valori da tale distribuzione: set.seed(12345) a &lt;- 2 b &lt;- 10 n &lt;- 30 y &lt;- 23 pred_p_sim &lt;- rbeta(1e5, a + y, b + n - y) pred_y_sim &lt;- rbinom(1e5, n, pred_p_sim) ppd &lt;- table(pred_y_sim) / 1e5 ppd #&gt; pred_y_sim #&gt; 3 4 5 6 7 8 9 10 11 12 #&gt; 0.00002 0.00004 0.00011 0.00036 0.00096 0.00241 0.00533 0.01000 0.01753 0.02882 #&gt; 13 14 15 16 17 18 19 20 21 22 #&gt; 0.04290 0.06110 0.07812 0.09476 0.10763 0.11311 0.10821 0.09765 0.07982 0.06185 #&gt; 23 24 25 26 27 28 29 30 #&gt; 0.04156 0.02536 0.01299 0.00630 0.00224 0.00064 0.00016 0.00002 LearnBayes::discint(cbind(3:30, ppd), 0.89) #&gt; $prob #&gt; 12 #&gt; 0.91553 #&gt; #&gt; $set #&gt; 12 13 14 15 16 17 18 19 20 21 22 23 #&gt; 12 13 14 15 16 17 18 19 20 21 22 23 Confrontiamo i valori prodotti dalla simulazione con i valori esatti della distribuzione predittiva a posteriori: prob30 &lt;- extraDistr::dbbinom(0:30, 30, 25, 17) LearnBayes::discint(cbind(0:30, prob30), 0.89) #&gt; $prob #&gt; [1] 0.9152885 #&gt; #&gt; $set #&gt; [1] 12 13 14 15 16 17 18 19 20 21 22 23 La distribuzione predittiva a posteriori esatta è tibble(Y = 0:30, Probability = prob30) %&gt;% ProbBayes::prob_plot(Color = &quot;black&quot;) Una rappresentazione della distribuzione a posteriori ottenuta mediante simulazione è tibble(Y = 0:30, Probability = c(0, 0, 0, ppd)) %&gt;% ProbBayes::prob_plot(Color = &quot;black&quot;) Si noti la somiglianza tra le due distribuzioni. In conclusione, per il caso che abbiamo discusso, la predizione bayesiana di una nuova osservazione è una distribuzione beta-binomiale di parametri \\(m\\), \\(\\alpha + y\\), e \\(\\beta + n - y\\), dove \\(m\\) è il numero di prove nel nuovo campione, \\(\\alpha\\) e \\(\\beta\\) sono i parametri della distribuzione a priori, e \\(y\\) e \\(n\\) sono le quantità della verosimiglianza. Ricordiamo che, nello schema beta-binomiale, la distribuzione a posteriori è una Beta di parametri \\(\\alpha + y\\) e \\(\\beta + n - y\\). Quindi, detto in un altro modo, nello schema beta-binomiale la distribuzione predittiva a posteriori è una distribuzione beta-binomiale i cui tre parametri sono \\(m\\) (la numerosità del nuovo campione) e i due parametri di forma della distribuzione Beta che descrive la distribuzione a posteriori. "],["metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html", "2.3 Metodi MCMC per la distribuzione predittiva a posteriori", " 2.3 Metodi MCMC per la distribuzione predittiva a posteriori Il metodo basato su simulazione che abbiamo discusso nel paragrafo precedente viene utilizzato per ottenere un’approssimazione della distribuzione predittiva a posteriori quando l’inferenza bayesiana viene svolta mediante l’utilizzo di metodi MCMC. Le stime delle possibili osservazioni future \\(p(\\tilde{y} \\mid y)\\), che vengono chiamate \\(p(y^{rep} \\mid y)\\), si ottengono nel modo seguente: campionare \\(\\theta_i \\sim p(\\theta \\mid y)\\), ovvero campionare un valore del parametro dalla distribuzione a posteriori; campionare \\(y^{rep} \\sim p(y^{rep} \\mid \\theta_i)\\), ovvero campionare il valore di un’osservazione dalla funzione di verosimiglianza condizionata al valore del parametro definito nel passo precedente. Se i due passaggi descritti sopra vengono ripetuti un numero sufficiente di volte, l’istogramma risultante approssimerà la distribuzione predittiva a posteriori che, in teoria (ma non in pratica) potrebbe essere ottenuta per via analitica. Esercizio 2.1 Riportiamo qui sotto il codice Stan per generare \\(p(y^{rep} \\mid y)\\) nel caso dell’inferenza su una proporzione. modelString &lt;- &quot; data { int&lt;lower=0&gt; N; int&lt;lower=0, upper=1&gt; y[N]; } parameters { real&lt;lower=0, upper=1&gt; theta; } model { theta ~ beta(2, 10); y ~ bernoulli(theta); } generated quantities { int y_rep[N]; real log_lik[N]; for (n in 1:N) { y_rep[n] = bernoulli_rng(theta); log_lik[n] = bernoulli_lpmf(y[n] | theta); } } &quot; writeLines(modelString, con = &quot;code/betabin23-30-2-10.stan&quot;) Si noti che nel nel blocco generated quantities sono state aggiunte le istruzioni necessarie per simulare \\(y^{rep}\\), ovvero, y_rep[n] = bernoulli_rng(theta). I dati dell’esempio sono: data_list &lt;- list( N = 30, y = c(rep(1, 23), rep(0, 7)) ) Compiliamo il codice Stan file &lt;- file.path(&quot;code&quot;, &quot;betabin23-30-2-10.stan&quot;) mod &lt;- cmdstan_model(file) ed eseguiamo il campionamento MCMC: fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, cores = 4L, chains = 4L, parallel_chains = 4L, refresh = 0, thin = 1 ) Per comodità, trasformiamo l’oggetto fit in un oggetto di classe stanfit: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) Il contenuto dell’oggetto stanfit può essere esaminato nel modo seguente: list_of_draws &lt;- extract(stanfit) print(names(list_of_draws)) #&gt; [1] &quot;theta&quot; &quot;y_rep&quot; &quot;log_lik&quot; &quot;lp__&quot; Dall’oggetto list_of_draws recuperiamo y_rep: y_bern &lt;- list_of_draws$y_rep dim(y_bern) #&gt; [1] 16000 30 head(y_bern) #&gt; #&gt; iterations [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] #&gt; [1,] 1 1 1 1 0 1 1 1 1 1 1 1 1 #&gt; [2,] 0 1 0 1 1 1 0 0 1 0 0 0 0 #&gt; [3,] 0 1 0 1 1 1 0 0 1 1 1 0 1 #&gt; [4,] 1 0 0 1 1 0 0 1 0 1 1 1 0 #&gt; [5,] 0 0 0 1 1 0 1 1 0 1 0 0 1 #&gt; [6,] 1 1 1 1 1 1 0 1 0 1 1 1 0 #&gt; #&gt; iterations [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] #&gt; [1,] 0 1 1 1 1 1 0 0 1 0 1 #&gt; [2,] 1 0 0 1 0 1 1 1 0 0 0 #&gt; [3,] 0 0 1 0 1 1 0 1 0 0 1 #&gt; [4,] 0 1 0 1 0 1 0 0 1 0 1 #&gt; [5,] 0 0 1 1 1 1 1 0 1 0 1 #&gt; [6,] 1 1 0 1 0 1 1 0 0 1 0 #&gt; #&gt; iterations [,25] [,26] [,27] [,28] [,29] [,30] #&gt; [1,] 1 1 1 1 1 1 #&gt; [2,] 0 1 1 0 1 1 #&gt; [3,] 1 1 1 1 1 0 #&gt; [4,] 0 1 1 0 0 1 #&gt; [5,] 0 0 0 0 1 0 #&gt; [6,] 0 0 1 0 1 1 Dato che il codice Stan definisce un modello per i dati grezzi (ovvero, per ciascuna singola prova Bernoulliana del campione), ogni riga di y_bern include 30 colonne, ciascuna delle quali corrisponde ad un campione (\\(n\\) = 16000 in questa simulazione) di possibili valori futuri \\(y_i \\in \\{0, 1\\}\\). Per ottenere una stima della distribuzione predittiva a posteriori p(y_rep), ovvero, una stima della probabilità associata a ciascuno dei possibili numeri di “successi” in \\(N = 30\\) nuove prove future, è sufficiente calcolare la proporzione di valori 1 in ciascuna riga: tibble(y_rep = rowSums(y_bern)) %&gt;% ggplot(aes(x = y_rep, after_stat(density))) + geom_histogram(binwidth = 1) "],["posterior-predictive-checks.html", "2.4 Posterior predictive checks", " 2.4 Posterior predictive checks La distribuzione predittiva a posteriori viene utilizzata per eseguire i cosiddetti controlli predittivi a posteriori (Posterior Predictive Checks, PPC). Ricordiamo che la distribuzione predittiva a posteriori corrisponde alla simulazione di un campione di dati generati utilizzando le proprietà del modello adattato. Nei PPC si realizza un confronto grafico tra \\(p(y^{rep} \\mid y)\\) e i dati osservati \\(y\\). Confrontando visivamente gli aspetti chiave dei dati previsti futuri \\(y^{rep}\\) e dei dati osservati \\(y\\) possiamo determinare se il modello è adeguato. Oltre al confronto tra le distribuzioni \\(p(y)\\) e \\(p(y^{rep})\\) è anche possibile un confronto tra la distribuzione di varie statistiche descrittive, i cui valori sono calcolati su diversi campioni \\(y^{rep}\\), e le corrispondenti statistiche descrittive calcolate sui dati osservati. Vengono solitamente considerate statistiche descrittive quali la media, la varianza, la deviazione standard, il minimo o il massimo. Ma confronti di questo tipo sono possibili per qualunque statistica descrittiva. Questi confronti sono chiamati PPC. Esercizio 2.2 Esaminiamo ora un set di dati che non seguono la distribuzione normale (Gelman, Hill, and Vehtari 2020). I dati corrispondono ad una serie di misurazioni prese da Simon Newcomb nel 1882 come parte di un esperimento per stimare la velocità della luce. A questi dati verrà (inappropriatamente) adattata una distribuzione normale. L’obiettivo dell’esempio è quello di mostrare come i PPC possono rivelare la mancanza di adattamento di un modello ai dati. I PPC mostrano che il modo più semplice per verificare l’adattamento del modello è quello di visualizzare \\(y^{rep}\\) insieme ai dati effettivi. Iniziamo a caricare i dati: library(&quot;MASS&quot;) data(&quot;newcomb&quot;) Visualizziamo la distribuzione dei dati con un istogramma: tibble(newcomb) %&gt;% ggplot(aes(x = newcomb, after_stat(density))) + geom_histogram(binwidth = 1) Creiamo un oggetto di tipo list dove inserire i dati: data_list &lt;- list( y = newcomb, N = length(newcomb) ) Il codice Stan per il modello normale è il seguente: modelString &lt;- &quot; data { int&lt;lower=0&gt; N; vector[N] y; } parameters { real mu; real&lt;lower=0&gt; sigma; } model { mu ~ normal(25, 10); sigma ~ cauchy(0, 10); y ~ normal(mu, sigma); } generated quantities { vector[N] y_rep; for (n in 1:N) { y_rep[n] = normal_rng(mu, sigma); } } &quot; writeLines(modelString, con = &quot;code/newcomb.stan&quot;) Adattando il modello ai dati file &lt;- file.path(&quot;code&quot;, &quot;newcomb.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, cores = 4L, refresh = 0, thin = 1 ) otteniamo le seguenti stime dei parametri \\(\\mu\\) e \\(\\sigma\\): fit$summary(c(&quot;mu&quot;, &quot;sigma&quot;)) #&gt; # A tibble: 2 × 10 #&gt; variable mean median sd mad q5 q95 rhat ess_bulk ess_tail #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 mu 26.2 26.2 1.33 1.30 24.0 28.4 1.00 13305. 11189. #&gt; 2 sigma 10.9 10.8 0.958 0.943 9.40 12.5 1.00 12614. 10352. Trasformiamo fit in un oggetto stanfit: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) La distribuzione a posteriori di \\(\\mu\\) è mu_draws &lt;- as.matrix(stanfit, pars = &quot;mu&quot;) mcmc_areas(mu_draws, prob = 0.95) # color 95% interval Confrontiamo \\(\\mu\\) con la media di \\(y\\): mean(newcomb) #&gt; [1] 26.21212 Anche se trova la media giusta, il modello non è comunque adeguato a prevedere le altre proprietà della \\(y\\). Estraiamo \\(y^{rep}\\) dall’oggetto stanfit: y_rep &lt;- as.matrix(stanfit, pars = &quot;y_rep&quot;) dim(y_rep) #&gt; [1] 16000 66 I valori y_rep sono i dati della distribuzione predittiva a posteriori che sono stati simulati usando gli stessi valori \\(X\\) dei predittori utilizzati per adattare il modello. Il confronto tra l’istogramma della \\(y\\) e gli istogrammi di diversi campioni \\(y^{rep}\\) mostra una scarsa corrispondenza tra i due: ppc_hist(data_list$y, y_rep[1:8, ], binwidth = 1) Alla stessa conclusione si giunge tramite un confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\): ppc_dens_overlay(data_list$y, y_rep[1:50, ]) Generiamo ora i PPC per la media e il minimo della distribuzione: ppc_stat_2d(data_list$y, y_rep, stat = c(&quot;mean&quot;, &quot;min&quot;)) Mentre la media viene riprodotta accuratamente dal modello (come abbiamo visto sopra), ciò non è vero per il minimo dela distribuzione. L’origine di questa mancanza di adattamento è il fatto che la distribuzione delle misurazioni della velocità della luce è asimmetrica negativa. Dato che ci sono poche osservazioni nella coda negativa della distribuzione, solo per fare un esempio, utilizzeremo ora un secondo modello che ipotizza una distribuzione \\(t\\) di Student: modelString &lt;- &quot; data { int&lt;lower=0&gt; N; vector[N] y; } parameters { real mu; real&lt;lower=0&gt; sigma; real&lt;lower=0&gt; nu; } model { mu ~ normal(25, 10); sigma ~ cauchy(0, 10); nu ~ cauchy(0, 10); y ~ student_t(nu, mu, sigma); } generated quantities { vector[N] y_rep; for (n in 1:N) { y_rep[n] = student_t_rng(nu, mu, sigma); } } &quot; writeLines(modelString, con = &quot;code/newcomb2.stan&quot;) Adattiamo questo secondo modello ai dati. file &lt;- file.path(&quot;code&quot;, &quot;newcomb2.stan&quot;) mod &lt;- cmdstan_model(file) fit &lt;- mod$sample( data = data_list, iter_sampling = 4000L, iter_warmup = 2000L, seed = SEED, chains = 4L, cores = 4L, parallel_chains = 2L, refresh = 0, thin = 1 ) #&gt; Running MCMC with 4 parallel chains... #&gt; #&gt; Chain 1 finished in 0.3 seconds. #&gt; Chain 2 finished in 0.3 seconds. #&gt; Chain 3 finished in 0.3 seconds. #&gt; Chain 4 finished in 0.3 seconds. #&gt; #&gt; All 4 chains finished successfully. #&gt; Mean chain execution time: 0.3 seconds. #&gt; Total execution time: 0.4 seconds. Per questo secondo modello il confronto tra la funzione di densità empirica della \\(y\\) e quella di diversi campioni \\(y^{rep}\\) risulta adeguato: stanfit &lt;- rstan::read_stan_csv(fit$output_files()) y_rep &lt;- as.matrix(stanfit, pars = &quot;y_rep&quot;) ppc_dens_overlay(data_list$y, y_rep[1:50, ]) Inoltre, anche la statistica “minimo della distribuzione” viene ben predetta dal modello. ppc_stat_2d(data_list$y, y_rep, stat = c(&quot;mean&quot;, &quot;min&quot;)) In conclusione, per le misurazioni della velocità della luce di Newcomb l’accuratezza predittiva del modello basato sulla distribuzione \\(t\\) di Student è chiaramente migliore di quella del modello normale. References "],["commenti-e-considerazioni-finali-1.html", "Commenti e considerazioni finali", " Commenti e considerazioni finali Questo capitolo presenta i controlli predittivi a posteriori. A questo proposito è necessario notare un punto importante: i controlli predittivi a posteriori, quando suggeriscono un buon adattamento del modello alle caratterische dei dati previsti futuri \\(y^{rep}\\), non forniscono necessariamente una forte evidenza della capacità del modello di generalizzarsi a nuovi campioni di dati. Una tale evidenza sulla generalizzabilità del modello può solo essere fornita da studi di holdout validation, ovvero da studi nei quali viene utilizzato un nuovo campione di dati. Se i PPC mostrano un cattivo adattamento del modello ai dati previsti futuri, però, questo controllo fornisce una forte evidenza di una errata specificazione del modello. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
