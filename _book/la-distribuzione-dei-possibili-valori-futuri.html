<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13.1 La distribuzione dei possibili valori futuri | Data Science per psicologi</title>
  <meta name="description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="13.1 La distribuzione dei possibili valori futuri | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  <meta name="github-repo" content="ccaudek/ds4psy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13.1 La distribuzione dei possibili valori futuri | Data Science per psicologi" />
  
  <meta name="twitter:description" content="The first official book authored by the core R Markdown developers that provides a comprehensive and accurate reference to the R Markdown ecosystem. With R Markdown, you can easily create reproducible data analysis reports, presentations, dashboards, interactive applications, books, dissertations, websites, and journal articles, while enjoying the simplicity of Markdown and the great power of R and other languages." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-01-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter-ppc.html"/>
<link rel="next" href="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefazione</a>
<ul>
<li class="chapter" data-level="" data-path="la-psicologia-e-la-data-science.html"><a href="la-psicologia-e-la-data-science.html"><i class="fa fa-check"></i>La psicologia e la Data science</a></li>
<li class="chapter" data-level="" data-path="come-studiare.html"><a href="come-studiare.html"><i class="fa fa-check"></i>Come studiare</a></li>
<li class="chapter" data-level="" data-path="sviluppare-un-metodo-di-studio-efficace.html"><a href="sviluppare-un-metodo-di-studio-efficace.html"><i class="fa fa-check"></i>Sviluppare un metodo di studio efficace</a></li>
</ul></li>
<li class="part"><span><b>I Nozioni preliminari</b></span></li>
<li class="chapter" data-level="1" data-path="concetti-chiave.html"><a href="concetti-chiave.html"><i class="fa fa-check"></i><b>1</b> Concetti chiave</a>
<ul>
<li class="chapter" data-level="1.1" data-path="popolazioni-e-campioni.html"><a href="popolazioni-e-campioni.html"><i class="fa fa-check"></i><b>1.1</b> Popolazioni e campioni</a></li>
<li class="chapter" data-level="1.2" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html"><i class="fa fa-check"></i><b>1.2</b> Variabili e costanti</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#variabili-casuali"><i class="fa fa-check"></i><b>1.2.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="1.2.2" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#variabili-indipendenti-e-variabili-dipendenti"><i class="fa fa-check"></i><b>1.2.2</b> Variabili indipendenti e variabili dipendenti</a></li>
<li class="chapter" data-level="1.2.3" data-path="variabili-e-costanti.html"><a href="variabili-e-costanti.html#la-matrice-dei-dati"><i class="fa fa-check"></i><b>1.2.3</b> La matrice dei dati</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="parametri-e-modelli.html"><a href="parametri-e-modelli.html"><i class="fa fa-check"></i><b>1.3</b> Parametri e modelli</a></li>
<li class="chapter" data-level="1.4" data-path="effetto.html"><a href="effetto.html"><i class="fa fa-check"></i><b>1.4</b> Effetto</a></li>
<li class="chapter" data-level="1.5" data-path="stima-e-inferenza.html"><a href="stima-e-inferenza.html"><i class="fa fa-check"></i><b>1.5</b> Stima e inferenza</a></li>
<li class="chapter" data-level="1.6" data-path="metodi-e-procedure-della-psicologia.html"><a href="metodi-e-procedure-della-psicologia.html"><i class="fa fa-check"></i><b>1.6</b> Metodi e procedure della psicologia</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-misurazione.html"><a href="chapter-misurazione.html"><i class="fa fa-check"></i><b>2</b> La misurazione in psicologia</a>
<ul>
<li class="chapter" data-level="2.1" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html"><i class="fa fa-check"></i><b>2.1</b> Le scale di misura</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-nominale"><i class="fa fa-check"></i><b>2.1.1</b> Scala nominale</a></li>
<li class="chapter" data-level="2.1.2" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-ordinale"><i class="fa fa-check"></i><b>2.1.2</b> Scala ordinale</a></li>
<li class="chapter" data-level="2.1.3" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-ad-intervalli"><i class="fa fa-check"></i><b>2.1.3</b> Scala ad intervalli</a></li>
<li class="chapter" data-level="2.1.4" data-path="le-scale-di-misura.html"><a href="le-scale-di-misura.html#scala-di-rapporti"><i class="fa fa-check"></i><b>2.1.4</b> Scala di rapporti</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="gerarchia-dei-livelli-di-scala-di-misura.html"><a href="gerarchia-dei-livelli-di-scala-di-misura.html"><i class="fa fa-check"></i><b>2.2</b> Gerarchia dei livelli di scala di misura</a></li>
<li class="chapter" data-level="2.3" data-path="variabili-discrete-o-continue.html"><a href="variabili-discrete-o-continue.html"><i class="fa fa-check"></i><b>2.3</b> Variabili discrete o continue</a></li>
<li class="chapter" data-level="2.4" data-path="alcune-misure-sono-migliori-di-altre.html"><a href="alcune-misure-sono-migliori-di-altre.html"><i class="fa fa-check"></i><b>2.4</b> Alcune misure sono migliori di altre</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="alcune-misure-sono-migliori-di-altre.html"><a href="alcune-misure-sono-migliori-di-altre.html#tipologie-di-errori"><i class="fa fa-check"></i><b>2.4.1</b> Tipologie di errori</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="conclusioni.html"><a href="conclusioni.html"><i class="fa fa-check"></i>Conclusioni</a></li>
</ul></li>
<li class="part"><span><b>Statistica descrittiva ed analisi esplorativa dei dati</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stats.html"><a href="descriptive-stats.html"><i class="fa fa-check"></i><b>3</b> Statistica descrittiva</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-descript.html"><a href="chapter-descript.html"><i class="fa fa-check"></i><b>3.1</b> Introduzione all’esplorazione dei dati</a></li>
<li class="chapter" data-level="3.2" data-path="un-excursus-storico.html"><a href="un-excursus-storico.html"><i class="fa fa-check"></i><b>3.2</b> Un excursus storico</a></li>
<li class="chapter" data-level="3.3" data-path="riassumere-i-dati.html"><a href="riassumere-i-dati.html"><i class="fa fa-check"></i><b>3.3</b> Riassumere i dati</a></li>
<li class="chapter" data-level="3.4" data-path="i-dati-grezzi.html"><a href="i-dati-grezzi.html"><i class="fa fa-check"></i><b>3.4</b> I dati grezzi</a></li>
<li class="chapter" data-level="3.5" data-path="distribuzioni-di-frequenze.html"><a href="distribuzioni-di-frequenze.html"><i class="fa fa-check"></i><b>3.5</b> Distribuzioni di frequenze</a></li>
<li class="chapter" data-level="3.6" data-path="istogramma.html"><a href="istogramma.html"><i class="fa fa-check"></i><b>3.6</b> Istogramma</a></li>
<li class="chapter" data-level="3.7" data-path="kernel-density-plot.html"><a href="kernel-density-plot.html"><i class="fa fa-check"></i><b>3.7</b> Kernel density plot</a></li>
<li class="chapter" data-level="3.8" data-path="forma-di-una-distribuzione.html"><a href="forma-di-una-distribuzione.html"><i class="fa fa-check"></i><b>3.8</b> Forma di una distribuzione</a></li>
<li class="chapter" data-level="3.9" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html"><i class="fa fa-check"></i><b>3.9</b> Indici di posizione</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#quantili"><i class="fa fa-check"></i><b>3.9.1</b> Quantili</a></li>
<li class="chapter" data-level="3.9.2" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#diagramma-a-scatola"><i class="fa fa-check"></i><b>3.9.2</b> Diagramma a scatola</a></li>
<li class="chapter" data-level="3.9.3" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#sina-plot"><i class="fa fa-check"></i><b>3.9.3</b> Sina plot</a></li>
<li class="chapter" data-level="3.9.4" data-path="indici-di-posizione.html"><a href="indici-di-posizione.html#leccellenza-grafica"><i class="fa fa-check"></i><b>3.9.4</b> L’eccellenza grafica</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html"><i class="fa fa-check"></i><b>3.10</b> Indici di tendenza centrale</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#media"><i class="fa fa-check"></i><b>3.10.1</b> Media</a></li>
<li class="chapter" data-level="3.10.2" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#media-spuntata"><i class="fa fa-check"></i><b>3.10.2</b> Media spuntata</a></li>
<li class="chapter" data-level="3.10.3" data-path="indici-di-tendenza-centrale.html"><a href="indici-di-tendenza-centrale.html#moda-e-mediana"><i class="fa fa-check"></i><b>3.10.3</b> Moda e mediana</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html"><i class="fa fa-check"></i><b>3.11</b> Indici di dispersione</a>
<ul>
<li class="chapter" data-level="3.11.1" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#indici-basati-sullordinamento-dei-dati"><i class="fa fa-check"></i><b>3.11.1</b> Indici basati sull’ordinamento dei dati</a></li>
<li class="chapter" data-level="3.11.2" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#varianza"><i class="fa fa-check"></i><b>3.11.2</b> Varianza</a></li>
<li class="chapter" data-level="3.11.3" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#precisione"><i class="fa fa-check"></i><b>3.11.3</b> Precisione</a></li>
<li class="chapter" data-level="3.11.4" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#scarto-tipo"><i class="fa fa-check"></i><b>3.11.4</b> Scarto tipo</a></li>
<li class="chapter" data-level="3.11.5" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#deviazione-mediana-assoluta"><i class="fa fa-check"></i><b>3.11.5</b> Deviazione mediana assoluta</a></li>
<li class="chapter" data-level="3.11.6" data-path="indici-di-dispersione.html"><a href="indici-di-dispersione.html#indici-di-variabilità-relativi"><i class="fa fa-check"></i><b>3.11.6</b> Indici di variabilità relativi</a></li>
</ul></li>
<li class="chapter" data-level="3.12" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html"><i class="fa fa-check"></i><b>3.12</b> Le relazioni tra variabili</a>
<ul>
<li class="chapter" data-level="3.12.1" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#diagramma-a-dispersione"><i class="fa fa-check"></i><b>3.12.1</b> Diagramma a dispersione</a></li>
<li class="chapter" data-level="3.12.2" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#covarianza"><i class="fa fa-check"></i><b>3.12.2</b> Covarianza</a></li>
<li class="chapter" data-level="3.12.3" data-path="le-relazioni-tra-variabili.html"><a href="le-relazioni-tra-variabili.html#correlazione"><i class="fa fa-check"></i><b>3.12.3</b> Correlazione</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html"><i class="fa fa-check"></i><b>3.13</b> Correlazione e causazione</a>
<ul>
<li class="chapter" data-level="3.13.1" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#usi-della-correlazione"><i class="fa fa-check"></i><b>3.13.1</b> Usi della correlazione</a></li>
<li class="chapter" data-level="3.13.2" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#correlazione-di-spearman"><i class="fa fa-check"></i><b>3.13.2</b> Correlazione di Spearman</a></li>
<li class="chapter" data-level="3.13.3" data-path="correlazione-e-causazione.html"><a href="correlazione-e-causazione.html#correlazione-nulla"><i class="fa fa-check"></i><b>3.13.3</b> Correlazione nulla</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive.html"><a href="considerazioni-conclusive.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="part"><span><b>Nozioni di base</b></span></li>
<li class="chapter" data-level="4" data-path="intro-prob-1.html"><a href="intro-prob-1.html"><i class="fa fa-check"></i><b>4</b> Il calcolo delle probabilità</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inf-stat-probl-inv.html"><a href="inf-stat-probl-inv.html"><i class="fa fa-check"></i><b>4.1</b> La probabilità come la logica della scienza</a></li>
<li class="chapter" data-level="4.2" data-path="che-cosè-la-probabilità.html"><a href="che-cosè-la-probabilità.html"><i class="fa fa-check"></i><b>4.2</b> Che cos’è la probabilità?</a></li>
<li class="chapter" data-level="4.3" data-path="variabili-casuali-e-probabilità-di-un-evento.html"><a href="variabili-casuali-e-probabilità-di-un-evento.html"><i class="fa fa-check"></i><b>4.3</b> Variabili casuali e probabilità di un evento</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="variabili-casuali-e-probabilità-di-un-evento.html"><a href="variabili-casuali-e-probabilità-di-un-evento.html#variabili-casuali-1"><i class="fa fa-check"></i><b>4.3.1</b> Variabili casuali</a></li>
<li class="chapter" data-level="4.3.2" data-path="variabili-casuali-e-probabilità-di-un-evento.html"><a href="variabili-casuali-e-probabilità-di-un-evento.html#eventi-e-probabilità"><i class="fa fa-check"></i><b>4.3.2</b> Eventi e probabilità</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="spazio-campionario-e-risultati-possibili.html"><a href="spazio-campionario-e-risultati-possibili.html"><i class="fa fa-check"></i><b>4.4</b> Spazio campionario e risultati possibili</a></li>
<li class="chapter" data-level="4.5" data-path="usare-la-simulazione-per-stimare-le-probabilità.html"><a href="usare-la-simulazione-per-stimare-le-probabilità.html"><i class="fa fa-check"></i><b>4.5</b> Usare la simulazione per stimare le probabilità</a></li>
<li class="chapter" data-level="4.6" data-path="la-legge-dei-grandi-numeri.html"><a href="la-legge-dei-grandi-numeri.html"><i class="fa fa-check"></i><b>4.6</b> La legge dei grandi numeri</a></li>
<li class="chapter" data-level="4.7" data-path="variabili-casuali-multiple.html"><a href="variabili-casuali-multiple.html"><i class="fa fa-check"></i><b>4.7</b> Variabili casuali multiple</a></li>
<li class="chapter" data-level="4.8" data-path="sec:fun-mass-prob.html"><a href="sec:fun-mass-prob.html"><i class="fa fa-check"></i><b>4.8</b> Funzione di massa di probabilità</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-1.html"><a href="considerazioni-conclusive-1.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-prob-cond.html"><a href="chapter-prob-cond.html"><i class="fa fa-check"></i><b>5</b> Probabilità condizionata</a>
<ul>
<li class="chapter" data-level="5.1" data-path="probabilità-condizionata-su-altri-eventi.html"><a href="probabilità-condizionata-su-altri-eventi.html"><i class="fa fa-check"></i><b>5.1</b> Probabilità condizionata su altri eventi</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="probabilità-condizionata-su-altri-eventi.html"><a href="probabilità-condizionata-su-altri-eventi.html#la-fallacia-del-condizionale-trasposto"><i class="fa fa-check"></i><b>5.1.1</b> La fallacia del condizionale trasposto</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="legge-della-probabilità-composta.html"><a href="legge-della-probabilità-composta.html"><i class="fa fa-check"></i><b>5.2</b> Legge della probabilità composta</a></li>
<li class="chapter" data-level="5.3" data-path="lindipendendenza-stocastica.html"><a href="lindipendendenza-stocastica.html"><i class="fa fa-check"></i><b>5.3</b> L’indipendendenza stocastica</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-2.html"><a href="considerazioni-conclusive-2.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapter-teo-bayes.html"><a href="chapter-teo-bayes.html"><i class="fa fa-check"></i><b>6</b> Il teorema di Bayes</a>
<ul>
<li class="chapter" data-level="6.1" data-path="il-teorema-della-probabilità-totale.html"><a href="il-teorema-della-probabilità-totale.html"><i class="fa fa-check"></i><b>6.1</b> Il teorema della probabilità totale</a></li>
<li class="chapter" data-level="6.2" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html"><i class="fa fa-check"></i><b>6.2</b> La regola di Bayes</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html#le-probabilita-come-grado-di-fiducia"><i class="fa fa-check"></i><b>6.2.1</b> Le probabilità come grado di fiducia</a></li>
<li class="chapter" data-level="6.2.2" data-path="la-regola-di-bayes.html"><a href="la-regola-di-bayes.html#aggiornamento-bayesiano"><i class="fa fa-check"></i><b>6.2.2</b> Aggiornamento bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-3.html"><a href="considerazioni-conclusive-3.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapter-prob-congiunta.html"><a href="chapter-prob-congiunta.html"><i class="fa fa-check"></i><b>7</b> Probabilità congiunta</a>
<ul>
<li class="chapter" data-level="7.1" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html"><i class="fa fa-check"></i><b>7.1</b> Funzione di probabilità congiunta</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#proprietà"><i class="fa fa-check"></i><b>7.1.1</b> Proprietà</a></li>
<li class="chapter" data-level="7.1.2" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#eventi"><i class="fa fa-check"></i><b>7.1.2</b> Eventi</a></li>
<li class="chapter" data-level="7.1.3" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#regola-della-catena"><i class="fa fa-check"></i><b>7.1.3</b> Regola della catena</a></li>
<li class="chapter" data-level="7.1.4" data-path="funzione-di-probabilità-congiunta.html"><a href="funzione-di-probabilità-congiunta.html#funzioni-di-probabilità-marginali"><i class="fa fa-check"></i><b>7.1.4</b> Funzioni di probabilità marginali</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="indipendenza-stocastica.html"><a href="indipendenza-stocastica.html"><i class="fa fa-check"></i><b>7.2</b> Indipendenza stocastica</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-4.html"><a href="considerazioni-conclusive-4.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapter-intro-density-function.html"><a href="chapter-intro-density-function.html"><i class="fa fa-check"></i><b>8</b> Funzione di densità di probabilità</a>
<ul>
<li class="chapter" data-level="8.1" data-path="spinner-e-variabili-casuali-continue-uniformi.html"><a href="spinner-e-variabili-casuali-continue-uniformi.html"><i class="fa fa-check"></i><b>8.1</b> Spinner e variabili casuali continue uniformi</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="spinner-e-variabili-casuali-continue-uniformi.html"><a href="spinner-e-variabili-casuali-continue-uniformi.html#il-paradosso-delle-variabili-casuali-continue"><i class="fa fa-check"></i><b>8.1.1</b> Il paradosso delle variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="la-funzione-di-ripartizione-per-una-variabile-casuale-continua.html"><a href="la-funzione-di-ripartizione-per-una-variabile-casuale-continua.html"><i class="fa fa-check"></i><b>8.2</b> La funzione di ripartizione per una variabile casuale continua</a></li>
<li class="chapter" data-level="8.3" data-path="la-distribuzione-uniforme.html"><a href="la-distribuzione-uniforme.html"><i class="fa fa-check"></i><b>8.3</b> La distribuzione uniforme</a></li>
<li class="chapter" data-level="8.4" data-path="la-trasformazione-logit.html"><a href="la-trasformazione-logit.html"><i class="fa fa-check"></i><b>8.4</b> La trasformazione logit</a></li>
<li class="chapter" data-level="8.5" data-path="dagli-istogrammi-alle-densità.html"><a href="dagli-istogrammi-alle-densità.html"><i class="fa fa-check"></i><b>8.5</b> Dagli istogrammi alle densità</a></li>
<li class="chapter" data-level="8.6" data-path="funzione-di-densità-di-probabilità.html"><a href="funzione-di-densità-di-probabilità.html"><i class="fa fa-check"></i><b>8.6</b> Funzione di densità di probabilità</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="exp-val-and-variance-rv.html"><a href="exp-val-and-variance-rv.html"><i class="fa fa-check"></i><b>9</b> Valore atteso e varianza</a>
<ul>
<li class="chapter" data-level="9.1" data-path="valore-atteso.html"><a href="valore-atteso.html"><i class="fa fa-check"></i><b>9.1</b> Valore atteso</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="valore-atteso.html"><a href="valore-atteso.html#interpretazione"><i class="fa fa-check"></i><b>9.1.1</b> Interpretazione</a></li>
<li class="chapter" data-level="9.1.2" data-path="valore-atteso.html"><a href="valore-atteso.html#proprietà-del-valore-atteso"><i class="fa fa-check"></i><b>9.1.2</b> Proprietà del valore atteso</a></li>
<li class="chapter" data-level="9.1.3" data-path="valore-atteso.html"><a href="valore-atteso.html#variabili-casuali-continue"><i class="fa fa-check"></i><b>9.1.3</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="varianza-1.html"><a href="varianza-1.html"><i class="fa fa-check"></i><b>9.2</b> Varianza</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="varianza-1.html"><a href="varianza-1.html#formula-alternativa-per-la-varianza"><i class="fa fa-check"></i><b>9.2.1</b> Formula alternativa per la varianza</a></li>
<li class="chapter" data-level="9.2.2" data-path="varianza-1.html"><a href="varianza-1.html#variabili-casuali-continue-1"><i class="fa fa-check"></i><b>9.2.2</b> Variabili casuali continue</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="deviazione-standard.html"><a href="deviazione-standard.html"><i class="fa fa-check"></i><b>9.3</b> Deviazione standard</a></li>
<li class="chapter" data-level="9.4" data-path="standardizzazione.html"><a href="standardizzazione.html"><i class="fa fa-check"></i><b>9.4</b> Standardizzazione</a></li>
<li class="chapter" data-level="9.5" data-path="momenti-di-variabili-casuali.html"><a href="momenti-di-variabili-casuali.html"><i class="fa fa-check"></i><b>9.5</b> Momenti di variabili casuali</a></li>
<li class="chapter" data-level="9.6" data-path="funzione-di-ripartizione.html"><a href="funzione-di-ripartizione.html"><i class="fa fa-check"></i><b>9.6</b> Funzione di ripartizione</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="distr-rv-discr.html"><a href="distr-rv-discr.html"><i class="fa fa-check"></i><b>10</b> Distribuzioni di v.c. discrete</a>
<ul>
<li class="chapter" data-level="10.1" data-path="una-prova-bernoulliana.html"><a href="una-prova-bernoulliana.html"><i class="fa fa-check"></i><b>10.1</b> Una prova Bernoulliana</a></li>
<li class="chapter" data-level="10.2" data-path="una-sequenza-di-prove-bernoulliane.html"><a href="una-sequenza-di-prove-bernoulliane.html"><i class="fa fa-check"></i><b>10.2</b> Una sequenza di prove Bernoulliane</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="una-sequenza-di-prove-bernoulliane.html"><a href="una-sequenza-di-prove-bernoulliane.html#valore-atteso-e-deviazione-standard"><i class="fa fa-check"></i><b>10.2.1</b> Valore atteso e deviazione standard</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="distribuzione-di-poisson.html"><a href="distribuzione-di-poisson.html"><i class="fa fa-check"></i><b>10.3</b> Distribuzione di Poisson</a></li>
<li class="chapter" data-level="10.4" data-path="alcune-proprietà-della-variabile-di-poisson.html"><a href="alcune-proprietà-della-variabile-di-poisson.html"><i class="fa fa-check"></i><b>10.4</b> Alcune proprietà della variabile di Poisson</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-5.html"><a href="considerazioni-conclusive-5.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="distr-rv-cont.html"><a href="distr-rv-cont.html"><i class="fa fa-check"></i><b>11</b> Distribuzioni di v.c. continue</a>
<ul>
<li class="chapter" data-level="11.1" data-path="distribuzione-normale.html"><a href="distribuzione-normale.html"><i class="fa fa-check"></i><b>11.1</b> Distribuzione Normale</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="distribuzione-normale.html"><a href="distribuzione-normale.html#limite-delle-distribuzioni-binomiali"><i class="fa fa-check"></i><b>11.1.1</b> Limite delle distribuzioni binomiali</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="normal-random-walk.html"><a href="normal-random-walk.html"><i class="fa fa-check"></i><b>11.2</b> La Normale prodotta con una simulazione</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="normal-random-walk.html"><a href="normal-random-walk.html#concentrazione"><i class="fa fa-check"></i><b>11.2.1</b> Concentrazione</a></li>
<li class="chapter" data-level="11.2.2" data-path="normal-random-walk.html"><a href="normal-random-walk.html#funzione-di-ripartizione-1"><i class="fa fa-check"></i><b>11.2.2</b> Funzione di ripartizione</a></li>
<li class="chapter" data-level="11.2.3" data-path="normal-random-walk.html"><a href="normal-random-walk.html#distribuzione-normale-standard"><i class="fa fa-check"></i><b>11.2.3</b> Distribuzione Normale standard</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="teorema-del-limite-centrale.html"><a href="teorema-del-limite-centrale.html"><i class="fa fa-check"></i><b>11.3</b> Teorema del limite centrale</a></li>
<li class="chapter" data-level="11.4" data-path="distribuzione-chi-quadrato.html"><a href="distribuzione-chi-quadrato.html"><i class="fa fa-check"></i><b>11.4</b> Distribuzione Chi-quadrato</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="distribuzione-chi-quadrato.html"><a href="distribuzione-chi-quadrato.html#proprietà-1"><i class="fa fa-check"></i><b>11.4.1</b> Proprietà</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="distribuzione-t-di-student.html"><a href="distribuzione-t-di-student.html"><i class="fa fa-check"></i><b>11.5</b> Distribuzione <span class="math inline">\(t\)</span> di Student</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="distribuzione-t-di-student.html"><a href="distribuzione-t-di-student.html#proprietà-2"><i class="fa fa-check"></i><b>11.5.1</b> Proprietà</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="funzione-beta-di-eulero.html"><a href="funzione-beta-di-eulero.html"><i class="fa fa-check"></i><b>11.6</b> Funzione beta di Eulero</a></li>
<li class="chapter" data-level="11.7" data-path="distribuzione-beta.html"><a href="distribuzione-beta.html"><i class="fa fa-check"></i><b>11.7</b> Distribuzione Beta</a></li>
<li class="chapter" data-level="11.8" data-path="distribuzione-di-cauchy.html"><a href="distribuzione-di-cauchy.html"><i class="fa fa-check"></i><b>11.8</b> Distribuzione di Cauchy</a></li>
<li class="chapter" data-level="11.9" data-path="distribuzione-log-normale.html"><a href="distribuzione-log-normale.html"><i class="fa fa-check"></i><b>11.9</b> Distribuzione log-normale</a></li>
<li class="chapter" data-level="11.10" data-path="distribuzione-di-pareto.html"><a href="distribuzione-di-pareto.html"><i class="fa fa-check"></i><b>11.10</b> Distribuzione di Pareto</a></li>
</ul></li>
<li class="part"><span><b>Inferenza statistica bayesiana</b></span></li>
<li class="chapter" data-level="12" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html"><i class="fa fa-check"></i><b>12</b> Inferenza bayesiana</a>
<ul>
<li class="chapter" data-level="12.1" data-path="modellizzazione-bayesiana.html"><a href="modellizzazione-bayesiana.html"><i class="fa fa-check"></i><b>12.1</b> Modellizzazione bayesiana</a></li>
<li class="chapter" data-level="12.2" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html"><i class="fa fa-check"></i><b>12.2</b> Inferenza bayesiana come un problema inverso</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html#notazione"><i class="fa fa-check"></i><b>12.2.1</b> Notazione</a></li>
<li class="chapter" data-level="12.2.2" data-path="inferenza-bayesiana-come-un-problema-inverso.html"><a href="inferenza-bayesiana-come-un-problema-inverso.html#funzioni-di-probabilità"><i class="fa fa-check"></i><b>12.2.2</b> Funzioni di probabilità</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="la-regola-di-bayes-1.html"><a href="la-regola-di-bayes-1.html"><i class="fa fa-check"></i><b>12.3</b> La regola di Bayes</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="la-regola-di-bayes-1.html"><a href="la-regola-di-bayes-1.html#un-esempio-di-aggiornamento-bayesiano"><i class="fa fa-check"></i><b>12.3.1</b> Un esempio di aggiornamento bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="modello-probabilistico.html"><a href="modello-probabilistico.html"><i class="fa fa-check"></i><b>12.4</b> Modello probabilistico</a></li>
<li class="chapter" data-level="12.5" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html"><i class="fa fa-check"></i><b>12.5</b> Distribuzioni a priori</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#tipologie-di-distribuzioni-a-priori"><i class="fa fa-check"></i><b>12.5.1</b> Tipologie di distribuzioni a priori</a></li>
<li class="chapter" data-level="12.5.2" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#selezione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>12.5.2</b> Selezione della distribuzione a priori</a></li>
<li class="chapter" data-level="12.5.3" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#la-distribuzione-a-priori-per-i-dati-di-zetschefuture2019"><i class="fa fa-check"></i><b>12.5.3</b> La distribuzione a priori per i dati di <span class="citation">Zetsche, Bürkner, and Renneberg (<span>2019</span>)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="verosimiglianza.html"><a href="verosimiglianza.html"><i class="fa fa-check"></i><b>12.6</b> Verosimiglianza</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="verosimiglianza.html"><a href="verosimiglianza.html#la-stima-di-massima-verosimiglianza"><i class="fa fa-check"></i><b>12.6.1</b> La stima di massima verosimiglianza</a></li>
<li class="chapter" data-level="12.6.2" data-path="verosimiglianza.html"><a href="verosimiglianza.html#la-log-verosimiglianza"><i class="fa fa-check"></i><b>12.6.2</b> La log-verosimiglianza</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="sec:const-normaliz-bino23.html"><a href="sec:const-normaliz-bino23.html"><i class="fa fa-check"></i><b>12.7</b> La verosimiglianza marginale</a></li>
<li class="chapter" data-level="12.8" data-path="distribuzione-a-posteriori.html"><a href="distribuzione-a-posteriori.html"><i class="fa fa-check"></i><b>12.8</b> Distribuzione a posteriori</a></li>
<li class="chapter" data-level="12.9" data-path="distribuzione-predittiva-a-priori.html"><a href="distribuzione-predittiva-a-priori.html"><i class="fa fa-check"></i><b>12.9</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="12.10" data-path="distribuzione-predittiva-a-posteriori.html"><a href="distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>12.10</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-6.html"><a href="considerazioni-conclusive-6.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chapter-ppc.html"><a href="chapter-ppc.html"><i class="fa fa-check"></i><b>13</b> Distribuzione predittiva a posteriori</a>
<ul>
<li class="chapter" data-level="13.1" data-path="la-distribuzione-dei-possibili-valori-futuri.html"><a href="la-distribuzione-dei-possibili-valori-futuri.html"><i class="fa fa-check"></i><b>13.1</b> La distribuzione dei possibili valori futuri</a></li>
<li class="chapter" data-level="13.2" data-path="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"><a href="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>13.2</b> Metodi MCMC per la distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="13.3" data-path="posterior-predictive-checks.html"><a href="posterior-predictive-checks.html"><i class="fa fa-check"></i><b>13.3</b> Posterior predictive checks</a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-7.html"><a href="considerazioni-conclusive-7.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="normal-normal-mod-stan.html"><a href="normal-normal-mod-stan.html"><i class="fa fa-check"></i><b>14</b> Modello Normale-Normale</a>
<ul>
<li class="chapter" data-level="14.1" data-path="distribuzione-normale-normale-con-varianza-nota.html"><a href="distribuzione-normale-normale-con-varianza-nota.html"><i class="fa fa-check"></i><b>14.1</b> Distribuzione Normale-Normale con varianza nota</a></li>
<li class="chapter" data-level="14.2" data-path="il-modello-normale-con-stan.html"><a href="il-modello-normale-con-stan.html"><i class="fa fa-check"></i><b>14.2</b> Il modello Normale con Stan</a></li>
<li class="chapter" data-level="14.3" data-path="il-modello-normale-con-quap.html"><a href="il-modello-normale-con-quap.html"><i class="fa fa-check"></i><b>14.3</b> Il modello normale con <code>quap()</code></a></li>
<li class="chapter" data-level="14.4" data-path="il-modello-normale-con-brmsbrm.html"><a href="il-modello-normale-con-brmsbrm.html"><i class="fa fa-check"></i><b>14.4</b> Il modello normale con <code>brms::brm()</code></a></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-8.html"><a href="considerazioni-conclusive-8.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="regr-models-intro.html"><a href="regr-models-intro.html"><i class="fa fa-check"></i><b>15</b> Introduzione al modello lineare</a>
<ul>
<li class="chapter" data-level="15.1" data-path="la-funzione-lineare.html"><a href="la-funzione-lineare.html"><i class="fa fa-check"></i><b>15.1</b> La funzione lineare</a></li>
<li class="chapter" data-level="15.2" data-path="lerrore-di-misurazione.html"><a href="lerrore-di-misurazione.html"><i class="fa fa-check"></i><b>15.2</b> L’errore di misurazione</a></li>
<li class="chapter" data-level="15.3" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html"><i class="fa fa-check"></i><b>15.3</b> Una media per ciascuna osservazione</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html#relazione-lineare-tra-la-media-y-mid-x-e-il-predittore"><i class="fa fa-check"></i><b>15.3.1</b> Relazione lineare tra la media <span class="math inline">\(y \mid x\)</span> e il predittore</a></li>
<li class="chapter" data-level="15.3.2" data-path="una-media-per-ciascuna-osservazione.html"><a href="una-media-per-ciascuna-osservazione.html#il-modello-lineare"><i class="fa fa-check"></i><b>15.3.2</b> Il modello lineare</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="considerazioni-conclusive-9.html"><a href="considerazioni-conclusive-9.html"><i class="fa fa-check"></i>Considerazioni conclusive</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="simbologia-di-base.html"><a href="simbologia-di-base.html"><i class="fa fa-check"></i><b>A</b> Simbologia di base</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="la-distribuzione-dei-possibili-valori-futuri" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> La distribuzione dei possibili valori futuri</h2>
<p>La distribuzione dei possibili valori futuri della variabile di esito può essere predetta da un modello statistico sulla base della distribuzione a posteriori dei parametri, <span class="math inline">\(p(\theta \mid y)\)</span>, avendo già osservato <span class="math inline">\(n\)</span> manifestazioni del fenomeno <span class="math inline">\(y\)</span>. Una tale distribuzione va sotto il nome di <em>distribuzione predittiva a posteriori</em> (<em>posterior predictive distribution</em>, PPD).</p>
<p>Quando vengono simulate le osservazioni della distribuzione predittiva a posteriori si usa la notazione <span class="math inline">\(y^{rep}\)</span> (dove <span class="math inline">\(rep\)</span> sta per <em>replica</em>) quando, nella simulazione, vengono utilizzate le stesse osservazioni di <span class="math inline">\(X\)</span> che erano state usate per stimare i parametri del modello. Si usa invece la notazione <span class="math inline">\(\tilde{y}\)</span> per fare riferimento a possibili valori <span class="math inline">\(X\)</span> che non sono contenuti nel campione osservato, ovvero, ad un campione di dati che potrebbe essere osservato in qualche futura occasione.</p>
<p>La distribuzione predittiva a posteriori viene usata per fare inferenze predittive. L’idea è che, se il modello ben si adatta bene ai dati del campione allora, sulla base dei parametri stimati, dovremmo essere in grado di generare nuovi dati non osservati <span class="math inline">\(y^{rep}\)</span> che risultano molto simili ai dati osservati <span class="math inline">\(y\)</span>. I dati <span class="math inline">\(y^{rep}\)</span> vengono concepiti come stime di <span class="math inline">\(\tilde{y}\)</span>. La distribuzione predittiva a posteriorie è data da:</p>
<p><span class="math display">\[\begin{equation}
p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y}, \theta \mid y) d \theta = \int_{\theta} p(\tilde{y} \mid \theta, y) p(\theta \mid y) d\theta.\notag
\end{equation}\]</span></p>
<p>Supponendo che le osservazioni passate e future siano condizionalmente indipendenti dato <span class="math inline">\(\theta\)</span>, ovvero che <span class="math inline">\(p(\tilde{y} \mid \theta, y) = p(\tilde{y} \mid \theta)\)</span>, possiamo scrivere</p>
<p><span class="math display" id="eq:dist-pred-post">\[\begin{equation}
p(\tilde{y} \mid y) = \int_{\theta} p(\tilde{y} \mid \theta) p(\theta \mid y) d\theta.
\tag{13.1}
\end{equation}\]</span></p>
<p>La <a href="la-distribuzione-dei-possibili-valori-futuri.html#eq:dist-pred-post">(13.1)</a> descrive la nostra incertezza sulla distribuzione di future osservazioni di dati, data la distribuzione a posteriori di <span class="math inline">\(\theta\)</span>, ovvero tenendo conto della scelta del modello e della stima dei parametri mediante i dati osservati. Si noti che, nella <a href="la-distribuzione-dei-possibili-valori-futuri.html#eq:dist-pred-post">(13.1)</a>, <span class="math inline">\(\tilde{y}\)</span> è condizionato da <span class="math inline">\(y\)</span> ma non da ciò che è incognito, ovvero <span class="math inline">\(\theta\)</span>. La distribuzione predittiva a posteriori è invece ottenuta mediante marginalizzazione sopra le variabili da “scartare”, ovvero sopra i parametri incogniti <span class="math inline">\(\theta\)</span>.</p>
<p>Un esempio formulato mediante il codice Stan può chiarire questo concetto.
Consideriamo il codice relativo alla distribuzione predittiva a posteriori nel caso di un modello di regressione lineare classico con un solo predittore <span class="math inline">\(x\)</span>. Il blocco <em>Model</em> sarà:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb73-1" aria-hidden="true" tabindex="-1"></a>model {</span>
<span id="cb73-2"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb73-2" aria-hidden="true" tabindex="-1"></a> y <span class="sc">~</span> <span class="fu">normal</span>(x <span class="sc">*</span> beta <span class="sc">+</span> alpha, sigma);</span>
<span id="cb73-3"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb73-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Quello che è di interesse per la discussione presente è il blocco <em>Generated Quantities</em>. Tale blocco avrà questa forma:</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb74-1" aria-hidden="true" tabindex="-1"></a>generated quantities {</span>
<span id="cb74-2"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb74-2" aria-hidden="true" tabindex="-1"></a> real y_rep[N];</span>
<span id="cb74-3"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb74-3" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span> (n <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N) {</span>
<span id="cb74-4"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb74-4" aria-hidden="true" tabindex="-1"></a>   y_rep[n] <span class="ot">=</span> <span class="fu">normal_rng</span>(x[n] <span class="sc">*</span> beta <span class="sc">+</span> alpha, sigma);</span>
<span id="cb74-5"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb74-5" aria-hidden="true" tabindex="-1"></a> }</span>
<span id="cb74-6"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb74-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>La variabile <code>y_rep</code> è ciò a cui siamo interessati. Nel codice precedente, <code>x</code> è il vettore che contiene i valori della variabile indipendente nel campione di osservazioni esaminato. I parametri del modello di regressione sono <code>alpha</code> e <code>beta</code>; <code>sigma</code> è la stima dell’errore standard della regressione. Supponiamo che questi tre parametri siano degli scalari. Se lo fossero, per il valore <code>x</code> <span class="math inline">\(n\)</span>-esimo, l’istruzione <code>normal_rng()</code> ritornerebbe un valore a caso dalla distribuzione normale con media <span class="math inline">\(\alpha + \beta x_n\)</span> e deviazione standard <span class="math inline">\(\sigma\)</span>. Il ciclo <code>for()</code> ripete questa operazione <span class="math inline">\(N\)</span> volte, ovvero tante volte quanti sono gli elementi del vettore <code>x</code> del campione. Quello che è stato detto sopra ci dà un’idea di quello che succederebbe se <code>alpha</code>, <code>beta</code> e <code>sigma</code> fossero degli scalari. Ma non lo sono. Per ciascuno dei tre paramatri abbiamo un numero molto alto di stime, ovvero l’approssimazione MCMC della distribuzione a posteriori. Poniamo che l’ampiezza campionaria <span class="math inline">\(N\)</span> sia 30. Se <code>alpha</code>, <code>beta</code> e <code>sigma</code> fossero degli scalari, la distribuzione predittiva a posteriori sarebbe costituita da 30 valori <span class="math inline">\(y^{rep}\)</span>, ovvero, non sarebbe nient’altro che <span class="math inline">\(\hat{y} = \hat{\alpha} + \hat{\beta} x\)</span>. Ma <code>alpha</code>, <code>beta</code> e <code>sigma</code> non sono degli scalari: per ciascuno di questi parametri abbiamo un grande numero di stime, diciamo 2000. Dunque, quando <code>normal_rng()</code> estrae un valore a caso dalla distribuzione normale, i parametri della normale non sono fissi: per determinare <span class="math inline">\(\mu\)</span> prendiamo un valore a caso, chiamiamolo <code>beta'</code>, dalla distribuzione dei valori <code>beta</code> e un valore a caso, chiamiamolo <code>alpha'</code>, dalla distribuzione dei valori <code>alpha</code>. Avendo questi due valori, calcoliamo il valore <span class="math inline">\(\mu&#39;_n = \alpha&#39; + \beta&#39; x_n\)</span>. Lo stesso si può dire per <span class="math inline">\(\sigma&#39;\)</span>. A questo punto possiamo trovare il valore <code>y_n'</code> estraendo un valore a caso dalla distribuzione gaussiana di parametri <span class="math inline">\(\mu&#39;\)</span> e <span class="math inline">\(\sigma&#39;\)</span>. Per l’<span class="math inline">\(n\)</span>-esimo valore <span class="math inline">\(x\)</span> possiamo ripetere questo processo tante volte. Se lo ripetiamo, ad esempio, 2,000 volte, per tutti e 30 i valori <span class="math inline">\(x\)</span> del campione otterremo una matrice <span class="math inline">\(30 \times 2,000\)</span>. In questo modo possiamo generare le previsioni del modello, ovvero <span class="math inline">\(y^{rep}\)</span>, che includono due fonti di incertezza:</p>
<ul>
<li>la variabilità campionaria, ovvero il fatto che abbiamo osservato uno specifico insieme di valori <span class="math inline">\((x, y)\)</span>; in un altro campione tali valori saranno diversi;</li>
<li>la variabilità a posteriori della distribuzione dei parametri, ovvero il fatto che di ciascun parametro non conosciamo il “valore vero” ma solo una distribuzione (a posteriori) di valori.</li>
</ul>
<p>Nel caso dell’esempio presente, l’integrale della <a href="la-distribuzione-dei-possibili-valori-futuri.html#eq:dist-pred-post">(13.1)</a> può essere interpretato dicendo che, nell’esempio della matrice di dimensioni <span class="math inline">\(30 \times 2,000\)</span>, noi marginalizziamo rispetto alle colonne, ovvero, per ciascuna riga facciamo la media dei valori colonna. Otteniamo così un vettore di 30 osservazioni, ovvero <span class="math inline">\(y^{rep}\)</span>.</p>
<p>Quando, con metodi grafici, vengono esaminati i valori della distribuzione predittiva a posteriori, possiamo esaminare un numero arbitrario di previsioni. Per esempio, possiamo rappresentare graficamente 50 rette di regressione predette – o un qualsiasi altro numero. Questa rappresentazione grafica quantifica la nostra incertezza a posteriori relativamente (in questo esempio) all’orientamento della retta di regressione.</p>
<div class="exercise">
<p><span id="exr:unlabeled-div-89" class="exercise"><strong>Esercizio 13.1  </strong></span>Illustreremo ora il problema di trovare la distribuzione <span class="math inline">\(p(\tilde{y} \mid y)\)</span> in un caso semplice, ovvero quello dello schema Beta-Binomiale. Nell’esempio, useremo un’altra volta i dati del campione di pazienti clinici depressi di <span class="citation">Zetsche, Bürkner, and Renneberg (<a href="#ref-zetschefuture2019" role="doc-biblioref">2019</a>)</span> – si veda l’Appendice <a href="#es-pratico-zetsche"><strong>??</strong></a>. Supponendo di volere esaminare in futuro altri 30 pazienti clinici, ci chiediamo: quanti di essi manifesteranno una depressione grave?</p>
<p>Se vogliamo fare predizioni su <span class="math inline">\(\tilde{y}\)</span> (il numero di “successi” previsti futuri) dobbiamo innanzitutto riconoscere che i possibili valori <span class="math inline">\(\tilde{y} \in \{0, 1, \dots, 30\}\)</span> non sono tutti egualmente plausibili. Sappiamo che <span class="math inline">\(\tilde{y}\)</span> è una v.c. binomiale con distribuzione</p>
<p><span class="math display" id="eq:post-yprime">\[\begin{equation}
p(\tilde{y}\mid \theta) = \binom{30}{\tilde{y}} \theta^{\tilde{y}}(1-\theta)^{30 - \tilde{y}} \; .
\tag{13.2}
\end{equation}\]</span></p>
<p>La v.c. <span class="math inline">\(\tilde{y}\)</span> dipende da <span class="math inline">\(\theta\)</span>, ma il parametro <span class="math inline">\(\theta\)</span> è esso stesso una variabile casuale. Avendo osservato <span class="math inline">\(y = 23\)</span> successi in <span class="math inline">\(n = 30\)</span> prove nel campione (laddove la presenza di una depressione grave è stata considerata un “successo”), e avendo assunto come distribuzione a priori per <span class="math inline">\(\theta\)</span> una <span class="math inline">\(\mbox{Beta}(2, 10)\)</span> (per continuare con l’esempio precedente), la distribuzione a posteriori di <span class="math inline">\(\theta\)</span> sarà una <span class="math inline">\(\mbox{Beta}(25, 17)\)</span>:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb75-1" aria-hidden="true" tabindex="-1"></a>bayesrules<span class="sc">::</span><span class="fu">summarize_beta_binomial</span>(</span>
<span id="cb75-2"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb75-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">alpha =</span> <span class="dv">2</span>, <span class="at">beta =</span> <span class="dv">10</span>, <span class="at">y =</span> <span class="dv">23</span>, <span class="at">n =</span> <span class="dv">30</span></span>
<span id="cb75-3"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb75-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb75-4"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb75-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       model alpha beta   mean mode      var      sd</span></span>
<span id="cb75-5"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb75-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     prior     2   10 0.1667  0.1 0.010684 0.10336</span></span>
<span id="cb75-6"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb75-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 posterior    25   17 0.5952  0.6 0.005603 0.07485</span></span></code></pre></div>
<p>Per trovare la distribuzione sui possibili dati previsti futuri <span class="math inline">\(\tilde{y}\)</span> dobbiamo applicare la <a href="la-distribuzione-dei-possibili-valori-futuri.html#eq:dist-pred-post">(13.1)</a>:</p>
<p><span class="math display" id="eq:post-yprime-y17">\[\begin{align}
p(\tilde{y} \mid y = 23) = \int_0^1 p(\tilde{y} \mid \theta) p(\theta \mid y = 23) d\theta \; .
\tag{13.3}
\end{align}\]</span></p>
<p>Per il modello Beta-Binomiale è possibile trovare una soluzione analitica alla <a href="la-distribuzione-dei-possibili-valori-futuri.html#eq:dist-pred-post">(13.1)</a>.</p>
<p>Poniamo di avere osservato <span class="math inline">\(y\)</span> successi in <span class="math inline">\(n\)</span> prove e di utilizzare una distribuzione a priori <span class="math inline">\(\mbox{Beta}(a, b)\)</span>. Possiamo scrivere</p>
<p><span class="math display" id="eq:post-yprime-an-sol-betabin">\[\begin{align}
p(\tilde{y} \mid y) &amp;= \int_0^1 p(\tilde{y} \mid \theta)
p(\theta \mid y)\, d\theta \notag\\
&amp;= \int_0^1 \begin{pmatrix}\tilde{n}\\\tilde{y}\end{pmatrix}
\theta^{\tilde{y}}
(1-\theta)^{\tilde{n}-\tilde{y}} \mbox{Beta}(a+y,b+n-y) \, d\theta \notag\\
&amp;= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \int_0^1 \theta^{\tilde{y}}
(1-\theta)^{\tilde{n}-\tilde{y}} \frac{1}{B(a+y, b+n-y)}\theta^{a+y-1}(1-\theta)^{b+n-y-1}\notag\\
&amp;= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \frac{1}{B(a+y, b+n-y)}\int_0^1 \theta^{\tilde{y}+a+y-1}(1-\theta)^{\tilde{n}-\tilde{y}+b+n-y-1}\notag\\
&amp;= \begin{pmatrix}{\tilde{n}}\\\tilde{y}\end{pmatrix} \frac{B(\tilde{y}+a+y,b+n-y+\tilde{n}-\tilde{y})}{B(a+y, b+n-y)} \; .
\tag{13.4}
\end{align}\]</span></p>
<p>Svolgendo i calcoli in <span class="math inline">\(\R\)</span>, per i dati dell’esempio otteniamo:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-1" aria-hidden="true" tabindex="-1"></a>beta_binom <span class="ot">&lt;-</span> <span class="cf">function</span>(rp) {</span>
<span id="cb76-2"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-2" aria-hidden="true" tabindex="-1"></a>  val <span class="ot">&lt;-</span> <span class="fu">choose</span>(np, rp) <span class="sc">*</span></span>
<span id="cb76-3"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">beta</span>(rp <span class="sc">+</span> a <span class="sc">+</span> y, b <span class="sc">+</span> n <span class="sc">-</span> y <span class="sc">+</span> np <span class="sc">-</span> rp) <span class="sc">/</span></span>
<span id="cb76-4"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">beta</span>(a <span class="sc">+</span> y, b <span class="sc">+</span> n <span class="sc">-</span> y)</span>
<span id="cb76-5"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-5" aria-hidden="true" tabindex="-1"></a>  val</span>
<span id="cb76-6"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb76-7"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-8"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-8" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb76-9"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-9" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">23</span></span>
<span id="cb76-10"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-10" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb76-11"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-11" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb76-12"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-12" aria-hidden="true" tabindex="-1"></a>np <span class="ot">&lt;-</span> <span class="dv">30</span></span>
<span id="cb76-13"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-13" aria-hidden="true" tabindex="-1"></a><span class="fu">data.frame</span>(</span>
<span id="cb76-14"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">heads =</span> <span class="dv">0</span><span class="sc">:</span>np,</span>
<span id="cb76-15"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">pmf =</span> <span class="fu">beta_binom</span>(<span class="dv">0</span><span class="sc">:</span>np)</span>
<span id="cb76-16"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-16" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb76-17"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">factor</span>(heads), <span class="at">y =</span> pmf)) <span class="sc">+</span></span>
<span id="cb76-18"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb76-19"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb76-20"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;Distribuzione predittiva a posteriori&quot;</span>,</span>
<span id="cb76-21"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;y&#39;&quot;</span>,</span>
<span id="cb76-22"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;P(Y = y&#39; | Data)&quot;</span></span>
<span id="cb76-23"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb76-23" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-79-1.png" width="2100" style="display: block; margin: auto;" /></p>
<p>
È facile vedere come, in questo esempio, la distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span> sia diversa dalla binomiale di parametro <span class="math inline">\(\theta = 23/30\)</span>:</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb77-2"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">heads =</span> <span class="dv">0</span><span class="sc">:</span>np,</span>
<span id="cb77-3"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">pmf =</span> <span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span>np, <span class="at">size =</span> np, <span class="at">prob =</span> <span class="dv">23</span> <span class="sc">/</span> <span class="dv">30</span>)</span>
<span id="cb77-4"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb77-5"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> <span class="fu">factor</span>(heads), <span class="at">y =</span> pmf)) <span class="sc">+</span></span>
<span id="cb77-6"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb77-7"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb77-8"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">&quot;p(y | theta = 0.77)&quot;</span>,</span>
<span id="cb77-9"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;y&quot;</span>,</span>
<span id="cb77-10"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Probabilità&quot;</span></span>
<span id="cb77-11"><a href="la-distribuzione-dei-possibili-valori-futuri.html#cb77-11" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-80-1.png" width="2100" style="display: block; margin: auto;" /></p>
<p>
In particolare, la <span class="math inline">\(p(\tilde{y} \mid y)\)</span> ha una varianza maggiore di <span class="math inline">\(\Bin(y \mid \theta = 0.77, n = 30)\)</span>. Questa maggiore varianza riflette le due fonti di incertezza che sono presenti nella <a href="la-distribuzione-dei-possibili-valori-futuri.html#eq:dist-pred-post">(13.1)</a>: l’incertezza sul valore del parametro (descritta dalla distribuzione a posteriori) e l’incertezza dovuta alla variabilità campionaria (descritta dalla funzione di verosimiglianza). Possiamo concludere la discussione di questo esempio dicendo che, nel caso di 30 nuovi pazienti clinici, alla luce delle nostre credenze precedenti e dei dati osservati nel campione, ci aspettiamo di osservare 18 pazienti con una depressione severa, anche se è ragionevole aspettarci un numero compreso, diciamo, tra 10 e 25.</p>
<p>Una volta trovata la distribuzione predittiva a posteriori <span class="math inline">\(p(\tilde{y} \mid y)\)</span> diventa possibile rispondere a domande come: qual è la probabilità di depressione grave in almeno 10 dei 30 pazienti futuri? Rispondere a domande di questo tipo è possibile, ma richiede un po’ di lavoro. Tuttavia, non è importante imparare scrivere il codice necessario a risolvere problemi di questo tipo perché, in generale, anche per problemi solo leggermente più complessi di quello discusso qui, non sono disponibili espressioni analitiche della distribuzione predittiva a posteriori. Invece, è possibile trovare una approssimazione numerica della <span class="math inline">\(p(\tilde{y} \mid y)\)</span> mediante simulazioni MCMC. Inoltre, se viene utilizzato un tale metodo, risulta facile rispondere a domande simili a quella che abbiamo presentato sopra.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-zetschefuture2019" class="csl-entry">
Zetsche, Ulrike, Paul-Christian Bürkner, and Babette Renneberg. 2019. <span>“Future Expectations in Clinical Depression: <span>Biased</span> or Realistic?”</span> <em>Journal of Abnormal Psychology</em> 128 (7): 678–88.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-ppc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="metodi-mcmc-per-la-distribuzione-predittiva-a-posteriori.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/ds4psy/edit/master/046_ppc.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ds4psy.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
