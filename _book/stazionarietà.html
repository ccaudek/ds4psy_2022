<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.4 Stazionarietà | Data Science per psicologi</title>
  <meta name="description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="generator" content="bookdown 0.24.4 and GitBook 2.6.7" />

  <meta property="og:title" content="5.4 Stazionarietà | Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="github-repo" content="ccaudek/ds4psy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.4 Stazionarietà | Data Science per psicologi" />
  
  <meta name="twitter:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-01-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter-simulazioneMC.html"/>
<link rel="next" href="commenti-e-considerazioni-finali-3.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science per psicologi</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> mainfont: “Palatino nova W1G”</a>
<ul>
<li class="chapter" data-level="" data-path="la-psicologia-e-la-data-science.html"><a href="la-psicologia-e-la-data-science.html"><i class="fa fa-check"></i>La psicologia e la Data science</a></li>
<li class="chapter" data-level="" data-path="come-studiare.html"><a href="come-studiare.html"><i class="fa fa-check"></i>Come studiare</a></li>
<li class="chapter" data-level="" data-path="sviluppare-un-metodo-di-studio-efficace.html"><a href="sviluppare-un-metodo-di-studio-efficace.html"><i class="fa fa-check"></i>Sviluppare un metodo di studio efficace</a></li>
</ul></li>
<li class="part"><span><b>I Inferenza bayesiana</b></span></li>
<li class="chapter" data-level="2" data-path="ch:intro-bayes-inference.html"><a href="ch:intro-bayes-inference.html"><i class="fa fa-check"></i><b>2</b> Flusso di lavoro bayesiano</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modellizzazione-bayesiana.html"><a href="modellizzazione-bayesiana.html"><i class="fa fa-check"></i><b>2.1</b> Modellizzazione bayesiana</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="modellizzazione-bayesiana.html"><a href="modellizzazione-bayesiana.html#notazione"><i class="fa fa-check"></i><b>2.1.1</b> Notazione</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html"><i class="fa fa-check"></i><b>2.2</b> Distribuzioni a priori</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#tipologie-di-distribuzioni-a-priori"><i class="fa fa-check"></i><b>2.2.1</b> Tipologie di distribuzioni a priori</a></li>
<li class="chapter" data-level="2.2.2" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#selezione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>2.2.2</b> Selezione della distribuzione a priori</a></li>
<li class="chapter" data-level="2.2.3" data-path="distribuzioni-a-priori.html"><a href="distribuzioni-a-priori.html#un-esempio-concreto"><i class="fa fa-check"></i><b>2.2.3</b> Un esempio concreto</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="la-funzione-di-verosimiglianza.html"><a href="la-funzione-di-verosimiglianza.html"><i class="fa fa-check"></i><b>2.3</b> La funzione di verosimiglianza</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="la-funzione-di-verosimiglianza.html"><a href="la-funzione-di-verosimiglianza.html#notazione-1"><i class="fa fa-check"></i><b>2.3.1</b> Notazione</a></li>
<li class="chapter" data-level="2.3.2" data-path="la-funzione-di-verosimiglianza.html"><a href="la-funzione-di-verosimiglianza.html#la-log-verosimiglianza"><i class="fa fa-check"></i><b>2.3.2</b> La log-verosimiglianza</a></li>
<li class="chapter" data-level="2.3.3" data-path="la-funzione-di-verosimiglianza.html"><a href="la-funzione-di-verosimiglianza.html#un-esempio-concreto-1"><i class="fa fa-check"></i><b>2.3.3</b> Un esempio concreto</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sec:const-normaliz-bino23.html"><a href="sec:const-normaliz-bino23.html"><i class="fa fa-check"></i><b>2.4</b> La verosimiglianza marginale</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="sec:const-normaliz-bino23.html"><a href="sec:const-normaliz-bino23.html#un-esempio-concreto-2"><i class="fa fa-check"></i><b>2.4.1</b> Un esempio concreto</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="distribuzione-a-posteriori.html"><a href="distribuzione-a-posteriori.html"><i class="fa fa-check"></i><b>2.5</b> Distribuzione a posteriori</a></li>
<li class="chapter" data-level="2.6" data-path="distribuzione-predittiva-a-priori.html"><a href="distribuzione-predittiva-a-priori.html"><i class="fa fa-check"></i><b>2.6</b> Distribuzione predittiva a priori</a></li>
<li class="chapter" data-level="2.7" data-path="distribuzione-predittiva-a-posteriori.html"><a href="distribuzione-predittiva-a-posteriori.html"><i class="fa fa-check"></i><b>2.7</b> Distribuzione predittiva a posteriori</a></li>
<li class="chapter" data-level="" data-path="commenti-e-considerazioni-finali.html"><a href="commenti-e-considerazioni-finali.html"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-distr-coniugate.html"><a href="chapter-distr-coniugate.html"><i class="fa fa-check"></i><b>3</b> Distribuzioni a priori coniugate</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-distr-priori-coniugate.html"><a href="chapter-distr-priori-coniugate.html"><i class="fa fa-check"></i><b>3.1</b> Lo schema beta-binomiale</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="chapter-distr-priori-coniugate.html"><a href="chapter-distr-priori-coniugate.html#la-specificazione-della-distribuzione-a-priori"><i class="fa fa-check"></i><b>3.1.1</b> La specificazione della distribuzione a priori</a></li>
<li class="chapter" data-level="3.1.2" data-path="chapter-distr-priori-coniugate.html"><a href="chapter-distr-priori-coniugate.html#la-specificazione-della-distribuzione-a-posteriori"><i class="fa fa-check"></i><b>3.1.2</b> La specificazione della distribuzione a posteriori</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="principali-distribuzioni-coniugate.html"><a href="principali-distribuzioni-coniugate.html"><i class="fa fa-check"></i><b>3.2</b> Principali distribuzioni coniugate</a></li>
<li class="chapter" data-level="" data-path="commenti-e-considerazioni-finali-1.html"><a href="commenti-e-considerazioni-finali-1.html"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter-balance.html"><a href="chapter-balance.html"><i class="fa fa-check"></i><b>4</b> L’influenza della distribuzione a priori</a>
<ul>
<li class="chapter" data-level="4.1" data-path="il-test-di-benchdel.html"><a href="il-test-di-benchdel.html"><i class="fa fa-check"></i><b>4.1</b> Il test di Benchdel</a></li>
<li class="chapter" data-level="4.2" data-path="stessi-dati-ma-diverse-distribuzioni-a-priori.html"><a href="stessi-dati-ma-diverse-distribuzioni-a-priori.html"><i class="fa fa-check"></i><b>4.2</b> Stessi dati ma diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="4.3" data-path="dati-diversi-ma-la-stessa-distribuzione-a-priori.html"><a href="dati-diversi-ma-la-stessa-distribuzione-a-priori.html"><i class="fa fa-check"></i><b>4.3</b> Dati diversi ma la stessa distribuzione a priori</a></li>
<li class="chapter" data-level="4.4" data-path="dati-diversi-e-diverse-distribuzioni-a-priori.html"><a href="dati-diversi-e-diverse-distribuzioni-a-priori.html"><i class="fa fa-check"></i><b>4.4</b> Dati diversi e diverse distribuzioni a priori</a></li>
<li class="chapter" data-level="4.5" data-path="collegare-le-intuizioni-alla-teoria.html"><a href="collegare-le-intuizioni-alla-teoria.html"><i class="fa fa-check"></i><b>4.5</b> Collegare le intuizioni alla teoria</a></li>
<li class="chapter" data-level="" data-path="commenti-e-considerazioni-finali-2.html"><a href="commenti-e-considerazioni-finali-2.html"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch:metropolis.html"><a href="ch:metropolis.html"><i class="fa fa-check"></i><b>5</b> Approssimazione della distribuzione a posteriori</a>
<ul>
<li class="chapter" data-level="5.1" data-path="metodo-basato-su-griglia.html"><a href="metodo-basato-su-griglia.html"><i class="fa fa-check"></i><b>5.1</b> Metodo basato su griglia</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="metodo-basato-su-griglia.html"><a href="metodo-basato-su-griglia.html#modello-beta-binomiale"><i class="fa fa-check"></i><b>5.1.1</b> Modello Beta-Binomiale</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="approssimazione-quadratica.html"><a href="approssimazione-quadratica.html"><i class="fa fa-check"></i><b>5.2</b> Approssimazione quadratica</a></li>
<li class="chapter" data-level="5.3" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html"><i class="fa fa-check"></i><b>5.3</b> Metodo Monte Carlo</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#integration-mc"><i class="fa fa-check"></i><b>5.3.1</b> Integrazione di Monte Carlo</a></li>
<li class="chapter" data-level="5.3.2" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#un-esempio-concreto-3"><i class="fa fa-check"></i><b>5.3.2</b> Un esempio concreto</a></li>
<li class="chapter" data-level="5.3.3" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#metodi-mc-basati-su-catena-di-markov"><i class="fa fa-check"></i><b>5.3.3</b> Metodi MC basati su Catena di Markov</a></li>
<li class="chapter" data-level="5.3.4" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#campionamento-mediante-algoritmi-mcmc"><i class="fa fa-check"></i><b>5.3.4</b> Campionamento mediante algoritmi MCMC</a></li>
<li class="chapter" data-level="5.3.5" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#una-passeggiata-casuale-sui-numeri-naturali"><i class="fa fa-check"></i><b>5.3.5</b> Una passeggiata casuale sui numeri naturali</a></li>
<li class="chapter" data-level="5.3.6" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#lalgoritmo-di-metropolis"><i class="fa fa-check"></i><b>5.3.6</b> L’algoritmo di Metropolis</a></li>
<li class="chapter" data-level="5.3.7" data-path="chapter-simulazioneMC.html"><a href="chapter-simulazioneMC.html#un-esempio-concreto-4"><i class="fa fa-check"></i><b>5.3.7</b> Un esempio concreto</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="stazionarietà.html"><a href="stazionarietà.html"><i class="fa fa-check"></i><b>5.4</b> Stazionarietà</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="stazionarietà.html"><a href="stazionarietà.html#approx-post-autocor"><i class="fa fa-check"></i><b>5.4.1</b> Autocorrelazione</a></li>
<li class="chapter" data-level="5.4.2" data-path="stazionarietà.html"><a href="stazionarietà.html#test-di-convergenza"><i class="fa fa-check"></i><b>5.4.2</b> Test di convergenza</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="commenti-e-considerazioni-finali-3.html"><a href="commenti-e-considerazioni-finali-3.html"><i class="fa fa-check"></i>Commenti e considerazioni finali</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="stazionarietà" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Stazionarietà</h2>
<p>Un punto importante da verificare è se il campionatore ha raggiunto la sua distribuzione stazionaria. La convergenza di una catena di Markov alla distribuzione stazionaria viene detta “mixing”.</p>
<div id="approx-post-autocor" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Autocorrelazione</h3>
<p>Informazioni sul “mixing” della catena di Markov sono fornite dall’autocorrelazione. L’autocorrelazione misura la correlazione tra i valori successivi di una catena di Markov. Il valore <span class="math inline">\(m\)</span>-esimo della serie ordinata viene confrontato con un altro valore ritardato di una quantità <span class="math inline">\(k\)</span> (dove <span class="math inline">\(k\)</span> è l’entità del ritardo) per verificare quanto si correli al variare di <span class="math inline">\(k\)</span>. L’autocorrelazione di ordine 1 (<em>lag 1</em>) misura la correlazione tra valori successivi della catena di Markow (cioè, la correlazione tra <span class="math inline">\(\theta^{(m)}\)</span> e <span class="math inline">\(\theta^{(m-1)}\)</span>); l’autocorrelazione di ordine 2 (<em>lag 2</em>) misura la correlazione tra valori della catena di Markow separati da due “passi” (cioè, la correlazione tra <span class="math inline">\(\theta^{(m)}\)</span> e <span class="math inline">\(\theta^{(m-2)}\)</span>); e così via.</p>
<p>L’autocorrelazione di ordine <span class="math inline">\(k\)</span> è data da <span class="math inline">\(\rho_k\)</span> e può essere stimata come:</p>
<p><span class="math display" id="eq:autocor">\[\begin{align}
\rho_k &amp;= \frac{\Cov(\theta_m, \theta_{m+k})}{\Var(\theta_m)}\notag\\
&amp;= \frac{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})(\theta_{m-k} - \bar{\theta})}{\sum_{m=1}^{n-k}(\theta_m - \bar{\theta})^2} \qquad\text{con }\quad \bar{\theta} = \frac{1}{n}\sum_{m=1}^{n}\theta_m.
\tag{5.2}
\end{align}\]</span></p>
<p>Per fare un esempio pratico, simuliamo dei dati autocorrelati con la funzione R <code>colorednoise::colored_noise()</code>:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="stazionarietà.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(<span class="st">&quot;colorednoise&quot;</span>))</span>
<span id="cb31-2"><a href="stazionarietà.html#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">34783859</span>)</span>
<span id="cb31-3"><a href="stazionarietà.html#cb31-3" aria-hidden="true" tabindex="-1"></a>rednoise <span class="ot">&lt;-</span> <span class="fu">colored_noise</span>(</span>
<span id="cb31-4"><a href="stazionarietà.html#cb31-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">timesteps =</span> <span class="dv">30</span>, <span class="at">mean =</span> <span class="fl">0.5</span>, <span class="at">sd =</span> <span class="fl">0.05</span>, <span class="at">phi =</span> <span class="fl">0.3</span></span>
<span id="cb31-5"><a href="stazionarietà.html#cb31-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>L’autocorrelazione di ordine 1 è semplicemente la correlazione tra ciascun elemento e quello successivo nella sequenza. Nell’esempio, il vettore <code>rednoise</code> è una sequenza temporale di 30 elementi. Il vettore <code>rednoise[-length(rednoise)]</code> include gli elementi con gli indici da 1 a 29 nella sequenza originaria, mentre il vettore <code>rednoise[-1]</code> include gli elementi 2:30. Gli elementi delle coppie ordinate dei due vettori avranno dunque gli indici <span class="math inline">\((1, 2), (2, 3), \dots (29, 30)\)</span> degli elementi della sequenza originaria. La correlazione di Pearson tra i vettori <code>rednoise[-length(rednoise)]</code> e <code>rednoise[-1]</code> corrisponde dunque all’autocorrelazione di ordine 1 della serie temporale.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="stazionarietà.html#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(rednoise[<span class="sc">-</span><span class="fu">length</span>(rednoise)], rednoise[<span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb32-2"><a href="stazionarietà.html#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.3967366</span></span></code></pre></div>
<p>Il Correlogramma è uno strumento grafico usato per la valutazione della tendenza di una catena di Markov nel tempo. Il correlogramma si costruisce a partire dall’autocorrelazione <span class="math inline">\(\rho_k\)</span> di una catena di Markov in funzione del ritardo (<em>lag</em>) <span class="math inline">\(k\)</span> con cui l’autocorrelazione è calcolata: nel grafico ogni barretta verticale riporta il valore dell’autocorrelazione (sull’asse delle ordinate) in funzione del ritardo (sull’asse delle ascisse). In <span class="math inline">\(\R\)</span>, il correlogramma può essere prodotto con una chiamata a <code>acf()</code>:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="stazionarietà.html#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(rednoise)</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-26-1.png" width="2100" style="display: block; margin: auto;" /></p>
<p>Il correlogramma precedente mostra come l’autocorrelazione di ordine 1 sia circa pari a 0.4 e diminuisce per lag maggiori; per lag di 4, l’autocorrelazione diventa negativa e aumenta progressivamente fino ad un lag di 8; eccetera.</p>
<p>In situazioni ottimali l’autocorrelazione diminuisce rapidamente ed è effettivamente pari a 0 per piccoli lag. Ciò indica che i valori della catena di Markov che si trovano a più di soli pochi passi di distanza gli uni dagli altri non risultano associati tra loro, il che fornisce conferma del “mixing” della catena di Markov, ossia di convergenza alla distribuzione stazionaria.
Nelle analisi bayesiane, una delle strategie che consentono di ridurre l’autocorrelazione è quella di assottigliare l’output immagazzinando solo ogni <span class="math inline">\(m\)</span>-esimo punto dopo il periodo di burn-in. Una tale strategia va sotto il nome di <em>thinning</em>.</p>
</div>
<div id="test-di-convergenza" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Test di convergenza</h3>
<p>Un test di convergenza può essere svolto in maniera grafica mediante le tracce delle serie temporali (<em>trace plot</em>), cioè il grafico dei valori simulati rispetto al numero di iterazioni. Se la catena è in uno stato stazionario le tracce mostrano assenza di periodicità nel tempo e ampiezza costante, senza tendenze visibili o andamenti degni di nota. Un esempio di <em>trace plot</em> è fornito nella figura <a href="chapter-simulazioneMC.html#fig:sim-markov-chain-zetsche">5.8</a> (destra).</p>
<p>Ci sono inoltre alcuni test che permettono di verificare la stazionarietà del campionatore dopo un dato punto. Uno è il test di Geweke che suddivide il campione, dopo aver rimosso un periodo di burn in, in due parti. Se la catena è in uno stato stazionario, le medie dei due campioni dovrebbero essere uguali. Un test modificato, chiamato Geweke z-score, utilizza un test <span class="math inline">\(z\)</span> per confrontare i due subcampioni ed il risultante test statistico, se ad esempio è più alto di 2, indica che la media della serie sta ancora muovendosi da un punto ad un altro e quindi è necessario un periodo di burn-in più lungo.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-simulazioneMC.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="commenti-e-considerazioni-finali-3.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ccaudek/ds4psy/edit/master/036_posterior_sim.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ds4psy.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
