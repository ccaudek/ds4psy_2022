<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Data Science per psicologi</title>
  <meta name="description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="Data Science per psicologi" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  <meta name="github-repo" content="ccaudek/ds4psy" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data Science per psicologi" />
  
  <meta name="twitter:description" content="This document contains the materials of the lessons of Psicometria B000286 (2021/2022) aimed at students of the first year of the Degree Course in Psychological Sciences and Techniques of the University of Florence, Italy." />
  

<meta name="author" content="Corrado Caudek" />


<meta name="date" content="2022-01-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">Data Science per psicologi</h1>
<p class="author"><em>Corrado Caudek</em></p>
<p class="date"><em>2022-01-19</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#prefazione">Prefazione</a>
<ul>
<li><a href="#la-psicologia-e-la-data-science">La psicologia e la Data science</a></li>
<li><a href="#come-studiare">Come studiare</a></li>
<li><a href="#sviluppare-un-metodo-di-studio-efficace">Sviluppare un metodo di studio efficace</a></li>
</ul></li>
<li><a href="#part-nozioni-preliminari">(PART) Nozioni preliminari</a></li>
<li><a href="#concetti-chiave"><span class="toc-section-number">1</span> Concetti chiave</a>
<ul>
<li><a href="#popolazioni-e-campioni"><span class="toc-section-number">1.1</span> Popolazioni e campioni</a></li>
<li><a href="#variabili-e-costanti"><span class="toc-section-number">1.2</span> Variabili e costanti</a>
<ul>
<li><a href="#variabili-casuali"><span class="toc-section-number">1.2.1</span> Variabili casuali</a></li>
<li><a href="#variabili-indipendenti-e-variabili-dipendenti"><span class="toc-section-number">1.2.2</span> Variabili indipendenti e variabili dipendenti</a></li>
<li><a href="#la-matrice-dei-dati"><span class="toc-section-number">1.2.3</span> La matrice dei dati</a></li>
</ul></li>
<li><a href="#parametri-e-modelli"><span class="toc-section-number">1.3</span> Parametri e modelli</a></li>
<li><a href="#effetto"><span class="toc-section-number">1.4</span> Effetto</a></li>
<li><a href="#stima-e-inferenza"><span class="toc-section-number">1.5</span> Stima e inferenza</a></li>
<li><a href="#metodi-e-procedure-della-psicologia"><span class="toc-section-number">1.6</span> Metodi e procedure della psicologia</a></li>
</ul></li>
<li><a href="#inference-reg-lin-stan"><span class="toc-section-number">2</span> Inferenza sul modello lineare</a>
<ul>
<li><a href="#rappresentazione-grafica-dellincertezza-della-stima"><span class="toc-section-number">2.1</span> Rappresentazione grafica dell’incertezza della stima</a></li>
<li><a href="#intervalli-di-credibilità"><span class="toc-section-number">2.2</span> Intervalli di credibilità</a>
<ul>
<li><a href="#quale-soglia-usare"><span class="toc-section-number">2.2.1</span> Quale soglia usare?</a></li>
</ul></li>
<li><a href="#test-di-ipotesi"><span class="toc-section-number">2.3</span> Test di ipotesi</a></li>
<li><a href="#modello-lineare-robusto"><span class="toc-section-number">2.4</span> Modello lineare robusto</a></li>
<li><a href="#commenti-e-considerazioni-finali">Commenti e considerazioni finali</a></li>
</ul></li>
<li><a href="#bibliografia">Bibliografia</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science per psicologi</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<!-- https://github.com/rstudio/rmarkdown-book -->
<div id="prefazione" class="section level1 unnumbered">
<h1 class="unnumbered">Prefazione</h1>
<p><em>Data Science per psicologi</em> contiene il materiale delle lezioni dell’insegnamento di <em>Psicometria B000286</em> (A.A. 2021/2022) rivolto agli studenti del primo anno del Corso di Laurea in Scienze e Tecniche Psicologiche dell’Università degli Studi di Firenze. <em>Psicometria</em> si propone di fornire agli studenti un’introduzione all’analisi dei dati in psicologia. Le conoscenze/competenze che verranno sviluppate in questo insegnamento sono quelle della Data science, ovvero un insieme di conoscenze/competenze che si pongono all’intersezione tra statistica (ovvero, richiedono la capacità di comprendere teoremi statistici) e informatica (ovvero, richiedono la capacità di sapere utilizzare un software).</p>
<div id="la-psicologia-e-la-data-science" class="section level2 unnumbered">
<h2 class="unnumbered">La psicologia e la Data science</h2>
<p>Sembra sensato spendere due parole su un tema che è importante per gli studenti: quello indicato dal titolo di questo Capitolo. È ovvio che agli studenti di psicologia la statistica non piace. Se piacesse, forse studierebbero Data science e non psicologia; ma non lo fanno. Di conseguenza, gli studenti di psicologia si chiedono: “perché dobbiamo perdere tanto tempo a studiare queste cose quando in realtà quello che ci interessa è tutt’altro?” Questa è una bella domanda.</p>
<p>C’è una ragione molto semplice che dovrebbe farci capire perché la Data science è così importante per la psicologia. Infatti, a ben pensarci, la psicologia è una disciplina intrinsecamente statistica, se per statistica intendiamo quella disciplina che studia la variazione delle caratteristiche degli individui nella popolazione. La psicologia studia <em>gli individui</em> ed è proprio la variabilità inter- e intra-individuale ciò che vogliamo descrivere e, in certi casi, predire. In questo senso, la psicologia è molto diversa dall’ingegneria, per esempio. Le proprietà di un determinato ponte sotto certe condizioni, ad esempio, sono molto simili a quelle di un altro ponte, sotto le medesime condizioni. Quindi, per un ingegnere la statistica è poco importante: le proprietà dei materiali sono unicamente dipendenti dalla loro composizione e restano costanti. Ma lo stesso non può dirsi degli individui: ogni individuo è unico e cambia nel tempo. E le variazioni tra gli individui, e di un individuo nel tempo, sono l’oggetto di studio proprio della psicologia: è dunque chiaro che i problemi che la psicologia si pone sono molto diversi da quelli affrontati, per esempio, dagli ingegneri. Questa è la ragione per cui abbiamo tanto bisogno della Data science in psicologia: perché la Data science ci consente di descrivere la variazione e il cambiamento. E queste sono appunto le caratteristiche di base dei fenomeni psicologici.</p>
<p>Sono sicuro che, leggendo queste righe, a molti studenti sarà venuta in mente la seguente domanda: perché non chiediamo a qualche esperto di fare il “lavoro sporco” (ovvero le analisi statistiche) per noi, mentre noi (gli psicologi) ci occupiamo solo di ciò che ci interessa, ovvero dei problemi psicologici slegati dai dettagli “tecnici” della Data science? La risposta a questa domanda è che non è possibile progettare uno studio psicologico sensato senza avere almeno una comprensione rudimentale della Data science. Le tematiche della Data science non possono essere ignorate né dai ricercatori in psicologia né da coloro che svolgono la professione di psicologo al di fuori dell’Università. Infatti, anche i professionisti al di fuori dall’università non possono fare a meno di leggere la letteratura psicologica più recente: il continuo aggiornamento delle conoscenze è infatti richiesto dalla deontologia della professione. Ma per potere fare questo è necessario conoscere un bel po’ di Data science! Basta aprire a caso una rivista specialistica di psicologia per rendersi conto di quanto ciò sia vero: gli articoli che riportano i risultati delle ricerche psicologiche sono zeppi di analisi statistiche e di modelli formali. E la comprensione della letteratura psicologica rappresenta un requisito minimo nel bagaglio professionale dello psicologo.</p>
<p>Le considerazioni precedenti cercano di chiarire il seguente punto: la Data science non è qualcosa da studiare a malincuore, in un singolo insegnamento universitario, per poi poterla tranquillamente dimenticare. Nel bene e nel male, gli psicologi usano gli strumenti della Data science in tantissimi ambiti della loro attività professionale: in particolare quando costruiscono, somministrano e interpretano i test psicometrici. È dunque chiaro che possedere delle solide basi di Data science è un tassello imprescindibile del bagaglio professionale dello psicologo. In questo insegnamento verrano trattati i temi base della Data science e verrà adottato un punto di vista bayesiano, che corrisponde all’approccio più recente e sempre più diffuso in psicologia.</p>
</div>
<div id="come-studiare" class="section level2 unnumbered">
<h2 class="unnumbered">Come studiare</h2>
<p>Il giusto metodo di studio per prepararsi all’esame di Psicometria è quello di seguire attivamente le lezioni, assimilare i concetti via via che essi vengono presentati e verificare in autonomia le procedure presentate a lezione. Incoraggio gli studenti a farmi domande per chiarire ciò che non è stato capito appieno. Incoraggio gli studenti a utilizzare i forum attivi su Moodle e, soprattutto, a svolgere gli esercizi proposti su Moodle. I problemi forniti su Moodle rappresentano il livello di difficoltà richiesto per superare l’esame e consentono allo studente di comprendere se le competenze sviluppate fino a quel punto sono sufficienti rispetto alle richieste dell’esame.</p>
<p>La prima fase dello studio, che è sicuramente individuale, è quella in cui è necessario acquisire le conoscenze teoriche relative ai problemi che saranno presentati all’esame. La seconda fase di studio, che può essere facilitata da scambi con altri e da incontri di gruppo, porta ad acquisire la capacità di applicare le conoscenze: è necessario capire come usare un software (<span class="math inline">\(\textsf{R}\)</span>) per applicare i concetti statistici alla specifica situazione del problema che si vuole risolvere. Le due fasi non sono però separate: il saper fare molto spesso ci aiuta a capire meglio.</p>
</div>
<div id="sviluppare-un-metodo-di-studio-efficace" class="section level2 unnumbered">
<h2 class="unnumbered">Sviluppare un metodo di studio efficace</h2>
<p>Avendo insegnato molte volte in passato un corso introduttivo di analisi dei dati ho notato nel corso degli anni che gli studenti con l’atteggiamento mentale che descriverò qui sotto generalmente ottengono ottimi risultati. Alcuni studenti sviluppano naturalmente questo approccio allo studio, ma altri hanno bisogno di fare uno sforzo per maturarlo. Fornisco qui sotto una breve descrizione del “metodo di studio” che, nella mia esperienza, è il più efficace per affrontare le richieste di questo insegnamento.</p>
<ul>
<li>Dedicate un tempo sufficiente al materiale di base, apparentemente facile; assicuratevi di averlo capito bene. Cercate le lacune nella vostra comprensione. Leggere presentazioni diverse dello stesso materiale (in libri o articoli diversi) può fornire nuove intuizioni.</li>
<li>Gli errori che facciamo sono i nostri migliori maestri. Istintivamente cerchiamo di dimenticare subito i nostri errori. Ma il miglior modo di imparare è apprendere dagli errori che commettiamo. In questo senso, una soluzione corretta è meno utile di una soluzione sbagliata. Quando commettiamo un errore questo ci fornisce un’informazione importante: ci fa capire qual è il materiale di studio sul quale dobbiamo ritornare e che dobbiamo capire meglio.</li>
<li>C’è ovviamente un aspetto “psicologico” nello studio. Quando un esercizio o problema ci sembra incomprensibile, la cosa migliore da fare è dire: “mi arrendo”, “non ho idea di cosa fare!”. Questo ci rilassa: ci siamo già arresi, quindi non abbiamo niente da perdere, non dobbiamo più preoccuparci. Ma non dobbiamo fermarci qui. Le cose “migliori” che faccio (se ci sono) le faccio quando non ho voglia di lavorare. Alle volte, quando c’è qualcosa che non so fare e non ho idea di come affontare, mi dico: “oggi non ho proprio voglia di fare fatica”, non ho voglia di mettermi nello stato mentale per cui “in 10 minuti devo risolvere il problema perché dopo devo fare altre cose”. Però ho voglia di <em>divertirmi</em> con quel problema e allora mi dedico a qualche aspetto “marginale” del problema, che so come affrontare, oppure considero l’aspetto più difficile del problema, quello che non so come risolvere, ma invece di cercare di risolverlo, guardo come altre persone hanno affrontato problemi simili, opppure lo stesso problema in un altro contesto. Non mi pongo l’obiettivo “risolvi il problema in 10 minuti”, ma invece quello di farmi un’idea “generale” del problema, o quello di capire un caso più specifico e più semplice del problema. Senza nessuna pressione. Infatti, in quel momento ho deciso di non lavorare (ovvero, di non fare fatica). Va benissimo se “parto per la tangente”, ovvero se mi metto a leggere del materiale che sembra avere poco a che fare con il problema centrale (le nostre intuizioni e la nostra curiosità solitamente ci indirizzano sulla strada giusta). Quando faccio così, molto spesso trovo la soluzione del problema che mi ero posto e, paradossalmente, la trovo in un tempo minore di quello che, in precedenza, avevo dedicato a “lavorare” al problema. Allora perché non faccio sempre così? C’è ovviamente l’aspetto dei “10 minuti” che non è sempre facile da dimenticare. Sotto pressione, possiamo solo agire in maniera automatica, ovvero possiamo solo applicare qualcosa che già sappiamo fare. Ma se dobbiamo imparare qualcosa di nuovo, la pressione è un impedimento.</li>
<li>È utile farsi da soli delle domande sugli argomenti trattati, senza limitarsi a cercare di risolvere gli esercizi che vengono assegnati. Quando studio qualcosa mi viene in mente: “se questo è vero, allora deve succedere quest’altra cosa”. Allora verifico se questo è vero, di solito con una simulazione. Se i risultati della simulazione sono quelli che mi aspetto, allora vuol dire che ho capito. Se i risultati sono diversi da quelli che mi aspettavo, allora mi rendo conto di non avere capito e ritorno indietro a studiare con più attenzione la teoria che pensavo di avere capito – e ovviamente mi rendo conto che c’era un aspetto che avevo frainteso. Questo tipo di verifica è qualcosa che dobbiamo fare da soli, in prima persona: nessun altro può fare questo al posto nostro.</li>
<li>Non aspettatevi di capire tutto la prima volta che incontrate un argomento nuovo.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> È utile farsi una nota mentalmente delle lacune nella vostra comprensione e tornare su di esse in seguito per carcare di colmarle. L’atteggiamento naturale, quando non capiamo i dettagli di qualcosa, è quello di pensare: “non importa, ho capito in maniera approssimativa questo punto, non devo preoccuparmi del resto”. Ma in realtà non è vero: se la nostra comprensione è superficiale, quando il problema verrà presentato in una nuova forma, non riusciremo a risolverlo. Per cui i dubbi che ci vengono quando studiamo qualcosa sono il nostro alleato più prezioso: ci dicono esattamente quali sono gli aspetti che dobbiamo approfondire per potere migliorare la nostra preparazione.</li>
<li>È utile sviluppare una visione d’insieme degli argomenti trattati, capire l’obiettivo generale che si vuole raggiungere e avere chiaro il contributo che i vari pezzi di informazione forniscono al raggiungimento di tale obiettivo. Questa organizzazione mentale del materiale di studio facilita la comprensione. È estremamente utile creare degli schemi di ciò che si sta studiando. Non aspettate che sia io a fornirvi un riepilogo di ciò che dovete imparare: sviluppate da soli tali schemi e tali riassunti.</li>
<li>Tutti noi dobbiamo imparare l’arte di trovare le informazioni, non solo nel caso di questo insegnamento. Quando vi trovate di fronte a qualcosa che non capite, o ottenete un oscuro messaggio di errore da un software, ricordatevi: “Google is your friend”!</li>
</ul>

<p class="flushright">
Corrado Caudek<br />
Marzo 2022
</p>
<!--chapter:end:index.Rmd-->
</div>
</div>
<div id="part-nozioni-preliminari" class="section level1 unnumbered">
<h1 class="unnumbered">(PART) Nozioni preliminari</h1>
</div>
<div id="concetti-chiave" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Concetti chiave</h1>
<p>La <em>data science</em> si pone all’intersezione tra statistica e informatica. La statistica è un insieme di metodi ugilizzati per estrarre informazioni dai dati; l’informatica implementa tali procedure in un software. In questo Capitolo vengono introdotti i concetti fondamentali.</p>
<div id="popolazioni-e-campioni" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Popolazioni e campioni</h2>
<p><em>Popolazione.</em> L’analisi dei dati inizia con l’individuazione delle unità portatrici di informazioni circa il fenomeno di interesse. Si dice popolazione (o universo) l’insieme <span class="math inline">\(\Omega\)</span> delle entità capaci di fornire informazioni sul fenomeno oggetto dell’indagine statistica. Possiamo scrivere <span class="math inline">\(\Omega = \{\omega_i\}_{i=1, \dots, n}= \{\omega_1, \omega_2, \dots, \omega_n\}\)</span>, oppure <span class="math inline">\(\Omega = \{\omega_1, \omega_2, \dots \}\)</span> nel caso di popolazioni finite o infinite, rispettivamente.</p>
<p>L’obiettivo principale della ricerca psicologica è conoscere gli esiti psicologici e i loro fattori trainanti nella popolazione. Questo è l’obiettivo delle sperimentazioni psicologiche e della maggior parte degli studi osservazionali in psicologia. È quindi necessario essere molto chiari sulla popolazione a cui si applicano i risultati della ricerca. La popolazione può essere ben definita, ad esempio, tutte le persone che si trovavano nella città di Hiroshima al momento dei bombardamenti atomici e sono sopravvissute al primo anno, o può essere ipotetica, ad esempio, tutte le persone depresse che hanno subito o saranno sottoporsi ad un intervento di psicoterapia. Il ricercatore deve sempre essere in grado di determinare se un soggetto appartiene alla popolazione oggetto di interesse.</p>
<p>Una <em>sottopopolazione</em> è una popolazione in sé e per sé che soddisfa proprietà ben definite. Negli esempi precedenti, potremmo essere interessati alla sottopopolazione di uomini di età inferiore ai 20 anni o di pazienti depressi sottoposti ad uno specifico intervento psicologico. Molte questioni scientifiche riguardano le differenze tra sottopopolazioni; ad esempio, confrontando i gruppi con o senza psicoterapia per determinare se il trattamento è vantaggioso. I modelli di regressione, introdotti nel Capitolo @ref(regr-models-intro) riguardano le sottopopolazioni, in quanto stimano il risultato medio per diversi gruppi (sottopopolazioni) definiti dalle covariate.</p>
<p><em>Campione.</em> Gli elementi <span class="math inline">\(\omega_i\)</span> dell’insieme <span class="math inline">\(\Omega\)</span> sono detti <em>unità statistiche</em>. Un sottoinsieme della popolazione, ovvero un insieme di elementi <span class="math inline">\(\omega_i\)</span>, viene chiamato <em>campione</em>. Ciascuna unità statistica <span class="math inline">\(\omega_i\)</span> (abbreviata con u.s.) è portatrice dell’informazione che verrà rilevata mediante un’operazione di misurazione.</p>
<p>Un campione è dunque un sottoinsieme della popolazione utilizzato per conoscere tale popolazione. A differenza di una sottopopolazione definita in base a chiari criteri, un campione viene generalmente selezionato tramite un procedura casuale. Il <em>campionamento casuale</em> consente allo scienziato di trarre conclusioni sulla popolazione e, soprattutto, di quantificare l’incertezza sui risultati. I campioni di un sondaggio sono esempi di campioni casuali, ma molti studi osservazionali non sono campionati casualmente. Possono essere <em>campioni di convenienza</em>, come coorti di studenti in un unico istituto, che consistono di tutti gli studenti sottoposti ad un certo intervento psicologico in quell’istituto. Indipendentemente da come vengono ottenuti i campioni, il loro uso al fine di conoscere una popolazione target significa che i problemi di rappresentatività sono inevitabili e devono essere affrontati.</p>
</div>
<div id="variabili-e-costanti" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Variabili e costanti</h2>
<p>Definiamo <em>variabile statistica</em> la proprietà (o grandezza) che è
oggetto di studio nell’analisi dei dati. Una variabile è una proprietà
di un fenomeno che può essere espressa in più valori sia numerici sia
categoriali. Il termine “variabile” si contrappone al termine “costante”
che descrive una proprietà invariante di tutte le unità statistiche.</p>
<p>Si dice <em>modalità</em> ciascuna delle varianti con cui una variabile
statistica può presentarsi. Definiamo <em>insieme delle modalità</em> di una
variabile statistica l’insieme <span class="math inline">\(M\)</span> di tutte le possibili espressioni con
cui la variabile può manifestarsi. Le modalità osservate e facenti parte
del campione si chiamano <em>dati</em> (si veda la
Tabella <a href="#tab:term_st_desc" reference-type="ref" reference="tab:term_st_desc">1.1</a>).</p>
<div class="example">
<p><span id="exm:unlabeled-div-1" class="example"><strong>(#exm:unlabeled-div-1) </strong></span>Supponiamo che il fenomeno studiato sia l’intelligenza. In uno studio, la popolazione potrebbe corrispondere all’insieme di tutti gli italiani adulti. La variabile considerata potrebbe essere il punteggio del test standardizzato WAIS-IV. Le modalità di tale variabile potrebbero essere <span class="math inline">\(112, 92, 121, \dots\)</span>. Tale variabile è di tipo quantitativo discreto.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-2" class="example"><strong>(#exm:unlabeled-div-2) </strong></span>Supponiamo che il fenomeno studiato sia il compito Stroop. La popolazione potrebbe corrispondere all’insieme dei bambini dai 6 agli 8 anni. La variabile considerata potrebbe essere il reciproco dei tempi di reazione in secondi. Le modalità di tale variabile potrebbero essere <span class="math inline">\(1 / 2.35, 1/ 1.49, 1/2.93, \dots\)</span>. La variabile è di tipo quantitativo continuo.</p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-3" class="example"><strong>(#exm:unlabeled-div-3) </strong></span>Supponiamo che il fenomeno studiato sia il disturbo di personalità. La popolazione potrebbe corrispondere all’insieme dei detenuti nelle carceri italiane. La variabile considerata potrebbe essere l’assessment del disturbo di personalità tramite interviste cliniche strutturate. Le modalità di tale variabile potrebbero essere i Cluster A, Cluster B, Cluster C descritti dal DSM-V. Tale variabile è di tipo qualitativo.</p>
</div>
<div id="variabili-casuali" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Variabili casuali</h3>
<p>Il termine <em>variabile</em> usato nella statistica è equivalente al termine <em>variabile casuale</em> usato nella teoria delle probabilità. Lo studio dei risultati degli interventi psicologici è lo studio delle variabili casuali che misurano questi risultati. Una variabile casuale cattura una caratteristica specifica degli individui nella popolazione e i suoi valori variano tipicamente tra gli individui. Ogni variabile casuale può assumere in teoria una gamma di valori sebbene, in pratica, osserviamo un valore specifico per ogni individuo. Quando faremo riferiremo alle variabili casuali considerate in termini generali useremo lettere maiuscole come <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>; quando faremo riferimento ai valori che una variabile casuale assume in determinate circostanze useremo lettere minuscole come <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>.</p>
</div>
<div id="variabili-indipendenti-e-variabili-dipendenti" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Variabili indipendenti e variabili dipendenti</h3>
<p>Un primo compito fondamentale in qualsiasi analisi dei dati è l’identificazione delle variabili dipendenti (<span class="math inline">\(Y\)</span>) e delle variabili indipendenti (<span class="math inline">\(X\)</span>). Le variabili dipendenti sono anche chiamate variabili di esito o di risposta e le variabili indipendenti sono anche chiamate predittori o covariate. Ad esempio, nell’analisi di regressione, che esamineremo in seguito, la domanda centrale è quella di capire come <span class="math inline">\(Y\)</span> cambia al variare di <span class="math inline">\(X\)</span>. Più precisamente, la domanda che viene posta è: se il valore della variabile indipendente <span class="math inline">\(X\)</span> cambia, qual è la conseguenza per la variabile dipendente <span class="math inline">\(Y\)</span>? In parole povere, le variabili indipendenti e dipendenti sono analoghe a “cause” ed “effetti”, laddove le virgolette usate qui sottolineano che questa è solo un’analogia e che la determinazione delle cause può avvenire soltanto mediante l’utilizzo di un appropriato disegno sperimentale e di un’adeguata analisi statistica.</p>
<p>Se una variabile è una variabile indipendente o dipendente dipende dalla domanda di ricerca. A volte può essere difficile decidere quale variabile è dipendente e quale è indipendente, in particolare quando siamo specificamente interessati ai rapporti di causa/effetto. Ad esempio, supponiamo di indagare l’associazione tra esercizio fisico e insonnia. Vi sono evidenze che l’esercizio fisico (fatto al momento giusto della giornata) può ridurre l’insonnia. Ma l’insonnia può anche ridurre la capacità di una persona di fare esercizio fisico. In questo caso, dunque, non è facile capire quale sia la causa e quale l’effetto, quale sia la variabile dipendente e quale la variabile indipendente. La possibilità di identificare il ruolo delle variabili (dipendente/indipendente) dipende dalla nostra comprensione del fenomeno in esame.</p>
<div class="example">
<p><span id="exm:unlabeled-div-4" class="example"><strong>(#exm:unlabeled-div-4) </strong></span>Uno psicologo convoca 120 studenti universitari per un test di memoria.
Prima di iniziare l’esperimento, a metà dei soggetti viene detto che si
tratta di un compito particolarmente difficile; agli altri soggetti non
viene data alcuna indicazione. Lo psicologo misura il punteggio nella
prova di memoria di ciascun soggetto.</p>
<p>In questo esperimento, la variabile indipendente è l’informazione sulla difficoltà della prova. La variabile indipendente viene manipolata dallo sperimentatore assegnando i soggetti (di solito in maniera causale) o alla condizione (modalità) “informazione assegnata” o “informazione non data”. La
variabile dipendente è ciò che viene misurato nell’esperimento, ovvero
il punteggio nella prova di memoria di ciascun soggetto.</p>
</div>
</div>
<div id="la-matrice-dei-dati" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> La matrice dei dati</h3>
<p>Le realizzazioni delle variabili esaminate in una rilevazione statistica
vengono organizzate in una <em>matrice dei dati</em>. Le colonne della matrice
dei dati contengono gli insiemi dei dati individuali di ciascuna
variabile statistica considerata. Ogni riga della matrice contiene tutte
le informazioni relative alla stessa unità statistica. Una generica
matrice dei dati ha l’aspetto seguente:</p>
<p><span class="math display">\[
D_{m,n} =
\begin{pmatrix}
  \omega_1 &amp; a_{1}   &amp; b_{1}   &amp; \cdots &amp; x_{1} &amp; y_{1}\\
  \omega_2 &amp; a_{2}   &amp; b_{2}   &amp; \cdots &amp; x_{2} &amp; y_{2}\\
  \vdots   &amp; \vdots  &amp; \vdots  &amp; \ddots &amp; \vdots &amp; \vdots  \\
\omega_n  &amp; a_{n}   &amp; b_{n}   &amp; \cdots &amp; x_{n} &amp; y_{n}
\end{pmatrix}
\]</span></p>
<p>
dove, nel caso presente, la prima colonna contiene il
nome delle unità statistiche, la seconda e la terza colonna si
riferiscono a due mutabili statistiche (variabili categoriali; <span class="math inline">\(A\)</span> e
<span class="math inline">\(B\)</span>) e ne presentano le modalità osservate nel campione mentre le ultime
due colonne si riferiscono a due variabili statistiche (<span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>) e ne
presentano le modalità osservate nel campione. Generalmente, tra le
unità statistiche <span class="math inline">\(\omega_i\)</span> non esiste un ordine progressivo; l’indice
attribuito alle unità statistiche nella matrice dei dati si riferisce
semplicemente alla riga che esse occupano.</p>
</div>
</div>
<div id="parametri-e-modelli" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Parametri e modelli</h2>
<p>Ogni variabile casuale ha una <em>distribuzione</em> che descrive la probabilità che la variabile assuma qualsiasi valore in un dato intervallo.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Senza ulteriori specificazioni, una distribuzione può fare riferimento a un’intera famiglia di distribuzioni. I parametri, tipicamente indicati con lettere greche come <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\alpha\)</span>, ci permettono di specificare di quale membro della famiglia stiamo parlando. Quindi, si può parlare di una variabile casuale con una distribuzione Normale, ma se viene specificata la media <span class="math inline">\(\mu\)</span> = 100 e la varianza <span class="math inline">\(\sigma^2\)</span> = 15, viene individuata una specifica distribuzione Normale – nell’esempio, la distribuzione del quoziente di intelligenza.</p>
<p>I metodi statistici parametrici specificano la famiglia delle distribuzioni e quindi utilizzano i dati per individuare, stimando i parametri, una specifica distribuzione all’interno della famiglia di distribuzioni ipotizzata. Se <span class="math inline">\(f\)</span> è la PDF di una variabile casuale <span class="math inline">\(Y\)</span>, l’interesse può concentrarsi sulla sua media e varianza. Nell’analisi di regressione, ad esempio, cerchiamo di spiegare come i parametri di <span class="math inline">\(f\)</span> dipendano dalle covariate <span class="math inline">\(X\)</span>. Nella regressione lineare classica, assumiamo che <span class="math inline">\(Y\)</span> abbia una distribuzione normale con media <span class="math inline">\(\mu = \E(Y)\)</span>, e stimiamo come <span class="math inline">\(\E(Y)\)</span> dipenda da <span class="math inline">\(X\)</span>. Poiché molti esiti psicologici non seguono una distribuzione normale, verranno introdotte distribuzioni più appropriate per questi risultati. I metodi non parametrici, invece, non specificano una famiglia di distribuzioni per <span class="math inline">\(f\)</span>. In queste dispense faremo riferimento a metodi non parametrici quando discuteremo della statistica descrittiva.</p>
<p>Il termine <em>modello</em> è onnipresente in statistica e nella <em>data science</em>. Il modello statistico include le ipotesi e le specifiche matematiche relative alla distribuzione della variabile casuale di interesse. Il modello dipende dai dati e dalla domanda di ricerca, ma raramente è unico; nella maggior parte dei casi, esiste più di un modello che potrebbe ragionevolmente usato per affrontare la stessa domanda di ricerca e avendo a disposizione i dati osservati. Nella previsione delle aspettative future dei pazienti depressi che discuteremo in seguito <span class="citation">(<a href="#ref-zetschefuture2019" role="doc-biblioref">Zetsche, Bürkner, and Renneberg 2019</a>)</span>, ad esempio, la specifica del modello include l’insieme delle covariate candidate, l’espressione matematica che collega i predittori con le aspattative future e qualsiasi ipotesi sulla distribuzione della variabile dipendente. La domanda di cosa costituisca un buon modello è una domanda su cui torneremo ripetutamente in questo insegnamento.</p>
</div>
<div id="effetto" class="section level2" number="1.4">
<h2><span class="header-section-number">1.4</span> Effetto</h2>
<p>L’<em>effetto</em> è una qualche misura dei dati. Dipende dal tipo di dati e dal tipo di test statistico che si vuole utilizzare. Ad esempio, se viene lanciata una moneta 100 volte e esce testa 66 volte, l’effetto sarà 66/100. Diventa poi possibile confrontare l’effetto ottenuto con l’effetto nullo che ci si aspetterebbe da una moneta bilanciata (50/100), o con qualsiasi altro effetto che può essere scelto. La <em>dimensione dell’effetto</em> si riferisce alla differenza tra l’effetto misurato nei dati e l’effetto nullo (di solito un valore che ci si aspetta di ottenere in base al caso soltanto).</p>
</div>
<div id="stima-e-inferenza" class="section level2" number="1.5">
<h2><span class="header-section-number">1.5</span> Stima e inferenza</h2>
<p>La stima è il processo mediante il quale il campione viene utilizzato per conoscere le proprietà di interesse della popolazione. La media campionaria è una stima naturale della media della popolazione e la mediana campionaria è una stima naturale della mediana della popolazione. Quando parliamo di stimare una proprietà della popolazione (a volte indicata come parametro della popolazione) o di stimare la distribuzione di una variabile casuale, stiamo parlando dell’utilizzo dei dati osservati per conoscere le proprietà di interesse della popolazione. L’inferenza statistica è il processo mediante il quale le stime campionarie vengono utilizzate per rispondere a domande di ricerca e per valutare specifiche ipotesi relative alla popolazione. Discuteremo le procedure bayesiane dell’inferenza nell’ultima parte di queste dispense.</p>
</div>
<div id="metodi-e-procedure-della-psicologia" class="section level2" number="1.6">
<h2><span class="header-section-number">1.6</span> Metodi e procedure della psicologia</h2>
<p>Un modello psicologico di un qualche aspetto del comportamento umano o della mente ha le seguenti proprietà:</p>
<ol style="list-style-type: decimal">
<li>descrive le caratteristiche del comportamento in questione,</li>
<li>formula predizioni sulle caratteristiche future del comportamento,</li>
<li>è sostenuto da evidenze empiriche,</li>
<li>deve essere falsificabile (ovvero, in linea di principio, deve
potere fare delle predizioni su aspetti del fenomeno considerato che
non sono ancora noti e che, se venissero indagati, potrebbero
portare a rigettare il modello, se si dimostrassero incompatibili con
esso).</li>
</ol>
<p>
L’analisi dei dati valuta un modello psicologico utilizzando strumenti statistici.</p>
<p>Questa dispensa è strutturata in maniera tale da rispecchiare la suddivisione tra i temi della misurazione, dell’analisi descrittiva e dell’inferenza. Nel prossimo Capitolo sarà affrontato il tema della misurazione e, nell’ultima parte della dispensa verrà discusso l’argomento più difficile, quello dell’inferenza. Prima di affrontare il secondo tema, l’analisi descrittiva dei dati, sarà necessario introdurre il linguaggio di programmazione statistica R (un’introduzione a R è fornita in Appendice). Inoltre, prima di potere discutere l’inferenza, dovranno essere introdotti i concetti di base della teoria delle probabilità, in quanto l’inferenza non è che l’applicazione della teoria delle probabilità all’analisi dei dati.</p>
<!--chapter:end:001_key_notions.Rmd-->
</div>
</div>
<div id="inference-reg-lin-stan" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Inferenza sul modello lineare</h1>
<div id="rappresentazione-grafica-dellincertezza-della-stima" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Rappresentazione grafica dell’incertezza della stima</h2>
<p>Un primo modo per rappresentare l’incertezza dell’inferenza in un ottica bayesiana è quella di rappresentare graficamente la retta specificata dal modello lineare. Continuando con l’esempio descritto nel Capitolo precedente (ovvero, i dati <code>kid_score</code> e <code>mom_iq</code> centrati), usando la funzione <code>rstan::read_stan_csv</code> leggiamo i file CSV generati da <code>cmdstan</code> e trasformiamo le stime a posteriori dei parametri in formato <code>stanfit</code>:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>stanfit <span class="ot">&lt;-</span> rstan<span class="sc">::</span><span class="fu">read_stan_csv</span>(fit2<span class="sc">$</span><span class="fu">output_files</span>())</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">extract</span>(stanfit)</span></code></pre></div>
<p>Creiamo ora un diagramma a dispersione dei dati con sovrapposto il valore atteso della <span class="math inline">\(y\)</span>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">kid_score =</span> df<span class="sc">$</span>kid_score,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">mom_iq =</span> df<span class="sc">$</span>mom_iq <span class="sc">-</span> <span class="fu">mean</span>(df<span class="sc">$</span>mom_iq)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(mom_iq, kid_score)) <span class="sc">+</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">intercept =</span> <span class="fu">mean</span>(posterior<span class="sc">$</span>alpha),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">slope =</span> <span class="fu">mean</span>(posterior<span class="sc">$</span>beta)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-4-1.png" width="2100" style="display: block; margin: auto;" /></p>
<p>Un modo per visualizzare l’incertezza della stima della retta specifiata dal modello lineare è quello di tracciare molteplici rette, ciascuna delle quali definita da una diversa stima dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>; le diverse stime dei parametri <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> vengono estratta a caso dalle rispettive distribuzioni a posteriori.</p>
<p>Per ottenere questo risultato dobbiamo estrarre le informazioni richieste dall’oggetto <code>stanfit</code> che abbiamo creato. Per fare questo usiamo le funzionalità di <code>tidybayes</code>. Per esempio</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>tidybayes<span class="sc">::</span><span class="fu">get_variables</span>(stanfit)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;alpha_std&quot;     &quot;beta_std&quot;      &quot;sigma_std&quot;    </span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [4] &quot;alpha&quot;         &quot;beta&quot;          &quot;sigma&quot;        </span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [7] &quot;lp__&quot;          &quot;accept_stat__&quot; &quot;treedepth__&quot;  </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [10] &quot;stepsize__&quot;    &quot;divergent__&quot;   &quot;n_leapfrog__&quot; </span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [13] &quot;energy__&quot;</span></span></code></pre></div>
<p>Creiamo un Dataframe in formato tidy che contiene le stime a posteriori di <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> nel modo seguente:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>draws <span class="ot">&lt;-</span> stanfit <span class="sc">%&gt;%</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">spread_draws</span>(beta, alpha)</span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>draws <span class="sc">%&gt;%</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">head</span>(<span class="dv">10</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 10 × 5</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   .chain .iteration .draw  beta alpha</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    &lt;int&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1      1          1     1 0.632  88.4</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2      1          2     2 0.491  87.5</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3      1          3     3 0.717  85.9</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4      1          4     4 0.478  87.5</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5      1          5     5 0.610  86.4</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6      1          6     6 0.570  86.7</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 7      1          7     7 0.623  87.0</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 8      1          8     8 0.616  87.2</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 2 more rows</span></span></code></pre></div>
<p>Possiamo ora generare il diagramma a dispersione con <code>ggplot()</code>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">kid_score =</span> df<span class="sc">$</span>kid_score,</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">mom_iq =</span> df<span class="sc">$</span>mom_iq <span class="sc">-</span> <span class="fu">mean</span>(df<span class="sc">$</span>mom_iq)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(mom_iq, kid_score)) <span class="sc">+</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> draws, <span class="fu">aes</span>(<span class="at">intercept =</span> alpha, <span class="at">slope =</span> beta),</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">0.2</span>, <span class="at">alpha =</span> <span class="fl">0.01</span>, <span class="at">color =</span> <span class="st">&quot;darkgray&quot;</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">intercept =</span> <span class="fu">mean</span>(posterior<span class="sc">$</span>alpha),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">slope =</span> <span class="fu">mean</span>(posterior<span class="sc">$</span>beta)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">&quot;Quoziente di intelligenza della madre&quot;</span>,</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">&quot;Quoziente di intelligenza del bambino&quot;</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-8-1.png" width="2100" style="display: block; margin: auto;" /></p>
<p>Il grafico indica che le rette di regressione costruite estraendo a caso valori dalla distribuzione a posteriori dei parametri <span class="math inline">\(\beta_0\)</span> e <span class="math inline">\(\beta_1\)</span> tendono ad essere molto simili tra loro. Ciò significa che, relativamente alla dipendenza (lineare) del quoziente di intelligenza del bambino da quello della madra, l’incertezza è piccola (ovvero, la certezza è alta).</p>
</div>
<div id="intervalli-di-credibilità" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Intervalli di credibilità</h2>
<p>L’incertezza inferenziale sui parametri può anche essere rappresentata mediante gli <em>intervalli di credibilità</em>, ovvero gli intervalli che contengono la quota desiderata (es., il 95%) della distribuzione a posteriori. Per l’esempio che stiamo discutendo, gli intervalli di credibilità al 95% si ottengono nel modo seguente:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>rstantools<span class="sc">::</span><span class="fu">posterior_interval</span>(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>(stanfit), </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> <span class="fl">0.95</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                 2.5%      97.5%</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alpha_std   -0.08427    0.08442</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; beta_std     0.36137    0.53165</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sigma_std    0.83903    0.96033</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alpha       85.07713   88.52021</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; beta         0.49172    0.72343</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sigma       17.12519   19.60111</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lp__      -173.15908 -168.54400</span></span></code></pre></div>
<p>Un grafico che, nel caso dei dati standardizzati, riporta l’intervallo di credibilità ai livelli di probabilità desiderati per i parametri <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> e <span class="math inline">\(\sigma\)</span> si ottiene con l’istruzione</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  fit2<span class="sc">$</span><span class="fu">draws</span>(<span class="fu">c</span>(<span class="st">&quot;alpha_std&quot;</span>, <span class="st">&quot;beta_std&quot;</span>, <span class="st">&quot;sigma_std&quot;</span>)),</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> <span class="fl">0.8</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob_outer =</span> <span class="fl">0.95</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-10-1.png" width="2100" style="display: block; margin: auto;" /></p>
<p>oppure nel modo nel modo seguente</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>stanfit <span class="sc">%&gt;%</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mcmc_intervals</span>(</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;alpha_std&quot;</span>, <span class="st">&quot;beta_std&quot;</span>, <span class="st">&quot;sigma_std&quot;</span>),</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob =</span> <span class="fl">0.8</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">prob_outer =</span> <span class="fl">0.95</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-11-1.png" width="2100" style="display: block; margin: auto;" /></p>
<div id="quale-soglia-usare" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Quale soglia usare?</h3>
<p>Non c’è niente di “magico” o necessario relativamente al livello di 0.95: il valore 0.95 è arbitrario. Sono possibili tantissime altre soglie per quantificare la nostra incertezza: alcuni ricercatori usano il livello di 0.89, altri quello di 0.5. Se l’obiettivo è quello di descrivere il livello della nostra incertezza relativamente alla stima del parametro, allora dobbiamo riconoscere che la nostra incertezza è descritta dall’<em>intera</em> distribuzione a posteriori. Per cui il metodo più semplice, più diretto e più completo per descrivere la nostra incertezza rispetto alla stima dei parametri è semplicemente quello di riportare graficamente <em>tutta</em> la distribuzione a posteriori. Una rappresentazione della distribuzione a posteriori dei parametri del modello dell’esempio si ottiene nel modo seguente:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>rstan<span class="sc">::</span><span class="fu">stan_dens</span>(</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  stanfit,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;sigma&quot;</span>),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">fill =</span> <span class="st">&quot;lightgray&quot;</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="ds4psy_files/figure-html/unnamed-chunk-12-1.png" width="2100" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="test-di-ipotesi" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Test di ipotesi</h2>
<p>È facile valutare ipotesi direzionali usando Stan. Per esempio, la probabilità <span class="math inline">\(Pr(\hat{\beta}_1 &gt; 0)\)</span> è</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(posterior<span class="sc">$</span>beta <span class="sc">&gt;</span> <span class="dv">0</span>) <span class="sc">/</span> <span class="fu">length</span>(posterior<span class="sc">$</span>beta)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span></code></pre></div>
<p>ovvero, la probabilità <span class="math inline">\(Pr(\hat{\beta}_1 &lt; 0)\)</span> è</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(posterior<span class="sc">$</span>beta <span class="sc">&lt;</span> <span class="dv">0</span>) <span class="sc">/</span> <span class="fu">length</span>(posterior<span class="sc">$</span>beta)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0</span></span></code></pre></div>
</div>
<div id="modello-lineare-robusto" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Modello lineare robusto</h2>
<p>Spesso i ricercatori devono affrontare il problema degli outlier: in presenza di outlier, un modello statistico basato sulla distribuzione gaussiana produrrà delle stime distorte dei parametri, ovvero stime che non si generalizzano ad altri campioni di dati. Il metodo tradizionale per affrontare questo problema è quello di eliminare gli outlier prima di eseguire l’analisi statistica. Il problema di questo approccio, però, è che il criterio utilizzato per eliminare gli outlier, quale esso sia, è arbitrario; dunque, usando criteri diversi per la rimozione di outlier, i ricercatori finiscono per trovare risultati diversi.</p>
<p>Questo problema trova una semplice soluzione nell’approccio bayesiano. Il modello lineare che abbiamo dicusso finora ipotizza una specifica distribuzione degli errori, ovvero <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma_{\varepsilon})\)</span>. In un modello formulato in questi termini, la presenza di solo un valore anomalo e influente ha un effetto drammatico sulle stime dei parametri.</p>
<p>Per fare un esempio, introduciamo un singlo valore anomalo e influente nel set dei dati dell’esempio che stiamo discutendo:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>df2 <span class="ot">&lt;-</span> df</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df2<span class="sc">$</span>kid_score[<span class="dv">434</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">500</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>df2<span class="sc">$</span>mom_iq[<span class="dv">434</span>] <span class="ot">&lt;-</span> <span class="dv">140</span></span></code></pre></div>
<p>Per comodità, calcoliamo le stime di <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> con il metodo dei minimi quadrati (tali stime sono simili a quelle che si otterrebbero con un modello bayesiano gaussiano che impiega distribuzioni a priori debolmente informative). Sappiamo che, nel campione originale di dati, <span class="math inline">\(\hat{\beta} \approx 0.6\)</span>. In presenza di un solo outlier troviamo la stima di <span class="math inline">\(\beta\)</span> viene drammaticamente ridotta:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(kid_score <span class="sc">~</span> mom_iq, <span class="at">data =</span> df2) <span class="sc">%&gt;%</span> </span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coef</span>() </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)      mom_iq </span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     49.1880      0.3626</span></span></code></pre></div>
<p>In generale, però, non è necessario assumere <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma_{\varepsilon})\)</span>. È altrettanto valido un modello che ipotizza una diversa distribuzione di densità per gli errori come, ad esempio, la distribuzione <span class="math inline">\(t\)</span> di Student con un piccolo numero di gradi di libertà. Una caratteristica della <span class="math inline">\(t\)</span> di Student è che le code della distribuzione contengono una massa di probabilità maggiore della distribuzione gaussiana. Ciò fornisce alla <span class="math inline">\(t\)</span> di Student la possibilità di “rendere conto” della presenza di osservazioni lontane dalla media della distribuzione. In altri termini, se in modello lineare usiamo la <span class="math inline">\(t\)</span> di Student quale distribuzione degli errori, la presenza di outlier avrà una minore influenza sulle stime dei parametri di quanto avvenga nel tradizionale modello lineare gaussiano.</p>
<p>Per verificare questa affermazione, modifichiamo il codice Stan usato in precedenza in modo tale da ipotizzare che <span class="math inline">\(y\)</span> segua una distribuzione <span class="math inline">\(t\)</span> di Student con un numero <span class="math inline">\(\nu\)</span> gradi di libertà stimato dal modello: <code>student_t(nu, mu, sigma)</code>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>modelString <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; N;</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y;</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x;</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="st">transformed data {</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] x_std;</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="st">  vector[N] y_std;</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="st">  x_std = (x - mean(x)) / sd(x);</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="st">  y_std = (y - mean(y)) / sd(y);</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha_std;</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta_std;</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma_std;</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=1&gt; nu;    // degrees of freedom is constrained &gt;1</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha_std ~ normal(0, 1);</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="st">  beta_std ~ normal(0, 1);</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma_std ~ normal(0, 1);</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="st">  nu ~ gamma(2, 0.1);   // Juárez and Steel(2010)</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="st">  y_std ~ student_t(nu, alpha_std + beta_std * x_std, sigma_std);</span></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="st">generated quantities {</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="st">  real alpha;</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="st">  real beta;</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="st">  real&lt;lower=0&gt; sigma;</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="st">  alpha = sd(y) * (alpha_std - beta_std * mean(x) / sd(x))</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="st">           + mean(y);</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="st">  beta = beta_std * sd(y) / sd(x);</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma = sd(y) * sigma_std;</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a><span class="fu">writeLines</span>(modelString, <span class="at">con =</span> <span class="st">&quot;code/simpleregstdrobust.stan&quot;</span>)</span></code></pre></div>
<p>Costruiamo la lista dei dati usando il data.frame <code>df2</code> che include l’outlier:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>data3_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">N =</span> <span class="fu">length</span>(df2<span class="sc">$</span>kid_score),</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> df2<span class="sc">$</span>kid_score,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> df2<span class="sc">$</span>mom_iq <span class="sc">-</span> <span class="fu">mean</span>(df2<span class="sc">$</span>mom_iq)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Adattiamo il modello lineare robusto ai dati:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>file <span class="ot">&lt;-</span> <span class="fu">file.path</span>(<span class="st">&quot;code&quot;</span>, <span class="st">&quot;simpleregstdrobust.stan&quot;</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">cmdstan_model</span>(file)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>fit4 <span class="ot">&lt;-</span> mod<span class="sc">$</span><span class="fu">sample</span>(</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> data3_list,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_sampling =</span> 4000L,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">iter_warmup =</span> 2000L,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">seed =</span> SEED,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">chains =</span> 4L,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">parallel_chains =</span> 2L,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">refresh =</span> <span class="dv">0</span>,</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">thin =</span> <span class="dv">1</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Se esaminiamo le stime dei parametri notiamo che la stima di <span class="math inline">\(\beta\)</span> non è stata influenzata dalla presenza di un’osservazione anomala e influente:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>fit4<span class="sc">$</span><span class="fu">summary</span>(<span class="fu">c</span>(<span class="st">&quot;alpha&quot;</span>, <span class="st">&quot;beta&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;nu&quot;</span>))</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # A tibble: 4 × 10</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   variable   mean median     sd    mad     q5    q95</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 alpha    87.8   87.8   0.901  0.898  86.3   89.3  </span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 beta      0.602  0.602 0.0589 0.0587  0.505  0.699</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 sigma    15.9   15.9   0.800  0.803  14.6   17.2  </span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 nu        5.58   5.46  1.15   1.09    3.93   7.64 </span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; # … with 3 more variables: rhat &lt;dbl&gt;, ess_bulk &lt;dbl&gt;,</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; #   ess_tail &lt;dbl&gt;</span></span></code></pre></div>
<p>Il modello lineare robusto non risente dunque della presenza di outlier.</p>
</div>
<div id="commenti-e-considerazioni-finali" class="section level2 unnumbered">
<h2 class="unnumbered">Commenti e considerazioni finali</h2>
<p>Nell’approccio bayesiano possiamo rappresentare l’incertezza delle nostre credenze a posteriori in due modi: mediante la rappresentazione grafica dell’intera distribuzione a posteriori dei parametri o mediante l’uso degli intervalli di credibilità. Un bonus della discussione del presente Capitolo è quello di mostrare come il modello lineare tradizionale (che assume <span class="math inline">\(\varepsilon \sim \mathcal{N}(0, \sigma_{\varepsilon})\)</span>) possa essere facilmente esteso nei termini di un modello robusto che offre una semplice soluzione al problema di ridurre l’effetto della presenza di osservazioni outlier.</p>
<!--chapter:end:054_reglin4.Rmd-->
</div>
</div>
<div id="bibliografia" class="section level1 unnumbered">
<h1 class="unnumbered">Bibliografia</h1>
<!--chapter:end:999_references.Rmd-->
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-horn2021underestimating" class="csl-entry">
Horn, Samantha, and George Loewenstein. 2021. <span>“Underestimating Learning by Doing.”</span> <em>Available at SSRN 3941441</em>.
</div>
<div id="ref-zetschefuture2019" class="csl-entry">
Zetsche, Ulrike, Paul-Christian Bürkner, and Babette Renneberg. 2019. <span>“Future Expectations in Clinical Depression: <span>Biased</span> or Realistic?”</span> <em>Journal of Abnormal Psychology</em> 128 (7): 678–88.
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Ricordatevi inoltre che gli individui tendono a sottostimare la propria capacità di apprendere <span class="citation">(<a href="#ref-horn2021underestimating" role="doc-biblioref">Horn and Loewenstein 2021</a>)</span>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>In questo e nei successivi Paragrafi di questo Capitolo introduco gli obiettivi della <em>data science</em> utilizzando una serie di concetti che saranno chiariti solo in seguito. Questa breve panoramica risulterà dunque solo in parte comprensibile ad una prima lettura e serve solo per definire la <em>big picture</em> dei temi trattati in questo insegnamento. Il significato dei termini qui utilizzati sarà chiarito nei Capitoli successivi.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>È equivalente scrivere <span class="math inline">\(y_i = \mu_i + \varepsilon_i\)</span>, dove <span class="math inline">\(\mu_i = \alpha + \beta x_i, \varepsilon_i \sim \mathcal{N}(0, \sigma_\varepsilon),\)</span> oppure <span class="math inline">\(y_i \sim \mathcal{N}(\mu_i, \sigma_\varepsilon).\)</span><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
